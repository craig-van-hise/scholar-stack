Title,Authors,Original_Filename,Publication_Date,Category,Description,Is_Paywalled,Is_Downloaded,Source_URL,DOI,_Source
"IEEE Transactions on Audio, Speech, and Language Processing Edics",Unknown Authors,06558818.pdf,2013/01/01,Unsorted,"Transducer modeling and design Transducer calibration and compensation Novel transducers AUD-LMAP Loudspeaker and Microphone Array Signal Processing Far-field and near-field beamforming and array processing Source localization and tracking Time-delay estimation Audio enhancement using transducer arrays Wavefield synthesis Sound field analysis and synthesis AUD-ANCO Active Noise Control Acoustic noise cancellation and suppression Adaptive techniques for feedforward control Feedback control algorithms Multichannel systems AUD-ECHO Echo CancellationSingle-channel and multichannel acoustic echo cancellation Echo path estimation and modeling Echo suppression and dereverberation Double-talk detection Adaptive filter theory for audio applications AUD-AUDI Auditory Modeling and Hearing AidsHuman audition and psychoacoustics Computational auditory scene analysis Perceptual and psychophysical models of audio algorithms and systems Perceptual measures of audio quality Aids for the handicapped (cochlear implants, hearing aids) Binaural hearing AUD-SSEN Audio Source Separation and EnhancementSingle-channel and multichannel source separation Blind deconvolution Noise reduction, compensation, and equalization Audio denoising and restoration AUD-SMCA Spatial and Multichannel AudioSpatial sound analysis and reproduction Spatialization and virtualization Measurement, modeling, and use of head-related transfer functions Crosstalk cancellation and binaural synthesis Artificial reverberation algorithms AUD-ACOD Audio CodingLow bit-rate and high-quality audio coding Scalable and lossless audio coding Spatial audio coding Joint source-channel coding Signal representations for coding Parametric and structured audio coding Psychoacoustic models for coding Objective and subjective quality assessment Error detection, correction, and concealment AUD-ANSY Audio Analysis and SynthesisMusic analysis, modification, and synthesis Models and representations for musical signals Pitch and multi-pitch ...",False,False,https://ieeexplore.ieee.org/ielx7/10376/6508879/06558818.pdf,10.1109/tasl.2013.2273051,OpenAlex
"IEEE/ACM Transactions on Audio, Speech, and Language Processing - EDICS",Unknown Authors,06716128.pdf,2014/01/01,Unsorted,"Transducer modeling and design Transducer calibration and compensation Novel transducers AUD-LMAP Loudspeaker and Microphone Array Signal Processing Far-field and near-field beamforming and array processing Source localization and tracking Time-delay estimation Audio enhancement using transducer arrays Wavefield synthesis Sound field analysis and synthesis AUD-ANCO Active Noise Control Acoustic noise cancellation and suppression Adaptive techniques for feedforward control Feedback control algorithms Multichannel systems AUD-ECHO Echo CancellationSingle-channel and multichannel acoustic echo cancellation Echo path estimation and modeling Echo suppression and dereverberation Double-talk detection Adaptive filter theory for audio applications AUD-AUDI Auditory Modeling and Hearing AidsHuman audition and psychoacoustics Computational auditory scene analysis Perceptual and psychophysical models of audio algorithms and systems Perceptual measures of audio quality Aids for the handicapped (cochlear implants, hearing aids) Binaural hearing AUD-SSEN Audio Source Separation and EnhancementSingle-channel and multichannel source separation Blind deconvolution Noise reduction, compensation, and equalization Audio denoising and restoration AUD-SMCA Spatial and Multichannel AudioSpatial sound analysis and reproduction Spatialization and virtualization Measurement, modeling, and use of head-related transfer functions Crosstalk cancellation and binaural synthesis Artificial reverberation algorithms AUD-ACOD Audio CodingLow bit-rate and high-quality audio coding Scalable and lossless audio coding Spatial audio coding Joint source-channel coding Signal representations for coding Parametric and structured audio coding Psychoacoustic models for coding Objective and subjective quality assessment Error detection, correction, and concealment AUD-ANSY Audio Analysis and SynthesisMusic analysis, modification, and synthesis Models and representations for musical signals Pitch and multi-pitch ...",False,False,https://ieeexplore.ieee.org/ielx7/6570655/6701198/06716128.pdf,10.1109/taslp.2014.2300358,OpenAlex
Binaural Ambisonics: Its optimization and applications for auralization,"Makoto Otani, Haruki Shigetani, Masataka Mitsuishi, Ryo Matsuda",_pdf.pdf,2020/01/01,Unsorted,"To better understand acoustic environment and the resulting auditory perception, it is essential to capture, analyze, and reproduce a sound field as a three-dimensional physical phenomenon because spatial aspects of auditory perception play important roles in various situations in our lives. Some approaches have been proposed to achieve the three-dimensional capture and reproduction of acoustic fields. Among them, Higher-Order Ambisonics (HOA) based on spherical harmonics expansion enables the capture and reproduction of a directivity pattern of incoming sound waves. On the basis of HOA, three-dimensional auditory space can be presented to a listener typically via a spherical loudspeaker array. In addition, binaural synthesis emulating the loudspeaker presentation enables HOA reproduction with a set of headphones or several loudspeakers by employing crosstalk cancellation. Thus, we are developing an HOA-based binaural reproduction/auralization system with head tracking. This system is aimed at realizing the reproduction and auralization of a sound field, including one excited by the listener's own voice. In this paper, we review the topics related to the reproduction and auralization of the sound field and introduce the HOA-based binaural synthesis system we have developed, as well as our works on sweet-spot expansion in HOA decoding and self-voice reproduction/auralization.",False,False,https://www.jstage.jst.go.jp/article/ast/41/1/41_E19229/_pdf,10.1250/ast.41.142,OpenAlex
An Efficient Implementation of Parallel Parametric HRTF Models for Binaural Sound Synthesis in Mobile Multimedia,"Jose A. Belloch, Germán Ramos, José M. Badía, Máximo Cobos",09028216.pdf,2020/01/01,Unsorted,"The extended use of mobile multimedia devices in applications like gaming, 3D video and audio reproduction, immersive teleconferencing, or virtual and augmented reality, is demanding efficient algorithms and methodologies. All these applications require real-time spatial audio engines with the capability of dealing with intensive signal processing operations while facing a number of constraints related to computational cost, latency and energy consumption. Most mobile multimedia devices include a Graphics Processing Unit (GPU) that is primarily used to accelerate video processing tasks, providing high computational capabilities due to its inherent parallel architecture. This paper describes a scalable parallel implementation of a real-time binaural audio engine for GPU-equipped mobile devices. The engine is based on a set of head-related transfer functions (HRTFs) modelled with a parametric parallel structure, allowing efficient synthesis and interpolation while reducing the size required for HRTF data storage. Several strategies to optimize the GPU implementation are evaluated over a well-known kind of processor present in a wide range of mobile devices. In this context, we analyze both the energy consumption and real-time capabilities of the system by exploring different GPU and CPU configuration alternatives. Moreover, the implementation has been conducted using the OpenCL framework, guarantying the portability of the code.",False,False,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09028216.pdf,10.1109/access.2020.2979489,OpenAlex
Head-Related Transfer Functions and Virtual Auditory Display,"Xiaoli Zhong, Bosun Xie",45612.pdf,2014/01/01,Unsorted,,False,False,https://www.intechopen.com/citation-pdf-url/45612,10.5772/56907,OpenAlex
"Immersive audio, capture, transport, and rendering: a review",Xuejing Sun,div-class-title-immersive-audio-capture-transport-and-rendering-a-review-div.pdf,2021/01/01,Unsorted,"Immersive audio has received significant attention in the past decade. The emergence of a few groundbreaking systems and events (Dolby Atmos, MPEG-H, VR/AR, AI) contributes to reshaping the landscape of this field, accelerating the mass market adoption of immersive audio. This review serves as a quick recap of some immersive audio background, end to end workflow, covering audio capture, compression, and rendering. The technical aspects of object audio and ambisonic will be explored, as well as other related topics such as binauralization, virtual surround, and upmix. Industry trends and applications are also discussed where user experience ultimately decides the future direction of the immersive audio technologies.",False,False,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/A39094D58238A0F66750D48362D5FF17/S2048770321000123a.pdf/div-class-title-immersive-audio-capture-transport-and-rendering-a-review-div.pdf,10.1017/atsip.2021.12,OpenAlex
The Availability of a Hidden Real Reference Affects the Plausibility of Position-Dynamic Auditory AR,"Annika Neidhardt, Anna Maria Zerlik",pdf.pdf,2021/01/01,Unsorted,"This study examines the plausibility of Auditory Augmented Reality (AAR) realized with position-dynamic binaural synthesis over headphones. An established method to evaluate the plausibility of AAR asks participants to decide whether they are listening to the virtual or real version of the sound object. To date, this method has only been used to evaluate AAR systems for seated listeners. The AAR realization examined in this study instead allows listeners to turn to arbitrary directions and walk towards, past, and away from a real loudspeaker that reproduced sound only virtually. The experiment was conducted in two parts. In the first part, the subjects were asked whether they are listening to the real or the virtual version, not knowing that it was always the virtual version. In the second part, the real versions of the scenes where the loudspeaker actually reproduced sound were added. Two different source positions, three different test stimuli, and two different sound levels were considered. Seventeen volunteers, including five experts, participated. In the first part, none of the participants noticed that the virtual reproduction was active throughout the different test scenes. The inexperienced listeners tended to accept the virtual reproduction as real, while experts distributed their answers approximately equally. In the second part, experts could identify the virtual version quite reliably. For inexperienced listeners, the individual results varied enormously. Since the presence of the headphones influences the perception of the real sound field, this shadowing effect had to be considered in the creation of the virtual sound source as well. This requirement still limits test methods considering the real version in its ecological validity. Although the results indicate that the availability of a hidden real reference leads to a more critical evaluation, it is crucial to be aware that the presence of the headphones slightly distorts the reference. This issue se...",False,False,https://www.frontiersin.org/articles/10.3389/frvir.2021.678875/pdf,10.3389/frvir.2021.678875,OpenAlex
Design and Implementation Analysis of OSD based Audio Crosstalk Cancellation with Multi-Channel Inputs on DSP Processors,"Ch. Sreenivasa Rao, Dhulipalla Venkata Rao, S. Lakshminarayana",Article9.pdf,2015/01/01,Unsorted,"To overcome the basic system inversion problems in conventional crosstalk cancellation systems, the three channel Optimum Source Distribution (OSD) was developed by Takashi et al., that provides balance between in-phase and out of phase components. The main difficulty in this system is real-time implementation of cross talk cancellation filters on DSP platforms, particularly when filter lengths are very long with system operates on multichannel inputs. This paper discusses the implementation complexities and proposes an efficient approach to reduce the power consumption. It also discusses efficient usage of available processor memory. By utilizing the processor resources and existing frequency domain techniques, this approach would be one of best methods for long filters. The mathematical model, with efficient design for floating point DSP processors, clearly explains the optimization methods at algorithmic and instruction levels. The computational complexity of the proposed method was measured for various multi-channel input sources and the comparison was shown. The results indicate that the proposed method provides efficient computations than existing methods. Keywords: Convolution, Crosstalk Cancellation, Optimal Source Distribution, Overlap Save Method, Uniform Partitioned Convolution",False,False,https://sciresol.s3.us-east-2.amazonaws.com/IJST/Articles/2015/Issue-5/Article9.pdf,10.17485/ijst/2015/v8i5/60708,OpenAlex
SCaLAr – A surrounding spherical cap loudspeaker array for flexible generation and evaluation of virtual acoustic environments,"Florian Pausch, Gottfried Behler, Janina Fels",aacus200030.pdf,2020/01/01,Unsorted,"Introduction : Surrounding spherical loudspeaker arrays facilitate the application of various spatial audio reproduction methods and can be used for a broad range of acoustic measurements and perceptual evaluations. Methods : Installed in an anechoic chamber, the design and implementation of such an array of 68 coaxial loudspeakers, sampling a spherical cap with a radius of 1.35 m on an equal-area grid, is presented. A network-based audio backbone enables low-latency signal transmission with low-noise amplifiers providing a high signal-to-noise ratio. To address batch-to-batch variations, the loudspeaker transfer functions were equalised by individually designed 512-taps finite impulse response filters. Time delays and corresponding level adjustments further helped to minimise radial mounting imperfections. Results : The equalised loudspeaker transfer functions measured under ideal conditions and when mounted, their directivity patterns, and in-situ background noise levels satisfy key criteria towards applicability. Advantages and shortcomings of the selected decoders for panning-based techniques, as well as the influence of loudspeaker positioning errors, are analysed in terms of simulated performance metrics. An evaluation of the achievable channel separation allows deriving recommendations of feasible subset layouts for loudspeaker-based binaural reproduction. Conclusion : The combination of electroacoustic properties, simulated sound field synthesis performance and measured channel separation classifies the system as suitable for its target applications.",False,False,https://acta-acustica.edpsciences.org/articles/aacus/pdf/2020/05/aacus200030.pdf,10.1051/aacus/2020014,OpenAlex
Audio Quality Assessment for Virtual Reality,"Fabian Brinkmann, Stefan Weinzierl",978-3-031-04021-4_5.pdf,2022/01/01,Unsorted,"Abstract A variety of methods for audio quality evaluation are available ranging from classic psychoacoustic methods like alternative forced-choice tests to more recent approaches such as quality taxonomies and plausibility. This chapter introduces methods that are deemed to be relevant for audio evaluation in virtual and augmented reality. It details in how far these methods can directly be used for testing in virtual reality or have to be adapted with respect to specific aspects. In addition, it highlights new areas, for example, quality of experience and presence that arise from audiovisual interactions and the mediation of virtual reality. After briefly introducing 3D audio reproduction approaches for virtual reality, the quality that these approaches can achieve is discussed along with the aspects that influence the quality. The concluding section elaborates on current challenges and hot topics in the field of audio quality evaluation and audio reproduction for virtual reality. To bridge the gap between theory and practice useful resources, software and hardware for 3D audio production and research are pointed out.",False,False,https://link.springer.com/content/pdf/10.1007/978-3-031-04021-4_5.pdf,10.1007/978-3-031-04021-4_5,OpenAlex
Reverberation and its Binaural Reproduction: The Trade-off between Computational Efficiency and Perceived Quality,"Isaac Engel, Lorenzo Picinali",80155.pdf,2022/01/01,Unsorted,"Accurately rendering reverberation is critical to produce realistic binaural audio, particularly in augmented reality applications where virtual objects must blend in seamlessly with real ones. However, rigorously simulating sound waves interacting with the auralised space can be computationally costly, sometimes to the point of being unfeasible in real time applications on resource-limited mobile platforms. Luckily, knowledge of auditory perception can be leveraged to make computational savings without compromising quality. This chapter reviews different approaches and methods for rendering binaural reverberation efficiently, focusing specifically on Ambisonics-based techniques aimed at reducing the spatial resolution of late reverberation components. Potential future research directions in this area are also discussed.",False,False,https://www.intechopen.com/citation-pdf-url/80155,10.5772/intechopen.101940,OpenAlex
Loudspeaker distributions suitable for crosstalk cancellers robust to head rotation,"Cheolsu Han, Takuma Okamoto, Yukio Iwaya, Yôiti Suzuki",_pdf.pdf,2012/01/01,Unsorted,,False,False,https://www.jstage.jst.go.jp/article/ast/33/4/33_E1176/_pdf,10.1250/ast.33.266,OpenAlex
Parametric Coding of Stereo Audio,"Jeroen Breebaart, Steven van de Par, Armin Kohlrausch, Erik Schuijers",ASP.2005.1305.pdf,2005/01/01,Unsorted,,False,False,https://asp-eurasipjournals.springeropen.com/counter/pdf/10.1155/ASP.2005.1305,10.1155/asp.2005.1305,OpenAlex
Virtual Reality System with Integrated Sound Field Simulation and Reproduction,"Tobias Lentz, Dirk Schröder, Michael Vorländer, Ingo Assenmacher",70540.pdf,2007/01/01,Unsorted,"A real-time audio rendering system is introduced which combines a full room-specific simulation, dynamic crosstalk cancellation, and multitrack binaural synthesis for virtual acoustical imaging. The system is applicable for any room shape (normal, long, flat, coupled), independent of the a priori assumption of a diffuse sound field. This provides the possibility of simulating indoor or outdoor spatially distributed, freely movable sources and a moving listener in virtual environments. In addition to that, near-to-head sources can be simulated by using measured near-field HRTFs. The reproduction component consists of a headphone-free reproduction by dynamic crosstalk cancellation. The focus of the project is mainly on the integration and interaction of all involved subsystems. It is demonstrated that the system is capable of real-time room simulation and reproduction and, thus, can be used as a reliable platform for further research on VR applications.",False,False,https://asp-eurasipjournals.springeropen.com/counter/pdf/10.1155/2007/70540,10.1155/2007/70540,OpenAlex
VR/AR and hearing research: current examples and future challenges,"Lorenzo Picinali, Giso Grimm, Yusuke Hioka, Gavin Kearney, Deborah Johnston, Craig Jin, Laurent Simon, Hannes Wüthrich, Michael Mihocic, Piotr Majdak, Deborah Vickers",000322.pdf,2024/01/01,Unsorted,"A well-known issue in clinical audiology and hearing research is the level of abstraction of traditional experimental assessments and methods, which lack ecological validity and differ significantly from real-life experiences, often resulting in unreliable outcomes.Attempts to deal with this matter by, for example, performing experiments in real-life contexts, can be problematic due to the difficulty of accurately identifying control-specific parameters and events.Virtual and augmented reality (VR/AR) have the potential to provide dynamic and immersive audiovisual experiences that are at the same time realistic and highly controllable.Several successful attempts have been made to create and validate VR-based implementations of standard audiological and linguistic tests, as well as to design procedures and technologies to assess meaningful and ecologically-valid data.Similarly, new viewpoints on auditory perception have been provided by looking at hearing training and auditory sensory augmentation, aiming at improving perceptual skills in tasks such as speech understanding and sound-source localisation.",False,False,https://dael.euracoustics.org/confs/fa2023/data/articles/000322.pdf,10.61782/fa.2023.0322,OpenAlex
Implementation Analysis of Binaural Audio Crosstalk Cancellation on Heterogeneous Parallel Computing platforms using Mixed Non-Uniform Partitioned Convolution,"Chunduri Sreenivasa Rao, Dhulipalla Venkata Rao, Somayajula Lakshminarayana",Article6.pdf,2015/01/01,Unsorted,"As general DSP processors don’t have massive parallel architecture, they are not suitable to implement 3D audio virtual techniques at very long filters due to computational problems. To address these implementation issues of very long filters, an efficient method called Mixed Non-uniform Partitioned Convolution is proposed in this paper for implementing binaural audio crosstalk cancellation on heterogeneous parallel computing platforms. By using massive parallel architecture of heterogeneous platforms, the proposed approach is able to solve computational problems even at filter lengths of 65536 (32-bit floating point). The partitioning scheme followed in this paper is explained in detail to schedule partitions on various compute units of GPU device. The proposed approach was implemented on AMD GPUs using task parallel concept. The instruction level optimization was also provided for complex frequency multiplication and addition using OpenCL. The performance of this approach is compared against the existing techniques proposed by Garcia and Gardener. The cost vs. computational performance tradeoff comparison was given between proposed approach and existing methods. The comparison clearly shows that proposed approach is very efficient at very long filters and requires reasonable cost of implementation in terms of number of compute units. The combination of instruction level and algorithmic level optimizations make the proposed approach more suitable for implementation of not only stereo inputs based audio CTC but also multichannel inputs, particularly at very long filter lengths on parallel computing platforms. Keywords: Crosstalk Cancellation, Heterogeneous Parallel Computing, Mixed Filtering, OpenCL, Partitioned Convolution",False,False,https://sciresol.s3.us-east-2.amazonaws.com/IJST/Articles/2015/Issue-33/Article6.pdf,10.17485/ijst/2015/v8i33/80399,OpenAlex
Automotive sound field reproduction using deep optimization with spatial domain constraint,"Qian Yufan, Qu, Tianshu, Wu, Xihong",2509.09149.pdf,2025/01/01,Unsorted,"Sound field reproduction with undistorted sound quality and precise spatial localization is desirable for automotive audio systems. However, the complexity of automotive cabin acoustic environment often necessitates a trade-off between sound quality and spatial accuracy. To overcome this limitation, we propose Spatial Power Map Net (SPMnet), a learning-based sound field reproduction method that improves both sound quality and spatial localization in complex environments. We introduce a spatial power map (SPM) constraint, which characterizes the angular energy distribution of the reproduced field using beamforming. This constraint guides energy toward the intended direction to enhance spatial localization, and is integrated into a multi-channel equalization framework to also improve sound quality under reverberant conditions. To address the resulting non-convexity, deep optimization that use neural networks to solve optimization problems is employed for filter design. Both in situ objective and subjective evaluations confirm that our method enhances sound quality and improves spatial localization within the automotive cabin. Furthermore, we analyze the influence of different audio materials and the arrival angles of the virtual sound source in the reproduced sound field, investigating the potential underlying factors affecting these results.",False,False,https://arxiv.org/pdf/2509.09149,10.48550/arxiv.2509.09149,OpenAlex
Near-field source reproduction in large loudspeaker arrays,"Laurent Simon, Stefan Klockgether",000830.pdf,2024/01/01,Unsorted,"Spatial decomposition techniques can help to compensate for some of the limitations of higher order Ambisonics (HOA).Compared to HOA, higher order spatial impulse response rendering (HO-SIRR) has proven to substantially increase the sweet spot of a simulated space.For HO-SIRR-simulated scenes, it has also been shown that the performance of hearing aid beamformers is closer to the performance in real acoustic environments, and that interaural time and level differences are more similar to those recorded with an artificial head (KEMAR) in the original space than with a simulation based on simple HOA.However, with spatial decomposition techniques, it is more difficult to simulate sources at various distances, especially when trying to simulate focused sources within a loudspeaker array.In this presentation, we describe a near-field source rendering technique.HOA and hearing aid recordings were made in a reference room.The method presented in this paper was compared to HOA and HO-SIRR methods in a sound reproduction room, with regard to direct-toreverberant ratio (DRR), coherence, and performance of the hearing aid beamformer.",False,False,https://dael.euracoustics.org/confs/fa2023/data/articles/000830.pdf,10.61782/fa.2023.0830,OpenAlex
Spatial Audio,"Woon‐Seng Gan, Jung‐Woo Choi, Xiaoyan Chen, Alice Zhang, Daria Shi, Candice Zhuo, Sydni Sun, Wen Zhang, Prasanga N. Samarasinghe, Hanchi Chen, Thushara D. Abhayapala, Joo Young Hong, Jianjun He, Bhan Lam, Rishabh Gupta, Jonathan Albert Gößwein, Julian Grosse, Steven van de Par, Jiho Chang, Cheol-Ho Jeong",Spatial_Audio.pdf,2017/01/01,Unsorted,"Three-dimensional (or spatial) audio is a growing research field that plays a key role in realizing immersive communication in many of today's applications for teleconferencing, entertainment, gaming, navigation guidance, and virtual reality (VR)/augmented reality (AR).Technologies in spatial sound capture and binaural recording are becoming an add-on module to our mobile devices to capture the surrounding soundscape, pickup directional and ambient cues, and create an immersive 3D audio media for playback.We are seeing a surge in research activities and applications that rely on digital spatial audio processing and rendering over loudspeakers (stereo, wave field synthesis, ambisonics) and headphones, and seeing new emerging fields of mobile spatial audio, personal assisted listening, and spatial audio for VR/AR.New developments in graphical processing units and multi-core processors are accelerating the pace for real-time spatial audio processing, and new techniques that can lead to high quality and immersive spatial audio reproduction.",False,False,https://mdpi-res.com/bookfiles/book/465/Spatial_Audio.pdf,10.3390/books978-3-03842-586-1,OpenAlex
Examining auditory selective attention. From dichotic towards realistic environments,Josefa Oberem,978-3-8325-5101-8.pdf,2020/01/01,Unsorted,"The aim of the present thesis is to examine the cognitive control mechanisms underlying auditory selective attention by considering the influence of variables that increase the complexity of an auditory scene. Therefore, technical aspects such as dynamic binaural hearing, room acoustics and head movements as well as those that influence the efficiency of cognitive processing are taken into account. Step-by-step the well-established dichotic-listening paradigm is extended into a realistic spatial listening paradigm.\n\nConducted empirical surveys are based on a paradigm examining the intentional switching of auditory selective attention. Performance measure differences between the repetition of the target's spatial position and the related switch describe the loss of efficiency associated with redirecting attention from one target's location to another. To examine whether the irrelevant auditory information is decoded, interference in the processing of task-relevant and task-irrelevant information is created in the paradigm.\n\nUsing the binaural-listening paradigm, the ability to intentionally switch auditory selective attention is tested when applying different methods of spatial reproduction. Essential differences between real sources, an individual and a non-individual binaural synthesis are found. As a step towards multi-talker scenarios in realistic environments participants are tested in differently reverberating environments, resulting in highly affected switch costs. Age-related effects are found when applying the binaural-listening paradigm, indicating difficulties for elderly to suppress processing the distractor's speech.",False,False,https://www.logos-verlag.de/ebooks/OA/978-3-8325-5101-8.pdf,10.30819/5101,OpenAlex
Imagem sonora imersiva com arranjos circulares de transdutores espaçados em segmentos iguais,"José Augusto Mannis, Igor Abdo Aguilar, Angela Cristina Rodrigues",Pending_Header_Check,2025/01/01,Unsorted,"Este artigo apresenta o desenvolvimento de uma pesquisa em gravação e reprodução de áudio imersivo multicanal ocorrida de 2016 a 2020 na Universidade Estadual de Campinas (Brasil), que resultou em arranjos circulares de transdutores (microfones e caixas acústicas) espaçados em segmentos iguais. A mesma tecnologia de captação sonora multicanal imersiva já havia sido formulada em 1991 pelo engenheiro de som Michael Williams. Por caminhos distintos, os dois estudos chegaram a um resultado comum. Reconhecendo o mérito do achado a Williams, detalha-se, neste artigo, o percurso da pesquisa brasileira, com comentários complementares que ilustram a potência e a riqueza dos fenômenos envolvidos na solução do problema. Também são apresentados os desdobramentos do produto inicial, notadamente o desenvolvimento de uma ferramenta de simulação acústica e auralização com aplicações em artes, comunicação, bioacústica, ecologia e monitoramento ambiental. Ao final apresentamos composições musicais em áudio espacial destacando as facilidades expressivas dos novos recursos desenvolvidos.",False,False,https://periodicos.unespar.edu.br/vortex/article/download/9752/6723,10.33871/vortex.2024.12.9752,OpenAlex
Controle da diretividade sonora no espaço tridimensional por um arranjo esférico compacto de alto-falantes,Alexander Mattioli Pasqual,Pending_Header_Check,2010/01/01,Unsorted,"Angular control of the sound radiation can be achieved by using a compact array of independently programmable loudspeakers operating at the same frequency range.The drivers are usually distributed over a sphere-like frame according to a Platonic solid geometry to obtain a highly symmetrical configuration.Prototypes of compact spherical loudspeaker arrays have been recently developed and applied in room acoustics measurements, electroacoustic music performance and synthesis of directivity patterns of acoustical sources such as musical instruments.However, many aspects concerning their control, design, electromechanical behavior and ability to provide a more realistic sound experience than conventional audio systems remain unclear.This work concerns the analysis and synthesis of sound fields by a compact spherical loudspeaker array and aims to contribute to clarifying some aspects mentioned above.A control strategy based on the acoustic radiation modes of the spherical array is proposed, which presents several advantages over the usual strategy based on the spherical harmonics.A theoretical and experimental analysis of the electromechanical behavior of compact loudspeaker arrays is also presented, in which the acoustic coupling between drivers inside the array frame is taken into account.In addition, optimum driver signals corresponding to a given target directivity pattern are derived using two different cost functions, indicating that the realism of the synthesized pattern may be significantly increased by neglecting the phase of the target directivity pattern.Finally, the proposed theoretical models are validated through measurements of electrical impedance, loudspeaker diaphragm velocity and directivity patterns.viii 6.30 Theoretical and experimental directivity pattern at 600Hz corresponding to a rotated lateral quadrupole obtained from a linear combination of the ARM #05 to #09. . . . . . . . . . .",False,False,https://doi.org/10.47749/t/unicamp.2010.771382,10.47749/t/unicamp.2010.771382,OpenAlex
Analysis and Experiment on the Limitations of Static and Dynamic Transaural Reproduction with Two Frontal Loudspeakers,"Lulu Liu, Bosun Xie",aoa.2021.136577.pdf,2021/01/01,Unsorted,"By duplicating the binaural pressures of an actual source, transaural reproduction with two frontal loudspeakers is expected to recreate a virtual source in arbitrary direction. However, experiments indicated that in static transaural reproduction, the perceived virtual source is usually limited to the frontalhorizontal plane. The reasons for this limitation, as guessed, are that, in static reproduction, the dynamic cues for front-back and vertical localisation are incorrect, and the high-frequency spectral cues are unstable with head movement. To validate this hypothesis, the variations of ITD (interaural time difference) caused by head turning in both static and dynamic transaural reproductions are analysed. The results indicate that dynamic reproduction is able to create appropriate low-frequency ITD variations, and the static transaural reproduction is unable to do so. Psychoacoustic experiments are conducted to compare virtual source localisation in static and dynamic reproductions. The results indicate that dynamic reproduction is able to recreate the front, back, and vertical virtual source for low-pass stimuli below 3 kHz, while for full audible bandwidth stimulus, appropriate low-frequency dynamic cue and unstable high-frequency spectral cues in dynamic reproduction result in two splitting virtual sources.",False,False,http://journals.pan.pl/Content/119919/aoa.2021.136577.pdf,10.24425/aoa.2021.136577,OpenAlex
Proposing Factors Towards a Standardised Testing Environment for Binaural and 3D Sound Systems,Sebastian Chandler Crnigoj,2020chandlerphd.pdf,2020/01/01,Unsorted,"Binaural sound systems are a growing industry in spatial audio. For the first time, a method of defining and evaluating the efficiency of such systems is investigated. A testing, and comparison, methodology is proposed based on implicating factors which determine the location of a sound. This proposed methodology provides quantitative and qualitative comparison methods to determine the function and suggested application of any given binaural sound system. A series of tests are conducted and results provide a foundation for proposing and creating a standardised testing environment.",False,False,https://researchonline.ljmu.ac.uk/id/eprint/14035/1/2020chandlerphd.pdf,10.24377/ljmu.t.00014035,OpenAlex
Subband Approach to Bandlimited Crosstalk Cancellation System in Spatial Sound Reproduction,"Mingsian R. Bai, Chih-Chung Lee",71948.pdf,2006/01/01,Unsorted,"Crosstalk cancellation system (CCS) plays a vital role in spatial sound reproduction using multichannel loudspeakers. However, this technique is still not of full-blown use in practical applications due to heavy computation loading. To reduce the computation loading, a bandlimited CCS is presented in this paper on the basis of subband filtering approach. A pseudoquadrature mirror filter (QMF) bank is employed in the implementation of CCS filters which are bandlimited to 6 kHz, where human&#39;s localization is the most sensitive. In addition, a frequency-dependent regularization scheme is adopted in designing the CCS inverse filters. To justify the proposed system, subjective listening experiments were undertaken in an anechoic room. The experiments include two parts: the source localization test and the sound quality test. Analysis of variance (ANOVA) is applied to process the data and assess statistical significance of subjective experiments. The results indicate that the bandlimited CCS performed comparably well as the fullband CCS, whereas the computation loading was reduced by approximately eighty percent.",False,False,https://asp-eurasipjournals.springeropen.com/counter/pdf/10.1155/2007/71948,10.1155/2007/71948,OpenAlex
Sound Zone Interaction in Homes: Studying and Designing for Modification of Personal Soundscapes,Stine S. Johansen,PHD_SSJ_E_pdf.pdf,2021/01/01,Unsorted,"This dissertation is based on research conducted from 2018 to 2021 at the Department of Computer Science, Aalborg University. The dissertation consists of six full papers as well as a synopsis that outlines research questions, related work, research design, a summary of the paper contributions, and a discussion that positions the research. In this research, I investigate how to support users' understanding and control of sound zone systems with interaction designs. I do so in seven studies in field and lab settings where I apply approaches to (1) articulate experiences of sound zones in different situations and (2) designing interaction with sound zones. From this investigation, I make three propositions towards a theory of sound zone configurations. The research offers a foundation for asking and investigating more far-reaching questions that pertain to experiences of and designing for sound zone systems.",False,False,https://vbn.aau.dk/ws/files/455013535/PHD_SSJ_E_pdf.pdf,10.54337/aau455013535,OpenAlex
Goniometers are a Powerful Acoustic Feature for Music Information Retrieval Tasks,Tim Ziemer,2302.01090.pdf,2023/02/02,Unsorted,"Goniometers, also known as Phase Scopes or Vector Scopes, are audio metering tools that help music producers and mixing engineers monitor spatial aspects of a music mix, such as the stereo panorama, the width of single sources, the amount and diffuseness of reverberation as well as phase cancellations that may occur on the sweet-spot and in a mono-mixdown. In addition, they implicitly inform about the dynamics of the sound. Self-organizing maps trained with a goniometer, are consulted to explore the usefulness of this acoustic feature for music information retrieval tasks. One can see that goniometers are able to classify different genres and cluster a single album. The advantage of goniometers is the causality: Music producers and mixing engineers consciously consult goniometers to reach their desired sound, which is not the case for other acoustic features, from Zero-Crossing Rate to Mel-Frequency Cepstral Coefficients.",False,False,https://arxiv.org/pdf/2302.01090,10.48550/arXiv.2302.01090,Semantic Scholar
Towards Faster Continuous Multi-Channel HRTF Measurements Based On Learning System Models,"Tobias Kabzinski, P. Jax",2110.03630.pdf,2021/10/07,Unsorted,"Measuring personal head-related transfer functions (HRTFs) is essential in binaural audio. Personal HRTFs are not only required for binaural rendering and for loudspeaker-based binaural reproduction using crosstalk cancellation, but they also serve as a basis for data-driven HRTF individualization techniques and psychoacoustic experiments. Although many attempts have been made to expedite HRTF measurements, the rotational velocities in today’s measurement systems remain lower than those in natural head movements. To cope with faster rotations, we present a novel continuous HRTF measurement method. This method estimates the HRTFs offline using a Kalman smoother and learns state-space parameters, including the system model, on short signal segments, utilizing the expectation maximization algorithm. We evaluated our method in simulated single-channel and multi-channel measurements using a rigid sphere HRTF model. Comparing with conventional methods, we found that the system distances are improved by up to 30 dB.",False,False,https://arxiv.org/pdf/2110.03630,10.1109/ICASSP43922.2022.9746559,Semantic Scholar
Common-Slope Modeling of Late Reverberation,"Georg Götz, Sebastian J. Schlecht, V. Pulkki",10256141.pdf,2000/01/01,Unsorted,"The decaying sound field in rooms is typically described by energy decay functions (EDFs). Late reverberation can deviate considerably from the ideal diffuse field, for example, in multiple connected rooms or non-uniform absorption material distributions. This paper proposes the common-slope model of late reverberation. The model describes spatial and directional late reverberation as linear combinations of exponential decays called common slopes. Its fundamental idea is that common slopes have decay times that are invariant across space and direction, while their amplitudes vary across both. We explore different approaches for determining the common slopes for large EDF sets describing different source-receiver configurations of the same environment. Among the presented approaches, the k-means clustering of decay times is the most general. Our evaluation shows that the common-slope model introduces only a small error between the modeled and the true EDF, while being considerably more compact than the traditional multi-exponential model. The amplitude variations of the common slopes yield interpretable room acoustic analyses. The common-slope model has potential applications in all fields relying on late reverberation models, such as source separation, dereverberation, echo cancellation, and parametric spatial audio rendering.",False,False,https://ieeexplore.ieee.org/ielx7/6570655/6633080/10256141.pdf,10.1109/TASLP.2023.3317572,Semantic Scholar
Learning to Separate Voices by Spatial Regions,"Alan Xu, Romit Roy Choudhury",2207.04203.pdf,2022/07/09,Unsorted,"We consider the problem of audio voice separation for binaural applications, such as earphones and hearing aids. While today's neural networks perform remarkably well (separating $4+$ sources with 2 microphones) they assume a known or fixed maximum number of sources, K. Moreover, today's models are trained in a supervised manner, using training data synthesized from generic sources, environments, and human head shapes. This paper intends to relax both these constraints at the expense of a slight alteration in the problem definition. We observe that, when a received mixture contains too many sources, it is still helpful to separate them by region, i.e., isolating signal mixtures from each conical sector around the user's head. This requires learning the fine-grained spatial properties of each region, including the signal distortions imposed by a person's head. We propose a two-stage self-supervised framework in which overheard voices from earphones are pre-processed to extract relatively clean personalized signals, which are then used to train a region-wise separation model. Results show promising performance, underscoring the importance of personalization over a generic supervised approach. (audio samples available at our project website: https://uiuc-earable-computing.github.io/binaural/. We believe this result could help real-world applications in selective hearing, noise cancellation, and audio augmented reality.",False,False,http://arxiv.org/pdf/2207.04203,10.48550/arXiv.2207.04203,Semantic Scholar
Performance Evaluation of Adaptive Algorithms for Wave Field Analysis/Synthesis Using Sound Field Simulations,"P. Peretti, S. Cecchi, L. Romoli, F. Piazza",21798.pdf,2011/10/26,Unsorted,"The main objective of a multi-channel sound reproduction system is to give an optimal acoustical sensation to the listener. These systems are designed to produce sounds that are as natural as possible, so that the listener does not realize that they are generated by a loudspeakers system. For this purpose, the knowledge of only audio temporal information is not sufficient: also spatial information is needed. Furthermore, since the invention of stereophony, it is well known that at least two loudspeakers are needed in order to generate a virtual source that is not spatially localized at the speaker position. However, the stereo reproduction is very limited because the optimal source localization is focused on one point, called sweet spot. Starting from this assumption, in the recent literature, research efforts have focused on reproduction techniques that use an extremely high number of loudspeakers in order to reproduce not only a simple audio source but a complete sound field. Various techniques, able to record and to reproduce the entire sound field, have been proposed in the literature (Berkhout et al., 1993; Daniel et al., 2003; Fazi et al., 2008). One of the most studied techniques is Wave Field Synthesis (WFS) that is directly based on the Huygens’ principle. It has been introduced in the late ’80s by Berkhout, who showed that audio reproduction can be linked to audio holography concepts (Berkhout, 1988). WFS is based on Kirchhoff-Helmholtz integral which permits the calculation of the pressure field inside a volume by knowing pressure and normal particle velocity on the enclosing surface. The underlying idea of WFS is to generate a sound field inside a volume bounded by an array of loudspeakers. Actually, the surface is reduced to a 2D curve positioned on the ear plane. The number of loudspeakers on this curve depends on the desired localization quality. Similarly, Wave Field Analysis (WFA) implements a sound field recording technique based on microphone arra...",False,False,https://www.intechopen.com/citation-pdf-url/21798,10.5772/24513,Semantic Scholar
Contextual Localization Bias for Low- and High-Frequency Stimuli,"Bernhard Laback, Jonas Schültke",001081.pdf,2022/01/17,Unsorted,"* The perceived azimuth of a sound source is biased by a preceding source (precursor), typically, towards midline (medial) by a lateral and towards the side (lateral) by a central precursor. Little is known about effects of intermediate precursor azimuths and the contribution of low and high frequency regions. We tested the hypothesis that for a certain intermediate precursor azimuth, lateral and central biases cancel each other out. Ten normal-hearing listeners localized 300-ms targets following 600-ms precursors using a head-pointing task in a virtual audio-visual environment. Both target and precursor azimuths were systematically varied across the entire azimuth range. Stimuli were white noises, filtered with listener-specific head-related transfer functions. Low-pass (0.5-2 kHz), high-pass (2.8-16 kHz), and broadband (0.5-16 kHz) stimuli were tested to study effects in frequency regions dominated by different localization cues: interaural time differences in low-pass, interaural level differences and spectral shape in high-pass, and all three cues in broadband stimuli. Precursor effects were overall strongest for target azimuths of +/-70°. Cancellation of lateral and central biases was found only for +/-70°-targets, at a precursor azimuth of 58.3°. Importantly, the data showed selective spatial contrast enhancement for targets preceded by azimuthally matched Ps. Patterns of precursor effects were relatively similar across frequency regions.",False,False,https://dael.euracoustics.org/confs/fa2023/data/articles/001081.pdf,10.61782/fa.2023.1081,Semantic Scholar
"Independent Component Analysis and Signal Separation, 8th International Conference, ICA 2009, Paraty, Brazil, March 15-18, 2009. Proceedings","T. Adalı, C. Jutten, J. Romano, A. Barros",article.pdf,2000/01/01,Unsorted,,False,False,https://hal.archives-ouvertes.fr/hal-00369922/file/article.pdf,10.1007/978-3-642-00599-2,Semantic Scholar
Johnson-noise-limited cancellation-free microwave impedance microscopy with monolithic silicon cantilever probes,"Jun-Yi Shan, Nathaniel Morrison, Sudi Chen, Feng Wang, Eric Y. Ma",s41467-024-49405-8.pdf,2024/03/06,Unsorted,"Microwave impedance microscopy (MIM) is an emerging scanning probe technique for nanoscale complex permittivity mapping and has made significant impacts in diverse fields. To date, the most significant hurdles that limit its widespread use are the requirements of specialized microwave probes and high-precision cancellation circuits. Here, we show that forgoing both elements not only is feasible but also enhances performance. Using monolithic silicon cantilever probes and a cancellation-free architecture, we demonstrate Johnson-noise-limited, drift-free MIM operation with 15 nm spatial resolution, minimal topography crosstalk, and an unprecedented sensitivity of 0.26 zF/√Hz. We accomplish this by taking advantage of the high mechanical resonant frequency and spatial resolution of silicon probes, the inherent common-mode phase noise rejection of self-referenced homodyne detection, and the exceptional stability of the streamlined architecture. Our approach makes MIM drastically more accessible and paves the way for advanced operation modes as well as integration with complementary techniques. The authors introduce a new approach to microwave impedance microscopy, eliminating once-indispensable specialized probes and cancellation circuits. Using monolithic silicon probes and a streamlined architecture, they achieve 0.26 zF/√Hz sensitivity and 15 nm resolution with drift-free operation.",False,False,https://www.nature.com/articles/s41467-024-49405-8.pdf,10.1038/s41467-024-49405-8,Semantic Scholar
Spatial Aliasing Effects in a Steerable Parametric Loudspeaker for Stereophonic Sound Reproduction,"Chuang Shi, H. Nomura, T. Kamakura, W. Gan",Spatial%20aliasing%20effects%20in%20a%20steerable%20parametric%20loudspeaker%20for%20stereophonic%20sound%20reproduction.pdf,2014/09/01,Unsorted,,False,False,https://dr.ntu.edu.sg/bitstream/10356/101132/1/Spatial%20aliasing%20effects%20in%20a%20steerable%20parametric%20loudspeaker%20for%20stereophonic%20sound%20reproduction.pdf,10.1587/TRANSFUN.E97.A.1859,Semantic Scholar
