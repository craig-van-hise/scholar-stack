
### Phase 1: The "Unlimited" Environment

I need to build a comprehensive academic crawler. Update `requirements.txt` to include all these libraries:

* `arxiv` (ArXiv API)
* `semanticscholar` (Semantic Scholar API)
* `scholarly` (Google Scholar wrapper - include rate limiting logic)
* `habanero` (Crossref API for DOI lookup)
* `pyunpaywall` (Unpaywall API to unlock DOIs)
* `sickle` (OAI-PMH client for querying **BASE** and **CORE**)
* `requests` (For OSF, PLOS, DOAJ, and generic APIs)
* `beautifulsoup4` (For scraping DAFx/ISMIR archives directly)
* `pandas`
* `google-generativeai` (For the dynamic taxonomy later)
* `tqdm` (Progress bars)

Install these now.

