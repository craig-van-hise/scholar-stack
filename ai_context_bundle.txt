--- PROJECT CONTEXT FOR AI ---


==================================================
FILE: scheduler_test.py
==================================================
#!/usr/bin/env python3
"""
Scholar-Alert Scheduler
Checks for new papers and sends email notifications.
"""

import os
import sys
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime
from dotenv import load_dotenv
import argparse

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from alerts_db import (
    init_db, 
    get_active_subscriptions, 
    update_last_run,
    reset_dates_for_testing
)

# Load environment variables
load_dotenv(override=True)

def send_notification_email(to_email: str, query: str, papers_list: list):
    """
    Send email notification about new papers.
    
    Args:
        to_email: Recipient email address
        query: Search query that triggered the alert
        papers_list: List of paper dictionaries with 'title', 'doi', 'url', etc.
    """
    sender_email = os.getenv("GOOGLE_EMAIL") or os.getenv("SENDER_EMAIL")
    app_password = os.getenv("GOOGLE_APP_PASSWORD") or os.getenv("SENDER_APP_PASSWORD")
    
    if not sender_email or not app_password:
        print("‚ùå Error: GOOGLE_EMAIL and GOOGLE_APP_PASSWORD must be set in .env")
        return False
    
    # Create message
    msg = MIMEMultipart('alternative')
    msg['Subject'] = f"üîî New Research Found: {query}"
    msg['From'] = sender_email
    msg['To'] = to_email
    
    # Create HTML body
    html_body = f"""
    <html>
      <head></head>
      <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
        <h2 style="color: #2c3e50;">üìö ScholarStack Alert</h2>
        <p>New papers found for your search: <strong>{query}</strong></p>
        <p>Found <strong>{len(papers_list)}</strong> new paper(s):</p>
        <hr style="border: 1px solid #ecf0f1;">
    """
    
    for i, paper in enumerate(papers_list, 1):
        title = paper.get('Title', 'Untitled')
        doi = paper.get('DOI', '')
        url = paper.get('Source_URL', '')
        authors = paper.get('Authors', 'Unknown')
        year = paper.get('Year', '')
        
        # Prefer DOI link, fallback to source URL
        link = f"https://doi.org/{doi}" if doi else url
        
        html_body += f"""
        <div style="margin-bottom: 20px; padding: 15px; background-color: #f8f9fa; border-left: 4px solid #3498db;">
          <h3 style="margin-top: 0; color: #2c3e50;">{i}. {title}</h3>
          <p style="margin: 5px 0; color: #7f8c8d;">
            <strong>Authors:</strong> {authors[:100]}{'...' if len(str(authors)) > 100 else ''}<br>
            <strong>Year:</strong> {year}
          </p>
          <p style="margin: 10px 0;">
            <a href="{link}" style="color: #3498db; text-decoration: none;">üìÑ View Paper</a>
          </p>
        </div>
        """
    
    html_body += """
        <hr style="border: 1px solid #ecf0f1;">
        <p style="color: #95a5a6; font-size: 12px;">
          This is an automated alert from ScholarStack. 
          To manage your alerts, open the ScholarStack app.
        </p>
      </body>
    </html>
    """
    
    # Attach HTML
    msg.attach(MIMEText(html_body, 'html'))
    
    # Send email
    try:
        print(f"üìß Connecting to Gmail SMTP...")
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            print(f"üîê Logging in as {sender_email}...")
            server.login(sender_email, app_password)
            print(f"üì§ Sending email to {to_email}...")
            server.send_message(msg)
        
        print(f"‚úÖ Email sent successfully to {to_email}")
        return True
        
    except smtplib.SMTPAuthenticationError as e:
        print(f"‚ùå SMTP Authentication Error: {e}")
        print("   Check that GOOGLE_APP_PASSWORD is correct (16-char app password, not regular password)")
        return False
    except Exception as e:
        print(f"‚ùå Email send error: {e}")
        return False

def check_alerts(test_mode=False):
    """
    Check all active subscriptions for new papers.
    
    Args:
        test_mode: If True, uses time travel to trigger alerts
    """
    print("\n" + "="*60)
    print("üîç ScholarStack Alert Checker")
    print("="*60 + "\n")
    
    # Initialize database
    init_db()
    
    # Time travel for testing
    if test_mode:
        print("‚è∞ TEST MODE: Resetting dates to 30 days ago...")
        reset_dates_for_testing()
    
    # Get active subscriptions
    subscriptions = get_active_subscriptions()
    
    if not subscriptions:
        print("üì≠ No active subscriptions found.")
        return
    
    print(f"üì¨ Found {len(subscriptions)} active subscription(s)\n")
    
    for sub in subscriptions:
        sub_id = sub['id']
        email = sub['user_email']
        query = sub['search_query']
        source = sub['search_source']
        frequency = sub.get('frequency', 'daily')
        last_run = sub['last_run']
        
        print(f"üîé Checking: '{query}' for {email}")
        print(f"   Frequency: {frequency}")
        print(f"   Last checked: {last_run}")
        
        # Check if alert should run based on frequency
        from alert_scheduler import should_run_alert
        
        if not should_run_alert(str(last_run), frequency):
            print(f"   ‚è≠Ô∏è  Skipping (not time yet based on {frequency} schedule)\n")
            continue
        
        # TODO: Implement actual search logic using src/1_search_omni.py
        # For now, we'll simulate finding papers
        
        # Simulated new papers (in production, this would call the search API)
        new_papers = [
            {
                'Title': 'Example Paper on Spatial Audio',
                'Authors': 'Smith, J., Doe, A.',
                'Year': '2024',
                'DOI': '10.1234/example.2024',
                'Source_URL': 'https://example.com/paper1'
            }
        ]
        
        if new_papers:
            print(f"   ‚ú® Found {len(new_papers)} new paper(s)!")
            
            # Send notification
            success = send_notification_email(email, query, new_papers)
            
            if success:
                # Update last_run timestamp
                update_last_run(sub_id, datetime.now())
                print(f"   ‚úÖ Notification sent and timestamp updated\n")
            else:
                print(f"   ‚ùå Failed to send notification\n")
        else:
            print(f"   üì≠ No new papers found\n")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ScholarStack Alert Scheduler")
    parser.add_argument('--test', action='store_true', help='Run in test mode (time travel enabled)')
    args = parser.parse_args()
    
    check_alerts(test_mode=args.test)


==================================================
FILE: requirements.txt
==================================================
arxiv
semanticscholar
scholarly
habanero
unpywall
sickle
requests
beautifulsoup4
pandas
google-generativeai
tqdm
python-dotenv
streamlit
google-auth-oauthlib
google-api-python-client
ddgs
googlesearch-python


==================================================
FILE: PRIVACY.md
==================================================
# Privacy Policy for ScholarStack

**Last Updated:** December 30, 2024

## Overview

ScholarStack is a research paper discovery and management tool designed to help researchers find, organize, and manage academic papers. This privacy policy explains how we handle your data.

## Information We Collect

### Information You Provide
- **Google Account Information:** When you sign in with Google, we access:
  - Your name
  - Your email address
  - Your profile picture
- **Search Queries:** Topics and keywords you search for
- **Alert Subscriptions:** Email addresses and search queries for research alerts
- **Settings:** Your preferences for paper organization and search parameters

### Automatically Collected Information
- **Search History:** Locally stored record of your previous searches
- **Downloaded Papers:** Metadata about papers you've downloaded (titles, authors, DOIs, etc.)

## How We Use Your Information

We use the collected information to:
- **Authenticate Your Account:** Verify your identity via Google OAuth
- **Provide Core Functionality:** Search for papers, organize results, and manage your library
- **Send Research Alerts:** Email you when new papers matching your saved searches are found
- **Export to Google Drive:** Upload your research library to your Google Drive account (only when you explicitly request it)
- **Improve User Experience:** Remember your preferences and search history

## Data Storage

### Local Storage
- All data is stored **locally on your device**
- Search history, settings, and downloaded papers are stored in local files
- Alert subscriptions are stored in a local SQLite database (`data/alerts.db`)

### Google Services
- **Google OAuth:** Used only for authentication
- **Google Drive:** Used only when you explicitly click "Save to Drive" - uploads papers to a folder named `_Research_Assistant_Imports` in your Google Drive

### No Cloud Storage
- We do **not** store your data on any remote servers
- We do **not** share your data with third parties
- We do **not** sell your data

## Third-Party Services

ScholarStack integrates with the following third-party services:

1. **Google OAuth & Drive API**
   - Purpose: Authentication and optional file storage
   - Data shared: Name, email, profile picture (for OAuth); PDF files (for Drive export)
   - Privacy Policy: [Google Privacy Policy](https://policies.google.com/privacy)

2. **OpenAlex**
   - Purpose: Academic paper search
   - Data shared: Search queries
   - Privacy Policy: [OpenAlex Privacy](https://openalex.org/privacy)

3. **Unpaywall**
   - Purpose: Finding open-access versions of papers
   - Data shared: DOIs and search queries
   - Privacy Policy: [Unpaywall Privacy](https://unpaywall.org/legal)

4. **Gmail SMTP**
   - Purpose: Sending research alert emails
   - Data shared: Your email address and alert preferences
   - Privacy Policy: [Google Privacy Policy](https://policies.google.com/privacy)

## Data Security

- **OAuth Credentials:** Stored in session state (cleared when you sign out)
- **API Keys:** Stored in `.env` file (never committed to version control)
- **Local Files:** Protected by your device's file system permissions
- **Email Alerts:** Sent via encrypted SMTP (TLS)

## Your Rights

You have the right to:
- **Access Your Data:** All data is stored locally and accessible to you
- **Delete Your Data:** Delete local files, clear search history, or remove alert subscriptions at any time
- **Revoke Access:** Revoke ScholarStack's access to your Google account at [Google Account Permissions](https://myaccount.google.com/permissions)
- **Export Your Data:** Download your library as a ZIP file at any time

## Data Retention

- **Search History:** Retained locally until you clear it
- **Alert Subscriptions:** Retained until you delete them
- **Downloaded Papers:** Retained locally until you delete them
- **OAuth Tokens:** Cleared when you sign out or revoke access

## Children's Privacy

ScholarStack is not intended for use by children under 13. We do not knowingly collect personal information from children.

## Changes to This Policy

We may update this privacy policy from time to time. Changes will be reflected by updating the "Last Updated" date at the top of this policy.

## Open Source

ScholarStack is open-source software. You can review the code to verify our privacy practices at any time.

## Contact

For questions about this privacy policy or data practices, please contact the developer via the project repository.

## Consent

By using ScholarStack, you consent to this privacy policy.


==================================================
FILE: README.md
==================================================

# ScholarStack: Your AI Research Librarian

**ScholarStack** is an intelligent, AI-driven automation pipeline that acts as a digital librarian for building comprehensive academic libraries. It retrieves, reads, and organizes research papers, transforming a simple query into a **structured, downloadable library** categorized by AI.

## üöÄ Features

* **Omni-Channel Search**: Your librarian leverages **OpenAlex** to query a massive global index of research papers, utilizing **Unpaywall** to resolve open-access PDF links.
* **Topic Expansion**: Uses **Google Gemini** to generate intelligent search verticals (e.g., "Spatial Audio" -> "Ambisonics", "Binaural") to find papers that keyword matching often misses.
* **Smart Retrieval**: Aggressively acquires PDFs and validates file headers to ensure you receive high-quality, readable documents. Uses parallel processing for max speed.
* **Strict Taxonomy**: Powered by **Google Gemini**, the agent reads abstracts and organizes papers into precise, technical sub-fields (e.g., "Ambisonics" instead of "General Audio").
* **Search History & Persistence**: The app "remembers" your settings between sessions. A **Mission Log** lets you review and reload past search configurations instantly.
* **Curated Packaging**: Packages your research into a **downloadable ZIP file** or syncs it directly to **Google Drive**.
* **Modern Interface**: A Streamlit web app with **Research Modes** (Fast vs. Deep), sortable history, and granular controls.
* **Storage Management**: Automatically manages disk space by cleaning up old missions and serving large files efficiently.

---

---

## üìÇ Project Structure

*   **`src/`**: Core application code (`app.py`, pipelines).
*   **`data/`**: Application state (`search_history.json`, `user_settings.json`), search cache, and `Library/` output.
*   **`scripts/`**: Utility scripts for verification and debugging (e.g., `verify_density.py`).
*   **`tests/`**: Unit tests and test data.
*   **`PRPs/`**: Product Requirements Prompts (Feature backlog).

## üìÇ The "Stacked" Output

ScholarStack organizes your research into a clean, logical structure. Whether you download the **ZIP** or sync to **Drive**, you get:

```text
Library_Topic_Name/
‚îú‚îÄ‚îÄ Catalog_Summary.md          # A master manifest (includes Search Settings, Date Range, Sort Method)
‚îú‚îÄ‚îÄ Keyword_Folder/             # (Optional) Segregated by your specific search term
‚îÇ   ‚îú‚îÄ‚îÄ Category_A/             # Precise AI Cluster (e.g., "Diffraction Modeling")
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ paper_1.pdf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.json          # Metadata
‚îÇ   ‚îî‚îÄ‚îÄ Category_B/             # (e.g., "Binaural Rendering")
‚îÇ       ‚îî‚îÄ‚îÄ paper_2.pdf
‚îî‚îÄ‚îÄ ...

```

---

## üõ†Ô∏è Setup & Installation

### Prerequisites

1. **Python 3.10+**
2. **Google Cloud Project (for Auth & Drive Sync):**
* Create a project at [console.cloud.google.com](https://console.cloud.google.com).
* Enable **Google Drive API**.
* Create OAuth 2.0 Credentials (Web Application).
* Download the JSON and save it as `client_secrets.json` in the project root.


3. **Gemini API Key (Optional but Recommended):**
* Get a free key from [aistudio.google.com](https://aistudio.google.com).
* **Important:** Ensure your key is in a `.env` file as `GOOGLE_API_KEY=...`. The system is configured to prioritize this file over shell variables to prevent key exhaustion errors.



### Installation

```bash
git clone https://github.com/craig-van-hise/scholar-stack.git
cd scholar-stack
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

```

---

## üíª Running the Web App

To launch the interface:

```bash
source .venv/bin/activate && streamlit run src/app.py

```

* **Search & Curate**: Enter your topic and watch the librarian agent work in real-time.
* **Export**: Once the pipeline completes, download the organized **ZIP file** or click to sync the folder to your **Google Drive**.
* **AI Power**: Add your Gemini API Key in the "Settings" sidebar to enable the intelligent folder categorization.

---

## ‚ö†Ô∏è Notes

* **Data Privacy**: ScholarStack processes data locally and only exports to Google Drive if authorized.
* **Storage**: The app manages a local cache of recent missions. Older missions are automatically cleaned up to save space.
* **Rate Limits**: Includes automatic backoff for Semantic Scholar to prevent API interruptions.

## License

MIT License

---



==================================================
FILE: PROJECT_STATE.md
==================================================
# Project Status Report

**Date:** 2025-12-30
**Status:** Operational / Polished
**Current Phase:** Final Verification & Documentation

## Executive Summary
**ScholarStack** is now a robust, user-aligned research agent with a strictly organized codebase. We have refined the **Taxonomy Logic** (Per-Keyword), overhauled the **Search History UI**, and formally refactored the project structure into modular directories (`src`, `data`, `scripts`, `tests`). Recent additions include a **Fast Mode** for rapid research and a **Storage Management System** to handle large datasets efficiently.

## Implemented Architecture

### 1. The Omni-Search Module (`src/1_search_omni.py`)
*   **Search Verticals:** Successfully creates 15+ sub-topic queries (e.g. "Spatial Audio" -> "HRTF", "Ambisonics").
*   **Parallel Processing:** Uses `ThreadPoolExecutor` for high-speed OpenAlex querying.
*   **Metadata Capture:** Captures `Citation_Count` and maps Search Verticals to results.

### 2. The Interface (`src/app.py`)
*   **Research Modes:** Toggle between "Fast Mode" (Direct Download, ~15m) and "Deep Mode" (Full AI Clustering, ~90m).
*   **Persistence:** Automatically saves state to `data/user_settings.json`.
*   **Search History V2:** Multi-row selection table with explicit "Load" and "Delete" actions. History stored in `data/search_history.json`.
*   **Structure:** Code explicitly separated from data.

### 3. Core Pipeline (`src/2_cluster_taxonomy.py`)
*   **Per-Keyword Taxonomy:** AI categorization runs *per Search Vertical* for higher relevance.
*   **Count Stability:** Buffer logic (`Limit * 2`) prevents "Musical Chairs" paper loss.
*   **Paths:** Scripts auto-detect input/output paths in `data/` if running manually.

## Recent Accomplishments
*   **Fast Mode:** Implemented a high-speed research option that bypasses AI clustering for quick results.
*   **Storage Management:** Added automated cleanup of old missions and large file handling (serving direct downloads from disk) to prevent server crashes.
*   **Project Refactor:** Cleaned root directory. Moved source code to `src/`, data to `data/`, tools to `scripts/`.
*   **UI Polish:** "Zombie Modal" fixed. Search History uses native multi-select and persistent resizing.

## Technical Notes
*   **Launch Command:** `source .venv/bin/activate && streamlit run src/app.py`
*   **Data Storage:** All generated files (Library, CSVs, Cache) now reside in `data/`.



==================================================
FILE: TERMS.md
==================================================
# Terms of Service for ScholarStack

**Last Updated:** December 30, 2024

## 1. Acceptance of Terms

By accessing and using ScholarStack ("the Software"), you accept and agree to be bound by these Terms of Service ("Terms"). If you do not agree to these Terms, do not use the Software.

## 2. Description of Service

ScholarStack is an open-source research paper discovery and management tool that:
- Searches academic databases for research papers
- Organizes and categorizes research findings
- Downloads open-access papers
- Sends email alerts for new research
- Exports libraries to Google Drive

## 3. License

ScholarStack is provided as open-source software. The specific license terms are defined in the LICENSE file included with the Software.

## 4. User Responsibilities

### 4.1 Acceptable Use
You agree to use ScholarStack only for lawful purposes and in accordance with these Terms. You agree NOT to:
- Use the Software to violate any applicable laws or regulations
- Attempt to gain unauthorized access to any systems or networks
- Use the Software to download copyrighted materials without proper authorization
- Abuse or overload third-party APIs (OpenAlex, Unpaywall, etc.)
- Share your Google OAuth credentials with others

### 4.2 Academic Integrity
You are responsible for:
- Properly citing all papers you download and use
- Respecting copyright and licensing terms of downloaded papers
- Using open-access papers in accordance with their licenses
- Verifying the accuracy of metadata and citations

### 4.3 API Usage
You agree to:
- Respect rate limits of third-party services
- Use your own API keys where required
- Not abuse the email alert system for spam

## 5. Third-Party Services

ScholarStack integrates with third-party services including:
- Google OAuth and Drive API
- OpenAlex
- Unpaywall
- Gmail SMTP

Your use of these services is subject to their respective terms of service and privacy policies. We are not responsible for the availability, accuracy, or policies of these third-party services.

## 6. Disclaimer of Warranties

**THE SOFTWARE IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY KIND.**

We make no warranties, expressed or implied, including but not limited to:
- Fitness for a particular purpose
- Accuracy or completeness of search results
- Availability or reliability of the service
- Freedom from errors or bugs
- Compatibility with your system

## 7. Limitation of Liability

**TO THE MAXIMUM EXTENT PERMITTED BY LAW:**

We shall not be liable for any:
- Direct, indirect, incidental, or consequential damages
- Loss of data, profits, or business opportunities
- Damages resulting from use or inability to use the Software
- Damages from third-party services or content
- Damages from unauthorized access to your data

## 8. Data and Privacy

### 8.1 Local Storage
All data is stored locally on your device. You are responsible for:
- Backing up your data
- Securing your device
- Managing your local storage

### 8.2 Privacy
Your use of ScholarStack is subject to our Privacy Policy (see PRIVACY.md).

### 8.3 Google Services
When you sign in with Google or use Google Drive export:
- You grant ScholarStack permission to access your Google account as specified in the OAuth consent
- You can revoke this access at any time via Google Account settings
- We do not store your Google credentials

## 9. Intellectual Property

### 9.1 Software
ScholarStack is open-source software. Intellectual property rights are governed by the LICENSE file.

### 9.2 Downloaded Content
Papers and content downloaded through ScholarStack remain the intellectual property of their respective authors and publishers. You must respect all copyright and licensing terms.

### 9.3 User Data
You retain all rights to your search queries, notes, and organizational structures.

## 10. Modifications to Service

We reserve the right to:
- Modify or discontinue the Software at any time
- Update these Terms with or without notice
- Change features or functionality

Continued use of the Software after changes constitutes acceptance of the modified Terms.

## 11. Termination

You may stop using ScholarStack at any time by:
- Uninstalling the Software
- Deleting local data files
- Revoking Google OAuth access

We may terminate or suspend access to the Software for violations of these Terms.

## 12. Open Source

As open-source software:
- You may inspect the source code
- You may modify the Software for personal use
- Redistribution is subject to the LICENSE terms
- We welcome contributions via the project repository

## 13. Email Alerts

When using the email alert feature:
- You consent to receive automated emails about new research
- You can unsubscribe by deleting your alert subscriptions
- We are not responsible for email deliverability
- You must provide a valid email address

## 14. Export Features

When exporting to Google Drive:
- Files are uploaded to your personal Google Drive
- You are responsible for managing Drive storage limits
- We are not responsible for data loss during upload
- You can delete uploaded files at any time

## 15. No Professional Advice

ScholarStack is a research tool only. It does not provide:
- Legal advice
- Medical advice
- Professional consultation
- Academic endorsement

## 16. Indemnification

You agree to indemnify and hold harmless the developers and contributors of ScholarStack from any claims, damages, or expenses arising from:
- Your use of the Software
- Your violation of these Terms
- Your violation of any third-party rights

## 17. Governing Law

These Terms shall be governed by and construed in accordance with applicable laws, without regard to conflict of law principles.

## 18. Severability

If any provision of these Terms is found to be unenforceable, the remaining provisions shall remain in full force and effect.

## 19. Entire Agreement

These Terms, together with the Privacy Policy, constitute the entire agreement between you and ScholarStack regarding use of the Software.

## 20. Contact

For questions about these Terms, please contact the developer via the project repository.

## 21. Acknowledgment

By using ScholarStack, you acknowledge that you have read, understood, and agree to be bound by these Terms of Service.

---

**For Developers and Contributors:**

If you contribute to ScholarStack, you agree that your contributions will be licensed under the same license as the project.


==================================================
FILE: test_json.py
==================================================

import importlib.util
import sys
import json

# Import module manually because it starts with a number
spec = importlib.util.spec_from_file_location("cluster_mod", "src/2_cluster_taxonomy.py")
cluster_mod = importlib.util.module_from_spec(spec)
sys.modules["cluster_mod"] = cluster_mod
spec.loader.exec_module(cluster_mod)

clean_json_string = cluster_mod.clean_json_string

test_str_markdown = """```json
{"id": "123"}
```"""

test_str_raw = """
{"id": "456"}
"""

assert json.loads(clean_json_string(test_str_markdown))['id'] == "123"
assert json.loads(clean_json_string(test_str_raw))['id'] == "456"

print("‚úÖ clean_json_string tests passed.")


==================================================
FILE: # target for returns on use-case.md
==================================================
Based on a search of major open-access repositories (arXiv, ResearchGate, and university archives), you can find **approximately 200‚Äì400 high-quality open access research papers** that specifically focus on "spatial audio" and "crosstalk cancellation."

If you broaden your criteria to include papers that merely *mention* these terms rather than focusing on them as a primary topic, the number rises to the **low thousands (1,000+)**.

Here is the breakdown of where these papers are located and examples of what you will find.

### 1. Approximate Count by Source

* **arXiv.org (Preprints):** ~50‚Äì100 papers. These are often the most recent (2020‚Äì2025) and frequently include links to code or datasets.
* **ResearchGate (Author-Uploaded):** ~200+ papers. Many authors upload the "accepted version" of their IEEE or AES papers here for free public access.
* **University Repositories:** ~100+ papers. Universities with strong audio labs (like the University of Southampton or Princeton) often host their PhD theses and conference papers publicly.

### 2. Selected Open Source/Access Papers Found

Here are five concrete examples of papers found during this search that you can read immediately for free:

* **"Spatial Audio Empowered Smart Speakers with Xblock" (2023)**
* *Topic:* A pose-adaptive crosstalk cancellation algorithm for free-moving users.
* *Source:* arXiv / ResearchGate


* **"Optimal Crosstalk Cancellation for Binaural Audio with Two Loudspeakers"**
* *Topic:* Theoretical analysis of the "sweet spot" and filter design for two-speaker setups.
* *Source:* Princeton University / Semantic Scholar


* **"Investigation on a Crosstalk Cancellation Algorithm for Binaural Audio Headrest" (2025)**
* *Topic:* Applying crosstalk cancellation specifically to headrests in cars to create immersive audio without headphones.
* *Source:* ResearchGate (Journal of the Audio Engineering Society draft)


* **"Towards Faster Continuous Multi-Channel HRTF Measurements Based on Learning System Models" (2021)**
* *Topic:* While focused on HRTF, this paper explicitly discusses crosstalk cancellation for loudspeaker reproduction and includes links to **code and data**.
* *Source:* arXiv:2110.03630


* **"Crosstalk Cancellation in Virtual Acoustic Imaging Systems for Multiple Listeners"**
* *Topic:* Addressing the difficult problem of canceling crosstalk for more than one person at a time.
* *Source:* University of Southampton (ISVR)



### 3. "Open Source" vs. "Open Access"

* **Open Access (Papers):** As noted above, there are hundreds of free PDFs available.
* **Open Source (Code):** Actual *code* implementations are rarer. However, papers on **arXiv** are your best bet. Look for papers titled "Reproducible research" or those with a "GitHub" link in the abstract.
* *Tip:* Search GitHub for "Crosstalk Cancellation" directly. You will find roughly **10‚Äì20 repositories** (mostly Python and MATLAB implementations) that correspond to these research papers.



### 4. How to Find Them (Search Strings)

To access these specific papers, use these targeted search strings in Google or Google Scholar:

* **For PDFs:** `filetype:pdf "spatial audio" "crosstalk cancellation"`
* **For arXiv specifically:** `site:arxiv.org "spatial audio" "crosstalk cancellation"`
* **For Code:** `site:github.com "crosstalk cancellation" audio`



==================================================
FILE: # Guide to OpenAlex parameters.md
==================================================
In the context of the OpenAlex API, "args" are the **query parameters** you append to the URL (e.g., `?search=...&filter=...`).

Because OpenAlex is a REST API, these arguments are universal across all endpoints (Works, Authors, Sources, etc.), but the *values* they accept change depending on what you are searching.

Here is the complete reference guide to the input arguments, categorized by function.

---

### **1. The "Big Six" Control Arguments**

These are the top-level parameters you will use to control *what* you get back and *how* it looks.

| Argument | Purpose | Example Value |
| --- | --- | --- |
| **`search`** | The "Google" bar. Searches titles, abstracts, and full text. | `?search=generative+ai` |
| **`filter`** | Precise constraints. The most powerful argument (see ¬ß2). | `?filter=is_oa:true,year:2024` |
| **`select`** | Limits the response fields (reduces JSON size/latency). | `?select=id,title,doi` |
| **`sort`** | Controls the order of results. | `?sort=cited_by_count:desc` |
| **`per-page`** | Number of results per request (Max: 200). | `?per-page=200` |
| **`page`** | Pagination (Works for the first 10k results). | `?page=2` |

---

### **2. Deep Dive: The `filter` Argument**

The `filter` argument is a container for dozens of specific "keys." You verify these by appending them as a comma-separated string: `filter=key1:value1,key2:value2`.

**Common Filter Keys for Papers (Works):**

| Category | Filter Key | Description |
| --- | --- | --- |
| **Access** | `is_oa` | `true`/`false`. Is the paper free to read? |
|  | `has_doi` | `true`/`false`. Does it have a valid DOI? |
|  | `open_access.oa_status` | `gold`, `green`, `bronze`, `hybrid`. |
| **Dates** | `publication_year` | E.g., `2023` or `>2020` (ranges supported). |
|  | `from_publication_date` | `2023-01-01` (Specific start date). |
|  | `to_publication_date` | `2023-12-31` (Specific end date). |
| **Impact** | `cited_by_count` | `>100`. Papers with high citations. |
|  | `has_fulltext` | `true`. Works where OpenAlex indexed the full text. |
| **Identity** | `authorships.author.id` | Search for a specific author by OpenAlex ID. |
|  | `primary_location.source.id` | Search for a specific Journal/Conference ID. |
|  | `institutions.id` | Search for papers from a specific university. |
| **Content** | `type` | `article`, `book-chapter`, `dissertation`. |
|  | `language` | `en`, `fr`, `zh`, etc. |

---

### **3. Deep Dive: The `search` Argument**

While `?search=` searches everything, you can also be surgical by attaching `.search` to specific fields within the filter parameter (a common "power user" trick).

* **Standard:** `?search=dna` (Searches title, abstract, and full text).
* **Title Only:** `?filter=title.search:dna` (Ignores mentions in the abstract).
* **Abstract Only:** `?filter=abstract.search:dna` (Only looks inside the abstract).
* **Affiliation:** `?filter=raw_affiliation_string.search:harvard` (Finds strings like "Harvard Medical School").

---

### **4. Advanced & Utility Arguments**

These are less common but critical for specific scraping tasks.

| Argument | Purpose |
| --- | --- |
| **`cursor`** | **Critical for Deep Scraping.** Used instead of `page` to retrieve >10,000 results. You pass the `next_cursor` string returned in the previous API response. |
| **`sample`** | Returns a random sample of  papers. `?sample=50`. Great for testing pipelines. |
| **`seed`** | Used with `sample`. Ensures the "random" sample is the same every time you run it (reproducibility). |
| **`group_by`** | Returns summary statistics instead of a list of papers. E.g., `?group_by=publication_year` returns a count of papers per year. |
| **`mailto`** | Not a query param, but **highly recommended**. Add `&mailto=your@email.com` to get into the "polite pool" (faster response times). |

### **5. Valid Sort Options**

You can sort by almost any numerical or date field. Add `:desc` (descending) or `:asc` (ascending).

* `relevance_score` (Default when searching)
* `publication_year`
* `publication_date`
* `cited_by_count` (Find the most influential papers)
* `title` (Alphabetical)

### **Example: The "Perfect" Query**

If you want **50 highly-cited Open Access papers on LLMs from 2024**, your URL inputs would look like this:

```http
https://api.openalex.org/works?
  search=Large Language Models
  &filter=is_oa:true,publication_year:2024,cited_by_count:>10
  &sort=cited_by_count:desc
  &per-page=50
  &select=id,title,open_access,cited_by_count
  &mailto=yourname@example.com

```

==================================================
FILE: .idx/airules.md
==================================================
# Gemini AI Rules for Firebase Studio Nix Projects

## 1. Persona & Expertise

You are an expert in configuring development environments within Firebase Studio. You are proficient in using the `dev.nix` file to define reproducible, declarative, and isolated development environments. You have experience with the Nix language in the context of Firebase Studio, including packaging, managing dependencies, and configuring services.

## 2. Project Context

This project is a Nix-based environment for Firebase Studio, defined by a `.idx/dev.nix` file. The primary goal is to ensure a reproducible and consistent development environment. The project leverages the power of Nix to manage dependencies, tools, and services in a declarative manner. **Note:** This is not a Nix Flake-based environment.

## 3. `dev.nix` Configuration

The `.idx/dev.nix` file is the single source of truth for the development environment. Here are some of the most common configuration options:

### `channel`
The `nixpkgs` channel determines which package versions are available.

```nix
{ pkgs, ... }: {
  channel = "stable-24.05"; # or "unstable"
}
```

### `packages`
A list of packages to install from the specified channel. You can search for packages on the [NixOS package search](https://search.nixos.org/packages).

```nix
{ pkgs, ... }: {
  packages = [
    pkgs.nodejs_20
    pkgs.go
  ];
}
```

### `env`
A set of environment variables to define within the workspace.

```nix
{ pkgs, ... }: {
  env = {
    API_KEY = "your-secret-key";
  };
}
```

### `idx.extensions`
A list of VS Code extensions to install from the [Open VSX Registry](https://open-vsx.org/).

```nix
{ pkgs, ... }: {
  idx = {
    extensions = [
      "vscodevim.vim"
      "golang.go"
    ];
  };
}
```

### `idx.workspace`
Workspace lifecycle hooks.

- **`onCreate`:** Runs when a workspace is first created.
- **`onStart`:** Runs every time the workspace is (re)started.

```nix
{ pkgs, ... }: {
  idx = {
    workspace = {
      onCreate = {
        npm-install = "npm install";
      };
      onStart = {
        start-server = "npm run dev";
      };
    };
  };
}
```

### `idx.previews`
Configure a web preview for your application. The `$PORT` variable is dynamically assigned.

```nix
{ pkgs, ... }: {
  idx = {
    previews = {
      enable = true;
      previews = {
        web = {
          command = ["npm" "run" "dev" "--" "--port" "$PORT"];
          manager = "web";
        };
      };
    };
  };
}
```

## 4. Example Setups for Common Frameworks

Here are some examples of how to configure your `dev.nix` for common languages and frameworks.

### Node.js Web Server
This example sets up a Node.js environment, installs dependencies, and runs a development server with a web preview.

```nix
{ pkgs, ... }: {
  packages = [ pkgs.nodejs_20 ];
  idx = {
    extensions = [ "dbaeumer.vscode-eslint" ];
    workspace = {
      onCreate = {
        npm-install = "npm install";
      };
      onStart = {
        dev-server = "npm run dev";
      };
    };
    previews = {
      enable = true;
      previews = {
        web = {
          command = ["npm" "run" "dev" "--" "--port" "$PORT"];
          manager = "web";
        };
      };
    };
  };
}
```

### Python with Flask
This example sets up a Python environment for a Flask web server. Remember to create a `requirements.txt` file with `Flask` in it.

```nix
{ pkgs, ... }: {
  packages = [ pkgs.python3 pkgs.pip ];
  idx = {
    extensions = [ "ms-python.python" ];
    workspace = {
      onCreate = {
        pip-install = "pip install -r requirements.txt";
      };
    };
    previews = {
      enable = true;
      previews = {
        web = {
          command = ["flask" "run" "--port" "$PORT"];
          manager = "web";
        };
      };
    };
  };
}
```

### Go CLI
This example sets up a Go environment for building a command-line interface.

```nix
{ pkgs, ... }: {
  packages = [ pkgs.go ];
  idx = {
    extensions = [ "golang.go" ];
    workspace = {
      onCreate = {
        go-mod = "go mod tidy";
      };
      onStart = {
        run-app = "go run .";
      };
    };
  };
}
```

## 5. Interaction Guidelines

- Assume the user is familiar with general software development concepts but may be new to Nix and Firebase Studio.
- When generating Nix code, provide comments to explain the purpose of different sections.
- Explain the benefits of using `dev.nix` for reproducibility and dependency management.
- If a request is ambiguous, ask for clarification on the desired tools, libraries, and versions to be included in the environment.
- When suggesting changes to `dev.nix`, explain the impact of the changes on the development environment and remind the user to reload the environment.


==================================================
FILE: tests/test_quota_failover.py
==================================================

import importlib.util
import sys
import unittest
from unittest.mock import MagicMock, patch

# Dynamically import the script
spec = importlib.util.spec_from_file_location("search_omni", "1_search_omni.py")
search_omni = importlib.util.module_from_spec(spec)
sys.modules["search_omni"] = search_omni
spec.loader.exec_module(search_omni)

ResearchCrawler = search_omni.ResearchCrawler

class TestQuotaFailover(unittest.TestCase):
    def setUp(self):
        self.crawler = ResearchCrawler(
            topic="Spatial Audio", keywords="HRTF", author="", publication="", 
            date_start="", date_end="", count=10, sites=[], no_llm=False
        )

    def test_verticals_quota_exhaustion(self):
        print("\n‚ö°Ô∏è TEST: Simulating Global 429 Quota Exhaustion...")
        
        # Mock the client and generate_content to raise Exception
        mock_client = MagicMock()
        mock_models = MagicMock()
        # Side effect: always raise Exception with "429"
        mock_models.generate_content.side_effect = Exception("429 RESOURCE_EXHAUSTED: You have exceeded your quota.")
        mock_client.models = mock_models
        
        # Patch get_genai_client to return our mock
        with patch.object(self.crawler, 'get_genai_client', return_value=mock_client):
            # Patch time.sleep to run fast
            with patch('time.sleep', return_value=None):
                verticals = self.crawler.get_search_verticals_from_llm("Spatial Audio")
                
        print(f"   -> Resulting Verticals: {verticals}")
        
    def test_global_circuit_breaker(self):
        print("\n‚ö°Ô∏è TEST: Verifying Circuit Breaker (Auto-Kill LLM)...")
        # Ensure LLM is on initially
        self.crawler.no_llm = False
        
        mock_client = MagicMock()
        mock_models = MagicMock()
        # First call triggers RESOURCE_EXHAUSTED
        mock_models.generate_content.side_effect = Exception("429 RESOURCE_EXHAUSTED")
        mock_client.models = mock_models
        
        with patch.object(self.crawler, 'get_genai_client', return_value=mock_client):
            with patch('time.sleep', return_value=None): # Speed up first fail
                # Call 1: Should trigger kill switch
                self.crawler._query_llm_with_rotation("test")
                
        # Assert kill switch is active
        if self.crawler.no_llm:
            print("   ‚úÖ Circuit Breaker ACTIVATED: no_llm is now True.")
        else:
            print("   ‚ùå Circuit Breaker FAILED: no_llm is still False.")
            self.fail("Circuit breaker failed.")
            
        # Call 2: Should return None immediately (mock not called)
        with patch.object(self.crawler, 'get_genai_client') as mock_get_client:
             res = self.crawler._query_llm_with_rotation("test 2")
             if res is None and not mock_get_client.called:
                 print("   ‚úÖ Short-Circuit Logic WORKS: API not called.")
             else:
                 print("   ‚ùå Short-Circuit Logic FAILED.")

if __name__ == '__main__':
    unittest.main()


==================================================
FILE: tests/test_real_api_connection.py
==================================================

import os
from dotenv import load_dotenv
from google import genai
import time

# Load environment
load_dotenv()

key = os.getenv("GOOGLE_API_KEY")

print("\nüîç API DIAGNOSTIC UTIL")
print("=======================")

if not key:
    print("‚ùå ERROR: GOOGLE_API_KEY not found in environment.")
    exit(1)

print(f"üîë Key loaded: {key[:8]}...{key[-4:]} (Length: {len(key)})")
print("   (Please compare this prefix with the credentials in your Google Cloud Console)\n")

print("üì° Attempting connection to 'gemini-2.0-flash-001'...")

try:
    client = genai.Client(api_key=key)
    prompt = "Hello. Reply with 'OK'."
    
    start = time.time()
    response = client.models.generate_content(model='gemini-2.0-flash-001', contents=prompt)
    duration = time.time() - start
    
    print("\n‚úÖ SUCCESS!")
    print(f"   Response: {response.text.strip()}")
    print(f"   Latency: {duration:.2f}s")
    
    # Try to inspect usage metadata if available
    if hasattr(response, 'usage_metadata'):
        print(f"   Usage Metadata: {response.usage_metadata}")

except Exception as e:
    print("\n‚ùå FAILURE / QUOTA HIT")
    print(f"   Type: {type(e).__name__}")
    print(f"   Message: {e}")
    # Print full details if it's an API error
    if hasattr(e, 'message'):
        print(f"   Full Details: {e.message}")


==================================================
FILE: tests/test_pdf_resolution.py
==================================================

import sys
import os
import requests
import pandas as pd
from tqdm import tqdm

# Add parent directory to path so we can import from 3_download_library
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from library_downloader import attempt_ddg_fallback, attempt_secondary_search
except ImportError:
    # Try importing directly if the file is named 3_download_library.py
    # We might need to rename it or dynamic import to test it properly without renaming
    import importlib.util
    spec = importlib.util.spec_from_file_location("library_downloader", os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "3_download_library.py"))
    library_downloader = importlib.util.module_from_spec(spec)
    sys.modules["library_downloader"] = library_downloader
    spec.loader.exec_module(library_downloader)
    attempt_ddg_fallback = library_downloader.attempt_ddg_fallback
    attempt_secondary_search = library_downloader.attempt_secondary_search


MISSING_PAPERS = [
    "Influence of height-channel contents on enhancing spatial impressions through virtually elevated loudspeaker",
    "A Spatial Audio System Using Multiple Microphones on a Rigid Sphere",
    "Recent Advances in an Open Software for Numerical HRTF Calculation",
    "A Unified Approach To Numerical Auditory Scene Synthesis Using Loudspeaker Arrays",
    "Sound Source and Loudspeaker Base Angle Dependency of Phantom Image Elevation Effect",
    "The SONICOM HRTF Dataset"
]

def test_retrieval_logic():
    print(f"=== TEST SUITE: Resolving {len(MISSING_PAPERS)} Missing Papers ===")
    
    # Import download_file
    try:
        download_file = library_downloader.download_file
    except AttributeError:
        # Fallback if import weirdness
        def download_file(url, path):
            try:
                r = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
                if r.status_code == 200 and b'%PDF' in r.content[:1024]:
                    return True
            except: pass
            return False

    results = []
    
    
        
    for title in MISSING_PAPERS:
        print(f"\nüîé Testing: {title}")
        
        found_url = False
        download_success = False
        method = None
        final_url = None
        
        # 1. Secondary Search (Semantic Scholar)
        url = attempt_secondary_search(title)
        
        if url:
             print(f"   [Secondary] Found: {url}")
             # Try Download
             temp_path = f"temp_test_{abs(hash(title))}.pdf"
             if download_file(url, temp_path):
                 download_success = True
                 method = "Secondary"
                 final_url = url
                 print(f"   -> üíæ Secondary Search SUCCESS")
                 if os.path.exists(temp_path): os.remove(temp_path)
             else:
                 print(f"   -> ‚ùå Secondary Download FAILED (proceeding to fallback)")
                 
        # 2. DDG Fallback (if Secondary failed search OR download)
        if not download_success:
            candidates = attempt_ddg_fallback(title)
            if candidates:
                for cand_url in candidates:
                    print(f"   [DDG] Candidate: {cand_url}")
                    temp_path = f"temp_test_{abs(hash(title))}.pdf"
                    if download_file(cand_url, temp_path):
                        download_success = True
                        method = "DDG"
                        final_url = cand_url
                        print(f"   -> üíæ DDG Search SUCCESS")
                        if os.path.exists(temp_path): os.remove(temp_path)
                        break
                    else:
                        print(f"   -> ‚ùå DDG Download FAILED (Candidate Failed)")


        results.append({
            "title": title,
            "found_url": final_url is not None,
            "download_success": download_success,
            "method": method,
            "url": final_url
        })
        
    # Summary
    found_count = len([r for r in results if r['found_url']])
    downloaded_count = len([r for r in results if r['download_success']])
    
    print("\n" + "="*40)
    print(f"SUMMARY: {downloaded_count}/{len(MISSING_PAPERS)} Papers Fully Resolved (Downloaded)")
    print(f"         {found_count}/{len(MISSING_PAPERS)} URLs Found")
    print("="*40)
    
    if downloaded_count < len(MISSING_PAPERS) * 0.5:
        print("‚ùå FAILURE: Download rate < 50%")
        sys.exit(1)
    else:
        print("‚úÖ SUCCESS: Download rate >= 50%")
        sys.exit(0)

if __name__ == "__main__":
    test_retrieval_logic()


==================================================
FILE: tests/test_quota.py
==================================================

from google import genai
import os
import time
from dotenv import load_dotenv

load_dotenv()
client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

model = "gemini-2.0-flash-001"
print(f"‚ö°Ô∏è Stress Testing Model: {model} with 5 rapid-fire requests...")

try:
    for i in range(5):
        print(f"   Request {i+1}/5...", end="", flush=True)
        start = time.time()
        client.models.generate_content(model=model, contents=f"Reply with the number {i}")
        print(f" OK ({time.time()-start:.2f}s)")
    print("\n‚úÖ PASSED. Model can handle burst traffic.")
except Exception as e:
    print(f"\n‚ùå FAILED. Error: {e}")


==================================================
FILE: tests/test_crawler_logic.py
==================================================
import unittest
from unittest.mock import MagicMock, patch
import json
import sys
import os
import importlib.util

# Adjust import for '1_search_omni.py' which is not a standard module name
try:
    if os.path.exists("1_search_omni.py"):
        spec = importlib.util.spec_from_file_location("research_crawler", "1_search_omni.py")
        research_crawler = importlib.util.module_from_spec(spec)
        sys.modules["research_crawler"] = research_crawler
        spec.loader.exec_module(research_crawler)
        from research_crawler import ResearchCrawler
    else:
        # Fallback if testing in an environment where file is named differently or standard import works
        from research_crawler import ResearchCrawler
except ImportError:
    print("‚ö†Ô∏è Warning: '1_search_omni.py' not found. Ensure it is in the same directory.")
    sys.exit(1)

class TestTrustBasedLogic(unittest.TestCase):
    
    def setUp(self):
        """Setup a crawler instance with dummy data for each test."""
        # Initialize with dummy values
        self.crawler = ResearchCrawler(
            topic="Spatial Audio",
            keywords="crosstalk cancellation",
            author=None, publication=None, 
            date_start="2020-01-01", date_end="2024-01-01",
            count=10, sites=None
        )
        
        # Define fake IDs for the mocking logic
        self.GHOST_ID = "W88888888"  # The seminal paper
        self.VIP_ID = "A99999999"    # The expert author (e.g., Choueiri)
        self.VIP_NAME = "Dr. Audio Expert"

    @patch('research_crawler.genai.Client')
    def test_iterative_loop_logic(self, mock_client_cls):
        """Test the Iterative "Divide and Conquer" Logic."""
        print("\nüß™ TEST: Iterative Loop Execution")
        
        # 1. Mock GenAI Client & Models
        mock_client = MagicMock()
        mock_client_cls.return_value = mock_client
        
        # Mock models.list()
        mock_model_obj = MagicMock()
        mock_model_obj.name = "models/gemini-1.5-flash"
        mock_client.models.list.return_value = [mock_model_obj]
        
        # Mock models.generate_content() response for Verticals
        mock_resp = MagicMock()
        mock_resp.text = '"Ambisonics", "Binaural", "Wave Field Synthesis"'
        mock_client.models.generate_content.return_value = mock_resp
        
        # 2. Patch execute_openalex_query to count calls
        with patch.object(self.crawler, 'execute_openalex_query') as mock_execute:
            self.crawler.search_via_iterative_loop()
            
            # 3. Assertions
            # Should call 4 times: 1 (Original Topic) + 3 (LLM Verticals)
            # Or fewer if originals are deduped. Original "Spatial Audio" is not in the list I mocked above.
            # Verticals: ["Spatial Audio", "Ambisonics", "Binaural", "Wave Field Synthesis"]
            
            self.assertEqual(mock_execute.call_count, 4)
            
            # Check a sample call args
            calls = mock_execute.call_args_list
            # First call should be the original topic "Spatial Audio"
            args1, _ = calls[0]
            label1, _, query1 = args1
            self.assertIn('"Spatial Audio"', query1)
            self.assertIn('"crosstalk cancellation"', query1)
            
            # Second call should be "Ambisonics"
            args2, _ = calls[1]
            label2, _, query2 = args2
            self.assertIn('"Ambisonics"', query2)
            
            print("‚úÖ Passed: Iterative Loop triggered correctly for multiple verticals.")

    def test_deduplication_and_inferred_acceptance(self):
        """Test PRP 9.9.9.1: Deduplication + Metadata Audit + Inferred Acceptance."""
        print("\nüß™ TEST: Trust-Based Validation (Dedup & Inference)")
        
        # Candidate 1: Perfect Match (should be Accepted)
        c1 = {
            'id': 'W1', 
            'title': 'Crosstalk Cancellation in Audio', 
            'description': 'This paper discusses filters.',
            'keywords': 'spatial audio',
            'url': 'http://pdf1', 'doi': '10.1/1', 'authors': 'A', 'date': '2023', 'source_name': 'OA'
        }
        
        # Candidate 2: No Keyword Match (should be Accepted as Inferred)
        c2 = {
            'id': 'W2', 
            'title': 'Generic Audio Paper', 
            'description': 'Abstract truncated...', 
            'keywords': 'sound',
            'url': 'http://pdf2', 'doi': '10.1/2', 'authors': 'B', 'date': '2023', 'source_name': 'OA'
        }
        
        # Candidate 3: Duplicate of W1 (should be skipped)
        c3 = {
            'id': 'W1', # SAME ID
            'title': 'Crosstalk Cancellation in Audio', 
            'description': 'Duplicate.',
            'keywords': 'spatial audio',
            'url': 'http://pdf1', 'doi': '10.1/1', 'authors': 'A', 'date': '2023', 'source_name': 'OA'
        }
        
        batch = [c1, c2, c3]
        
        # Run _process_batch
        self.crawler._process_batch(batch)
        
        # Assertions
        results = self.crawler.results
        print(f"   Debug: Results count = {len(results)}")
        
        self.assertEqual(len(results), 2, "Should accept W1 (Match) and W2 (Inferred), but reject W3 (Dupe).")
        
        # Check W1
        titles = [r['Title'] for r in results]
        self.assertIn("Crosstalk Cancellation in Audio", titles)
        self.assertIn("Generic Audio Paper", titles)
        
        # Verify IDs in seen_ids
        self.assertIn('W1', self.crawler.seen_ids)
        self.assertIn('W2', self.crawler.seen_ids)
        
        print("‚úÖ Passed: Deduplication and Inferred Acceptance logic is valid.")
    @patch('research_crawler.fitz.open')
    def test_validate_full_text_success(self, mock_fitz_open):
        """Test strict regex validation on extracted PDF text (Success Case)."""
        print("\nüß™ TEST: validate_full_text (Success)")
        
        # Mock PDF Doc
        mock_doc = MagicMock()
        mock_doc.page_count = 5 # Ensure it loops only first 2
        mock_page = MagicMock()
        mock_page.get_text.return_value = "This paper discusses crosstalk-cancellation techniques in detail."
        mock_doc.load_page.return_value = mock_page
        mock_fitz_open.return_value = mock_doc
        
        mock_content = b"%PDF-1.4 Fake Content"
        is_valid, reason = self.crawler._validate_full_text(mock_content, ["crosstalk cancellation"])
        
        self.assertTrue(is_valid)
        self.assertIn("Found match", reason)
        print("‚úÖ Passed: Correctly identified hyphenated keyword 'crosstalk-cancellation'.")

    @patch('research_crawler.fitz.open')
    def test_validate_full_text_failure(self, mock_fitz_open):
        """Test strict regex validation failure when keyword is missing."""
        print("\nüß™ TEST: validate_full_text (Failure)")
        
        mock_doc = MagicMock()
        mock_doc.page_count = 1
        mock_page = MagicMock()
        mock_page.get_text.return_value = "This paper is about completely unrelated pizza topics."
        mock_doc.load_page.return_value = mock_page
        mock_fitz_open.return_value = mock_doc
        
        mock_content = b"%PDF-1.4 Fake Content"
        is_valid, reason = self.crawler._validate_full_text(mock_content, ["crosstalk cancellation"])
        
        self.assertFalse(is_valid)
        self.assertIn("No keywords found", reason)
        print("‚úÖ Passed: Correctly rejected irrelevant text.")

    def test_live_integration_sanity_check(self):
        """
        ‚ö†Ô∏è LIVE TEST: Hits the real OpenAlex API.
        This verifies that the 'Crosstalk -> Choueiri' citation path actually exists in reality.
        """
        # Skip if explicitly disabled (e.g., CI/CD), but let Agent run it by default
        if os.getenv("SKIP_LIVE_TESTS"):
            print("\n‚ö†Ô∏è Skipping Live Test (SKIP_LIVE_TESTS is set)")
            return

        print("\nüåç LIVE TEST: Hitting OpenAlex API to verify 'Crosstalk' Citation Chain...")
        
        # 1. Search for "crosstalk cancellation" (small batch)
        url = "https://api.openalex.org/works"
        params = {
            "filter": "title_and_abstract.search:crosstalk cancellation",
            "per-page": 20,
            "select": "referenced_works"
        }
        try:
            resp = self.crawler.session.get(url, params=params, timeout=10)
            if resp.status_code != 200:
                print("‚ùå API Error: Could not reach OpenAlex.")
                return
            
            data = resp.json()
            
            # 2. Count citations
            from collections import Counter
            c = Counter()
            for w in data.get('results', []):
                for ref in w.get('referenced_works', []):
                    c[ref] += 1
            
            if not c:
                print("‚ö†Ô∏è No citations found in live sample. The API might have changed.")
                return

            top_ghost_id = c.most_common(1)[0][0]
            print(f"   Found Top Ghost ID: {top_ghost_id} (Cited {c.most_common(1)[0][1]} times)")

            # 3. Verify the Ghost is relevant (Fetch Author)
            ghost_url = f"https://api.openalex.org/works/{top_ghost_id}"
            ghost_resp = self.crawler.session.get(ghost_url, timeout=10)
            ghost_data = ghost_resp.json()
            
            author_names = [a['author']['display_name'] for a in ghost_data.get('authorships', [])]
            print(f"   Ghost Paper Authors: {author_names}")
            
            # THE MOMENT OF TRUTH: Does Choueiri, Nelson, or Kirkeby appear?
            known_godfathers = ["Choueiri", "Nelson", "Kirkeby", "Takeuchi", "Bauck"]
            found_godfather = any(any(god in name for god in known_godfathers) for name in author_names)
            
            if found_godfather:
                print("‚úÖ SUCCESS: The Backdoor Logic works! Found a known 'Godfather' of the field.")
            else:
                print("‚ö†Ô∏è WARNING: The top cited paper was not by a known Godfather. Logic might need tuning.")
                
        except Exception as e:
            print(f"‚ùå Live Test Failed with Exception: {e}")

if __name__ == '__main__':
    unittest.main()


==================================================
FILE: tests/test_exact_prompt.py
==================================================

import os
from dotenv import load_dotenv
from google import genai
import time

# Load environment
load_dotenv()
key = os.getenv("GOOGLE_API_KEY")

print("\nüß™ EXACT PROMPT REPRODUCTION TEST")
print("================================")

if not key:
    print("‚ùå ERROR: GOOGLE_API_KEY not found.")
    exit(1)

# Replicating 1_search_omni.py Setup
topic = "Spatial Audio"
prompt = (
    f"The user is researching '{topic}'. Identify the 8 most distinct, high-yield 'Search Verticals' "
    f"for finding papers in this field. \n"
    f"INSTRUCTIONS:\n"
    f"1. Include Broad Synonyms (e.g., if topic is Spatial Audio -> '3D Audio', 'Immersive Audio')\n"
    f"2. Include Core Sub-disciplines (e.g., 'Binaural', 'Ambisonics', 'Wave Field Synthesis')\n"
    f"3. Return ONLY a comma-separated list of 8 terms."
)

print(f"üìù Prompt Config:\nModel: gemini-2.0-flash-001\nLength: {len(prompt)} chars\n")

try:
    # Exact Client Init from Script
    client = genai.Client(api_key=key)
    
    print("üöÄ Sending Request...")
    start = time.time()
    resp = client.models.generate_content(model='gemini-2.0-flash-001', contents=prompt)
    duration = time.time() - start
    
    print("\n‚úÖ SUCCESS!")
    print(f"   Response: {resp.text.strip()}")
    print(f"   Latency: {duration:.2f}s")

except Exception as e:
    print("\n‚ùå REPRODUCTION SUCCESSFUL (IT FAILED)")
    print(f"   Error: {e}")
    # Inspect if there's error details
    if hasattr(e, 'details'):
        print(f"   Details: {e.details()}")


==================================================
FILE: tests/library test results/Library_Spatial_Audio/Catalog_Spatial_Audio.md
==================================================
# Library Catalog: Spatial Audio

## Search Settings
- **Topics:** Spatial Audio
- **Keywords:** crosstalk cancellation, personal sound zones
- **Sort Order:** Citations: Most
- **Limit:** 10
- **Date Range:** All Time

**Total Papers Listed:** 10  
**Total Papers Downloaded:** 10  
**Generated:** 2025-12-30 21:24

## Application and System Overview

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| Clean Audio for TV broadcast: An Object-Based Approach for Hearing-Impaired Viewers | Ben Shirley et al. | 2015 | OpenAlex | 28 | [Source](http://downloads.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP324.pdf) |
| Project starline | Jason Lawrence et al. | 2021 | OpenAlex | 94 | [Source](https://hhoppe.com/starline.pdf) |
| Recent Advances in an Open Software for Numerical HRTF Calculation | Fabian Brinkmann et al. | 2023 | OpenAlex | 15 | [Source](https://projects.ari.oeaw.ac.at/research/Publications/Articles/2023/Brinkmann_et_al_2023_Mesh2HRTF.pdf) |
| Spatial Audio for Soundscape Design: Recording and Reproduction | Joo Young Hong et al. | 2017 | OpenAlex | 100 | [Source](https://www.mdpi.com/2076-3417/7/6/627/pdf?version=1497700319) |
## Binaural Synthesis and Reproduction Techniques

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| Binaural Ambisonics: Its optimization and applications for auralization | Makoto Otani et al. | 2020 | OpenAlex | 11 | [Source](https://www.jstage.jst.go.jp/article/ast/41/1/41_E19229/_pdf) |
## Crosstalk Cancellation Implementation

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| Virtual Reality System with Integrated Sound Field Simulation and Reproduction | Tobias Lentz et al. | 2007 | OpenAlex | 108 | [Source](https://asp-eurasipjournals.springeropen.com/counter/pdf/10.1155/2007/70540) |
## Inverse Filtering and System Identification

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| Solution Strategies for Linear Inverse Problems in Spatial Audio Signal Processing | Mingsian R. Bai et al. | 2017 | OpenAlex | 19 | [Source](https://www.mdpi.com/2076-3417/7/6/582/pdf?version=1496711486) |
## Loudspeaker Array Reproduction

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| Acoustic contrast, planarity and robustness of sound zone methods using a circular loudspeaker array | Peter John Cusack Coleman et al. | 2014 | OpenAlex | 107 | [Source](https://pdfs.semanticscholar.org/30e5/4f0f268e910d4c01baf1b2b9607576b0ad97.pdf) |
## Miscellaneous

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| Spatially Oriented Format for Acoustics 2.1: Introduction and Recent Advances | Piotr Majdak et al. | 2022 | OpenAlex | 23 | [Source](https://dael.euracoustics.org/confs/fa2023/data/articles/000729.pdf) |
## Perceptual Evaluation and Auditory Perception

| Title | First Author | Year | Journal | Citations | Link |
|---|---|---|---|---|---|
| The Availability of a Hidden Real Reference Affects the Plausibility of Position-Dynamic Auditory AR | Annika Neidhardt et al. | 2021 | OpenAlex | 13 | [Source](https://www.frontiersin.org/articles/10.3389/frvir.2021.678875/pdf) |



==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Crosstalk_Cancellation_Implementation/index.json
==================================================
[
  {
    "Title": "Virtual Reality System with Integrated Sound Field Simulation and Reproduction",
    "Authors": "Tobias Lentz, Dirk Schr\u00f6der, Michael Vorl\u00e4nder, Ingo Assenmacher",
    "Filename": "Virtual Reality System with Integrated Sound Field Simulation and Reproduction.pdf",
    "Description": "A real-time audio rendering system is introduced which combines a full room-specific simulation, dynamic crosstalk cancellation, and multitrack binaural synthesis for virtual acoustical imaging. The system is applicable for any room shape (normal, long, flat, coupled), independent of the a priori assumption of a diffuse sound field. This provides the possibility of simulating indoor or outdoor spatially distributed, freely movable sources and a moving listener in virtual environments. In addition to that, near-to-head sources can be simulated by using measured near-field HRTFs. The reproduction component consists of a headphone-free reproduction by dynamic crosstalk cancellation. The focus of the project is mainly on the integration and interaction of all involved subsystems. It is demonstrated that the system is capable of real-time room simulation and reproduction and, thus, can be used as a reliable platform for further research on VR applications.",
    "Source_URL": "https://asp-eurasipjournals.springeropen.com/counter/pdf/10.1155/2007/70540"
  }
]

==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Application_and_System_Overview/index.json
==================================================
[
  {
    "Title": "Spatial Audio for Soundscape Design: Recording and Reproduction",
    "Authors": "Joo Young Hong, Jianjun He, Bhan Lam, Rishabh Gupta, Woon\u2010Seng Gan",
    "Filename": "Spatial Audio for Soundscape Design Recording and Reproduction.pdf",
    "Description": "With the advancement of spatial audio technologies, in both recording and reproduction, we are seeing more applications that incorporate 3D sound to create an immersive aural experience. Soundscape design and evaluation for urban planning can now tap into the extensive spatial audio tools for sound capture and 3D sound rendering over headphones and speaker arrays. In this paper, we outline a list of available state-of-the-art spatial audio recording techniques and devices, spatial audio physical and perceptual reproduction techniques, emerging spatial audio techniques for virtual and augmented reality, followed by a discussion on the degree of perceptual accuracy of recording and reproduction techniques in representing the acoustic environment.",
    "Source_URL": "https://www.mdpi.com/2076-3417/7/6/627/pdf?version=1497700319"
  },
  {
    "Title": "Project starline",
    "Authors": "Jason Lawrence, Danb Goldman, Supreeth Achar, Gregory Major Blascovich, Joseph G. Desloge, Tommy Fortes, Eric M. Gomez, Sascha H\u00e4berling, Hugues Hoppe, Andy Huibers, Claude Knaus, Brian Kuschak, Ricardo Martin-Brualla, Harris Nover, Andrew Ian Russell, Steven M. Seitz, Kevin Tong",
    "Filename": "Project starline.pdf",
    "Description": "We present a real-time bidirectional communication system that lets two people, separated by distance, experience a face-to-face conversation as if they were copresent. It is the first telepresence system that is demonstrably better than 2D videoconferencing, as measured using participant ratings (e.g., presence, attentiveness, reaction-gauging, engagement), meeting recall, and observed nonverbal behaviors (e.g., head nods, eyebrow movements). This milestone is reached by maximizing audiovisual fidelity and the sense of copresence in all design elements, including physical layout, lighting, face tracking, multi-view capture, microphone array, multi-stream compression, loudspeaker output, and lenticular display. Our system achieves key 3D audiovisual cues (stereopsis, motion parallax, and spatialized audio) and enables the full range of communication cues (eye contact, hand gestures, and body language), yet does not require special glasses or body-worn microphones/headphones. The system consists of a head-tracked autostereoscopic display, high-resolution 3D capture and rendering subsystems, and network transmission using compressed color and depth video streams. Other contributions include a novel image-based geometry fusion algorithm, free-space dereverberation, and talker localization.",
    "Source_URL": "https://hhoppe.com/starline.pdf"
  },
  {
    "Title": "Clean Audio for TV broadcast: An Object-Based Approach for Hearing-Impaired Viewers",
    "Authors": "Ben Shirley, Rob Oldfield",
    "Filename": "Clean Audio for TV broadcast An Object-Based Approach for Hearing-Impaired Viewers.pdf",
    "Description": "As the percentage of the population with hearing loss increases, broadcasters are receiving more complaints about the difficulty in understanding dialog in the presence of background sound and music. This article explores these issues, reviews previously proposed solutions, and presents an object-based approach that can be implemented within MPEG-H to give listeners control of their audio mix. An object-based approach to clean audio, combined with methods to isolate sounds that are important to the narrative and meaning of a broadcast has the potential to enable users to have complete control of the relative levels of all aspects of audio from TV broadcast. This approach was demonstrated at the University of Salford campus in 2013.",
    "Source_URL": "http://downloads.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP324.pdf"
  },
  {
    "Title": "Recent Advances in an Open Software for Numerical HRTF Calculation",
    "Authors": "Fabian Brinkmann, W. Kreuzer, Jeffrey Thomsen, Sergejs Dombrovskis, Katharina Pollack, Stefan Weinzierl, Piotr Majdak",
    "Filename": "Recent Advances in an Open Software for Numerical HRTF Calculation.pdf",
    "Description": "Mesh2HRTF 1.x is an open-source and fully scriptable end-to-end pipeline for the numerical calculation of head-related transfer functions (HRTFs). The calculations are based on 3D meshes of listener\u2019s body parts such as the head, pinna, and torso. The numerical core of Mesh2HRTF is written in C++ and employs the boundary-element method for solving the Helmholtz equation. It is accelerated by a multilevel fast multipole method and can easily be parallelized to further speed up the computations. The recently refactored framework of Mesh2HRTF 1.x contains tools for preparing the meshes as well as specific post-processing and inspection of the calculatedHRTFs. The resultingHRTFs are saved in the spatially oriented format for acoustics being directly applicable in virtual and augmented reality applications and psychoacoustic research. The Mesh2HRTF 1.x code is automatically tested to assure high quality and reliability. A comprehensive online documentation enables easy access for users without in-depth knowledge of acoustic simulations.",
    "Source_URL": "https://projects.ari.oeaw.ac.at/research/Publications/Articles/2023/Brinkmann_et_al_2023_Mesh2HRTF.pdf"
  }
]

==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Perceptual_Evaluation_and_Auditory_Perception/index.json
==================================================
[
  {
    "Title": "The Availability of a Hidden Real Reference Affects the Plausibility of Position-Dynamic Auditory AR",
    "Authors": "Annika Neidhardt, Anna Maria Zerlik",
    "Filename": "The Availability of a Hidden Real Reference Affects the Plausibility of Position-Dynamic Auditory AR.pdf",
    "Description": "This study examines the plausibility of Auditory Augmented Reality (AAR) realized with position-dynamic binaural synthesis over headphones. An established method to evaluate the plausibility of AAR asks participants to decide whether they are listening to the virtual or real version of the sound object. To date, this method has only been used to evaluate AAR systems for seated listeners. The AAR realization examined in this study instead allows listeners to turn to arbitrary directions and walk towards, past, and away from a real loudspeaker that reproduced sound only virtually. The experiment was conducted in two parts. In the first part, the subjects were asked whether they are listening to the real or the virtual version, not knowing that it was always the virtual version. In the second part, the real versions of the scenes where the loudspeaker actually reproduced sound were added. Two different source positions, three different test stimuli, and two different sound levels were considered. Seventeen volunteers, including five experts, participated. In the first part, none of the participants noticed that the virtual reproduction was active throughout the different test scenes. The inexperienced listeners tended to accept the virtual reproduction as real, while experts distributed their answers approximately equally. In the second part, experts could identify the virtual version quite reliably. For inexperienced listeners, the individual results varied enormously. Since the presence of the headphones influences the perception of the real sound field, this shadowing effect had to be considered in the creation of the virtual sound source as well. This requirement still limits test methods considering the real version in its ecological validity. Although the results indicate that the availability of a hidden real reference leads to a more critical evaluation, it is crucial to be aware that the presence of the headphones slightly distorts the reference. This issue seems more vital to the plausibility estimates achieved with this evaluation method than the increased freedom in motion.",
    "Source_URL": "https://www.frontiersin.org/articles/10.3389/frvir.2021.678875/pdf"
  }
]

==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Miscellaneous/index.json
==================================================
[
  {
    "Title": "Spatially Oriented Format for Acoustics 2.1: Introduction and Recent Advances",
    "Authors": "Piotr Majdak, Franz Zotter, Fabian Brinkmann, Julien De Muynke, Michael Mihocic, Markus Noisternig",
    "Filename": "Spatially Oriented Format for Acoustics 2.1 Introduction and Recent Advances.pdf",
    "Description": "Spatially oriented acoustic data can range from a simple set of impulse responses, such as head-related transfer functions, to a large set of multiple-input multiple-output spatial room impulse responses obtained in complex measurements with a microphone array excited by a loudspeaker array at various conditions. The spatially oriented format for acoustics (SOFA), which was standardized by AES Standard 69, provides a format to store and share such data. SOFA takes into account geometric representations of many acoustic scenarios, data compression, network transfer, and a link to complex room geometries and aims at simplifying the development of interfaces for many programming languages. With the recent advancement of SOFA, the format offers new continuous-direction representation of data by means of spherical harmonics and novel conventions representing many measurement scenarios, such as source directivity and multiple-input multiple-output spatial room impulse responses. This article reviews SOFA by first providing an introduction to SOFA and then describing examples that demonstrate the most recent features of the SOFA 2.1 (AES Standard 69-2022).",
    "Source_URL": "https://dael.euracoustics.org/confs/fa2023/data/articles/000729.pdf"
  }
]

==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Binaural_Synthesis_and_Reproduction_Techniques/index.json
==================================================
[
  {
    "Title": "Binaural Ambisonics: Its optimization and applications for auralization",
    "Authors": "Makoto Otani, Haruki Shigetani, Masataka Mitsuishi, Ryo Matsuda",
    "Filename": "Binaural Ambisonics Its optimization and applications for auralization.pdf",
    "Description": "To better understand acoustic environment and the resulting auditory perception, it is essential to capture, analyze, and reproduce a sound field as a three-dimensional physical phenomenon because spatial aspects of auditory perception play important roles in various situations in our lives. Some approaches have been proposed to achieve the three-dimensional capture and reproduction of acoustic fields. Among them, Higher-Order Ambisonics (HOA) based on spherical harmonics expansion enables the capture and reproduction of a directivity pattern of incoming sound waves. On the basis of HOA, three-dimensional auditory space can be presented to a listener typically via a spherical loudspeaker array. In addition, binaural synthesis emulating the loudspeaker presentation enables HOA reproduction with a set of headphones or several loudspeakers by employing crosstalk cancellation. Thus, we are developing an HOA-based binaural reproduction/auralization system with head tracking. This system is aimed at realizing the reproduction and auralization of a sound field, including one excited by the listener's own voice. In this paper, we review the topics related to the reproduction and auralization of the sound field and introduce the HOA-based binaural synthesis system we have developed, as well as our works on sweet-spot expansion in HOA decoding and self-voice reproduction/auralization.",
    "Source_URL": "https://www.jstage.jst.go.jp/article/ast/41/1/41_E19229/_pdf"
  }
]

==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Inverse_Filtering_and_System_Identification/index.json
==================================================
[
  {
    "Title": "Solution Strategies for Linear Inverse Problems in Spatial Audio Signal Processing",
    "Authors": "Mingsian R. Bai, Chun Hui Chung, Po-Chen Wu, Yi-Hao Chiang, Chun-May Yang",
    "Filename": "Solution Strategies for Linear Inverse Problems in Spatial Audio Signal Processing.pdf",
    "Description": "The aim of this study was to compare algorithms for solving inverse problems generally encountered in spatial audio signal processing. Tikhonov regularization is typically utilized to solve overdetermined linear systems in which the regularization parameter is selected by the golden section search (GSS) algorithm. For underdetermined problems with sparse solutions, several iterative compressive sampling (CS) methods are suggested as alternatives to traditional convex optimization (CVX) methods that are computationally expensive. The focal underdetermined system solver (FOCUSS), the steepest descent (SD) method, Newton\u2019s (NT) method, and the conjugate gradient (CG) method were developed to solve CS problems more efficiently in this study. These algorithms were compared in terms of problems, including source localization and separation, noise source identification, and analysis and synthesis of sound fields, by using a uniform linear array (ULA), a uniform circular array (UCA), and a random array. The derived results are discussed herein and guidelines for the application of these algorithms are summarized.",
    "Source_URL": "https://www.mdpi.com/2076-3417/7/6/582/pdf?version=1496711486"
  }
]

==================================================
FILE: tests/library test results/Library_Spatial_Audio/crosstalk_cancellation/Loudspeaker_Array_Reproduction/index.json
==================================================
[
  {
    "Title": "Acoustic contrast, planarity and robustness of sound zone methods using a circular loudspeaker array",
    "Authors": "Peter John Cusack Coleman, Philip J. B. Jackson, Marek Olik, Martin Bo M\u00f8ller, Martin Olsen, Jan Abildgaard Pedersen",
    "Filename": "Acoustic contrast, planarity and robustness of sound zone methods using a circular loudspeaker array.pdf",
    "Description": "Since the mid 1990s, acoustics research has been undertaken relating to the sound zone problem\u2014using loudspeakers to deliver a region of high sound pressure while simultaneously creating an area where the sound is suppressed\u2014in order to facilitate independent listening within the same acoustic enclosure. The published solutions to the sound zone problem are derived from areas such as wave field synthesis and beamforming. However, the properties of such methods differ and performance tends to be compared against similar approaches. In this study, the suitability of energy focusing, energy cancelation, and synthesis approaches for sound zone reproduction is investigated. Anechoic simulations based on two zones surrounded by a circular array show each of the methods to have a characteristic performance, quantified in terms of acoustic contrast, array control effort and target sound field planarity. Regularization is shown to have a significant effect on the array effort and achieved acoustic contrast, particularly when mismatched conditions are considered between calculation of the source weights and their application to the system.",
    "Source_URL": "https://pdfs.semanticscholar.org/30e5/4f0f268e910d4c01baf1b2b9607576b0ad97.pdf"
  }
]

==================================================
FILE: tests/logs/2025-12-26 1.txt
==================================================


==================================================
FILE: tests/logs/2025-12-26 2.txt
==================================================
üöÄ Starting Mission in Isolated Workspace...
--- Starting Phase 1: Search (Topic: Spatial Audio) ---
DEBUG: Keywords: ['crosstalk', 'cancellation']

--- Search Round 1 (Collected: 0/35 for target 25) ---
Searching Crossref (Offset: 0)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/is264627.2025.11284603...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0217...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2248713...
DEBUG: Checking Unpywall for 10.17743/jaes.2018.0061...
DEBUG: Checking Unpywall for 10.1109/89.824710...
DEBUG: Checking Unpywall for 10.1145/3576914.3589563...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.833011...
DEBUG: Checking Unpywall for 10.1109/taslp.2021.3110651...
DEBUG: Checking Unpywall for 10.17743/jaes.2019.0037...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2329184...
DEBUG: Checking Unpywall for 10.1021/acs.analchem.4c06970.s001...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.905149...
DEBUG: Checking Unpywall for 10.1021/acs.analchem.4c06970.s002...
DEBUG: Checking Unpywall for 10.1121/1.4708000...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202055...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0067...
DEBUG: Checking Unpywall for 10.1007/0-387-28503-2_9...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2190929...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082309...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.3044444...
DEBUG: Checking Unpywall for 10.17485/ijst/2015/v8i5/60708...
DEBUG: Checking Unpywall for 10.1109/ssp.2014.6884682...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082281...
DEBUG: Checking Unpywall for 10.17485/ijst/2015/v8i33/80399...
DEBUG: Checking Unpywall for 10.3233/ica-130422...
DEBUG: Checking Unpywall for 10.1364/oe.22.003375...
DEBUG: Checking Unpywall for 10.4324/9780080498195-6...
DEBUG: Checking Unpywall for 10.1109/waspaa.2015.7336947...
DEBUG: Checking Unpywall for 10.1109/chinasip.2014.6889234...
DEBUG: Checking Unpywall for 10.1121/1.2257986...
DEBUG: Checking Unpywall for 10.1109/icet.2010.5638489...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.814798...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289558...
DEBUG: Checking Unpywall for 10.1109/taslp.2021.3130966...
DEBUG: Checking Unpywall for 10.1021/acs.analchem.4c06970...
DEBUG: Checking Unpywall for 10.1109/waspaa.2015.7336946...
DEBUG: Checking Unpywall for 10.1109/glocom.2001.965136...
DEBUG: Checking Unpywall for 10.1109/iscas.2006.1693373...
DEBUG: Checking Unpywall for 10.21275/v5i5.nov163188...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376616...
DEBUG: Checking Unpywall for 10.1109/glocom.2006.136...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.838531...
DEBUG: Checking Unpywall for 10.1109/icassp.2007.366647...
DEBUG: Checking Unpywall for 10.1109/tsa.2002.804537...
DEBUG: Checking Unpywall for 10.1016/j.jsv.2005.05.016...
DEBUG: Checking Unpywall for 10.1109/ecoc.2001.989448...
DEBUG: Checking Unpywall for 10.1109/oic.2012.6224428...
DEBUG: Checking Unpywall for 10.1364/ofc.1995.tuh7...
DEBUG: Checking Unpywall for 10.1007/978-3-642-27201-1_14...
DEBUG: Checking Unpywall for 10.5772/intechopen.105002...
DEBUG: Checking Unpywall for 10.1049/el:19960727...
DEBUG: Checking Unpywall for 10.1109/ivmspw.2013.6611908...
DEBUG: Checking Unpywall for 10.1109/icsigsys.2019.8811051...
DEBUG: Checking Unpywall for 10.1201/b17593-12...
DEBUG: Checking Unpywall for 10.1109/4234.769523...
DEBUG: Checking Unpywall for 10.1155/2007/72041...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch4...
DEBUG: Checking Unpywall for 10.1155/2007/71948...
DEBUG: Checking Unpywall for 10.1109/isemc.2011.6038416...
DEBUG: Checking Unpywall for 10.1007/978-3-540-37631-6_8...
DEBUG: Checking Unpywall for 10.4324/9780080498195-8...
DEBUG: Checking Unpywall for 10.1109/aspaa.1991.634116...
DEBUG: Checking Unpywall for 10.4324/9780080498195-7...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-8644-3_14...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2966869...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.851995...
DEBUG: Checking Unpywall for 10.25144/18196...
DEBUG: Checking Unpywall for 10.1109/glocom.1996.585974...
DEBUG: Checking Unpywall for 10.1109/icc.2010.5502538...
DEBUG: Checking Unpywall for 10.1109/89.928923...
DEBUG: Checking Unpywall for 10.1515/freq-2012-0029...
DEBUG: Checking Unpywall for 10.15368/theses.2014.85...
DEBUG: Checking Unpywall for 10.3390/books978-3-03842-586-1...
DEBUG: Checking Unpywall for 10.4324/9780080498195...
DEBUG: Checking Unpywall for 10.1109/isvlsi.2003.1183496...
DEBUG: Checking Unpywall for 10.1109/icosp.2008.4697414...
DEBUG: Checking Unpywall for 10.1364/cleo.2010.cthdd2...
DEBUG: Checking Unpywall for 10.1109/icc.2005.1494678...
DEBUG: Checking Unpywall for 10.4324/9780080498195-10...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.858065...
DEBUG: Checking Unpywall for 10.1109/icme.2010.5583244...
DEBUG: Checking Unpywall for 10.1109/89.279277...
DEBUG: Checking Unpywall for 10.1145/775978.775982...
DEBUG: Checking Unpywall for 10.1109/dac.2003.1219088...
DEBUG: Checking Unpywall for 10.1109/isemc.2012.6351785...
DEBUG: Checking Unpywall for 10.1109/ectc.2011.5898514...
DEBUG: Checking Unpywall for 10.1109/cmc.2010.266...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.809194...
DEBUG: Checking Unpywall for 10.1109/chinacom.2008.4685160...
DEBUG: Checking Unpywall for 10.1109/cmc.2010.252...
DEBUG: Checking Unpywall for 10.1109/ectc.2013.6575858...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch10...
DEBUG: Checking Unpywall for 10.25144/15310...
DEBUG: Checking Unpywall for 10.1109/aspaa.1997.625628...
DEBUG: Checking Unpywall for 10.1007/0-387-27676-9_8...
DEBUG: Checking Unpywall for 10.1109/isemc.2013.6670506...
DEBUG: Checking Unpywall for 10.15199/ele-2014-007...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.818110...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.848878...
DEBUG: Checking Unpywall for 10.1145/3771594.3771623...
DEBUG: Batch complete. Added 0 papers.
Searching ArXiv...

ArXiv: 0it [00:00, ?it/s]
ArXiv: 0it [00:00, ?it/s]
DEBUG: Processing batch of 0 candidates...
DEBUG: No candidates passed pre-filter.
Searching Semantic Scholar (Offset: 0)...
DEBUG: Processing batch of 20 candidates...
DEBUG: 20 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0049...
DEBUG: Checking Unpywall for 10.1145/3498361.3538933...
DEBUG: Checking Unpywall for 10.1155/2007/71948...
[Accepted] Learning to Separate Voices by Spatial Regions...
[Accepted] Common-Slope Modeling of Late Reverberation...
[Accepted] Inverse Filter Design Using Minimax Approximation Techniques...
[Accepted] Spatial Aliasing Effects in a Steerable Parametric Loudspeak...
[Accepted] Personal audio with a planar bright zone....
[Accepted] Multichannel massive audio processing for a generalized cros...
[Accepted] Towards Faster Continuous Multi-Channel HRTF Measurements Ba...
[Accepted] Design and Implementation Analysis of OSD based Audio Crosst...
[Accepted] Folk Music Audio Enhancement Method Combining Internet of Th...
[Accepted] Johnson-noise-limited cancellation-free microwave impedance ...
[Accepted] Goniometers are a Powerful Acoustic Feature for Music Inform...
[Accepted] Implementation Analysis of Binaural Audio Crosstalk Cancella...
DEBUG: Checking Unpywall for 10.1155/2007/70540...
DEBUG: Checking Unpywall for 10.5772/24513...
DEBUG: Checking Unpywall for 10.1250/ast.41.142...
[Accepted] A Joint Minimax Approach for Binaural Rendering of Audio Thr...
[Accepted] Contextual Localization Bias for Low- and High-Frequency Sti...
DEBUG: Batch complete. Added 14 papers.

--- Search Round 2 (Collected: 14/35 for target 25) ---
Searching Crossref (Offset: 100)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2159592...
DEBUG: Checking Unpywall for 10.23919/eusipco58844.2023.10289795...
DEBUG: Checking Unpywall for 10.1145/3771594.3771623...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2025903...
DEBUG: Checking Unpywall for 10.3390/buildings8060078...
DEBUG: Checking Unpywall for 10.1109/wcsp.2009.5371575...
DEBUG: Checking Unpywall for 10.1201/9781439864869-25...
DEBUG: Checking Unpywall for 10.1117/1.1386791...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.852986...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.885935...
DEBUG: Checking Unpywall for 10.1109/icct.2006.341946...
DEBUG: Checking Unpywall for 10.1364/sppcom.2015.sps3d.6...
DEBUG: Checking Unpywall for 10.1016/j.sigpro.2009.04.036...
DEBUG: Checking Unpywall for 10.1109/oecc.2015.7340187...
DEBUG: Checking Unpywall for 10.1109/tsa.2002.807350...
DEBUG: Checking Unpywall for 10.4324/9781315184432-4...
DEBUG: Checking Unpywall for 10.1109/taslpro.2025.3633085...
DEBUG: Checking Unpywall for 10.1109/icalip.2008.4590243...
DEBUG: Checking Unpywall for 10.1109/tsa.2002.800554...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376617...
DEBUG: Checking Unpywall for 10.1109/89.902283...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2196512...
DEBUG: Checking Unpywall for 10.1201/9781315220109-13...
DEBUG: Checking Unpywall for 10.1109/89.966096...
DEBUG: Checking Unpywall for 10.1364/ofc.1992.wm8...
DEBUG: Checking Unpywall for 10.1109/ipcon.2014.6995361...
DEBUG: Checking Unpywall for 10.1109/ods.2000.848024...
DEBUG: Checking Unpywall for 10.1109/lsp.2006.873661...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0116...
DEBUG: Checking Unpywall for 10.1109/cleo-pr62338.2022.10432394...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2019925...
DEBUG: Checking Unpywall for 10.1155/2007/96101...
DEBUG: Checking Unpywall for 10.1109/mwscas.2008.4616796...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch9...
DEBUG: Checking Unpywall for 10.1109/icc.2009.5198876...
DEBUG: Checking Unpywall for 10.1016/j.sigpro.2011.12.014...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0124...
DEBUG: Checking Unpywall for 10.1364/acpc.2015.asu3e.1...
DEBUG: Checking Unpywall for 10.14257/astl.2015.94.06...
DEBUG: Checking Unpywall for 10.1049/el:19800272...
DEBUG: Checking Unpywall for 10.4324/9781003627289-6...
DEBUG: Checking Unpywall for 10.1109/iscas56072.2025.11043397...
DEBUG: Checking Unpywall for 10.1145/775832.775982...
DEBUG: Checking Unpywall for 10.1007/bf02368417...
DEBUG: Checking Unpywall for 10.1109/cicc.2010.5617599...
DEBUG: Checking Unpywall for 10.1109/89.943346...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2245654...
DEBUG: Checking Unpywall for 10.1109/icassp.2013.6637971...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2502059...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009892...
DEBUG: Checking Unpywall for 10.1049/ic.2010.0230...
DEBUG: Checking Unpywall for 10.1109/acssc.2002.1197213...
DEBUG: Checking Unpywall for 10.1109/glocom.2005.1578087...
DEBUG: Checking Unpywall for 10.1121/1.1566323...
DEBUG: Checking Unpywall for 10.1109/icce-berlin.2016.7684730...
DEBUG: Checking Unpywall for 10.58837/chula.the.2005.1518...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3164211...
DEBUG: Checking Unpywall for 10.1109/glocom.2010.5683425...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2092768...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0022...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch4...
DEBUG: Checking Unpywall for 10.1121/1.415679...
DEBUG: Checking Unpywall for 10.1109/mcas.1979.6323383...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4393045...
DEBUG: Checking Unpywall for 10.1109/tsa.2002.800553...
DEBUG: Checking Unpywall for 10.4324/9780080498195-12...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170062...
DEBUG: Checking Unpywall for 10.17743/aesconf.2023.978-1-942220-44-2...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_2...
DEBUG: Checking Unpywall for 10.32657/10356/66031...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.894519...
DEBUG: Checking Unpywall for 10.1109/issoc.2003.1267725...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0049...
DEBUG: Checking Unpywall for 10.1109/icassp.2006.1660063...
DEBUG: Checking Unpywall for 10.1109/iccasm.2010.5620290...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0039...
DEBUG: Checking Unpywall for 10.1109/aps.1994.407844...
DEBUG: Checking Unpywall for 10.1109/cicc.2006.320971...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202099...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2052804...
DEBUG: Checking Unpywall for 10.17743/jaes.2014.0049...
DEBUG: Checking Unpywall for 10.1109/icccas.2007.6251620...
DEBUG: Checking Unpywall for 10.1504/ijart.2013.053556...
DEBUG: Checking Unpywall for 10.1109/icassp.2017.7952223...
DEBUG: Checking Unpywall for 10.2528/pierl19111102...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.2002980...
DEBUG: Checking Unpywall for 10.1109/89.876299...
DEBUG: Checking Unpywall for 10.1155/2007/78439...
DEBUG: Checking Unpywall for 10.1109/89.966094...
DEBUG: Checking Unpywall for 10.1109/icc.2006.255310...
DEBUG: Checking Unpywall for 10.1117/1.1569493...
DEBUG: Checking Unpywall for 10.1109/89.902282...
DEBUG: Checking Unpywall for 10.1109/icdsp.1997.628424...
DEBUG: Checking Unpywall for 10.26636/jtit.2001.3.70...
DEBUG: Checking Unpywall for 10.1109/jssc.2005.864113...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.858559...
DEBUG: Checking Unpywall for 10.1109/icassp.1995.479459...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch15...
DEBUG: Checking Unpywall for 10.1109/apace.2016.7915866...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 20)...
DEBUG: Processing batch of 2 candidates...
DEBUG: 2 candidates passed pre-filter. Checking accessibility concurrently...
[Accepted] Synthesising moving sounds...
[Accepted] Independent Component Analysis and Signal Separation, 8th In...
DEBUG: Batch complete. Added 2 papers.

--- Search Round 3 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 200)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1121/1.4988598...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2048941...
DEBUG: Checking Unpywall for 10.1109/ecoc.2015.7341997...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202099...
DEBUG: Checking Unpywall for 10.1109/icassp.1998.679636...
DEBUG: Checking Unpywall for 10.1049/ic:19980833...
DEBUG: Checking Unpywall for 10.1049/el:19921031...
DEBUG: Checking Unpywall for 10.1109/glocom.2001.965140...
DEBUG: Checking Unpywall for 10.1109/cicc.2006.320971...
DEBUG: Checking Unpywall for 10.1109/89.661474...
DEBUG: Checking Unpywall for 10.1109/esserc66193.2025.11214064...
DEBUG: Checking Unpywall for 10.1109/spi57109.2023.10145577...
DEBUG: Checking Unpywall for 10.4324/9780429491214-9...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4...
DEBUG: Checking Unpywall for 10.1109/89.985549...
DEBUG: Checking Unpywall for 10.1109/icc.1995.525180...
DEBUG: Checking Unpywall for 10.1109/taslpro.2025.3648802...
DEBUG: Checking Unpywall for 10.1109/isscc.2011.5746391...
DEBUG: Checking Unpywall for 10.1109/milcom.1993.408538...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2160852...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2744264...
DEBUG: Checking Unpywall for 10.7764/tesisuc/ing/63649...
DEBUG: Checking Unpywall for 10.1109/3dtv.2011.5877186...
DEBUG: Checking Unpywall for 10.1016/j.heares.2025.109390...
DEBUG: Checking Unpywall for 10.1109/50.405304...
DEBUG: Checking Unpywall for 10.1109/waspaa58266.2023.10248161...
DEBUG: Checking Unpywall for 10.1007/1-4020-7769-6_5...
DEBUG: Checking Unpywall for 10.1109/icassp.2019.8683254...
DEBUG: Checking Unpywall for 10.1109/taslp.2023.3325923...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2098868...
DEBUG: Checking Unpywall for 10.1049/cp.2012.1345...
DEBUG: Checking Unpywall for 10.47749/t/unicamp.2018.1045122...
DEBUG: Checking Unpywall for 10.1109/97.755428...
DEBUG: Checking Unpywall for 10.1029/rs014i006p01041...
DEBUG: Checking Unpywall for 10.1016/j.apacoust.2023.109755...
DEBUG: Checking Unpywall for 10.1109/icdsp.2011.6004931...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.845821...
DEBUG: Checking Unpywall for 10.1109/icassp.2001.940376...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289506...
DEBUG: Checking Unpywall for 10.1109/wcnc.2009.4917972...
DEBUG: Checking Unpywall for 10.1109/tmm.2003.811656...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2425955...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5684610...
DEBUG: Checking Unpywall for 10.17743/jaes.2014.0048...
DEBUG: Checking Unpywall for 10.1364/sppcom.2012.sptu3a.3...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4393047...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch13...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.916059...
DEBUG: Checking Unpywall for 10.25370/array.v20223478...
DEBUG: Checking Unpywall for 10.1109/waspaa.2015.7336925...
DEBUG: Checking Unpywall for 10.1109/isccsp.2008.4537378...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch3...
DEBUG: Checking Unpywall for 10.1109/aspaa.2005.1540163...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2144972...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch14...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2203810...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.00015...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2052249...
DEBUG: Checking Unpywall for 10.1109/icses.2016.7593844...
DEBUG: Checking Unpywall for 10.1007/978-3-540-70602-1_8...
DEBUG: Checking Unpywall for 10.1049/el:20080160...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch6...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2982578...
DEBUG: Checking Unpywall for 10.1109/taslpro.2025.3624967...
DEBUG: Checking Unpywall for 10.1109/icassp.2007.366646...
DEBUG: Checking Unpywall for 10.1155/asp/2006/16828...
DEBUG: Checking Unpywall for 10.1109/ispa.2015.7306063...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2057245...
DEBUG: Checking Unpywall for 10.2307/jj.34178662.32...
DEBUG: Checking Unpywall for 10.1109/acssc.2006.354984...
DEBUG: Checking Unpywall for 10.1186/1687-4722-2014-20...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2102752...
DEBUG: Checking Unpywall for 10.24425/aoa.2025.154827...
DEBUG: Checking Unpywall for 10.52202/079017-4477...
DEBUG: Checking Unpywall for 10.1016/j.mex.2023.102394...
DEBUG: Checking Unpywall for 10.4324/9780080498195-11...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2255276...
DEBUG: Checking Unpywall for 10.1121/1.1386635...
DEBUG: Checking Unpywall for 10.1016/j.ohx.2024.e00618...
DEBUG: Checking Unpywall for 10.1109/tce.2008.4711265...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3441848...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0130...
DEBUG: Checking Unpywall for 10.1109/iccs.1994.474273...
DEBUG: Checking Unpywall for 10.1121/1.406987...
DEBUG: Checking Unpywall for 10.4324/9780080498195-9...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0068...
DEBUG: Checking Unpywall for 10.4028/www.scientific.net/amm.716-717.1262...
DEBUG: Checking Unpywall for 10.1049/ic:19980822...
DEBUG: Checking Unpywall for 10.1121/1.4792355...
DEBUG: Checking Unpywall for 10.1109/icce56470.2023.10043413...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2134089...
DEBUG: Checking Unpywall for 10.1186/s13636-022-00248-5...
DEBUG: Checking Unpywall for 10.1109/icassp.2013.6637655...
DEBUG: Checking Unpywall for 10.14257/astl.2014.60.23...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4392982...
DEBUG: Checking Unpywall for 10.17743/jaes.2014.0047...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0131...
DEBUG: Checking Unpywall for 10.24003/emitter.v8i1.473...
DEBUG: Checking Unpywall for 10.1109/icassp.2010.5495934...
DEBUG: Checking Unpywall for 10.1109/lsp.2007.898329...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 40)...
>> Round 3: No new papers added (rejected/dup). Digging deeper...

--- Search Round 4 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 300)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.2528/pierl15011602...
DEBUG: Checking Unpywall for 10.61782/fa.2025.0447...
DEBUG: Checking Unpywall for 10.1109/atc58710.2023.10318849...
DEBUG: Checking Unpywall for 10.1109/aspaa.2003.1285801...
DEBUG: Checking Unpywall for 10.7567/jjap.56.09na10...
DEBUG: Checking Unpywall for 10.1558/ijsll.v8i2.9...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2206025...
DEBUG: Checking Unpywall for 10.1109/icmcis59922.2023.10253529...
DEBUG: Checking Unpywall for 10.17743/jaes.2019.0019...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2906427...
DEBUG: Checking Unpywall for 10.1201/9781439864869-18...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_3...
DEBUG: Checking Unpywall for 10.4324/9781003354352-42...
DEBUG: Checking Unpywall for 10.1121/1.421316...
DEBUG: Checking Unpywall for 10.1109/lcomm.2012.020212.111886...
DEBUG: Checking Unpywall for 10.1109/icvadv63329.2025.10960934...
DEBUG: Checking Unpywall for 10.1109/waspaa.2013.6701832...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_2...
DEBUG: Checking Unpywall for 10.61782/fa.2025.0809...
DEBUG: Checking Unpywall for 10.36227/techrxiv.24168660...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0070...
DEBUG: Checking Unpywall for 10.1016/j.sigpro.2007.06.008...
DEBUG: Checking Unpywall for 10.1111/2041-210x.70149/v1/review2...
DEBUG: Checking Unpywall for 10.1109/waspaa.2013.6701844...
DEBUG: Checking Unpywall for 10.1109/cicc.2009.5280899...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0059...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0025...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0079...
DEBUG: Checking Unpywall for 10.1109/icccas55266.2022.9824059...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0071...
DEBUG: Checking Unpywall for 10.4995/thesis/10251/8969...
DEBUG: Checking Unpywall for 10.1109/apsipa.2016.7820737...
DEBUG: Checking Unpywall for 10.1109/icspc.2007.4728405...
DEBUG: Checking Unpywall for 10.1109/icassp.2003.1202737...
DEBUG: Checking Unpywall for 10.1109/icc.2009.5199471...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2208629...
DEBUG: Checking Unpywall for 10.1109/biocas.2004.1454165...
DEBUG: Checking Unpywall for 10.1109/iscas.2005.1464800...
DEBUG: Checking Unpywall for 10.1109/acssc.2000.911265...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_1...
DEBUG: Checking Unpywall for 10.1109/aspaa.1991.634135...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2164529...
DEBUG: Checking Unpywall for 10.1109/tmm.2017.2777671...
DEBUG: Checking Unpywall for 10.1109/icme.2007.4284592...
DEBUG: Checking Unpywall for 10.1186/s13636-021-00219-2...
DEBUG: Checking Unpywall for 10.1016/j.ndteint.2013.12.003...
DEBUG: Checking Unpywall for 10.25144/16430...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch9...
DEBUG: Checking Unpywall for 10.1109/iscas.2015.7169167...
DEBUG: Checking Unpywall for 10.36548/jei.2023.4.001...
DEBUG: Checking Unpywall for 10.5194/ars-16-29-2018...
DEBUG: Checking Unpywall for 10.1109/aspaa.1995.482904...
DEBUG: Checking Unpywall for 10.1143/jjap.44.3445...
DEBUG: Checking Unpywall for 10.1109/mwscas.2014.6908356...
DEBUG: Checking Unpywall for 10.1007/978-3-030-11781-8_9...
DEBUG: Checking Unpywall for 10.25077/jnte.v6n2.383.2017...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_10...
DEBUG: Checking Unpywall for 10.1109/raai64504.2024.10949558...
DEBUG: Checking Unpywall for 10.1016/j.jsv.2006.03.042...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2515502...
DEBUG: Checking Unpywall for 10.1587/comex.2.435...
DEBUG: Checking Unpywall for 10.1121/10.0001529...
DEBUG: Checking Unpywall for 10.1109/83.841535...
DEBUG: Checking Unpywall for 10.12794/metadc1404593...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0017...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289279...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4392986...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.901832...
DEBUG: Checking Unpywall for 10.1109/epeps61853.2024.10753910...
DEBUG: Checking Unpywall for 10.1121/1.425154...
DEBUG: Checking Unpywall for 10.1121/1.3206660...
DEBUG: Checking Unpywall for 10.1002/9781119252634.fmatter...
DEBUG: Checking Unpywall for 10.1109/wacv57701.2024.00542...
DEBUG: Checking Unpywall for 10.1155/2008/156960...
DEBUG: Checking Unpywall for 10.1007/bfb0042734...
DEBUG: Checking Unpywall for 10.1016/j.mechatronics.2012.07.003...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0015...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0186...
DEBUG: Checking Unpywall for 10.1109/aspaa.1999.810892...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_9...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.883248...
DEBUG: Checking Unpywall for 10.1121/1.423378...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2978409...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0040...
DEBUG: Checking Unpywall for 10.1109/apemc.2016.7522802...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2045185...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2635029...
DEBUG: Checking Unpywall for 10.1201/b19378-19...
DEBUG: Checking Unpywall for 10.1109/glocomw.2015.7414216...
DEBUG: Checking Unpywall for 10.2174/1875934301205010001...
DEBUG: Checking Unpywall for 10.1109/jlt.2015.2505150...
DEBUG: Checking Unpywall for 10.1109/mwscas54063.2022.9859529...
DEBUG: Checking Unpywall for 10.1109/icassp.2008.4517632...
DEBUG: Checking Unpywall for 10.1109/ofc.2006.215787...
DEBUG: Checking Unpywall for 10.1109/jssc.2011.2151410...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4393021...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_6...
DEBUG: Checking Unpywall for 10.3403/30256040...
DEBUG: Checking Unpywall for 10.1145/3677386.3688883...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289388...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 60)...
>> Round 4: No new papers added (rejected/dup). Digging deeper...

--- Search Round 5 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 400)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.3403/30256040u...
DEBUG: Checking Unpywall for 10.1109/.2001.979412...
DEBUG: Checking Unpywall for 10.1007/978-3-031-23046-2_2...
DEBUG: Checking Unpywall for 10.1109/tenconspring.2018.8692024...
DEBUG: Checking Unpywall for 10.1250/ast.36.537...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2778150...
DEBUG: Checking Unpywall for 10.21437/interspeech.2010-755...
DEBUG: Checking Unpywall for 10.1002/9781119252634.index...
DEBUG: Checking Unpywall for 10.24425/aoa.2024.148798...
DEBUG: Checking Unpywall for 10.1109/dasc.2015.7311401...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082311...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170029...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289379...
DEBUG: Checking Unpywall for 10.1155/s1110865704309273...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610974...
DEBUG: Checking Unpywall for 10.1111/2041-210x.70149/v1/review1...
DEBUG: Checking Unpywall for 10.1109/icassp.2014.6854125...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2260742...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0153...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289616...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_4...
DEBUG: Checking Unpywall for 10.1007/978-3-540-30205-6_7...
DEBUG: Checking Unpywall for 10.1155/2010/719197...
DEBUG: Checking Unpywall for 10.1109/icassp.1998.679674...
DEBUG: Checking Unpywall for 10.1364/ofc.2013.ow4b.6...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610937...
DEBUG: Checking Unpywall for 10.1109/msp.2017.2666081...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346494...
DEBUG: Checking Unpywall for 10.1109/icassp.1985.1168121...
DEBUG: Checking Unpywall for 10.1109/leos.1997.630498...
DEBUG: Checking Unpywall for 10.1109/mwscas.1998.759455...
DEBUG: Checking Unpywall for 10.1145/3264869.3264871...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289320...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81295-3.00003-4...
DEBUG: Checking Unpywall for 10.1364/opticaopen.22186078.v1...
DEBUG: Checking Unpywall for 10.1109/cce.2008.4578977...
DEBUG: Checking Unpywall for 10.1186/s13638-017-0808-4...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610844...
DEBUG: Checking Unpywall for 10.1364/opticaopen.22186078...
DEBUG: Checking Unpywall for 10.1364/ofc.2022.th2a.29...
DEBUG: Checking Unpywall for 10.1109/isce.2006.1689526...
DEBUG: Checking Unpywall for 10.1109/icetcct.2017.8280292...
DEBUG: Checking Unpywall for 10.1364/oecc_ps.2013.wr4_4...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch2...
DEBUG: Checking Unpywall for 10.1109/vlsic.2012.6243829...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0039...
DEBUG: Checking Unpywall for 10.1038/417503a...
DEBUG: Checking Unpywall for 10.1364/ofc.2018.w2a.63...
DEBUG: Checking Unpywall for 10.5772/intechopen.91556...
DEBUG: Checking Unpywall for 10.2528/pierl20092303...
DEBUG: Checking Unpywall for 10.1109/ets.2001.979412...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0009...
DEBUG: Checking Unpywall for 10.1143/jjap.32.5277...
DEBUG: Checking Unpywall for 10.5402/2011/586574...
DEBUG: Checking Unpywall for 10.1109/30.642386...
DEBUG: Checking Unpywall for 10.1016/bs.acr.2024.06.009...
DEBUG: Checking Unpywall for 10.1201/9781420041262.ch13...
DEBUG: Checking Unpywall for 10.1109/jlt.2012.2208732...
DEBUG: Checking Unpywall for 10.3397/in_2023_0690...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0080...
DEBUG: Checking Unpywall for 10.1109/aspaa.1997.625579...
DEBUG: Checking Unpywall for 10.1109/icassp.2008.4517598...
DEBUG: Checking Unpywall for 10.4324/9781315727813-3...
DEBUG: Checking Unpywall for 10.1007/1-4020-7769-6_13...
DEBUG: Checking Unpywall for 10.1145/2466627.2481228...
DEBUG: Checking Unpywall for 10.1016/j.ultras.2013.09.007...
DEBUG: Checking Unpywall for 10.3813/aaa.918160...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.77...
DEBUG: Checking Unpywall for 10.1109/ecoc66593.2025.11263075...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2050716...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289336...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170008...
DEBUG: Checking Unpywall for 10.1002/9780470723494.fmatter...
DEBUG: Checking Unpywall for 10.1016/j.matpr.2021.07.080...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch5...
DEBUG: Checking Unpywall for 10.1299/mej.16-00284...
DEBUG: Checking Unpywall for 10.1002/9780470723494.index...
DEBUG: Checking Unpywall for 10.1109/isemc.2014.6899044...
DEBUG: Checking Unpywall for 10.1109/iwaenc53105.2022.9914773...
DEBUG: Checking Unpywall for 10.1109/aspaa.1999.810865...
DEBUG: Checking Unpywall for 10.1109/emczur.2009.4783459...
DEBUG: Checking Unpywall for 10.1186/1687-6180-2012-150...
DEBUG: Checking Unpywall for 10.1109/epeps53828.2022.9947191...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009752...
DEBUG: Checking Unpywall for 10.1049/iet-com.2010.0311...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch1...
DEBUG: Checking Unpywall for 10.5772/15206...
DEBUG: Checking Unpywall for 10.23919/dafx51585.2021.9768239...
DEBUG: Checking Unpywall for 10.1109/aspaa.1991.634119...
DEBUG: Checking Unpywall for 10.1109/89.544529...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_8...
DEBUG: Checking Unpywall for 10.1002/9780470723494.biblio...
DEBUG: Checking Unpywall for 10.1109/isscc19947.2020.9063162...
DEBUG: Checking Unpywall for 10.1109/iccdcs.2008.4542637...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0099...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0215...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202113...
DEBUG: Checking Unpywall for 10.1109/sarnof.2010.5469745...
DEBUG: Checking Unpywall for 10.1109/iscas.2013.6572009...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 80)...
>> Round 5: No new papers added (rejected/dup). Digging deeper...

--- Search Round 6 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 500)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/icpr.2008.4761474...
DEBUG: Checking Unpywall for 10.1049/pbra014e_ch17...
DEBUG: Checking Unpywall for 10.1002/9780470723494...
DEBUG: Checking Unpywall for 10.1145/3374920.3374999...
DEBUG: Checking Unpywall for 10.1109/taslp.2023.3328286...
DEBUG: Checking Unpywall for 10.1109/tcsii.2013.2251957...
DEBUG: Checking Unpywall for 10.1109/icocn63276.2024.10647225...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch2...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0055...
DEBUG: Checking Unpywall for 10.1109/a-sscc47793.2019.9056976...
DEBUG: Checking Unpywall for 10.25077/1520952004...
DEBUG: Checking Unpywall for 10.21437/eurospeech.2003-172...
DEBUG: Checking Unpywall for 10.1111/2041-210x.70149/v1/decision1...
DEBUG: Checking Unpywall for 10.1145/2788940.2794363...
DEBUG: Checking Unpywall for 10.1111/2041-210x.70149/v2/decision1...
DEBUG: Checking Unpywall for 10.1109/ectc51529.2024.00172...
DEBUG: Checking Unpywall for 10.1016/j.matpr.2021.07.080...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289599...
DEBUG: Checking Unpywall for 10.1163/22134808-00002611...
DEBUG: Checking Unpywall for 10.1103/physreva.80.053813...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346503...
DEBUG: Checking Unpywall for 10.25144/24005...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2975902...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0166...
DEBUG: Checking Unpywall for 10.1093/oso/9780197523889.003.0021...
DEBUG: Checking Unpywall for 10.1007/978-0-387-78263-8_22...
DEBUG: Checking Unpywall for 10.3389/fnint.2018.00037...
DEBUG: Checking Unpywall for 10.36227/techrxiv.24168660.v1...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch5...
DEBUG: Checking Unpywall for 10.1121/1.1917421...
DEBUG: Checking Unpywall for 10.1109/waspaa.2013.6701827...
DEBUG: Checking Unpywall for 10.1145/2788940.2788945...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610971...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v1/review2...
DEBUG: Checking Unpywall for 10.1109/aspaa.2003.1285869...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2892234...
DEBUG: Checking Unpywall for 10.1101/2025.10.25.681945...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289196...
DEBUG: Checking Unpywall for 10.1109/cstic64481.2025.11017832...
DEBUG: Checking Unpywall for 10.12720/jcm.17.7.528-540...
DEBUG: Checking Unpywall for 10.1109/ictest64710.2025.11042313...
DEBUG: Checking Unpywall for 10.1109/aspaa.2001.969577...
DEBUG: Checking Unpywall for 10.2139/ssrn.3414716...
DEBUG: Checking Unpywall for 10.25144/19116...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2324175...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0033...
DEBUG: Checking Unpywall for 10.1007/978-3-642-32796-4_3...
DEBUG: Checking Unpywall for 10.1016/j.aeue.2008.06.012...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch6...
DEBUG: Checking Unpywall for 10.1109/wcnc.2009.4917814...
DEBUG: Checking Unpywall for 10.1364/jocn.11.000260...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v1/review1...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v2/review1...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4393044...
DEBUG: Checking Unpywall for 10.1121/1.4799882...
DEBUG: Checking Unpywall for 10.1109/waspaa.2013.6701811...
DEBUG: Checking Unpywall for 10.1002/9781119252634...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0063...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0072...
DEBUG: Checking Unpywall for 10.1016/j.jsv.2020.115743...
DEBUG: Checking Unpywall for 10.4324/9781003354352-41...
DEBUG: Checking Unpywall for 10.36227/techrxiv.24288307.v1...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0022...
DEBUG: Checking Unpywall for 10.1109/jssc.2013.2252517...
DEBUG: Checking Unpywall for 10.17743/jaes.2019.0033...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346471...
DEBUG: Checking Unpywall for 10.1201/9781420093391-13...
DEBUG: Checking Unpywall for 10.1109/jssc.2012.2203870...
DEBUG: Checking Unpywall for 10.17743/jaes.2021.0009...
DEBUG: Checking Unpywall for 10.1002/9781119825449.ch12...
DEBUG: Checking Unpywall for 10.1109/isie.2011.5984197...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0179...
DEBUG: Checking Unpywall for 10.1145/2814895.2814917...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0175...
DEBUG: Checking Unpywall for 10.1016/0165-1684(91)90107-t...
DEBUG: Checking Unpywall for 10.1007/978-3-031-02559-4_7...
DEBUG: Checking Unpywall for 10.2139/ssrn.4882208...
DEBUG: Checking Unpywall for 10.30564/nmms.v3i1.3379...
DEBUG: Checking Unpywall for 10.1109/tcomm.2006.869858...
DEBUG: Checking Unpywall for 10.1109/icot56925.2022.10008141...
DEBUG: Checking Unpywall for 10.1364/cleo_si.2012.cf3i.6...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0059...
DEBUG: Checking Unpywall for 10.5391/jkiis.2007.17.1.058...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0092...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346485...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2988418...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2327300...
DEBUG: Checking Unpywall for 10.1109/wimax.2007.348702...
DEBUG: Checking Unpywall for 10.1145/1851600.1851642...
DEBUG: Checking Unpywall for 10.1016/j.aeue.2008.11.019...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2351614...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v2/review2...
DEBUG: Checking Unpywall for 10.1007/978-1-4615-5291-8_4...
DEBUG: Checking Unpywall for 10.1117/12.7974187...
DEBUG: Checking Unpywall for 10.1109/glocom.2011.6134167...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v1/review3...
DEBUG: Checking Unpywall for 10.1109/taslpro.2025.3544080...
DEBUG: Checking Unpywall for 10.36227/techrxiv.24288307...
DEBUG: Checking Unpywall for 10.21236/ada472111...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 100)...
>> Round 6: No new papers added (rejected/dup). Digging deeper...

--- Search Round 7 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 600)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0092...
DEBUG: Checking Unpywall for 10.1007/978-1-4614-8373-1_5...
DEBUG: Checking Unpywall for 10.1145/1851600.1851642...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610908...
DEBUG: Checking Unpywall for 10.4018/978-1-7998-9220-5.ch149...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289612...
DEBUG: Checking Unpywall for 10.1109/hscma.2014.6843267...
DEBUG: Checking Unpywall for 10.1109/taslp.2021.3076372...
DEBUG: Checking Unpywall for 10.1101/2022.04.25.489448...
DEBUG: Checking Unpywall for 10.1109/icassp.1984.1172655...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0087...
DEBUG: Checking Unpywall for 10.4324/9780080488066-39...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230933...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0059...
DEBUG: Checking Unpywall for 10.1109/iecon.2015.7392500...
DEBUG: Checking Unpywall for 10.1109/jssc.2010.2048136...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2097249...
DEBUG: Checking Unpywall for 10.1007/978-1-4614-4963-8_2...
DEBUG: Checking Unpywall for 10.1609/aaai.v35i3.16302...
DEBUG: Checking Unpywall for 10.1109/jssc.2013.2264618...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2439577...
DEBUG: Checking Unpywall for 10.1109/iswcs.2012.6328366...
DEBUG: Checking Unpywall for 10.1109/tmtt.2013.2283845...
DEBUG: Checking Unpywall for 10.1109/waspaa.2013.6701870...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2556280...
DEBUG: Checking Unpywall for 10.4324/9781003354352-36...
DEBUG: Checking Unpywall for 10.1109/82.199895...
DEBUG: Checking Unpywall for 10.1109/waspaa58266.2023.10248123...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v2/decision1...
DEBUG: Checking Unpywall for 10.1109/eucap.2006.4584763...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.889795...
DEBUG: Checking Unpywall for 10.25144/16452...
DEBUG: Checking Unpywall for 10.21437/interspeech.2013-651...
DEBUG: Checking Unpywall for 10.1121/10.0023499...
DEBUG: Checking Unpywall for 10.1109/temc.2017.2788500...
DEBUG: Checking Unpywall for 10.1109/tmm.2011.2168197...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346519...
DEBUG: Checking Unpywall for 10.1109/icassp.2009.4959571...
DEBUG: Checking Unpywall for 10.1145/3564533.3564563...
DEBUG: Checking Unpywall for 10.1093/iwc/iwac009...
DEBUG: Checking Unpywall for 10.1093/oxfordhb/9780199797226.013.001...
DEBUG: Checking Unpywall for 10.1109/iswcs.2018.8491041...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2365971...
DEBUG: Checking Unpywall for 10.17743/jaes.2019.0020...
DEBUG: Checking Unpywall for 10.1111/ejn.70226/v1/decision1...
DEBUG: Checking Unpywall for 10.1109/aspaa.1999.810888...
DEBUG: Checking Unpywall for 10.1002/ett.1348...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2261813...
DEBUG: Checking Unpywall for 10.25144/23996...
DEBUG: Checking Unpywall for 10.1109/vtc2025-spring65109.2025.11174681...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch8...
DEBUG: Checking Unpywall for 10.21437/interspeech.2015-393...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0063...
DEBUG: Checking Unpywall for 10.1007/978-1-4614-4963-8_3...
DEBUG: Checking Unpywall for 10.1109/waspaa.2019.8937228...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082288...
DEBUG: Checking Unpywall for 10.1109/psc57974.2023.10297275...
DEBUG: Checking Unpywall for 10.33959/cuijca.v1i1.19...
DEBUG: Checking Unpywall for 10.17743/jaes.2018.0067...
DEBUG: Checking Unpywall for 10.1109/tdpvt.2002.1024066...
DEBUG: Checking Unpywall for 10.1109/icme.2000.869588...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0144...
DEBUG: Checking Unpywall for 10.1109/newcas49341.2020.9159826...
DEBUG: Checking Unpywall for 10.1016/j.sctalk.2025.100421...
DEBUG: Checking Unpywall for 10.1109/lsp.2014.2320439...
DEBUG: Checking Unpywall for 10.1109/glocom.2005.1578326...
DEBUG: Checking Unpywall for 10.5594/m001712...
DEBUG: Checking Unpywall for 10.1109/lsp.2014.2320433...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3193285...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2277928...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2998328...
DEBUG: Checking Unpywall for 10.21437/interspeech.2025-746...
DEBUG: Checking Unpywall for 10.1109/wirles.2005.1549529...
DEBUG: Checking Unpywall for 10.1109/msp.2017.2784881...
DEBUG: Checking Unpywall for 10.25144/15706...
DEBUG: Checking Unpywall for 10.1037/neu0000776.supp...
DEBUG: Checking Unpywall for 10.17743/jaes.2018.0027...
DEBUG: Checking Unpywall for 10.1109/lsp.2014.2320436...
DEBUG: Checking Unpywall for 10.1117/12.7976780...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202056...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230921...
DEBUG: Checking Unpywall for 10.1143/jjap.39.837...
DEBUG: Checking Unpywall for 10.1109/icc.2015.7248639...
DEBUG: Checking Unpywall for 10.1109/icassp.2013.6637722...
DEBUG: Checking Unpywall for 10.1109/glocomw.2013.6825155...
DEBUG: Checking Unpywall for 10.23919/eucap48036.2020.9135954...
DEBUG: Checking Unpywall for 10.1002/9781119279860.ch3...
DEBUG: Checking Unpywall for 10.4218/etrij.05.0205.0025...
DEBUG: Checking Unpywall for 10.1002/9781119991298.ch5...
DEBUG: Checking Unpywall for 10.1016/j.cortex.2008.03.012...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v2/review1...
DEBUG: Checking Unpywall for 10.1016/j.cortex.2024.11.006...
DEBUG: Checking Unpywall for 10.4324/9780429491214-13...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610975...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v1/review1...
DEBUG: Checking Unpywall for 10.1109/taslp.2023.3250845...
DEBUG: Checking Unpywall for 10.1109/icassp.2018.8462389...
DEBUG: Checking Unpywall for 10.4324/9781003347149-11...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2327294...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 120)...
>> Round 7: No new papers added (rejected/dup). Digging deeper...

--- Search Round 8 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 700)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/icalip.2008.4590168...
DEBUG: Checking Unpywall for 10.1016/j.cortex.2008.03.012...
DEBUG: Checking Unpywall for 10.1109/icassp.2018.8462389...
DEBUG: Checking Unpywall for 10.1109/aspaa.1995.482949...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2203806...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2327294...
DEBUG: Checking Unpywall for 10.2139/ssrn.4577582...
DEBUG: Checking Unpywall for 10.1109/have.2009.5356116...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0017...
DEBUG: Checking Unpywall for 10.1145/3616195.3616211...
DEBUG: Checking Unpywall for 10.1002/9781119279860.ch10...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9...
DEBUG: Checking Unpywall for 10.1002/9780470723494.oth1...
DEBUG: Checking Unpywall for 10.1109/sam.2008.4606895...
DEBUG: Checking Unpywall for 10.1121/1.4899768...
DEBUG: Checking Unpywall for 10.1109/vlsitechnologyandcir46783.2024.10631466...
DEBUG: Checking Unpywall for 10.1109/vcip49819.2020.9301766...
DEBUG: Checking Unpywall for 10.1109/jstsp.2016.2639325...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2160167...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.2011517...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2540815...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v1/review2...
DEBUG: Checking Unpywall for 10.1364/fio.2022.jtu5a.69...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch8...
DEBUG: Checking Unpywall for 10.1109/icce.2011.5722594...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0005...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082293...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch10...
DEBUG: Checking Unpywall for 10.1109/waspaa52581.2021.9632781...
DEBUG: Checking Unpywall for 10.1109/ictc.2010.5674722...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2434272...
DEBUG: Checking Unpywall for 10.1109/aero.2007.352774...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2808042...
DEBUG: Checking Unpywall for 10.5772/intechopen.102029...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230936...
DEBUG: Checking Unpywall for 10.1364/np.2012.nw3d.1...
DEBUG: Checking Unpywall for 10.1186/s13636-016-0091-z...
DEBUG: Checking Unpywall for 10.21437/interspeech.2023-2117...
DEBUG: Checking Unpywall for 10.1109/icme.2011.6012203...
DEBUG: Checking Unpywall for 10.33103/uot.ijccce.20.2.6...
DEBUG: Checking Unpywall for 10.1002/hbm.20085...
DEBUG: Checking Unpywall for 10.1109/tifs.2014.2323157...
DEBUG: Checking Unpywall for 10.4304/jmm.5.3.224-231...
DEBUG: Checking Unpywall for 10.1109/iccs.2010.5686460...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v2/review2...
DEBUG: Checking Unpywall for 10.1109/icalip.2016.7846588...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2208625...
DEBUG: Checking Unpywall for 10.1109/pimrc.2006.254007...
DEBUG: Checking Unpywall for 10.1109/sbmomo.1995.509653...
DEBUG: Checking Unpywall for 10.1109/istel.2012.6482972...
DEBUG: Checking Unpywall for 10.1109/iihmsp.2010.133...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2690559...
DEBUG: Checking Unpywall for 10.1109/tifs.2014.2323154...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5685200...
DEBUG: Checking Unpywall for 10.1016/j.neures.2010.07.1299...
DEBUG: Checking Unpywall for 10.1117/12.964270...
DEBUG: Checking Unpywall for 10.4218/etrij.09.0108.0557...
DEBUG: Checking Unpywall for 10.1109/tifs.2014.2311916...
DEBUG: Checking Unpywall for 10.1109/mmsp.2018.8547099...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2303576...
DEBUG: Checking Unpywall for 10.1101/2022.04.30.490125...
DEBUG: Checking Unpywall for 10.1121/1.4806149...
DEBUG: Checking Unpywall for 10.1109/iwssip55020.2022.9854439...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2344856...
DEBUG: Checking Unpywall for 10.1007/978-3-642-24656-2_28...
DEBUG: Checking Unpywall for 10.1121/1.425147...
DEBUG: Checking Unpywall for 10.1364/cleo_si.2014.sw3j.8...
DEBUG: Checking Unpywall for 10.1109/mpot.2012.2212051...
DEBUG: Checking Unpywall for 10.1142/9789812774583_0008...
DEBUG: Checking Unpywall for 10.1037/e578252012-005...
DEBUG: Checking Unpywall for 10.1371/journal.pone.0023017...
DEBUG: Checking Unpywall for 10.1117/12.868320...
DEBUG: Checking Unpywall for 10.1109/89.902284...
DEBUG: Checking Unpywall for 10.3389/fpsyg.2015.01357...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2280210...
DEBUG: Checking Unpywall for 10.1109/icdsp.2011.6005001...
DEBUG: Checking Unpywall for 10.1101/2021.04.01.438106...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v2/decision1...
DEBUG: Checking Unpywall for 10.31219/osf.io/dwyr5...
DEBUG: Checking Unpywall for 10.1109/tifs.2014.2311918...
DEBUG: Checking Unpywall for 10.1016/j.specom.2014.10.003...
DEBUG: Checking Unpywall for 10.1002/9780470723494.ch7...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289165...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0157...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2033955...
DEBUG: Checking Unpywall for 10.1364/oe.20.022334...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2248712...
DEBUG: Checking Unpywall for 10.1145/2522848.2522863...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2570945...
DEBUG: Checking Unpywall for 10.2139/ssrn.4937483...
DEBUG: Checking Unpywall for 10.54941/ahfe1004990...
DEBUG: Checking Unpywall for 10.1109/vlsitechnologyandcir46783.2024.10631468...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v1/decision1...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2789320...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289525...
DEBUG: Checking Unpywall for 10.1186/s13636-024-00381-3...
DEBUG: Checking Unpywall for 10.1109/acssc.2006.354927...
DEBUG: Checking Unpywall for 10.1186/s13636-020-00186-0...
DEBUG: Checking Unpywall for 10.1007/978-3-7091-4891-4_1...
DEBUG: Checking Unpywall for 10.1002/ett.1345...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 140)...
>> Round 8: No new papers added (rejected/dup). Digging deeper...

--- Search Round 9 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 800)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1364/oct.2022.cs2e.2...
DEBUG: Checking Unpywall for 10.54941/ahfe1004990...
DEBUG: Checking Unpywall for 10.1109/icalip.2008.4590260...
DEBUG: Checking Unpywall for 10.3390/app7080788...
DEBUG: Checking Unpywall for 10.1109/iccchina.2014.7008232...
DEBUG: Checking Unpywall for 10.1121/1.3650321...
DEBUG: Checking Unpywall for 10.1016/j.actpsy.2021.103384...
DEBUG: Checking Unpywall for 10.1109/icassp.2008.4517633...
DEBUG: Checking Unpywall for 10.4103/0377-2063.123762...
DEBUG: Checking Unpywall for 10.1109/jssc.2014.2298456...
DEBUG: Checking Unpywall for 10.1109/icalip.2008.4589988...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5684966...
DEBUG: Checking Unpywall for 10.1038/s41598-018-27370-9...
DEBUG: Checking Unpywall for 10.20449/jnte.v6i1.372...
DEBUG: Checking Unpywall for 10.1101/2021.04.19.440487...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0026...
DEBUG: Checking Unpywall for 10.1186/s13636-023-00298-3...
DEBUG: Checking Unpywall for 10.1109/icassp.2002.1004888...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch1...
DEBUG: Checking Unpywall for 10.12968/s0047-9624(22)60514-5...
DEBUG: Checking Unpywall for 10.1109/milcom.2018.8599727...
DEBUG: Checking Unpywall for 10.1109/iwaenc.2018.8521343...
DEBUG: Checking Unpywall for 10.5194/isprsarchives-xl-4-187-2014...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2363407...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch12...
DEBUG: Checking Unpywall for 10.1109/jsac.2010.101207...
DEBUG: Checking Unpywall for 10.5220/0001095203950402...
DEBUG: Checking Unpywall for 10.1109/icassp.2016.7471632...
DEBUG: Checking Unpywall for 10.1109/iwaenc.2016.7602968...
DEBUG: Checking Unpywall for 10.1109/icosp.2006.346086...
DEBUG: Checking Unpywall for 10.1109/jstsp.2015.2411578...
DEBUG: Checking Unpywall for 10.1109/tvt.2007.907313...
DEBUG: Checking Unpywall for 10.1109/taslp.2023.3282103...
DEBUG: Checking Unpywall for 10.1142/s0129156405003260...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3458811...
DEBUG: Checking Unpywall for 10.1109/icassp.2002.1006124...
DEBUG: Checking Unpywall for 10.1121/2.0000457...
DEBUG: Checking Unpywall for 10.1103/physrevx.10.031065...
DEBUG: Checking Unpywall for 10.1007/s12206-024-0907-1...
DEBUG: Checking Unpywall for 10.1109/csse.2008.1276...
DEBUG: Checking Unpywall for 10.1007/978-3-642-37762-4_13...
DEBUG: Checking Unpywall for 10.1109/icme.2009.5202434...
DEBUG: Checking Unpywall for 10.1364/oe.24.010635...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2277937...
DEBUG: Checking Unpywall for 10.1121/1.3600932...
DEBUG: Checking Unpywall for 10.2139/ssrn.4834847...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2554288...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0030...
DEBUG: Checking Unpywall for 10.1007/978-3-319-52171-8_19...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2752364...
DEBUG: Checking Unpywall for 10.1386/ts_00017_1...
DEBUG: Checking Unpywall for 10.24135/ijcmr.v11i1.138...
DEBUG: Checking Unpywall for 10.1109/iscc58397.2023.10217949...
DEBUG: Checking Unpywall for 10.1109/ncc48643.2020.9056097...
DEBUG: Checking Unpywall for 10.1109/89.799696...
DEBUG: Checking Unpywall for 10.1109/ccnc.2010.5421622...
DEBUG: Checking Unpywall for 10.1016/j.jri.2018.06.016...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610887...
DEBUG: Checking Unpywall for 10.1109/icdsp.2013.6622780...
DEBUG: Checking Unpywall for 10.1109/tnsre.2025.3591819/mm1...
DEBUG: Checking Unpywall for 10.1155/2009/876297...
DEBUG: Checking Unpywall for 10.1101/2024.03.23.586434...
DEBUG: Checking Unpywall for 10.23919/transcom.2025ebp3053...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202080...
DEBUG: Checking Unpywall for 10.1109/aspaa.1997.625599...
DEBUG: Checking Unpywall for 10.1007/s00221-012-3393-0...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610850...
DEBUG: Checking Unpywall for 10.1037/e578512012-006...
DEBUG: Checking Unpywall for 10.1109/iwem.2014.6963652...
DEBUG: Checking Unpywall for 10.3389/fnint.2019.00074...
DEBUG: Checking Unpywall for 10.1109/sive.2014.7006287...
DEBUG: Checking Unpywall for 10.1111/ejn.70182/v2/response1...
DEBUG: Checking Unpywall for 10.1109/mvhi.2010.68...
DEBUG: Checking Unpywall for 10.1121/1.3472297...
DEBUG: Checking Unpywall for 10.1007/s12206-022-0206-7...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5685051...
DEBUG: Checking Unpywall for 10.1109/icassp.2008.4518536...
DEBUG: Checking Unpywall for 10.1109/ibcast.2017.7868144...
DEBUG: Checking Unpywall for 10.1109/tmm.2020.3037537...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2339195...
DEBUG: Checking Unpywall for 10.1515/joc-2017-0179...
DEBUG: Checking Unpywall for 10.1109/icassp.2010.5495803...
DEBUG: Checking Unpywall for 10.5573/ieek.2013.50.12.217...
DEBUG: Checking Unpywall for 10.1121/1.414951...
DEBUG: Checking Unpywall for 10.1007/3-540-33213-8_3...
DEBUG: Checking Unpywall for 10.1109/icme.2001.1237915...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_1...
DEBUG: Checking Unpywall for 10.1201/b18703-17...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0026...
DEBUG: Checking Unpywall for 10.1109/wcsp.2015.7341009...
DEBUG: Checking Unpywall for 10.1007/s11277-015-2859-3...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202072...
DEBUG: Checking Unpywall for 10.1109/tcomm.2009.08.070108...
DEBUG: Checking Unpywall for 10.1109/rfic.2016.7508260...
DEBUG: Checking Unpywall for 10.1016/j.neuropsychologia.2020.107530...
DEBUG: Checking Unpywall for 10.25077/jnte.v6n1.372.2017...
DEBUG: Checking Unpywall for 10.1121/1.4801086...
DEBUG: Checking Unpywall for 10.1162/comj_a_00402...
DEBUG: Checking Unpywall for 10.1109/embc40787.2023.10339960...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 160)...
>> Round 9: No new papers added (rejected/dup). Digging deeper...

--- Search Round 10 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 900)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/apsipaasc65261.2025.11249288...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5685038...
DEBUG: Checking Unpywall for 10.1109/icme.2007.4285045...
DEBUG: Checking Unpywall for 10.1109/icassp.2018.8462101...
DEBUG: Checking Unpywall for 10.1186/s13636-024-00386-y...
DEBUG: Checking Unpywall for 10.1101/2025.01.07.631825...
DEBUG: Checking Unpywall for 10.3109/00207459908994301...
DEBUG: Checking Unpywall for 10.3788/col201614.100604...
DEBUG: Checking Unpywall for 10.1023/a:1021749502914...
DEBUG: Checking Unpywall for 10.1088/2041-8205/793/1/l9...
DEBUG: Checking Unpywall for 10.1016/j.phycom.2018.02.008...
DEBUG: Checking Unpywall for 10.1109/icme.2001.1237915...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2134091...
DEBUG: Checking Unpywall for 10.1007/s10470-020-01709-7...
DEBUG: Checking Unpywall for 10.22215/etd/1989-01521...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0038...
DEBUG: Checking Unpywall for 10.4324/9780429439384-10...
DEBUG: Checking Unpywall for 10.1109/icc.2001.937371...
DEBUG: Checking Unpywall for 10.1109/temu.2014.6917734...
DEBUG: Checking Unpywall for 10.1109/icus55513.2022.9986987...
DEBUG: Checking Unpywall for 10.1007/s11277-015-2859-3...
DEBUG: Checking Unpywall for 10.1109/taslp.2023.3313446...
DEBUG: Checking Unpywall for 10.1109/icassp48485.2024.10447947...
DEBUG: Checking Unpywall for 10.1109/taslp.2023.3250841...
DEBUG: Checking Unpywall for 10.1109/icassp.2014.6854286...
DEBUG: Checking Unpywall for 10.58837/chula.the.2001.1019...
DEBUG: Checking Unpywall for 10.2307/3680992...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009939...
DEBUG: Checking Unpywall for 10.3389/fpsyg.2017.01932...
DEBUG: Checking Unpywall for 10.1007/978-3-319-11776-8_8...
DEBUG: Checking Unpywall for 10.1587/transinf.2015edl8248...
DEBUG: Checking Unpywall for 10.1109/sips.2018.8598414...
DEBUG: Checking Unpywall for 10.21437/interspeech.2022-406...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0064...
DEBUG: Checking Unpywall for 10.3389/fnint.2015.00034...
DEBUG: Checking Unpywall for 10.1016/j.ijleo.2019.163699...
DEBUG: Checking Unpywall for 10.1287/opre.2022.2399...
DEBUG: Checking Unpywall for 10.1117/12.780210...
DEBUG: Checking Unpywall for 10.1109/gem.2018.8516445...
DEBUG: Checking Unpywall for 10.1109/isscc.2018.8310182...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009902...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009850...
DEBUG: Checking Unpywall for 10.21428/8e6ba8ef.70474aa5...
DEBUG: Checking Unpywall for 10.1109/iccc65529.2025.11148838...
DEBUG: Checking Unpywall for 10.1109/spi.2004.1409009...
DEBUG: Checking Unpywall for 10.1109/glocom.2008.ecp.134...
DEBUG: Checking Unpywall for 10.29007/515s...
DEBUG: Checking Unpywall for 10.25144/16439...
DEBUG: Checking Unpywall for 10.1117/12.2212700...
DEBUG: Checking Unpywall for 10.1109/icm60448.2023.10378943...
DEBUG: Checking Unpywall for 10.1007/s00034-016-0324-5...
DEBUG: Checking Unpywall for 10.1101/2020.04.01.019638...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376678...
DEBUG: Checking Unpywall for 10.1007/1-4020-8092-1_6...
DEBUG: Checking Unpywall for 10.3390/app7040374...
DEBUG: Checking Unpywall for 10.1109/taslp.2014.2318519...
DEBUG: Checking Unpywall for 10.1017/s1355771810000336...
DEBUG: Checking Unpywall for 10.1007/978-3-642-24656-2_29...
DEBUG: Checking Unpywall for 10.1007/978-3-319-05660-9_1...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2958408...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2923969...
DEBUG: Checking Unpywall for 10.1121/1.3587943...
DEBUG: Checking Unpywall for 10.1109/isocc62682.2024.10762050...
DEBUG: Checking Unpywall for 10.1007/bf01324121...
DEBUG: Checking Unpywall for 10.1121/1.404077...
DEBUG: Checking Unpywall for 10.1007/978-3-642-15841-4_6...
DEBUG: Checking Unpywall for 10.1109/taslp.2021.3107983...
DEBUG: Checking Unpywall for 10.1016/j.neuropsychologia.2006.05.018...
DEBUG: Checking Unpywall for 10.1007/s00221-003-1473-x...
DEBUG: Checking Unpywall for 10.1109/icassp.2016.7471730...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202037...
DEBUG: Checking Unpywall for 10.1007/s10470-016-0699-z...
DEBUG: Checking Unpywall for 10.1109/vrw50115.2020.00085...
DEBUG: Checking Unpywall for 10.1007/978-3-642-23071-4_34...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3407676...
DEBUG: Checking Unpywall for 10.1371/journal.pone.0260700...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5685032...
DEBUG: Checking Unpywall for 10.1109/jstsp.2014.2322303...
DEBUG: Checking Unpywall for 10.1109/isscc.2001.912549...
DEBUG: Checking Unpywall for 10.1145/3123514.3123563...
DEBUG: Checking Unpywall for 10.1109/acssc.2001.987752...
DEBUG: Checking Unpywall for 10.5194/isprs-archives-xlvi-3-w1-2022-105-2022...
DEBUG: Checking Unpywall for 10.1109/waspaa52581.2021.9632793...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376772...
DEBUG: Checking Unpywall for 10.1109/iccworkshops49005.2020.9145385...
DEBUG: Checking Unpywall for 10.5810/kentucky/9780813167879.003.0007...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2020532...
DEBUG: Checking Unpywall for 10.1109/eit64391.2025.11103691...
DEBUG: Checking Unpywall for 10.1109/isscc49657.2024.10454508...
DEBUG: Checking Unpywall for 10.1109/lcomm.2021.3125340...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3357036...
DEBUG: Checking Unpywall for 10.23919/eusipco63237.2025.11226459...
DEBUG: Checking Unpywall for 10.1364/cleo_europe.1998.cwb4...
DEBUG: Checking Unpywall for 10.1109/tcsii.2022.3205246...
DEBUG: Checking Unpywall for 10.1109/jlt.2014.2334474...
DEBUG: Checking Unpywall for 10.1109/ieeeconf53345.2021.9723358...
DEBUG: Checking Unpywall for 10.1007/s12193-021-00383-x...
DEBUG: Checking Unpywall for 10.1037/e576862012-064...
DEBUG: Checking Unpywall for 10.1167/jov.21.9.2905...
DEBUG: Checking Unpywall for 10.1109/icassp.2010.5495933...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 180)...
>> Round 10: No new papers added (rejected/dup). Digging deeper...

--- Search Round 11 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1000)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/eusipco.2016.7760532...
DEBUG: Checking Unpywall for 10.1109/tmtt.2004.839311...
DEBUG: Checking Unpywall for 10.1145/142621.142628...
DEBUG: Checking Unpywall for 10.1016/j.trf.2011.02.003...
DEBUG: Checking Unpywall for 10.1186/s13634-016-0339-x...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610847...
DEBUG: Checking Unpywall for 10.1007/978-3-642-37762-4_4...
DEBUG: Checking Unpywall for 10.2139/ssrn.5340698...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch3...
DEBUG: Checking Unpywall for 10.1186/s13636-025-00392-8...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2425213...
DEBUG: Checking Unpywall for 10.1109/iccci49374.2020.9145986...
DEBUG: Checking Unpywall for 10.1186/s13636-021-00201-y...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0046...
DEBUG: Checking Unpywall for 10.1049/el.2016.2132...
DEBUG: Checking Unpywall for 10.1109/jlt.2014.2334474...
DEBUG: Checking Unpywall for 10.4324/9781315707525-2...
DEBUG: Checking Unpywall for 10.1109/cleoe.1998.719138...
DEBUG: Checking Unpywall for 10.1109/icassp.2008.4517623...
DEBUG: Checking Unpywall for 10.5772/intechopen.100402...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_7...
DEBUG: Checking Unpywall for 10.1121/1.2932498...
DEBUG: Checking Unpywall for 10.1109/icdcsw.2013.38...
DEBUG: Checking Unpywall for 10.1007/springerreference_9575...
DEBUG: Checking Unpywall for 10.1109/iciteed.2014.7007926...
DEBUG: Checking Unpywall for 10.1109/isscc49657.2024.10454508...
DEBUG: Checking Unpywall for 10.4324/9781003416180-6...
DEBUG: Checking Unpywall for 10.1109/icassp.2019.8683062...
DEBUG: Checking Unpywall for 10.1250/ast.22.380...
DEBUG: Checking Unpywall for 10.1017/s1355771825000044...
DEBUG: Checking Unpywall for 10.1109/vrais.1993.380780...
DEBUG: Checking Unpywall for 10.1109/icalip.2018.8455357...
DEBUG: Checking Unpywall for 10.1109/tap.1986.1143820...
DEBUG: Checking Unpywall for 10.1109/mmsp.2010.5662065...
DEBUG: Checking Unpywall for 10.1109/qomex.2012.6263861...
DEBUG: Checking Unpywall for 10.1063/1.4878261...
DEBUG: Checking Unpywall for 10.3145/epi.2022.sep.19...
DEBUG: Checking Unpywall for 10.1109/icme.2011.6012020...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610868...
DEBUG: Checking Unpywall for 10.1121/10.0023161...
DEBUG: Checking Unpywall for 10.1302/1358-992x.2025.7.103...
DEBUG: Checking Unpywall for 10.1109/isscc49661.2025.10904631...
DEBUG: Checking Unpywall for 10.1109/icccas65806.2025.11102363...
DEBUG: Checking Unpywall for 10.1109/iscas58744.2024.10558117...
DEBUG: Checking Unpywall for 10.3389/fvets.2023.1264151...
DEBUG: Checking Unpywall for 10.5772/intechopen.104845...
DEBUG: Checking Unpywall for 10.1109/iih-msp.2009.45...
DEBUG: Checking Unpywall for 10.1109/apsipaasc65261.2025.11249007...
DEBUG: Checking Unpywall for 10.1007/978-3-030-00386-9_20...
DEBUG: Checking Unpywall for 10.3389/fpsyg.2013.00189...
DEBUG: Checking Unpywall for 10.5594/j18221...
DEBUG: Checking Unpywall for 10.1109/icassp.2002.5744983...
DEBUG: Checking Unpywall for 10.1109/jssc.2024.3387355...
DEBUG: Checking Unpywall for 10.55810/2313-0083.1032...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346466...
DEBUG: Checking Unpywall for 10.7840/kics.2011.36c.5.309...
DEBUG: Checking Unpywall for 10.1109/icassp.2019.8682315...
DEBUG: Checking Unpywall for 10.1049/iet-spr.2013.0015...
DEBUG: Checking Unpywall for 10.1163/22134808-00002441...
DEBUG: Checking Unpywall for 10.1093/cercor/bhu034...
DEBUG: Checking Unpywall for 10.1037/e572172013-343...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4393040...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch11...
DEBUG: Checking Unpywall for 10.1167/6.6.511...
DEBUG: Checking Unpywall for 10.1121/1.4800599...
DEBUG: Checking Unpywall for 10.1109/mwp54208.2022.9997712...
DEBUG: Checking Unpywall for 10.1109/icpr.2014.145...
DEBUG: Checking Unpywall for 10.1145/2660579.2660581...
DEBUG: Checking Unpywall for 10.1201/9781315220420-2...
DEBUG: Checking Unpywall for 10.1109/eusipco.2016.7760321...
DEBUG: Checking Unpywall for 10.1353/pnm.2013.0011...
DEBUG: Checking Unpywall for 10.1109/isitia.2015.7220014...
DEBUG: Checking Unpywall for 10.5194/isprsarchives-xxxviii-6-w27-45-2011...
DEBUG: Checking Unpywall for 10.1109/iccnc.2019.8685514...
DEBUG: Checking Unpywall for 10.1109/icce.1996.517223...
DEBUG: Checking Unpywall for 10.1002/9781119252634.ch7...
DEBUG: Checking Unpywall for 10.54941/ahfe100212...
DEBUG: Checking Unpywall for 10.1109/bmsb47279.2019.8971936...
DEBUG: Checking Unpywall for 10.5772/intechopen.102908...
DEBUG: Checking Unpywall for 10.1109/icassp.2017.7952254...
DEBUG: Checking Unpywall for 10.24919/2308-4863/86-2-28...
DEBUG: Checking Unpywall for 10.1007/s100440200023...
DEBUG: Checking Unpywall for 10.1145/3681716.3689442...
DEBUG: Checking Unpywall for 10.1007/springerreference_184011...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3356987...
DEBUG: Checking Unpywall for 10.1049/iet-com.2009.0843...
DEBUG: Checking Unpywall for 10.1109/isspit.2005.1577071...
DEBUG: Checking Unpywall for 10.24271/garmian.scpas16...
DEBUG: Checking Unpywall for 10.1109/waspaa.2019.8937163...
DEBUG: Checking Unpywall for 10.1145/1520340.1520578...
DEBUG: Checking Unpywall for 10.3390/app7060627...
DEBUG: Checking Unpywall for 10.1023/a:1018675327815...
DEBUG: Checking Unpywall for 10.1103/physreve.87.062813...
DEBUG: Checking Unpywall for 10.1109/icassp.2018.8462315...
DEBUG: Checking Unpywall for 10.2139/ssrn.4261950...
DEBUG: Checking Unpywall for 10.1109/esscirc55480.2022.9911463...
DEBUG: Checking Unpywall for 10.1121/1.3525300...
DEBUG: Checking Unpywall for 10.1145/3411109.3411136...
DEBUG: Checking Unpywall for 10.1109/is262782.2024.10704097...
DEBUG: Checking Unpywall for 10.1109/wcnc61545.2025.10978423...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 200)...
>> Round 11: No new papers added (rejected/dup). Digging deeper...

--- Search Round 12 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1100)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/apsipa.2015.7415422...
DEBUG: Checking Unpywall for 10.3410/f.740391745.793587912...
DEBUG: Checking Unpywall for 10.21437/interspeech.2022-10073...
DEBUG: Checking Unpywall for 10.1109/peas53589.2021.9628657...
DEBUG: Checking Unpywall for 10.55810/2313-0083.1032...
DEBUG: Checking Unpywall for 10.1109/vlsitechnologyandcir46783.2024.10631489...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346524...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376689...
DEBUG: Checking Unpywall for 10.1121/1.4712244...
DEBUG: Checking Unpywall for 10.1007/springerreference_184011...
DEBUG: Checking Unpywall for 10.1109/taslp.2021.3087951...
DEBUG: Checking Unpywall for 10.1109/jssc.2004.833569...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2674975...
DEBUG: Checking Unpywall for 10.1145/351006.351051...
DEBUG: Checking Unpywall for 10.1109/aspaa.2009.5346466...
DEBUG: Checking Unpywall for 10.1109/tmm.2004.827516...
DEBUG: Checking Unpywall for 10.24425/ijet.2025.155463...
DEBUG: Checking Unpywall for 10.5772/intechopen.101940...
DEBUG: Checking Unpywall for 10.1109/aspaa.1993.379986...
DEBUG: Checking Unpywall for 10.1164/ajrccm-conference.2024.209.1_meetingabstracts.a3002...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2987748...
DEBUG: Checking Unpywall for 10.1109/waspaa.2019.8937163...
DEBUG: Checking Unpywall for 10.1049/el:20081199...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2633811...
DEBUG: Checking Unpywall for 10.1109/jstsp.2022.3180592...
DEBUG: Checking Unpywall for 10.1109/pimrc.2015.7343347...
DEBUG: Checking Unpywall for 10.1109/acp.2018.8595895...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610842...
DEBUG: Checking Unpywall for 10.3390/app7060627...
DEBUG: Checking Unpywall for 10.1121/1.5147315...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2443977...
DEBUG: Checking Unpywall for 10.1109/icce.2011.5722879...
DEBUG: Checking Unpywall for 10.3758/app.72.4.989...
DEBUG: Checking Unpywall for 10.1109/tit.2011.2178140...
DEBUG: Checking Unpywall for 10.1109/pimrc.2002.1045201...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610880...
DEBUG: Checking Unpywall for 10.25144/24812...
DEBUG: Checking Unpywall for 10.1109/icalip.2016.7846556...
DEBUG: Checking Unpywall for 10.1017/s1355771825100563...
DEBUG: Checking Unpywall for 10.1111/jnp.12177...
DEBUG: Checking Unpywall for 10.21203/rs.3.rs-6219019/v1...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_6...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_5...
DEBUG: Checking Unpywall for 10.14236/ewic/eva2023.21...
DEBUG: Checking Unpywall for 10.1109/tvt.2002.804851...
DEBUG: Checking Unpywall for 10.1091/mbc.p22-10-1005...
DEBUG: Checking Unpywall for 10.14236/ewic/ad1998.7...
DEBUG: Checking Unpywall for 10.1016/j.apacoust.2010.08.002...
DEBUG: Checking Unpywall for 10.1109/qomex.2016.7498948...
DEBUG: Checking Unpywall for 10.1109/aspaa.2003.1285874...
DEBUG: Checking Unpywall for 10.4018/978-1-4666-5888-2.ch594...
DEBUG: Checking Unpywall for 10.4049/jimmunol.212.supp.0537.5228...
DEBUG: Checking Unpywall for 10.4218/etrij.07.0206.0149...
DEBUG: Checking Unpywall for 10.1364/quantum.2023.qth2a.22...
DEBUG: Checking Unpywall for 10.1109/vtcspring.2013.6691828...
DEBUG: Checking Unpywall for 10.1109/taslp.2016.2560523...
DEBUG: Checking Unpywall for 10.1016/j.bbr.2006.05.030...
DEBUG: Checking Unpywall for 10.1250/ast.39.397...
DEBUG: Checking Unpywall for 10.1109/nsip.2005.1502303...
DEBUG: Checking Unpywall for 10.1145/1509315.1509440...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_3...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0059...
DEBUG: Checking Unpywall for 10.1163/22134808-000s0104...
DEBUG: Checking Unpywall for 10.1587/transcom.e93.b.1641...
DEBUG: Checking Unpywall for 10.1007/978-3-031-04021-4_6...
DEBUG: Checking Unpywall for 10.1109/imws2.2011.6027197...
DEBUG: Checking Unpywall for 10.1109/taslp.2015.2500028...
DEBUG: Checking Unpywall for 10.1109/icassp.2009.4959559...
DEBUG: Checking Unpywall for 10.1016/j.ijleo.2020.166190...
DEBUG: Checking Unpywall for 10.1201/9781410608888.ch9...
DEBUG: Checking Unpywall for 10.1121/1.1763973...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376778...
DEBUG: Checking Unpywall for 10.1049/el:19951375...
DEBUG: Checking Unpywall for 10.21236/ada430289...
DEBUG: Checking Unpywall for 10.1109/3dui.2012.6184204...
DEBUG: Checking Unpywall for 10.1109/eusipco.2015.7362551...
DEBUG: Checking Unpywall for 10.1109/cost68045.2025.00063...
DEBUG: Checking Unpywall for 10.1145/2808492.2808533...
DEBUG: Checking Unpywall for 10.1121/1.4799033...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202063...
DEBUG: Checking Unpywall for 10.1145/365024.365092...
DEBUG: Checking Unpywall for 10.1250/ast.25.393...
DEBUG: Checking Unpywall for 10.1109/icassp.2002.5745627...
DEBUG: Checking Unpywall for 10.1109/siu.2016.7495723...
DEBUG: Checking Unpywall for 10.1109/icassp49660.2025.10888786...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2665341...
DEBUG: Checking Unpywall for 10.5920/divp.2015.32...
DEBUG: Checking Unpywall for 10.1109/icassp.2019.8683810...
DEBUG: Checking Unpywall for 10.1109/vetecs.2010.5493822...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3410869...
DEBUG: Checking Unpywall for 10.1007/springerreference_13189...
DEBUG: Checking Unpywall for 10.1076/jcen.23.5.599.1243...
DEBUG: Checking Unpywall for 10.1109/ncc.2016.7561105...
DEBUG: Checking Unpywall for 10.1109/waspaa.2019.8937247...
DEBUG: Checking Unpywall for 10.1242/prelights.31795...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3451988...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3140548...
DEBUG: Checking Unpywall for 10.1121/1.3561537...
DEBUG: Checking Unpywall for 10.1016/j.apacoust.2019.107179...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2892895...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 220)...
>> Round 12: No new papers added (rejected/dup). Digging deeper...

--- Search Round 13 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1200)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 98 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/icassp49660.2025.10889311...
DEBUG: Checking Unpywall for 10.1121/1.4799033...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202063...
DEBUG: Checking Unpywall for 10.1109/29.1541...
DEBUG: Checking Unpywall for 10.1145/3616195.3616216...
DEBUG: Checking Unpywall for 10.1007/978-3-319-73031-8_10...
DEBUG: Checking Unpywall for 10.1145/3301293.3309567...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610910...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5684509...
DEBUG: Checking Unpywall for 10.1117/12.939703...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2915785...
DEBUG: Checking Unpywall for 10.1109/icassp.2015.7177989...
DEBUG: Checking Unpywall for 10.2307/1324576...
DEBUG: Checking Unpywall for 10.1007/978-3-319-08234-9_415-1...
DEBUG: Checking Unpywall for 10.1036/1097-8542.169100...
DEBUG: Checking Unpywall for 10.1109/cvpr52733.2024.02555...
DEBUG: Checking Unpywall for 10.1016/j.medengphy.2008.05.006...
DEBUG: Checking Unpywall for 10.1145/3469013.3469015...
DEBUG: Checking Unpywall for 10.1109/vsmm.2017.8346301...
DEBUG: Checking Unpywall for 10.1109/icsip55141.2022.9886106...
DEBUG: Checking Unpywall for 10.1109/icics.2011.6173615...
DEBUG: Checking Unpywall for 10.1007/978-981-10-1551-9_4...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009873...
DEBUG: Checking Unpywall for 10.1109/eusipco.2016.7760436...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3224295...
DEBUG: Checking Unpywall for 10.1016/j.compeleceng.2020.106579...
DEBUG: Checking Unpywall for 10.1007/978-3-031-23161-2_415...
DEBUG: Checking Unpywall for 10.1364/ofc.2018.th1j.3...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2924321...
DEBUG: Checking Unpywall for 10.1109/wevr.2016.7859538...
DEBUG: Checking Unpywall for 10.1145/2983310.2989196...
DEBUG: Checking Unpywall for 10.3403/03211187...
DEBUG: Checking Unpywall for 10.53755/pmcs.2024.8.2.130...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170024...
DEBUG: Checking Unpywall for 10.1109/vr50410.2021.00099...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3357037...
DEBUG: Checking Unpywall for 10.1109/is264627.2025.11284677...
DEBUG: Checking Unpywall for 10.3389/frvir.2024.1391987...
DEBUG: Checking Unpywall for 10.1145/365024.365092...
DEBUG: Checking Unpywall for 10.3403/30173483...
DEBUG: Checking Unpywall for 10.1109/apsipaasc58517.2023.10317480...
DEBUG: Checking Unpywall for 10.1121/1.3636057...
DEBUG: Checking Unpywall for 10.1142/9789814299312_0050...
DEBUG: Checking Unpywall for 10.4324/9780080472478-6...
DEBUG: Checking Unpywall for 10.1364/acpc.2021.t4a.55...
DEBUG: Checking Unpywall for 10.7840/kics.2011.36c.2.112...
DEBUG: Checking Unpywall for 10.1109/cc.2017.8233656...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610900...
DEBUG: Checking Unpywall for 10.1103/physreve.89.032803...
DEBUG: Checking Unpywall for 10.3403/01065078...
DEBUG: Checking Unpywall for 10.1109/glocom.2007.505...
DEBUG: Checking Unpywall for 10.7146/si.v2i1.110409...
DEBUG: Checking Unpywall for 10.1121/1.5035994...
DEBUG: Checking Unpywall for 10.1007/springerreference_11384...
DEBUG: Checking Unpywall for 10.3403/01065078u...
DEBUG: Checking Unpywall for 10.1186/s13636-024-00364-4...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2982291...
DEBUG: Checking Unpywall for 10.3788/aos201232.1012002...
DEBUG: Checking Unpywall for 10.1101/2025.08.05.25332835...
DEBUG: Checking Unpywall for 10.2352/ei.2023.35.17.3dia-108...
DEBUG: Checking Unpywall for 10.1037/e577462012-022...
DEBUG: Checking Unpywall for 10.1109/iccsi58851.2023.10303804...
DEBUG: Checking Unpywall for 10.1109/mitp.2025.3608908...
DEBUG: Checking Unpywall for 10.1787/844633432403...
DEBUG: Checking Unpywall for 10.1163/9789004337862__com_030085...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2851157...
DEBUG: Checking Unpywall for 10.1109/cig.2019.8847959...
DEBUG: Checking Unpywall for 10.3403/30132179...
DEBUG: Checking Unpywall for 10.1109/ojsscs.2024.3502315...
DEBUG: Checking Unpywall for 10.1109/icact.2008.4493981...
DEBUG: Checking Unpywall for 10.1162/comj_a_00382...
DEBUG: Checking Unpywall for 10.1121/1.5036003...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289498...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2830105...
DEBUG: Checking Unpywall for 10.1109/isscc49657.2024.10454320...
DEBUG: Checking Unpywall for 10.1109/qomex.2017.7965650...
DEBUG: Checking Unpywall for 10.4324/9780080472478-11...
DEBUG: Checking Unpywall for 10.1111/2041-210x.70149/v2/response1...
DEBUG: Checking Unpywall for 10.1145/3377290.3377291...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3449037...
DEBUG: Checking Unpywall for 10.1007/978-1-4471-0353-0_33...
DEBUG: Checking Unpywall for 10.1109/ijcnn.2017.7966291...
DEBUG: Checking Unpywall for 10.1109/jlt.2025.3567463...
DEBUG: Checking Unpywall for 10.1007/s11141-011-9295-3...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610957...
DEBUG: Checking Unpywall for 10.1109/a-sscc58667.2023.10347980...
DEBUG: Checking Unpywall for 10.1145/1056808.1056982...
DEBUG: Checking Unpywall for 10.1109/i3da48870.2021.9610905...
DEBUG: Checking Unpywall for 10.3403/30173487...
DEBUG: Checking Unpywall for 10.1121/2.0001904...
DEBUG: Checking Unpywall for 10.1109/aspaa.1991.634097...
DEBUG: Checking Unpywall for 10.1121/1.4820187...
DEBUG: Checking Unpywall for 10.3403/30168732u...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202096...
DEBUG: Checking Unpywall for 10.3403/03211254u...
DEBUG: Checking Unpywall for 10.23919/eusipco.2018.8553306...
DEBUG: Checking Unpywall for 10.1109/tcsii.2024.3410688...
DEBUG: Checking Unpywall for 10.3403/03211187u...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 240)...
>> Round 13: No new papers added (rejected/dup). Digging deeper...

--- Search Round 14 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1300)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.3403/03211254u...
DEBUG: Checking Unpywall for 10.3403/30173487...
DEBUG: Checking Unpywall for 10.4156/jdcta.vol6.issue23.1...
DEBUG: Checking Unpywall for 10.3403/30168732u...
DEBUG: Checking Unpywall for 10.1101/128918...
DEBUG: Checking Unpywall for 10.1109/pimrc.2008.4699567...
DEBUG: Checking Unpywall for 10.1145/3051519.3051521...
DEBUG: Checking Unpywall for 10.1386/rajo.5.2-3.129_1...
DEBUG: Checking Unpywall for 10.1109/jssc.2023.3261125...
DEBUG: Checking Unpywall for 10.1109/jsac.2016.2611961...
DEBUG: Checking Unpywall for 10.1145/2212776.2223667...
DEBUG: Checking Unpywall for 10.1068/ic769...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2908057...
DEBUG: Checking Unpywall for 10.7146/math.scand.a-12290...
DEBUG: Checking Unpywall for 10.1109/acp.2018.8596022...
DEBUG: Checking Unpywall for 10.1093/oed/2456936744...
DEBUG: Checking Unpywall for 10.3390/s24123966...
DEBUG: Checking Unpywall for 10.3403/30132179u...
DEBUG: Checking Unpywall for 10.1007/springerreference_16680...
DEBUG: Checking Unpywall for 10.3403/03211254...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2740001...
DEBUG: Checking Unpywall for 10.1109/taslp.2021.3126936...
DEBUG: Checking Unpywall for 10.1109/tuffc.2011.5733266/mm4...
DEBUG: Checking Unpywall for 10.24297/jam.v11i8.1208...
DEBUG: Checking Unpywall for 10.1109/icme.2003.1221247...
DEBUG: Checking Unpywall for 10.3403/30168732...
DEBUG: Checking Unpywall for 10.1007/s11664-013-2647-3...
DEBUG: Checking Unpywall for 10.1109/is262782.2024.10704105...
DEBUG: Checking Unpywall for 10.5040/9781350507463.ch-2...
DEBUG: Checking Unpywall for 10.1142/s0218339009002855...
DEBUG: Checking Unpywall for 10.1109/icassp.2014.6854892...
DEBUG: Checking Unpywall for 10.1109/tvcg.2024.3372112/mm1...
DEBUG: Checking Unpywall for 10.5772/intechopen.102810...
DEBUG: Checking Unpywall for 10.24425/ijet.2024.149544...
DEBUG: Checking Unpywall for 10.1155/2010/182627...
DEBUG: Checking Unpywall for 10.4324/9780080472065-8...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4393017...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-7...
DEBUG: Checking Unpywall for 10.1117/12.2603783...
DEBUG: Checking Unpywall for 10.1109/qomex.2018.8463408...
DEBUG: Checking Unpywall for 10.1017/s1355617720000041...
DEBUG: Checking Unpywall for 10.1037/e575812012-007...
DEBUG: Checking Unpywall for 10.1109/icassp48485.2024.10447577...
DEBUG: Checking Unpywall for 10.1145/1900179.1900198...
DEBUG: Checking Unpywall for 10.3403/30299210u...
DEBUG: Checking Unpywall for 10.1117/12.2038142...
DEBUG: Checking Unpywall for 10.1109/icme51207.2021.9428297...
DEBUG: Checking Unpywall for 10.1109/ismar-adjunct57072.2022.00103...
DEBUG: Checking Unpywall for 10.1109/icalip.2014.7009798...
DEBUG: Checking Unpywall for 10.3403/30301705...
DEBUG: Checking Unpywall for 10.1101/2024.12.16.628659...
DEBUG: Checking Unpywall for 10.5265/jcogpsy.3.13...
DEBUG: Checking Unpywall for 10.1109/etcm58927.2023.10309087...
DEBUG: Checking Unpywall for 10.1109/ieeeconf59510.2023.10335480...
DEBUG: Checking Unpywall for 10.1145/3625468.3652916...
DEBUG: Checking Unpywall for 10.1109/oecc54135.2024.10975685...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2881912...
DEBUG: Checking Unpywall for 10.1109/isemc.2018.8393819...
DEBUG: Checking Unpywall for 10.1109/gcce59613.2023.10315548...
DEBUG: Checking Unpywall for 10.7554/elife.43732.042...
DEBUG: Checking Unpywall for 10.1121/10.0023136...
DEBUG: Checking Unpywall for 10.1145/1377999.1378031...
DEBUG: Checking Unpywall for 10.1145/3334480.3381440...
DEBUG: Checking Unpywall for 10.21437/interspeech.2024-2419...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-11...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-12...
DEBUG: Checking Unpywall for 10.1145/3373087.3375323...
DEBUG: Checking Unpywall for 10.1109/tvcg.2024.3372112/mm2...
DEBUG: Checking Unpywall for 10.1163/9789004337862_lgbo_com_030085...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-8...
DEBUG: Checking Unpywall for 10.1109/cc.2017.8107636...
DEBUG: Checking Unpywall for 10.1121/1.4969294...
DEBUG: Checking Unpywall for 10.1109/taee59541.2024.10604949...
DEBUG: Checking Unpywall for 10.5594/j17254...
DEBUG: Checking Unpywall for 10.1007/3-540-33213-8_13...
DEBUG: Checking Unpywall for 10.1186/s12967-022-03510-8...
DEBUG: Checking Unpywall for 10.1007/978-1-4757-3594-9_5...
DEBUG: Checking Unpywall for 10.4324/9781315223162-1...
DEBUG: Checking Unpywall for 10.1007/springerreference_25661...
DEBUG: Checking Unpywall for 10.1007/978-3-642-15399-0_52...
DEBUG: Checking Unpywall for 10.1109/plasma.2016.7534082...
DEBUG: Checking Unpywall for 10.1109/icce.1993.697623...
DEBUG: Checking Unpywall for 10.1111/ejn.70182...
DEBUG: Checking Unpywall for 10.1017/s1355771804220155...
DEBUG: Checking Unpywall for 10.1109/icisa.2013.6579396...
DEBUG: Checking Unpywall for 10.3403/30299210...
DEBUG: Checking Unpywall for 10.1121/1.4805973...
DEBUG: Checking Unpywall for 10.3403/00308423u...
DEBUG: Checking Unpywall for 10.1186/s13636-022-00242-x...
DEBUG: Checking Unpywall for 10.3410/f.732304869.793553124...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289181...
DEBUG: Checking Unpywall for 10.1109/mdm.2009.120...
DEBUG: Checking Unpywall for 10.1007/978-3-031-86323-3_1...
DEBUG: Checking Unpywall for 10.1007/springerreference_16235...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170032...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-13...
DEBUG: Checking Unpywall for 10.1080/13528165.2024.2537572...
DEBUG: Checking Unpywall for 10.1145/2541016.2541022...
DEBUG: Checking Unpywall for 10.21203/rs.3.rs-1743523/v1...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 260)...
>> Round 14: No new papers added (rejected/dup). Digging deeper...

--- Search Round 15 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1400)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 97 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.4324/9780080472478-5...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-16...
DEBUG: Checking Unpywall for 10.3397/in-2021-2820...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-11...
DEBUG: Checking Unpywall for 10.1007/s11538-007-9200-6...
DEBUG: Checking Unpywall for 10.1016/j.chbr.2024.100451...
DEBUG: Checking Unpywall for 10.1109/mdm.2009.120...
DEBUG: Checking Unpywall for 10.1121/1.5101391...
DEBUG: Checking Unpywall for 10.1109/icme.2003.1221247...
DEBUG: Checking Unpywall for 10.1155/2010/182627...
DEBUG: Checking Unpywall for 10.61782/fa.2023.1181...
DEBUG: Checking Unpywall for 10.1109/is262782.2024.10704105...
DEBUG: Checking Unpywall for 10.1007/springerreference_16674...
DEBUG: Checking Unpywall for 10.1007/springerreference_11385...
DEBUG: Checking Unpywall for 10.1364/cleo_at.2018.jth2a.113...
DEBUG: Checking Unpywall for 10.1109/icsp65755.2025.11087172...
DEBUG: Checking Unpywall for 10.1007/springerreference_11387...
DEBUG: Checking Unpywall for 10.1145/378344.378364...
DEBUG: Checking Unpywall for 10.5040/9781350507463.ch-2...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-9...
DEBUG: Checking Unpywall for 10.1017/s1355617720000041...
DEBUG: Checking Unpywall for 10.3390/app112311242...
DEBUG: Checking Unpywall for 10.1186/s13636-022-00242-x...
DEBUG: Checking Unpywall for 10.1117/12.2083353...
DEBUG: Checking Unpywall for 10.1145/3411109.3411134...
DEBUG: Checking Unpywall for 10.1101/2022.06.04.494814...
DEBUG: Checking Unpywall for 10.1109/waspaa52581.2021.9632744...
DEBUG: Checking Unpywall for 10.1016/j.heares.2009.11.004...
DEBUG: Checking Unpywall for 10.3397/in_2022_0741...
DEBUG: Checking Unpywall for 10.1109/waspaa52581.2021.9632724...
DEBUG: Checking Unpywall for 10.1162/pres.16.5.509...
DEBUG: Checking Unpywall for 10.3403/30334751u...
DEBUG: Checking Unpywall for 10.7717/peerj.14628/supp-10...
DEBUG: Checking Unpywall for 10.1109/ojcoms.2024.3349695...
DEBUG: Checking Unpywall for 10.1007/978-1-4757-3594-9_8...
DEBUG: Checking Unpywall for 10.1007/springerreference_14201...
DEBUG: Checking Unpywall for 10.7554/elife.43732.048...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170032...
DEBUG: Checking Unpywall for 10.21437/avsec.2025-12...
DEBUG: Checking Unpywall for 10.1007/s00146-017-0766-8...
DEBUG: Checking Unpywall for 10.1109/icassp43922.2022.9746717...
DEBUG: Checking Unpywall for 10.1007/978-3-319-02681-7_17...
DEBUG: Checking Unpywall for 10.1121/1.428524...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.2967539...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2864577...
DEBUG: Checking Unpywall for 10.1109/taee59541.2024.10604949...
DEBUG: Checking Unpywall for 10.4324/9780080472478-10...
DEBUG: Checking Unpywall for 10.1109/icassp49660.2025.10889134...
DEBUG: Checking Unpywall for 10.1145/3424616.3424709...
DEBUG: Checking Unpywall for 10.1167/19.10.111c...
DEBUG: Checking Unpywall for 10.1162/0898929054985383...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.3019181...
DEBUG: Checking Unpywall for 10.1007/s007790200025...
DEBUG: Checking Unpywall for 10.1007/springerreference_13584...
DEBUG: Checking Unpywall for 10.4324/9781315223162-2...
DEBUG: Checking Unpywall for 10.1121/1.4784329...
DEBUG: Checking Unpywall for 10.1207/s15327108ijap1403_1...
DEBUG: Checking Unpywall for 10.7554/elife.43732.046...
DEBUG: Checking Unpywall for 10.1109/niles68063.2025.11232015...
DEBUG: Checking Unpywall for 10.7554/elife.43732.045...
DEBUG: Checking Unpywall for 10.1016/j.exmath.2016.10.003...
DEBUG: Checking Unpywall for 10.5772/intechopen.104931...
DEBUG: Checking Unpywall for 10.3403/30334751...
DEBUG: Checking Unpywall for 10.4016/38529.01...
DEBUG: Checking Unpywall for 10.5771/9783845251875_29...
DEBUG: Checking Unpywall for 10.1109/waspaa.2015.7336913...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00001-3...
DEBUG: Checking Unpywall for 10.5771/9783845216935-96...
DEBUG: Checking Unpywall for 10.1109/jssc.2025.3568095...
DEBUG: Checking Unpywall for 10.1167/11.11.799...
DEBUG: Checking Unpywall for 10.31219/osf.io/9tz2w...
DEBUG: Checking Unpywall for 10.1117/12.2605446...
DEBUG: Checking Unpywall for 10.1017/s0012162206000260...
DEBUG: Checking Unpywall for 10.3109/02699052.2013.767938...
DEBUG: Checking Unpywall for 10.7554/elife.43732.044...
DEBUG: Checking Unpywall for 10.1109/89.966095...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3190734...
DEBUG: Checking Unpywall for 10.1016/j.optlastec.2024.112168...
DEBUG: Checking Unpywall for 10.1364/ofc.2019.th1f.5...
DEBUG: Checking Unpywall for 10.1121/1.4969294...
DEBUG: Checking Unpywall for 10.1109/iwaenc.2016.7602903...
DEBUG: Checking Unpywall for 10.1145/1851600.1851716...
DEBUG: Checking Unpywall for 10.4324/9781315223162-15...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-1648-4_8...
DEBUG: Checking Unpywall for 10.32920/ryerson.14664612.v1...
DEBUG: Checking Unpywall for 10.1145/3411109.3411119...
DEBUG: Checking Unpywall for 10.1109/taslp.2019.2948770...
DEBUG: Checking Unpywall for 10.3390/app12042061...
DEBUG: Checking Unpywall for 10.4324/9780429197499-9...
DEBUG: Checking Unpywall for 10.2172/2228309...
DEBUG: Checking Unpywall for 10.4324/9780080472478-8...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165438...
DEBUG: Checking Unpywall for 10.1145/2459236.2459278...
DEBUG: Checking Unpywall for 10.1016/s0010-9452(89)80035-8...
DEBUG: Checking Unpywall for 10.3403/01739428...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082297...
DEBUG: Checking Unpywall for 10.1007/springerreference_20409...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 280)...
>> Round 15: No new papers added (rejected/dup). Digging deeper...

--- Search Round 16 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1500)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 95 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1007/s00138-025-01700-0...
DEBUG: Checking Unpywall for 10.23919/sicefes67750.2025.11236700...
DEBUG: Checking Unpywall for 10.5040/9781350931923...
DEBUG: Checking Unpywall for 10.1145/3411109.3411119...
DEBUG: Checking Unpywall for 10.4324/9780203467336...
DEBUG: Checking Unpywall for 10.4324/9780429197499-9...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-51941-8.50007-8...
DEBUG: Checking Unpywall for 10.5040/9781350931947...
DEBUG: Checking Unpywall for 10.4324/9780080470948-13...
DEBUG: Checking Unpywall for 10.4324/9781315223162-10...
DEBUG: Checking Unpywall for 10.2172/2228309...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082297...
DEBUG: Checking Unpywall for 10.1007/springerreference_11386...
DEBUG: Checking Unpywall for 10.1109/waspaa52581.2021.9632709...
DEBUG: Checking Unpywall for 10.4218/etrij.05.0104.0071...
DEBUG: Checking Unpywall for 10.1109/glocom.2008.ecp.279...
DEBUG: Checking Unpywall for 10.4324/9781003518242-2...
DEBUG: Checking Unpywall for 10.21203/rs.3.rs-7096435/v1...
DEBUG: Checking Unpywall for 10.7554/elife.43732.049...
DEBUG: Checking Unpywall for 10.1109/icassp48485.2024.10447970...
DEBUG: Checking Unpywall for 10.61782/fa.2023.0682...
DEBUG: Checking Unpywall for 10.3390/app12042061...
DEBUG: Checking Unpywall for 10.1109/aspaa.1991.634102...
DEBUG: Checking Unpywall for 10.1145/3625008.3625042...
DEBUG: Checking Unpywall for 10.7554/elife.43732.047...
DEBUG: Checking Unpywall for 10.1093/law-oeeul/e73.013.73...
DEBUG: Checking Unpywall for 10.5353/th_b3145936...
DEBUG: Checking Unpywall for 10.5771/9783845251875_11...
DEBUG: Checking Unpywall for 10.4324/9780429197499-8...
DEBUG: Checking Unpywall for 10.1017/s0012162206000260...
DEBUG: Checking Unpywall for 10.1109/glocom.1998.775811...
DEBUG: Checking Unpywall for 10.1145/1978942.1979258...
DEBUG: Checking Unpywall for 10.1007/978-1-4757-3594-9_3...
DEBUG: Checking Unpywall for 10.3109/02699052.2013.767938...
DEBUG: Checking Unpywall for 10.1002/brb3.2868/v1/review1...
DEBUG: Checking Unpywall for 10.3403/30236824u...
DEBUG: Checking Unpywall for 10.1145/2634317.2634318...
DEBUG: Checking Unpywall for 10.1371/journal.pone.0124759...
DEBUG: Checking Unpywall for 10.1007/978-981-13-9409-6_30...
DEBUG: Checking Unpywall for 10.1016/j.sna.2020.111862...
DEBUG: Checking Unpywall for 10.4018/9781599045139.ch010...
DEBUG: Checking Unpywall for 10.1007/11679363_83...
DEBUG: Checking Unpywall for 10.1080/09523986908547964...
DEBUG: Checking Unpywall for 10.1250/ast.38.175...
DEBUG: Checking Unpywall for 10.1121/10.0023318...
DEBUG: Checking Unpywall for 10.1186/s13636-025-00432-3...
DEBUG: Checking Unpywall for 10.1109/icuis64676.2024.10867224...
DEBUG: Checking Unpywall for 10.1109/iros45743.2020.9340938...
DEBUG: Checking Unpywall for 10.5771/9783845251875_43...
DEBUG: Checking Unpywall for 10.1145/3771594.3771651...
DEBUG: Checking Unpywall for 10.1007/springerreference_19525...
DEBUG: Checking Unpywall for 10.1002/wcm.1012...
DEBUG: Checking Unpywall for 10.1109/ismar-adjunct68609.2025.00144...
DEBUG: Checking Unpywall for 10.1111/jnp.12353...
DEBUG: Checking Unpywall for 10.1007/978-1-4757-3594-9_7...
DEBUG: Checking Unpywall for 10.32920/26871325.v1...
DEBUG: Checking Unpywall for 10.1109/icceai55464.2022.00030...
DEBUG: Checking Unpywall for 10.1177/1088467x251344931...
DEBUG: Checking Unpywall for 10.3389/fmars.2022.1015836...
DEBUG: Checking Unpywall for 10.1121/1.3508462...
DEBUG: Checking Unpywall for 10.1364/ao.434309...
DEBUG: Checking Unpywall for 10.21203/rs.3.rs-1743523/v2...
DEBUG: Checking Unpywall for 10.1364/oe.540756...
DEBUG: Checking Unpywall for 10.4324/9781003518242-15...
DEBUG: Checking Unpywall for 10.1109/vetecs.2003.1207100...
DEBUG: Checking Unpywall for 10.3788/lop51.061901...
DEBUG: Checking Unpywall for 10.22215/etd/2005-07596...
DEBUG: Checking Unpywall for 10.5040/9781350931909...
DEBUG: Checking Unpywall for 10.54941/ahfe1006916...
DEBUG: Checking Unpywall for 10.1007/springerreference_27486...
DEBUG: Checking Unpywall for 10.17743/jaes.2021.0015...
DEBUG: Checking Unpywall for 10.1364/oe.23.021994...
DEBUG: Checking Unpywall for 10.4324/9780240814681-26...
DEBUG: Checking Unpywall for 10.1007/s00221-014-4028-4...
DEBUG: Checking Unpywall for 10.1007/978-3-319-51814-5_32...
DEBUG: Checking Unpywall for 10.4324/9780429197499-10...
DEBUG: Checking Unpywall for 10.4324/9781003518242-10...
DEBUG: Checking Unpywall for 10.4324/9780203573310-12...
DEBUG: Checking Unpywall for 10.4324/9781003386964-3...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0056...
DEBUG: Checking Unpywall for 10.1109/waspaa.2017.8170015...
DEBUG: Checking Unpywall for 10.4324/9781315223162-3...
DEBUG: Checking Unpywall for 10.32920/ryerson.14664612...
DEBUG: Checking Unpywall for 10.1037/e578072012-013...
DEBUG: Checking Unpywall for 10.1109/icassp.2007.366604...
DEBUG: Checking Unpywall for 10.14217/9781848598485-10-en...
DEBUG: Checking Unpywall for 10.1109/memea.2019.8802172...
DEBUG: Checking Unpywall for 10.7312/chio18588-008...
DEBUG: Checking Unpywall for 10.1109/wpmc.2002.1088266...
DEBUG: Checking Unpywall for 10.1121/1.4805654...
DEBUG: Checking Unpywall for 10.4016/38528.01...
DEBUG: Checking Unpywall for 10.1007/978-3-642-33197-8_14...
DEBUG: Checking Unpywall for 10.1121/1.4970418...
DEBUG: Checking Unpywall for 10.1109/icassp40776.2020.9053427...
DEBUG: Checking Unpywall for 10.5771/9783845251875_49...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 300)...
>> Round 16: No new papers added (rejected/dup). Digging deeper...

--- Search Round 17 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1600)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1037/e578072012-013...
DEBUG: Checking Unpywall for 10.1007/s00221-014-4028-4...
DEBUG: Checking Unpywall for 10.5594/smpte.st2106.2016...
DEBUG: Checking Unpywall for 10.3403/30236824...
DEBUG: Checking Unpywall for 10.4018/979-8-3373-2508-8.ch010...
DEBUG: Checking Unpywall for 10.3998/mpub.12714424.cmp.3...
DEBUG: Checking Unpywall for 10.1007/978-3-319-51814-5_32...
DEBUG: Checking Unpywall for 10.32920/26871325...
DEBUG: Checking Unpywall for 10.1007/springerreference_24811...
DEBUG: Checking Unpywall for 10.1007/978-3-030-51249-1_7...
DEBUG: Checking Unpywall for 10.1109/vr.2019.8798247...
DEBUG: Checking Unpywall for 10.5040/9781350931961...
DEBUG: Checking Unpywall for 10.4324/9780203573310-12...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1165997...
DEBUG: Checking Unpywall for 10.1158/0008-5472.c.6626117.v2...
DEBUG: Checking Unpywall for 10.1109/icstcc.2014.6982496...
DEBUG: Checking Unpywall for 10.1201/9781439864869-13...
DEBUG: Checking Unpywall for 10.17743/jaes.2021.0044...
DEBUG: Checking Unpywall for 10.3403/30282803u...
DEBUG: Checking Unpywall for 10.7717/peerj-cs.2473/fig-2...
DEBUG: Checking Unpywall for 10.1109/lra.2023.3272518/mm1...
DEBUG: Checking Unpywall for 10.22215/etd/1992-02245...
DEBUG: Checking Unpywall for 10.4324/9780203573310-10...
DEBUG: Checking Unpywall for 10.4324/9781003512042-9...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166011...
DEBUG: Checking Unpywall for 10.1109/icassp40776.2020.9053427...
DEBUG: Checking Unpywall for 10.22541/au.174807390.07942089/v1...
DEBUG: Checking Unpywall for 10.4324/9780080926735-4...
DEBUG: Checking Unpywall for 10.4018/978-1-61520-903-3.ch001...
DEBUG: Checking Unpywall for 10.4324/9780080495811-3...
DEBUG: Checking Unpywall for 10.3403/30282803...
DEBUG: Checking Unpywall for 10.3403/30168982u...
DEBUG: Checking Unpywall for 10.4236/jcc.2022.105006...
DEBUG: Checking Unpywall for 10.4324/9780080499369-16...
DEBUG: Checking Unpywall for 10.4135/9781452229669.n544...
DEBUG: Checking Unpywall for 10.1364/oe.451286...
DEBUG: Checking Unpywall for 10.1002/brb3.2868/v1/review2...
DEBUG: Checking Unpywall for 10.5040/9781350931978...
DEBUG: Checking Unpywall for 10.1007/978-1-4757-3594-9_9...
DEBUG: Checking Unpywall for 10.1007/978-3-030-51249-1_6...
DEBUG: Checking Unpywall for 10.1007/s40998-018-0050-z...
DEBUG: Checking Unpywall for 10.1109/tmm.2019.2937185...
DEBUG: Checking Unpywall for 10.1109/icce.1992.697285...
DEBUG: Checking Unpywall for 10.5040/9781350931930...
DEBUG: Checking Unpywall for 10.1109/swc62898.2024.00038...
DEBUG: Checking Unpywall for 10.1109/aivr50618.2020.00071...
DEBUG: Checking Unpywall for 10.1109/tmm.2016.2594148...
DEBUG: Checking Unpywall for 10.3403/30101599...
DEBUG: Checking Unpywall for 10.14217/9781848598485-10-en...
DEBUG: Checking Unpywall for 10.4018/978-1-59904-513-9.ch010...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166039...
DEBUG: Checking Unpywall for 10.5194/isprsarchives-xl-5-w4-207-2015...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0074...
DEBUG: Checking Unpywall for 10.1007/978-3-642-30712-6_4...
DEBUG: Checking Unpywall for 10.1109/msp.1971.28166...
DEBUG: Checking Unpywall for 10.1093/neuonc/noaf201.1741...
DEBUG: Checking Unpywall for 10.22215/etd/2006-07676...
DEBUG: Checking Unpywall for 10.4324/9780080512556-10...
DEBUG: Checking Unpywall for 10.21203/rs.3.rs-1526092/v1...
DEBUG: Checking Unpywall for 10.3403/30247048...
DEBUG: Checking Unpywall for 10.1016/j.jid.2025.06.153...
DEBUG: Checking Unpywall for 10.21037/tlcr-2025-912...
DEBUG: Checking Unpywall for 10.1016/j.optcom.2020.125595...
DEBUG: Checking Unpywall for 10.4324/9780080495811-9...
DEBUG: Checking Unpywall for 10.18535/ijecs/v5i10.58...
DEBUG: Checking Unpywall for 10.32388/b6tdof...
DEBUG: Checking Unpywall for 10.3403/02862704...
DEBUG: Checking Unpywall for 10.1145/3663548.3688492...
DEBUG: Checking Unpywall for 10.23860/diss-3706...
DEBUG: Checking Unpywall for 10.1121/1.2935722...
DEBUG: Checking Unpywall for 10.1121/1.4969329...
DEBUG: Checking Unpywall for 10.4324/9780080495811-11...
DEBUG: Checking Unpywall for 10.1364/ecoc.2011.th.12.b.2...
DEBUG: Checking Unpywall for 10.1109/tau.8336...
DEBUG: Checking Unpywall for 10.1201/9781482267570...
DEBUG: Checking Unpywall for 10.1145/3757374.3771539...
DEBUG: Checking Unpywall for 10.4324/9780429343056-20...
DEBUG: Checking Unpywall for 10.1002/brb3.2868/v2/decision1...
DEBUG: Checking Unpywall for 10.1145/2814895.2814919...
DEBUG: Checking Unpywall for 10.1109/icassp.2007.366603...
DEBUG: Checking Unpywall for 10.1109/have.2009.5356122...
DEBUG: Checking Unpywall for 10.1145/3613904.3641919...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161823...
DEBUG: Checking Unpywall for 10.1080/00150190214460...
DEBUG: Checking Unpywall for 10.1007/978-3-642-40498-6_35...
DEBUG: Checking Unpywall for 10.3403/30352489...
DEBUG: Checking Unpywall for 10.22215/etd/1994-02727...
DEBUG: Checking Unpywall for 10.31234/osf.io/h7qwg...
DEBUG: Checking Unpywall for 10.1109/tau.8335...
DEBUG: Checking Unpywall for 10.1007/978-3-540-73549-6_13...
DEBUG: Checking Unpywall for 10.5040/9781350931954...
DEBUG: Checking Unpywall for 10.12958/adm1424...
DEBUG: Checking Unpywall for 10.1007/s00209-022-03026-3...
DEBUG: Checking Unpywall for 10.4324/9780203573310-5...
DEBUG: Checking Unpywall for 10.1109/icalip.2010.5684372...
DEBUG: Checking Unpywall for 10.1007/978-1-4757-3594-9_6...
DEBUG: Checking Unpywall for 10.1016/j.bpj.2017.11.684...
DEBUG: Checking Unpywall for 10.4324/9780429491214-7...
DEBUG: Checking Unpywall for 10.1515/ijdhd.2005.4.4.317...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 320)...
>> Round 17: No new papers added (rejected/dup). Digging deeper...

--- Search Round 18 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1700)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 98 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00063-3...
DEBUG: Checking Unpywall for 10.1016/j.jid.2025.06.153...
DEBUG: Checking Unpywall for 10.1109/aivr50618.2020.00071...
DEBUG: Checking Unpywall for 10.1201/b17593-15...
DEBUG: Checking Unpywall for 10.21037/tlcr-2025-912...
DEBUG: Checking Unpywall for 10.3403/02862704u...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00057-8...
DEBUG: Checking Unpywall for 10.1109/tau.8335...
DEBUG: Checking Unpywall for 10.4324/9780080495811-11...
DEBUG: Checking Unpywall for 10.3403/30352489u...
DEBUG: Checking Unpywall for 10.21136/mb.2003.133930...
DEBUG: Checking Unpywall for 10.1007/s00209-022-03026-3...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166011...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00071-2...
DEBUG: Checking Unpywall for 10.23860/diss-3706...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00058-x...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00070-0...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00059-1...
DEBUG: Checking Unpywall for 10.5771/9783845270753-24...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00061-x...
DEBUG: Checking Unpywall for 10.1145/3534088.3534343...
DEBUG: Checking Unpywall for 10.37789/rochi.2021.1.1.19...
DEBUG: Checking Unpywall for 10.21437/interspeech.2025-1053...
DEBUG: Checking Unpywall for 10.1109/taslp.2024.3374065...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00062-1...
DEBUG: Checking Unpywall for 10.1186/1687-6180-2013-149...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00060-8...
DEBUG: Checking Unpywall for 10.5771/9783845213927-33...
DEBUG: Checking Unpywall for 10.1364/oe.27.025046...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166121...
DEBUG: Checking Unpywall for 10.1145/3613905.3648109...
DEBUG: Checking Unpywall for 10.1145/3715336.3735712...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165649...
DEBUG: Checking Unpywall for 10.4018/978-1-59904-871-0.ch040...
DEBUG: Checking Unpywall for 10.3403/30247048u...
DEBUG: Checking Unpywall for 10.1109/icce-berlin.2016.7684737...
DEBUG: Checking Unpywall for 10.4324/9780240812748-6...
DEBUG: Checking Unpywall for 10.7757/persnewmusi.51.1.0256...
DEBUG: Checking Unpywall for 10.1109/vrw55335.2022.00079...
DEBUG: Checking Unpywall for 10.5040/9781472561398.ch-006...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00069-4...
DEBUG: Checking Unpywall for 10.4324/9780203714973-15...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165406...
DEBUG: Checking Unpywall for 10.1109/ismar-adjunct57072.2022.00050...
DEBUG: Checking Unpywall for 10.3403/02755535...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00064-5...
DEBUG: Checking Unpywall for 10.1145/3613904.3641919...
DEBUG: Checking Unpywall for 10.4324/9780429491214-4...
DEBUG: Checking Unpywall for 10.1007/s12008-025-02382-8...
DEBUG: Checking Unpywall for 10.5771/9783845216935-26...
DEBUG: Checking Unpywall for 10.17743/jaes...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00066-9...
DEBUG: Checking Unpywall for 10.1109/tmm.2023.3271022...
DEBUG: Checking Unpywall for 10.1109/tau.1972.237421...
DEBUG: Checking Unpywall for 10.1121/1.5067593...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00076-1...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00065-7...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166017...
DEBUG: Checking Unpywall for 10.1007/11922162_26...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.3019646...
DEBUG: Checking Unpywall for 10.3233/978-1-61499-927-0-941...
DEBUG: Checking Unpywall for 10.1109/aspaa.2011.6082269...
DEBUG: Checking Unpywall for 10.1049/el.2015.3422...
DEBUG: Checking Unpywall for 10.1109/lcomm.2006.1665133...
DEBUG: Checking Unpywall for 10.3403/30434638...
DEBUG: Checking Unpywall for 10.4324/9780080499369-14...
DEBUG: Checking Unpywall for 10.3403/00948697u...
DEBUG: Checking Unpywall for 10.4324/9780080493947-10...
DEBUG: Checking Unpywall for 10.53347/rid-16705...
DEBUG: Checking Unpywall for 10.1109/tau.8337...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165617...
DEBUG: Checking Unpywall for 10.1145/3757374.3771466...
DEBUG: Checking Unpywall for 10.1109/tau.1959.1166188...
DEBUG: Checking Unpywall for 10.3998/mpub.12063224.cmp.18...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-82100-9.00001-0...
DEBUG: Checking Unpywall for 10.1145/2010425.2010427...
DEBUG: Checking Unpywall for 10.1109/taslpro.2025.3570939...
DEBUG: Checking Unpywall for 10.1080/09523986708542623...
DEBUG: Checking Unpywall for 10.1109/tau.1968.1162005...
DEBUG: Checking Unpywall for 10.1002/brb3.2868/v1/review3...
DEBUG: Checking Unpywall for 10.1121/1.4987470...
DEBUG: Checking Unpywall for 10.3390/app9091724...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00073-6...
DEBUG: Checking Unpywall for 10.1121/1.4786231...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00067-0...
DEBUG: Checking Unpywall for 10.4324/9780429491214-1...
DEBUG: Checking Unpywall for 10.1109/icassp49660.2025.10890366...
DEBUG: Checking Unpywall for 10.18356/78a8131a-en...
DEBUG: Checking Unpywall for 10.1201/b10959-14...
DEBUG: Checking Unpywall for 10.1145/3626485.3626542...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166122...
DEBUG: Checking Unpywall for 10.1109/iceca63461.2024.10800851...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1165989...
DEBUG: Checking Unpywall for 10.1109/tau.1962.1161653...
DEBUG: Checking Unpywall for 10.3403/30434638u...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00068-2...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00009-1...
DEBUG: Checking Unpywall for 10.63485/a141d-8m343...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 340)...
>> Round 18: No new papers added (rejected/dup). Digging deeper...

--- Search Round 19 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1800)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 98 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.18356/78a8131a-en...
DEBUG: Checking Unpywall for 10.1002/0470093366.ch6...
DEBUG: Checking Unpywall for 10.1080/09523986908547874...
DEBUG: Checking Unpywall for 10.4324/9780080472478...
DEBUG: Checking Unpywall for 10.3403/00948697...
DEBUG: Checking Unpywall for 10.1109/tau.1959.1166188...
DEBUG: Checking Unpywall for 10.3403/02755535u...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00009-1...
DEBUG: Checking Unpywall for 10.3403/30434638u...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00068-2...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.3003165...
DEBUG: Checking Unpywall for 10.1109/tcsi.2014.2333362...
DEBUG: Checking Unpywall for 10.5594/smpte.st2109.2019...
DEBUG: Checking Unpywall for 10.3403/00948697u...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166121...
DEBUG: Checking Unpywall for 10.5040/9798216434368.ch-001...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161831...
DEBUG: Checking Unpywall for 10.5771/9783845216935-26...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00072-4...
DEBUG: Checking Unpywall for 10.1109/waspaa58266.2023.10248142...
DEBUG: Checking Unpywall for 10.1097/opx.0000000000001284...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00073-6...
DEBUG: Checking Unpywall for 10.2307/j.ctv36xvmz3.10...
DEBUG: Checking Unpywall for 10.1259/edu.20150210l1aa0002.001/a1...
DEBUG: Checking Unpywall for 10.1109/pads.2004.1301288...
DEBUG: Checking Unpywall for 10.1259/bired20150203l1aa0001.002/a1...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166150...
DEBUG: Checking Unpywall for 10.1109/tau.1973.237380...
DEBUG: Checking Unpywall for 10.1121/10.0013991...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161869...
DEBUG: Checking Unpywall for 10.3403/03105768u...
DEBUG: Checking Unpywall for 10.1121/1.4786231...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166119...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00075-x...
DEBUG: Checking Unpywall for 10.1080/09523986808547848...
DEBUG: Checking Unpywall for 10.1109/tau.1973.237365...
DEBUG: Checking Unpywall for 10.1080/09523986808547849...
DEBUG: Checking Unpywall for 10.1109/tau.1960.1166271...
DEBUG: Checking Unpywall for 10.1109/tau.1962.1161615...
DEBUG: Checking Unpywall for 10.1109/access.2021.3128786...
DEBUG: Checking Unpywall for 10.1007/978-3-642-30712-6_2...
DEBUG: Checking Unpywall for 10.1145/2010425.2010427...
DEBUG: Checking Unpywall for 10.1259/bired20150203l1aa0001.001/a1...
DEBUG: Checking Unpywall for 10.3403/00121602...
DEBUG: Checking Unpywall for 10.1109/vrw55335.2022.00079...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.05...
DEBUG: Checking Unpywall for 10.1259/edu.201402245197.002/a1...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166016...
DEBUG: Checking Unpywall for 10.23919/transcom.2024ebp3127...
DEBUG: Checking Unpywall for 10.1109/tvt.2025.3552282...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.832213...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165633...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00074-8...
DEBUG: Checking Unpywall for 10.3998/mpub.12714424.cmp.1...
DEBUG: Checking Unpywall for 10.1080/09523986708547888...
DEBUG: Checking Unpywall for 10.1016/b978-075068166-7/50034-6...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165616...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027239.v1...
DEBUG: Checking Unpywall for 10.1109/icalip.2008.4590237...
DEBUG: Checking Unpywall for 10.1142/s0218194025500676...
DEBUG: Checking Unpywall for 10.1259/edu.201404015202.001/a1...
DEBUG: Checking Unpywall for 10.17487/rfc9137...
DEBUG: Checking Unpywall for 10.4324/9780240814681-9...
DEBUG: Checking Unpywall for 10.1002/brb3.2868/v1/decision1...
DEBUG: Checking Unpywall for 10.1109/icassp.2013.6638336...
DEBUG: Checking Unpywall for 10.1109/waspaa.2015.7336928...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165617...
DEBUG: Checking Unpywall for 10.1109/vrw50115.2020.00184...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166159...
DEBUG: Checking Unpywall for 10.22215/etd/1983-00794...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161769...
DEBUG: Checking Unpywall for 10.1109/icecsp61809.2024.10698623...
DEBUG: Checking Unpywall for 10.1259/edu.201409285207.001/a1...
DEBUG: Checking Unpywall for 10.1109/icalip.2016.7846625...
DEBUG: Checking Unpywall for 10.1109/icassp49660.2025.10889750...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1165988...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.01...
DEBUG: Checking Unpywall for 10.1109/tvcg.2016.2518134...
DEBUG: Checking Unpywall for 10.1145/1085777.1085787...
DEBUG: Checking Unpywall for 10.4324/9780429491214-14...
DEBUG: Checking Unpywall for 10.4324/9781003220268-9...
DEBUG: Checking Unpywall for 10.4324/9780080948966-15...
DEBUG: Checking Unpywall for 10.1007/978-3-642-41248-6_4...
DEBUG: Checking Unpywall for 10.1080/09523986808547927...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.12...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165446...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165615...
DEBUG: Checking Unpywall for 10.1109/waspaa52581.2021.9632764...
DEBUG: Checking Unpywall for 10.5771/9783845251875_139...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0129...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1165989...
DEBUG: Checking Unpywall for 10.1109/tau.1959.1166214...
DEBUG: Checking Unpywall for 10.3998/mpub.12714424.cmp.2...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165417...
DEBUG: Checking Unpywall for 10.3403/30267594...
DEBUG: Checking Unpywall for 10.4324/9780080569338-26...
DEBUG: Checking Unpywall for 10.5040/9798881820442.ch-074...
DEBUG: Checking Unpywall for 10.1109/icce.2006.1598420...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 360)...
>> Round 19: No new papers added (rejected/dup). Digging deeper...

--- Search Round 20 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 1900)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 100 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1145/3347320.3357690...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230919...
DEBUG: Checking Unpywall for 10.1080/09523986708547898...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230947...
DEBUG: Checking Unpywall for 10.1037/e578342012-009...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0081...
DEBUG: Checking Unpywall for 10.4324/9780080495811-12...
DEBUG: Checking Unpywall for 10.3403/03105768u...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0037...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165615...
DEBUG: Checking Unpywall for 10.1201/9781003529064-1...
DEBUG: Checking Unpywall for 10.1259/bired20150203l1aa0001.002/a1...
DEBUG: Checking Unpywall for 10.1080/09523986708547890...
DEBUG: Checking Unpywall for 10.1007/978-981-15-8888-4_5...
DEBUG: Checking Unpywall for 10.1017/cbo9781316084205.009...
DEBUG: Checking Unpywall for 10.5040/9781350931916...
DEBUG: Checking Unpywall for 10.4324/9780080951461-26...
DEBUG: Checking Unpywall for 10.1145/2095667.2095682...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.03...
DEBUG: Checking Unpywall for 10.1115/winvr2009-756...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.04...
DEBUG: Checking Unpywall for 10.1002/brb3.2868/v1/decision1...
DEBUG: Checking Unpywall for 10.1080/09523986708547891...
DEBUG: Checking Unpywall for 10.1259/edu.20150210l1aa0002.003/a1...
DEBUG: Checking Unpywall for 10.5772/intechopen.90561...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-82100-9.00038-1...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166016...
DEBUG: Checking Unpywall for 10.1007/s11042-009-0326-4...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027242.v1...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.05...
DEBUG: Checking Unpywall for 10.1259/edu.201402245197.002/a1...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027248...
DEBUG: Checking Unpywall for 10.1007/978-981-16-0119-4_69...
DEBUG: Checking Unpywall for 10.1259/edu.20150210l1aa0002.002/a1...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-82100-9.00013-7...
DEBUG: Checking Unpywall for 10.1259/edu.201409285207.002/a1...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1165988...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165645...
DEBUG: Checking Unpywall for 10.1145/1085777.1085787...
DEBUG: Checking Unpywall for 10.3389/fnins.2019.00451...
DEBUG: Checking Unpywall for 10.4324/9780080481319-16...
DEBUG: Checking Unpywall for 10.1101/2023.12.23.573214...
DEBUG: Checking Unpywall for 10.1007/bf02764669...
DEBUG: Checking Unpywall for 10.22215/etd/2007-06239...
DEBUG: Checking Unpywall for 10.1109/icassp49357.2023.10096463...
DEBUG: Checking Unpywall for 10.1109/msp.1970.28099...
DEBUG: Checking Unpywall for 10.1109/msp.1971.28173...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165417...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027239...
DEBUG: Checking Unpywall for 10.1145/2641248.2642732...
DEBUG: Checking Unpywall for 10.1080/15213269.2021.1880439...
DEBUG: Checking Unpywall for 10.1109/tau.1972.237351...
DEBUG: Checking Unpywall for 10.1007/978-3-642-41248-6_4...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165662...
DEBUG: Checking Unpywall for 10.1109/icassp.2013.6638336...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166024...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027236...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027248.v1...
DEBUG: Checking Unpywall for 10.1109/icecsp61809.2024.10698623...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165664...
DEBUG: Checking Unpywall for 10.32657/10356/46901...
DEBUG: Checking Unpywall for 10.1109/aina.2010.149...
DEBUG: Checking Unpywall for 10.21437/interspeech.2019-1302...
DEBUG: Checking Unpywall for 10.1111/imr.70013...
DEBUG: Checking Unpywall for 10.1093/oed/7789009121...
DEBUG: Checking Unpywall for 10.3403/00121602...
DEBUG: Checking Unpywall for 10.1109/waspaa.2015.7336928...
DEBUG: Checking Unpywall for 10.3813/aaa.918878...
DEBUG: Checking Unpywall for 10.1201/9781003529064-2...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.45...
DEBUG: Checking Unpywall for 10.1145/3759275.3759286...
DEBUG: Checking Unpywall for 10.1038/s41598-021-92910-9...
DEBUG: Checking Unpywall for 10.3403/30140140...
DEBUG: Checking Unpywall for 10.1117/12.3038839...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027233...
DEBUG: Checking Unpywall for 10.1529/biophysj.108.128892...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161861...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2875325...
DEBUG: Checking Unpywall for 10.32388/pj2wtb...
DEBUG: Checking Unpywall for 10.4018/978-1-60960-495-0.ch021...
DEBUG: Checking Unpywall for 10.5040/9798881821043.ch-003...
DEBUG: Checking Unpywall for 10.2977/prims/1195162848...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166137...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165420...
DEBUG: Checking Unpywall for 10.1109/taslp.2020.3003165...
DEBUG: Checking Unpywall for 10.31096/wua9999-blettel-binder4-loadimage13...
DEBUG: Checking Unpywall for 10.3726/b22521...
DEBUG: Checking Unpywall for 10.3403/30347370...
DEBUG: Checking Unpywall for 10.3390/app7050532...
DEBUG: Checking Unpywall for 10.3403/30314243u...
DEBUG: Checking Unpywall for 10.1109/niles68063.2025.11232379...
DEBUG: Checking Unpywall for 10.1145/3672406.3672422...
DEBUG: Checking Unpywall for 10.56028/aemr.7.1.76.2023...
DEBUG: Checking Unpywall for 10.3998/mpub.12063224.cmp.21...
DEBUG: Checking Unpywall for 10.4324/9780240821030...
DEBUG: Checking Unpywall for 10.1609/aaai.v37i1.25174...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2852502...
DEBUG: Checking Unpywall for 10.4324/9780080926735-5...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027242...
DEBUG: Checking Unpywall for 10.1112/jlms/s2-40.1.57...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 380)...
>> Round 20: No new papers added (rejected/dup). Digging deeper...

--- Search Round 21 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2000)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 96 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1609/aaai.v37i1.25174...
DEBUG: Checking Unpywall for 10.1201/9781420093391-c8...
DEBUG: Checking Unpywall for 10.56028/aemr.7.1.76.2023...
DEBUG: Checking Unpywall for 10.1529/biophysj.108.128892...
DEBUG: Checking Unpywall for 10.1007/978-981-15-8888-4_5...
DEBUG: Checking Unpywall for 10.1109/aspaa.2005.1540223...
DEBUG: Checking Unpywall for 10.5040/9798881821043.ch-003...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.859134...
DEBUG: Checking Unpywall for 10.3726/b22521...
DEBUG: Checking Unpywall for 10.3403/30347370...
DEBUG: Checking Unpywall for 10.3403/00153673...
DEBUG: Checking Unpywall for 10.4324/9780240821030...
DEBUG: Checking Unpywall for 10.4324/9780080481319-12...
DEBUG: Checking Unpywall for 10.1145/3759275.3759286...
DEBUG: Checking Unpywall for 10.17487/rfc0483...
DEBUG: Checking Unpywall for 10.1259/edu.201409285207.003/a1...
DEBUG: Checking Unpywall for 10.3403/30186300u...
DEBUG: Checking Unpywall for 10.1109/icassp49357.2023.10096463...
DEBUG: Checking Unpywall for 10.3403/03105768...
DEBUG: Checking Unpywall for 10.1016/b978-075064332-0/50011-5...
DEBUG: Checking Unpywall for 10.3403/30160465u...
DEBUG: Checking Unpywall for 10.1115/winvr2009-756...
DEBUG: Checking Unpywall for 10.3789/niso-rp-41-2023...
DEBUG: Checking Unpywall for 10.1109/tvt.2025.3552282...
DEBUG: Checking Unpywall for 10.1016/b978-075068166-7/50028-0...
DEBUG: Checking Unpywall for 10.1109/icassp49660.2025.10888882...
DEBUG: Checking Unpywall for 10.1080/09523986808547844...
DEBUG: Checking Unpywall for 10.1109/tau.1970.1162115...
DEBUG: Checking Unpywall for 10.5040/9798881821074.ch-003...
DEBUG: Checking Unpywall for 10.1007/978-3-030-11781-8_8...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161849...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027236.v1...
DEBUG: Checking Unpywall for 10.1109/ecoc.2015.7341980...
DEBUG: Checking Unpywall for 10.4324/9780080926735-3...
DEBUG: Checking Unpywall for 10.1111/j.1467-9965.2010.00418.x...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2716188...
DEBUG: Checking Unpywall for 10.32657/10356/46901...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.859131...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0006...
DEBUG: Checking Unpywall for 10.4324/9781315707228-12...
DEBUG: Checking Unpywall for 10.21437/interspeech.2019-1302...
DEBUG: Checking Unpywall for 10.1201/9781003529064-2...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161863...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165442...
DEBUG: Checking Unpywall for 10.17743/jaes.2018.0056...
DEBUG: Checking Unpywall for 10.5594/smpte.rp64.1999...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.45...
DEBUG: Checking Unpywall for 10.4324/9780429197499...
DEBUG: Checking Unpywall for 10.1121/1.3384695...
DEBUG: Checking Unpywall for 10.1007/978-981-16-0119-4_69...
DEBUG: Checking Unpywall for 10.1145/1124772.1124826...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8...
DEBUG: Checking Unpywall for 10.4324/9780080521817-17...
DEBUG: Checking Unpywall for 10.17743/jaes.2019.0031...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027245.v1...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027233.v1...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0047...
DEBUG: Checking Unpywall for 10.4324/9781315184432-12...
DEBUG: Checking Unpywall for 10.1109/tau.1970.1162117...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.835368...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.844888...
DEBUG: Checking Unpywall for 10.4135/9781483346175.n87...
DEBUG: Checking Unpywall for 10.1167/12.9.1033...
DEBUG: Checking Unpywall for 10.1201/9781439864029-9...
DEBUG: Checking Unpywall for 10.23919/transcom.2024ebp3127...
DEBUG: Checking Unpywall for 10.3403/bsiec61937...
DEBUG: Checking Unpywall for 10.1109/tau.1967.1161894...
DEBUG: Checking Unpywall for 10.4324/9780080512556-7...
DEBUG: Checking Unpywall for 10.22215/etd/2000-04573...
DEBUG: Checking Unpywall for 10.1007/978-1-349-07404-4_2...
DEBUG: Checking Unpywall for 10.1201/9781439864029-8...
DEBUG: Checking Unpywall for 10.1007/978-3-642-23253-4_5...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.856051...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4392993...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.855907...
DEBUG: Checking Unpywall for 10.4324/9781003003052-34...
DEBUG: Checking Unpywall for 10.1016/b978-0-434-91210-0.50006-8...
DEBUG: Checking Unpywall for 10.3403/30430667...
DEBUG: Checking Unpywall for 10.1109/tau.1973.1162455...
DEBUG: Checking Unpywall for 10.4324/9781315184432-7...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165647...
DEBUG: Checking Unpywall for 10.5040/9798881821050.ch-003...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027245...
DEBUG: Checking Unpywall for 10.1155/2013/718574...
DEBUG: Checking Unpywall for 10.1121/1.4805449...
DEBUG: Checking Unpywall for 10.4324/9781315223162...
DEBUG: Checking Unpywall for 10.1109/tau.1971.1162199...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161856...
DEBUG: Checking Unpywall for 10.1017/cbo9781316084205.004...
DEBUG: Checking Unpywall for 10.1201/b22247-5...
DEBUG: Checking Unpywall for 10.21203/rs.3.rs-6912640/v1...
DEBUG: Checking Unpywall for 10.4324/9781315184432-8...
DEBUG: Checking Unpywall for 10.5594/smpte.eg32.1996...
DEBUG: Checking Unpywall for 10.1145/3290605.3300851...
DEBUG: Checking Unpywall for 10.3403/30444886u...
DEBUG: Checking Unpywall for 10.17743/jaes.2020.0029...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 400)...
>> Round 21: No new papers added (rejected/dup). Digging deeper...

--- Search Round 22 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2100)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 99 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.855907...
DEBUG: Checking Unpywall for 10.3403/30318514...
DEBUG: Checking Unpywall for 10.1201/9781439864029-7...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165647...
DEBUG: Checking Unpywall for 10.1158/0008-5472.27027233.v1...
DEBUG: Checking Unpywall for 10.1109/tau.1955.1165453...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161853...
DEBUG: Checking Unpywall for 10.1016/j.procs.2015.05.224...
DEBUG: Checking Unpywall for 10.1007/s12193-019-00314-x...
DEBUG: Checking Unpywall for 10.1007/978-981-13-2493-2_3...
DEBUG: Checking Unpywall for 10.5771/9783845216935-36...
DEBUG: Checking Unpywall for 10.1109/aspaa.2007.4392993...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.828082...
DEBUG: Checking Unpywall for 10.61782/fa.2025.0965...
DEBUG: Checking Unpywall for 10.1109/icassp49357.2023.10096846...
DEBUG: Checking Unpywall for 10.1109/tau.1956.1165619...
DEBUG: Checking Unpywall for 10.1121/1.3384695...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.832211...
DEBUG: Checking Unpywall for 10.4324/9781315184432-7...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.837944...
DEBUG: Checking Unpywall for 10.31096/wua9999-blettel-binder4-loadimage4...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.06...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0006...
DEBUG: Checking Unpywall for 10.1080/09523986808552520...
DEBUG: Checking Unpywall for 10.3403/30347370u...
DEBUG: Checking Unpywall for 10.4324/9780080878065-9...
DEBUG: Checking Unpywall for 10.1016/b978-075068166-7/50027-9...
DEBUG: Checking Unpywall for 10.17148/ijarcce.2016.512103...
DEBUG: Checking Unpywall for 10.14711/thesis-b679862...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.828660...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.835368...
DEBUG: Checking Unpywall for 10.1201/b22247-5...
DEBUG: Checking Unpywall for 10.32550/teknodik.v0i0.136...
DEBUG: Checking Unpywall for 10.5594/smpte.rp64.1999...
DEBUG: Checking Unpywall for 10.1201/9781439864852-10...
DEBUG: Checking Unpywall for 10.1167/12.9.1033...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.837941...
DEBUG: Checking Unpywall for 10.3403/30160465...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0251...
DEBUG: Checking Unpywall for 10.1007/978-3-030-11781-8_10...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.848061...
DEBUG: Checking Unpywall for 10.4324/9780429197499...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.828664...
DEBUG: Checking Unpywall for 10.7717/peerj-cs.2473/fig-1...
DEBUG: Checking Unpywall for 10.25144/15505...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.841655...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.832209...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161856...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.848063...
DEBUG: Checking Unpywall for 10.5771/9783845251875_81...
DEBUG: Checking Unpywall for 10.5040/9798216434368.ch-004...
DEBUG: Checking Unpywall for 10.3403/30083965...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.852604...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00006-6...
DEBUG: Checking Unpywall for 10.5040/9798881821050.ch-003...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-054564-6.50023-9...
DEBUG: Checking Unpywall for 10.1080/09523986708547893...
DEBUG: Checking Unpywall for 10.1109/icc.2003.1204034...
DEBUG: Checking Unpywall for 10.3403/30444886...
DEBUG: Checking Unpywall for 10.47348/samlj/v32/i2a5...
DEBUG: Checking Unpywall for 10.1109/tau.1969.1162021...
DEBUG: Checking Unpywall for 10.3813/aaa.918778...
DEBUG: Checking Unpywall for 10.4324/9780240816050-8...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3221007...
DEBUG: Checking Unpywall for 10.17487/rfc0483...
DEBUG: Checking Unpywall for 10.1109/tau.1970.1162089...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.844888...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.914399...
DEBUG: Checking Unpywall for 10.3403/00175440u...
DEBUG: Checking Unpywall for 10.1109/icsitech.2017.8257083...
DEBUG: Checking Unpywall for 10.4324/9780429491214-5...
DEBUG: Checking Unpywall for 10.1007/0-387-28503-2_4...
DEBUG: Checking Unpywall for 10.3403/30314243...
DEBUG: Checking Unpywall for 10.1002/9780470680018.ch9...
DEBUG: Checking Unpywall for 10.1109/inmmic.2008.4745716...
DEBUG: Checking Unpywall for 10.1080/09523986708542619...
DEBUG: Checking Unpywall for 10.1201/b22247-15...
DEBUG: Checking Unpywall for 10.3403/30184913...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.13...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-054564-6.50010-0...
DEBUG: Checking Unpywall for 10.1007/978-3-032-01024-7_29...
DEBUG: Checking Unpywall for 10.3403/01140487u...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81244-1.00002-x...
DEBUG: Checking Unpywall for 10.4324/9781003221937-20...
DEBUG: Checking Unpywall for 10.1121/10.0037255...
DEBUG: Checking Unpywall for 10.3403/02921991...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81467-4.10022-x...
DEBUG: Checking Unpywall for 10.1201/9781439864029-13...
DEBUG: Checking Unpywall for 10.1109/qomex55416.2022.9900892...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.852608...
DEBUG: Checking Unpywall for 10.4324/9781003003052-35...
DEBUG: Checking Unpywall for 10.1016/b978-0-434-91210-0.50008-1...
DEBUG: Checking Unpywall for 10.4324/9781315657813-10...
DEBUG: Checking Unpywall for 10.3403/03138614u...
DEBUG: Checking Unpywall for 10.1037/neu0000776...
DEBUG: Checking Unpywall for 10.5594/smpte.st2041-1.2010...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.907571...
DEBUG: Checking Unpywall for 10.1109/acii52823.2021.9597435...
DEBUG: Checking Unpywall for 10.1007/bf02772696...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 420)...
>> Round 22: No new papers added (rejected/dup). Digging deeper...

--- Search Round 23 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2200)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 98 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.859136...
DEBUG: Checking Unpywall for 10.1201/9781439864029-7...
DEBUG: Checking Unpywall for 10.2139/ssrn.2295784...
DEBUG: Checking Unpywall for 10.1145/1409240.1409251...
DEBUG: Checking Unpywall for 10.1007/s12070-022-03442-1...
DEBUG: Checking Unpywall for 10.5771/9783845216935-36...
DEBUG: Checking Unpywall for 10.3403/30318514...
DEBUG: Checking Unpywall for 10.5040/9798881821067.ch-003...
DEBUG: Checking Unpywall for 10.25144/22836...
DEBUG: Checking Unpywall for 10.17743/jaes.2016.0015...
DEBUG: Checking Unpywall for 10.1364/oe.539548...
DEBUG: Checking Unpywall for 10.1109/icct62411.2024.10946302...
DEBUG: Checking Unpywall for 10.2172/2205675...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.837941...
DEBUG: Checking Unpywall for 10.5594/smpte.eg26.1995...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166022...
DEBUG: Checking Unpywall for 10.1007/978-981-13-2493-2_3...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2173677...
DEBUG: Checking Unpywall for 10.5194/isprs-archives-xlvi-3-w1-2022-53-2022...
DEBUG: Checking Unpywall for 10.1201/9781439864852-8...
DEBUG: Checking Unpywall for 10.14264/uql.2019.255...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.852607...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_2...
DEBUG: Checking Unpywall for 10.1109/glocom.2003.1258530...
DEBUG: Checking Unpywall for 10.1201/9781439864029-12...
DEBUG: Checking Unpywall for 10.1007/978-3-031-36789-2_13...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_5...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.845817...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.844891...
DEBUG: Checking Unpywall for 10.1109/tau.1958.1166170...
DEBUG: Checking Unpywall for 10.1109/taslp.2017.2716188...
DEBUG: Checking Unpywall for 10.32388/efkw6i...
DEBUG: Checking Unpywall for 10.1016/b978-075068166-7/50026-7...
DEBUG: Checking Unpywall for 10.1201/9781439864852-15...
DEBUG: Checking Unpywall for 10.4324/9780203133149-18...
DEBUG: Checking Unpywall for 10.1090/mbk/130/11...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81915-0.00011-4...
DEBUG: Checking Unpywall for 10.1016/b978-0-434-91210-0.50009-3...
DEBUG: Checking Unpywall for 10.3403/03138614...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00019-4...
DEBUG: Checking Unpywall for 10.1109/msp.1970.28104...
DEBUG: Checking Unpywall for 10.1016/j.rineng.2025.105039...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0060...
DEBUG: Checking Unpywall for 10.4324/9781315694153-20...
DEBUG: Checking Unpywall for 10.3403/30326552...
DEBUG: Checking Unpywall for 10.1017/cbo9780511609640.007...
DEBUG: Checking Unpywall for 10.1002/9780470680018.ch4...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00016-5...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0125...
DEBUG: Checking Unpywall for 10.3403/00175440...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.859135...
DEBUG: Checking Unpywall for 10.1121/1.1945368...
DEBUG: Checking Unpywall for 10.4324/9781003221937-4...
DEBUG: Checking Unpywall for 10.3403/30326552u...
DEBUG: Checking Unpywall for 10.4324/9781315707228-5...
DEBUG: Checking Unpywall for 10.1109/qomex61742.2024.10598292...
DEBUG: Checking Unpywall for 10.4324/9780203838181-4...
DEBUG: Checking Unpywall for 10.4324/9781315707228-1...
DEBUG: Checking Unpywall for 10.17743/jaes.2018.0068...
DEBUG: Checking Unpywall for 10.1109/tau.1959.1166207...
DEBUG: Checking Unpywall for 10.1109/rfid.2012.24...
DEBUG: Checking Unpywall for 10.1109/icassp.2008.4517630...
DEBUG: Checking Unpywall for 10.1201/9781439864029-11...
DEBUG: Checking Unpywall for 10.4324/9781003369462-9...
DEBUG: Checking Unpywall for 10.1109/taslp.2018.2886743...
DEBUG: Checking Unpywall for 10.5040/9798216434368.ch-002...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-82100-9.00002-2...
DEBUG: Checking Unpywall for 10.14711/thesis-b679882...
DEBUG: Checking Unpywall for 10.2307/jj.30346843.30...
DEBUG: Checking Unpywall for 10.1007/978-3-031-36789-2_11...
DEBUG: Checking Unpywall for 10.1007/978-3-642-35314-7_65...
DEBUG: Checking Unpywall for 10.1109/i3da57090.2023.10289338...
DEBUG: Checking Unpywall for 10.4324/9781315707228-6...
DEBUG: Checking Unpywall for 10.3403/30184913u...
DEBUG: Checking Unpywall for 10.1109/bmsb65076.2025.11165553...
DEBUG: Checking Unpywall for 10.4324/9780080472478-9...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-1721-4_15...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00020-7...
DEBUG: Checking Unpywall for 10.1109/icalip.2016.7846605...
DEBUG: Checking Unpywall for 10.1109/tau.1966.1161838...
DEBUG: Checking Unpywall for 10.1016/b978-0-434-91210-0.50007-x...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202109...
DEBUG: Checking Unpywall for 10.1080/09523987008547778...
DEBUG: Checking Unpywall for 10.4324/9781003052968-8...
DEBUG: Checking Unpywall for 10.4324/9781003003052-43...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.841658...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0031...
DEBUG: Checking Unpywall for 10.17743/jaes.2021.0060...
DEBUG: Checking Unpywall for 10.1016/j.jpet.2024.101697...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.828662...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81295-3.00006-x...
DEBUG: Checking Unpywall for 10.1201/9781439864029-14...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81604-3.00001-0...
DEBUG: Checking Unpywall for 10.4324/9781315657813-17...
DEBUG: Checking Unpywall for 10.3403/30160465...
DEBUG: Checking Unpywall for 10.1101/2023.12.24.573275...
DEBUG: Checking Unpywall for 10.3403/01140487...
DEBUG: Checking Unpywall for 10.21236/ad1000133...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 440)...
>> Round 23: No new papers added (rejected/dup). Digging deeper...

--- Search Round 24 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2300)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 91 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.5771/9783845216935-76...
DEBUG: Checking Unpywall for 10.5594/smpte.eg23.2005...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.852608...
DEBUG: Checking Unpywall for 10.1007/978-3-030-11781-8_3...
DEBUG: Checking Unpywall for 10.3403/30152506...
DEBUG: Checking Unpywall for 10.4324/9780080948966-8...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00004-2...
DEBUG: Checking Unpywall for 10.1109/qomex55416.2022.9900892...
DEBUG: Checking Unpywall for 10.1016/j.jconrel.2024.06.015...
DEBUG: Checking Unpywall for 10.4324/9781843144595-18...
DEBUG: Checking Unpywall for 10.5594/smpte.st337.2008...
DEBUG: Checking Unpywall for 10.3403/30409177u...
DEBUG: Checking Unpywall for 10.1109/30.536134...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00010-8...
DEBUG: Checking Unpywall for 10.32388/cp6bm2...
DEBUG: Checking Unpywall for 10.1109/iceca.2018.8474758...
DEBUG: Checking Unpywall for 10.1109/iih-msp.2015.48...
DEBUG: Checking Unpywall for 10.1109/tsa.2004....
DEBUG: Checking Unpywall for 10.3357/asem.2248.2008...
DEBUG: Checking Unpywall for 10.1518/107118109x12524443344952...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-82100-9.00002-2...
DEBUG: Checking Unpywall for 10.32388/5nr3rt...
DEBUG: Checking Unpywall for 10.1201/9781482267570-4...
DEBUG: Checking Unpywall for 10.1109/icct.2017.8359474...
DEBUG: Checking Unpywall for 10.4324/9781315707228-5...
DEBUG: Checking Unpywall for 10.3403/01140487...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.856054...
DEBUG: Checking Unpywall for 10.1007/springerreference_8417...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.854105...
DEBUG: Checking Unpywall for 10.7717/peerj.5917/fig-1...
DEBUG: Checking Unpywall for 10.1201/9781439864852-11...
DEBUG: Checking Unpywall for 10.4324/9780080927626-4...
DEBUG: Checking Unpywall for 10.4992/pacjpa.82.0_1am-060...
DEBUG: Checking Unpywall for 10.1007/978-3-032-01024-7_14...
DEBUG: Checking Unpywall for 10.23919/eusipco63237.2025.11226209...
DEBUG: Checking Unpywall for 10.4324/9781003003052-31...
DEBUG: Checking Unpywall for 10.1007/1-4020-7769-6_11...
DEBUG: Checking Unpywall for 10.17743/jaes.2021.0012...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_8...
DEBUG: Checking Unpywall for 10.1201/9781003529064-5...
DEBUG: Checking Unpywall for 10.1186/s13636-018-0127-7...
DEBUG: Checking Unpywall for 10.1163/2210-7975_hrd-0903-20180014...
DEBUG: Checking Unpywall for 10.18535/ijecs/v5i4.19...
DEBUG: Checking Unpywall for 10.1109/icalip.2012.6376781...
DEBUG: Checking Unpywall for 10.4324/9780080948966-12...
DEBUG: Checking Unpywall for 10.4324/9781003052968-6...
DEBUG: Checking Unpywall for 10.4324/9780429292200-10...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0076...
DEBUG: Checking Unpywall for 10.4324/9781003221937-24...
DEBUG: Checking Unpywall for 10.1016/b978-0-434-91210-0.50007-x...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202118...
DEBUG: Checking Unpywall for 10.4324/9780429292200-8...
DEBUG: Checking Unpywall for 10.1007/978-3-032-01024-7_22...
DEBUG: Checking Unpywall for 10.31390/gradschool_theses.1619...
DEBUG: Checking Unpywall for 10.1201/9781439864869-4...
DEBUG: Checking Unpywall for 10.4324/9781315223162-20...
DEBUG: Checking Unpywall for 10.1101/2025.11.22.689892...
DEBUG: Checking Unpywall for 10.4324/9781315694153-24...
DEBUG: Checking Unpywall for 10.5040/9798881820442.ch-023...
DEBUG: Checking Unpywall for 10.1080/09523986808547921...
DEBUG: Checking Unpywall for 10.1080/09523986808552516...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.862700...
DEBUG: Checking Unpywall for 10.4324/9781315223162-16...
DEBUG: Checking Unpywall for 10.5771/9783845243559-93...
DEBUG: Checking Unpywall for 10.1111/j.1749-6632.2009.03860.x...
DEBUG: Checking Unpywall for 10.7717/peerj-cs.3369/fig-2...
DEBUG: Checking Unpywall for 10.1109/tau.1957.1166029...
DEBUG: Checking Unpywall for 10.4324/9780429292200-6...
DEBUG: Checking Unpywall for 10.4324/9781003003052-21...
DEBUG: Checking Unpywall for 10.4324/9781315223162-32...
DEBUG: Checking Unpywall for 10.1145/3654777.3676424...
DEBUG: Checking Unpywall for 10.1007/3-540-58476-5_117...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.881687...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00005-0...
DEBUG: Checking Unpywall for 10.1037/t16671-000...
DEBUG: Checking Unpywall for 10.1201/9781439864029-11...
DEBUG: Checking Unpywall for 10.1016/j.optlastec.2024.112301...
DEBUG: Checking Unpywall for 10.4324/9781315707228-7...
DEBUG: Checking Unpywall for 10.1103/physrevlett.129.060501...
DEBUG: Checking Unpywall for 10.1007/978-3-031-04021-4_9...
DEBUG: Checking Unpywall for 10.4324/9780429455971-3...
DEBUG: Checking Unpywall for 10.3403/30326562u...
DEBUG: Checking Unpywall for 10.1088/1555-6611/ab1839...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_17...
DEBUG: Checking Unpywall for 10.4324/9780080472478-12...
DEBUG: Checking Unpywall for 10.4324/9781003518242...
DEBUG: Checking Unpywall for 10.1201/9781482267570-6...
DEBUG: Checking Unpywall for 10.1201/b17593-16...
DEBUG: Checking Unpywall for 10.4324/9780080472065-9...
DEBUG: Checking Unpywall for 10.1201/9781439864852-12...
DEBUG: Checking Unpywall for 10.1201/9781439864029...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 460)...
>> Round 24: No new papers added (rejected/dup). Digging deeper...

--- Search Round 25 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2400)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 89 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1088/1674-1056/acdc10...
DEBUG: Checking Unpywall for 10.1088/1555-6611/ab1839...
DEBUG: Checking Unpywall for 10.1103/physrevlett.129.060501...
DEBUG: Checking Unpywall for 10.1016/j.optlastec.2024.112301...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.908128...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2104714...
DEBUG: Checking Unpywall for 10.1201/9781439864869...
DEBUG: Checking Unpywall for 10.1145/2814895.2814925...
DEBUG: Checking Unpywall for 10.4324/9781003003052-31...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2171602...
DEBUG: Checking Unpywall for 10.1037/t16671-000...
DEBUG: Checking Unpywall for 10.1145/3757374.3771434...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2112252...
DEBUG: Checking Unpywall for 10.1109/30.536134...
DEBUG: Checking Unpywall for 10.1121/1.4734290...
DEBUG: Checking Unpywall for 10.1017/cbo9780511609640.003...
DEBUG: Checking Unpywall for 10.4324/9781315733418-8...
DEBUG: Checking Unpywall for 10.3403/30490473u...
DEBUG: Checking Unpywall for 10.1007/978-3-031-04021-4_9...
DEBUG: Checking Unpywall for 10.1093/gmo/9781561592630.article.a2256346...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_17...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202118...
DEBUG: Checking Unpywall for 10.4324/9781003003052-30...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_8...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_8...
DEBUG: Checking Unpywall for 10.3403/30107011...
DEBUG: Checking Unpywall for 10.5771/9783845270753-70...
DEBUG: Checking Unpywall for 10.4324/9781032640150-4...
DEBUG: Checking Unpywall for 10.17743/jaes.2021.0065...
DEBUG: Checking Unpywall for 10.1201/9781439864852-13...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.37...
DEBUG: Checking Unpywall for 10.1016/b978-0-434-91210-0.50011-1...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.881687...
DEBUG: Checking Unpywall for 10.1007/978-1-4020-5614-7_2324...
DEBUG: Checking Unpywall for 10.3403/30107011u...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81467-4.10005-x...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-80621-1.50019-8...
DEBUG: Checking Unpywall for 10.1002/hbm.21254...
DEBUG: Checking Unpywall for 10.3403/30326562u...
DEBUG: Checking Unpywall for 10.4324/9781003386964-14...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0076...
DEBUG: Checking Unpywall for 10.1007/978-3-540-72816-0_6034...
DEBUG: Checking Unpywall for 10.4324/9781315733418-10...
DEBUG: Checking Unpywall for 10.4324/9781003003052-26...
DEBUG: Checking Unpywall for 10.1145/1851600.1851734...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202082...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.911552...
DEBUG: Checking Unpywall for 10.1007/1-4020-7769-6_11...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2217554...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.815820...
DEBUG: Checking Unpywall for 10.31390/gradschool_theses.1619...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00014-1...
DEBUG: Checking Unpywall for 10.5771/9783845251875_5...
DEBUG: Checking Unpywall for 10.5771/9783845243559-93...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_2...
DEBUG: Checking Unpywall for 10.1080/09523987008547905...
DEBUG: Checking Unpywall for 10.5594/smpte.st2098-1...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81213-7.00018-6...
DEBUG: Checking Unpywall for 10.1364/brain.2018.btu2c.2...
DEBUG: Checking Unpywall for 10.1201/9781482267570-7...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2097852...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161748...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.922902...
DEBUG: Checking Unpywall for 10.1201/9781482267570-4...
DEBUG: Checking Unpywall for 10.4324/9781003052968-4...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2203471...
DEBUG: Checking Unpywall for 10.4324/9780080472065-9...
DEBUG: Checking Unpywall for 10.1201/9781482267570-6...
DEBUG: Checking Unpywall for 10.1088/1741-2560/8/4/046016...
DEBUG: Checking Unpywall for 10.23919/eusipco63237.2025.11226209...
DEBUG: Checking Unpywall for 10.1109/tau.1973.1162523...
DEBUG: Checking Unpywall for 10.25144/18187...
DEBUG: Checking Unpywall for 10.1016/b978-0-7506-0614-1.50021-2...
DEBUG: Checking Unpywall for 10.4324/9780429292200-11...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0230...
DEBUG: Checking Unpywall for 10.4467/2353737xct.17.073.6430...
DEBUG: Checking Unpywall for 10.4992/pacjpa.82.0_1am-060...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2253681...
DEBUG: Checking Unpywall for 10.5771/9783845260815-11...
DEBUG: Checking Unpywall for 10.32388/8vw2gv...
DEBUG: Checking Unpywall for 10.4324/9781315694153-22...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-51969-2.50013-0...
DEBUG: Checking Unpywall for 10.5040/9781501328671.0007...
DEBUG: Checking Unpywall for 10.4324/9780080472065-7...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2282214...
DEBUG: Checking Unpywall for 10.5771/9783845230146-55...
DEBUG: Checking Unpywall for 10.4324/9781315832685-32...
DEBUG: Checking Unpywall for 10.5772/1375...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.889514...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 480)...
>> Round 25: No new papers added (rejected/dup). Digging deeper...

--- Search Round 26 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2500)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 90 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_6...
DEBUG: Checking Unpywall for 10.3403/01921887...
DEBUG: Checking Unpywall for 10.1109/t-sp.1954.28268...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.838533...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.845816...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230989...
DEBUG: Checking Unpywall for 10.1007/springerreference_64360...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_7...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_5...
DEBUG: Checking Unpywall for 10.29300/madania.v27i2.2863...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.908128...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_4...
DEBUG: Checking Unpywall for 10.4324/9781003386964-14...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.814412...
DEBUG: Checking Unpywall for 10.1080/09523986808547924...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.886072...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2163600...
DEBUG: Checking Unpywall for 10.1145/3757374.3771434...
DEBUG: Checking Unpywall for 10.1121/1.4734290...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0042...
DEBUG: Checking Unpywall for 10.4324/9781315733418-8...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.897014...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3173054...
DEBUG: Checking Unpywall for 10.1007/978-3-032-01024-7_8...
DEBUG: Checking Unpywall for 10.1109/t-sp.1953.28144...
DEBUG: Checking Unpywall for 10.17743/jaes.2019.0002...
DEBUG: Checking Unpywall for 10.1007/978-3-032-01024-7_28...
DEBUG: Checking Unpywall for 10.1007/978-3-540-72816-0_6034...
DEBUG: Checking Unpywall for 10.1109/waspaa66052.2025.11230997...
DEBUG: Checking Unpywall for 10.1007/978-3-662-04437-7_5...
DEBUG: Checking Unpywall for 10.1093/gmo/9781561592630.article.a2256346...
DEBUG: Checking Unpywall for 10.1016/b978-0-7506-0614-1.50021-2...
DEBUG: Checking Unpywall for 10.1109/twc.2022.3197275...
DEBUG: Checking Unpywall for 10.1007/1-4020-8092-1_1...
DEBUG: Checking Unpywall for 10.4324/9780080472065-7...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2227733...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161687...
DEBUG: Checking Unpywall for 10.1093/oso/9780190084097.003.0009...
DEBUG: Checking Unpywall for 10.3403/30490473u...
DEBUG: Checking Unpywall for 10.5040/9781501328671.0007...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2163597...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2064710...
DEBUG: Checking Unpywall for 10.1109/jstsp.2015.2447112...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_1...
DEBUG: Checking Unpywall for 10.4324/9780080470948...
DEBUG: Checking Unpywall for 10.5771/9783845236858-39...
DEBUG: Checking Unpywall for 10.1007/978-1-4615-6083-8_5...
DEBUG: Checking Unpywall for 10.5771/9783845230146-55...
DEBUG: Checking Unpywall for 10.1007/978-981-15-2325-0_3...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2203471...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.897012...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2217554...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2033978...
DEBUG: Checking Unpywall for 10.17743/jaes.2015.0090...
DEBUG: Checking Unpywall for 10.1093/oso/9780190084097.003.0008...
DEBUG: Checking Unpywall for 10.1080/09523987108548127...
DEBUG: Checking Unpywall for 10.1186/1687-4722-2010-404860...
DEBUG: Checking Unpywall for 10.5594/smpte.st2098-1...
DEBUG: Checking Unpywall for 10.25144/18187...
DEBUG: Checking Unpywall for 10.5771/9783845260815-103...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161763...
DEBUG: Checking Unpywall for 10.4324/9781003003052-8...
DEBUG: Checking Unpywall for 10.1057/978-1-137-56917-2_4...
DEBUG: Checking Unpywall for 10.1080/09523986908547943...
DEBUG: Checking Unpywall for 10.4324/9781315694153-22...
DEBUG: Checking Unpywall for 10.5220/0011071500003179...
DEBUG: Checking Unpywall for 10.4324/9781315223162-27...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.07...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161689...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00014-1...
DEBUG: Checking Unpywall for 10.1109/tsa.2002.800560...
DEBUG: Checking Unpywall for 10.3403/30355801u...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161678...
DEBUG: Checking Unpywall for 10.5771/9783845251875...
DEBUG: Checking Unpywall for 10.1201/b22247-3...
DEBUG: Checking Unpywall for 10.46430/phes0007...
DEBUG: Checking Unpywall for 10.1080/09523987108548128...
DEBUG: Checking Unpywall for 10.4324/9781003221937-1...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161748...
DEBUG: Checking Unpywall for 10.4324/9781003221937-8...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161774...
DEBUG: Checking Unpywall for 10.1109/tsa.89...
DEBUG: Checking Unpywall for 10.5594/smpte.eg7.1994...
DEBUG: Checking Unpywall for 10.4324/9781315774695-30...
DEBUG: Checking Unpywall for 10.3403/03031670...
DEBUG: Checking Unpywall for 10.1109/tau.1973.1162523...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.50...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-51941-8.50008-x...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161727...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2253681...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 500)...
>> Round 26: No new papers added (rejected/dup). Digging deeper...

--- Search Round 27 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2600)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 94 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/tsa.2004.838533...
DEBUG: Checking Unpywall for 10.5220/0011071500003179...
DEBUG: Checking Unpywall for 10.1093/oso/9780190084097.003.0008...
DEBUG: Checking Unpywall for 10.4324/9780080470948...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161678...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2273051...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.07...
DEBUG: Checking Unpywall for 10.1007/978-3-032-01024-7_19...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161727...
DEBUG: Checking Unpywall for 10.1080/09523986908547943...
DEBUG: Checking Unpywall for 10.32388/dizkae...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161687...
DEBUG: Checking Unpywall for 10.1090/dol/004/06...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2263990...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2163600...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2179737...
DEBUG: Checking Unpywall for 10.32614/cran.package.audio...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.927285...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2040099...
DEBUG: Checking Unpywall for 10.1201/9781439864852-9...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.897014...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00015-3...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.886072...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.814412...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2291470...
DEBUG: Checking Unpywall for 10.1109/temc.2016.2612401...
DEBUG: Checking Unpywall for 10.3403/03031670...
DEBUG: Checking Unpywall for 10.1109/ictc.2014.6983344...
DEBUG: Checking Unpywall for 10.4135/9781412953993.n127...
DEBUG: Checking Unpywall for 10.4324/9780080472065-15...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.16...
DEBUG: Checking Unpywall for 10.21136/cpm.1989.118364...
DEBUG: Checking Unpywall for 10.1201/b22247-3...
DEBUG: Checking Unpywall for 10.1109/t-sp.1953.28144...
DEBUG: Checking Unpywall for 10.4324/9781315223162-31...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.15...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0141...
DEBUG: Checking Unpywall for 10.32388/63ehyg...
DEBUG: Checking Unpywall for 10.5040/9798881821074.0004...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.878940...
DEBUG: Checking Unpywall for 10.1080/09523987008552205...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161820...
DEBUG: Checking Unpywall for 10.3403/03031670u...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.871495...
DEBUG: Checking Unpywall for 10.2172/1336366...
DEBUG: Checking Unpywall for 10.1007/978-1-4842-6658-8_6...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.882554...
DEBUG: Checking Unpywall for 10.1201/9781003330936-2...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2012480...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2264640...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.914212...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.859138...
DEBUG: Checking Unpywall for 10.4324/9781315707228-4...
DEBUG: Checking Unpywall for 10.4324/9781315707228-11...
DEBUG: Checking Unpywall for 10.14711/thesis-991012554966003412...
DEBUG: Checking Unpywall for 10.1007/978-1-0716-1006-0_300446...
DEBUG: Checking Unpywall for 10.1016/b978-075064332-0/50006-1...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2163599...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.890759...
DEBUG: Checking Unpywall for 10.3724/sp.j.1004.2008.01184...
DEBUG: Checking Unpywall for 10.3403/30409177...
DEBUG: Checking Unpywall for 10.3403/30338296u...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2038438...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2161156...
DEBUG: Checking Unpywall for 10.1007/1-4020-8092-1_7...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2291466...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161774...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00017-7...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161796...
DEBUG: Checking Unpywall for 10.3403/30430663u...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2042518...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2020585...
DEBUG: Checking Unpywall for 10.22215/etd/1997-03702...
DEBUG: Checking Unpywall for 10.1109/taslp.2022.3173054...
DEBUG: Checking Unpywall for 10.4324/9781003221937-1...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.50...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.892685...
DEBUG: Checking Unpywall for 10.1057/978-1-137-56917-2_4...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161745...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.882553...
DEBUG: Checking Unpywall for 10.4324/9781315778624-9...
DEBUG: Checking Unpywall for 10.3403/bsiec62702-1...
DEBUG: Checking Unpywall for 10.1186/s13636-023-00316-4...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.914214...
DEBUG: Checking Unpywall for 10.4324/9781003221937-8...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161826...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.925881...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2253677...
DEBUG: Checking Unpywall for 10.1080/09523987008552221...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0121...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00021-9...
DEBUG: Checking Unpywall for 10.1007/978-3-031-36789-2_9...
DEBUG: Checking Unpywall for 10.1080/09523987108548099...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.909134...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 520)...
>> Round 27: No new papers added (rejected/dup). Digging deeper...

--- Search Round 28 (Collected: 16/35 for target 25) ---
Searching Crossref (Offset: 2700)...
DEBUG: Processing batch of 100 candidates...
DEBUG: 96 candidates passed pre-filter. Checking accessibility concurrently...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161671...
DEBUG: Checking Unpywall for 10.1080/09523987008547775...
DEBUG: Checking Unpywall for 10.1109/tau.1964.1161746...
DEBUG: Checking Unpywall for 10.1186/s13636-023-00297-4...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2158936...
DEBUG: Checking Unpywall for 10.1007/0-387-28503-2_1...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2015019...
DEBUG: Checking Unpywall for 10.1109/tsa.2005.863092...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.918342...
DEBUG: Checking Unpywall for 10.1002/j.2168-0159.2013.tb06226.x...
DEBUG: Checking Unpywall for 10.1109/tau.1963.1161678...
DEBUG: Checking Unpywall for 10.1109/twc.2022.3197275...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2241338...
DEBUG: Checking Unpywall for 10.17771/pucrio.acad.69621...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.915869...
DEBUG: Checking Unpywall for 10.4324/9780080470948...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.878936...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0108...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2025164...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.872602...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.819953...
DEBUG: Checking Unpywall for 10.1109/tasl.2006.871496...
DEBUG: Checking Unpywall for 10.3403/30430663u...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00021-9...
DEBUG: Checking Unpywall for 10.1080/09523986908547867...
DEBUG: Checking Unpywall for 10.1109/npga.8462...
DEBUG: Checking Unpywall for 10.1109/tsa.2001.966099...
DEBUG: Checking Unpywall for 10.5040/9798881821050.0004...
DEBUG: Checking Unpywall for 10.4324/9780080887920...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161802...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.2002361...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2047991...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161789...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.897015...
DEBUG: Checking Unpywall for 10.1080/09523987008552201...
DEBUG: Checking Unpywall for 10.5771/9783845243559-53...
DEBUG: Checking Unpywall for 10.1080/09523987108548086...
DEBUG: Checking Unpywall for 10.1515/9781503606579-004...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.927284...
DEBUG: Checking Unpywall for 10.1186/s13636-014-0041-6...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.890753...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2282066...
DEBUG: Checking Unpywall for 10.17743/jaes.2014.0024...
DEBUG: Checking Unpywall for 10.1109/89.824698...
DEBUG: Checking Unpywall for 10.1109/i3da65421.2025.11202082...
DEBUG: Checking Unpywall for 10.4324/9780240813912-13...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161826...
DEBUG: Checking Unpywall for 10.1016/b978-0-08-099388-1.00017-0...
DEBUG: Checking Unpywall for 10.1007/978-981-15-2325-0_3...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2203472...
DEBUG: Checking Unpywall for 10.14324/111.9781800086616.23...
DEBUG: Checking Unpywall for 10.1145/1851600.1851734...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2228366...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_4...
DEBUG: Checking Unpywall for 10.1109/leos.2000.890655...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2038439...
DEBUG: Checking Unpywall for 10.1109/tau.1965.1161821...
DEBUG: Checking Unpywall for 10.1109/tasl.10376...
DEBUG: Checking Unpywall for 10.1016/b978-0-240-81273-1.00013-x...
DEBUG: Checking Unpywall for 10.1201/9781003519119-15...
DEBUG: Checking Unpywall for 10.4324/9781003003052-17...
DEBUG: Checking Unpywall for 10.1109/tasl.2013.2282214...
DEBUG: Checking Unpywall for 10.1109/tau.1960.1166285...
DEBUG: Checking Unpywall for 10.1109/t-sp.1953.28148...
DEBUG: Checking Unpywall for 10.1109/tasl.2008.918340...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0047...
DEBUG: Checking Unpywall for 10.1080/09523987008552205...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.892684...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2012485...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2052653...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2040100...
DEBUG: Checking Unpywall for 10.1109/tasl.2011.2171601...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2208072...
DEBUG: Checking Unpywall for 10.1109/tsa.2003.811538...
DEBUG: Checking Unpywall for 10.4324/9781003050346-18...
DEBUG: Checking Unpywall for 10.21275/v5i5.nov163640...
DEBUG: Checking Unpywall for 10.21236/ada516501...
DEBUG: Checking Unpywall for 10.3403/30338296...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2058291...
DEBUG: Checking Unpywall for 10.1109/scis-isis.2018.00123...
DEBUG: Checking Unpywall for 10.1109/tasl.2010.2084791...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2228364...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2211433...
DEBUG: Checking Unpywall for 10.1016/j.patrec.2025.07.021...
DEBUG: Checking Unpywall for 10.1007/springerreference_73102...
DEBUG: Checking Unpywall for 10.3389/fnhum.2025.1623431.s008...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2012472...
DEBUG: Checking Unpywall for 10.1007/978-1-4419-0947-3_7...
DEBUG: Checking Unpywall for 10.1007/978-3-031-75499-9_14...
DEBUG: Checking Unpywall for 10.1080/09523987108548125...
DEBUG: Checking Unpywall for 10.1109/tasl.2012.2211435...
DEBUG: Checking Unpywall for 10.1109/tasl.2007.903745...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0093...
DEBUG: Checking Unpywall for 10.1002/j.1538-7305.1961.tb03246.x...
DEBUG: Checking Unpywall for 10.1109/tasl.2009.2027378...
DEBUG: Checking Unpywall for 10.17743/jaes.2022.0046...
DEBUG: Batch complete. Added 0 papers.
Searching Semantic Scholar (Offset: 540)...

==================================================
FILE: .venv/etc/jupyter/nbconfig/notebook.d/pydeck.json
==================================================
{
    "load_extensions": {
        "pydeck/extension": true
    }
}


==================================================
FILE: scripts/cleanup_space.py
==================================================
import os
import shutil
import tempfile
import glob

def clean_temp():
    # 1. System Temp
    try:
        temp_dir = tempfile.gettempdir()
        # Pattern: scholar_stack_mission_* and urp_mission_* (old name)
        patterns = [
            os.path.join(temp_dir, "scholar_stack_mission_*"),
            os.path.join(temp_dir, "urp_mission_*")
        ]
        
        folders = []
        for p in patterns:
            folders.extend(glob.glob(p))
            
        print(f"Scanning for orphaned missions in: {temp_dir}")
        total_deleted = 0
        
        for f in folders:
            if os.path.isdir(f):
                size = 0
                for dirpath, dirnames, filenames in os.walk(f):
                    for filename in filenames:
                        fp = os.path.join(dirpath, filename)
                        if not os.path.islink(fp):
                            size += os.path.getsize(fp)
                
                size_gb = size/(1024**3)
                print(f"Found Orphan: {os.path.basename(f)} - {size_gb:.2f} GB")
                
                # Delete it
                try:
                    shutil.rmtree(f)
                    print(f"  -> Deleted: {os.path.basename(f)}")
                    total_deleted += size_gb
                except Exception as e:
                    print(f"  -> Failed to delete: {e}")

        print(f"Reclaimed from Temp: {total_deleted:.2f} GB\n")
    except Exception as e:
        print(f"Error scanning temp: {e}")

    # 2. Static Folder
    try:
        project_static = os.path.abspath("static")
        print(f"Scanning static folder: {project_static}")
        
        static_deleted = 0
        if os.path.exists(project_static):
            for f in os.listdir(project_static):
                if f.endswith(".zip"):
                    fp = os.path.join(project_static, f)
                    if os.path.islink(fp):
                        os.unlink(fp)
                        print(f"Removed Symlink: {f}")
                    else:
                        size = os.path.getsize(fp)
                        os.remove(fp)
                        static_deleted += size/(1024**3)
                        print(f"Deleted Static Zip: {f} - {size/(1024**3):.2f} GB")
        
        print(f"Reclaimed from Static: {static_deleted:.2f} GB")
        
    except Exception as e:
        print(f"Error scanning static: {e}")

if __name__ == "__main__":
    clean_temp()


==================================================
FILE: scripts/verify_llm_logic.py
==================================================

import importlib.util
import sys
import os
from dotenv import load_dotenv

load_dotenv()

# Dynamically import the script (since it starts with a number)
spec = importlib.util.spec_from_file_location("search_omni", "1_search_omni.py")
search_omni = importlib.util.module_from_spec(spec)
sys.modules["search_omni"] = search_omni
spec.loader.exec_module(search_omni)

ResearchCrawler = search_omni.ResearchCrawler

print("‚ö°Ô∏è Starting Live LLM Logic Verification...")

try:
    # Initialize Crawler (Dummy args)
    crawler = ResearchCrawler(
        topic="Spatial Audio", 
        keywords="HRTF", 
        author="", 
        publication="", 
        date_start="", 
        date_end="", 
        count=10, 
        sites=[], 
        keyword_logic='any', 
        no_llm=False
    )
    
    # Test 1: Topic Expansion (Uses Model Rotation)
    print("\n[Test 1] Testing expand_topic_with_llm...")
    topics = crawler.expand_topic_with_llm("Spatial Audio")
    print(f"   -> Result: {topics[:3]}... (Total {len(topics)})")
    if len(topics) > 1:
        print("   ‚úÖ Topic Expansion Passed.")
    else:
        print("   ‚ùå Topic Expansion Returned Default (Failed).")

    # Test 2: Synonym Expansion (Uses Model Rotation)
    print("\n[Test 2] Testing expand_keywords_with_llm...")
    syns = crawler.expand_keywords_with_llm(["HRTF"])
    print(f"   -> Result: {syns[:3]}... (Total {len(syns)})")
    if len(syns) > 1:
         print("   ‚úÖ Synonym Expansion Passed.")
    else:
         print("   ‚ùå Synonym Expansion Returned Default (Failed).")

    
    # Test 3: Search Verticals (Uses Model Rotation) - CRITICAL FAIL POINT
    print("\n[Test 3] Testing get_search_verticals_from_llm...")
    verticals = crawler.get_search_verticals_from_llm("Spatial Audio")
    print(f"   -> Result: {verticals}")
    if len(verticals) > 1:
         print("   ‚úÖ Verticals Generation Passed.")
    else:
         print("   ‚ùå Verticals Generation Failed (Returned Default).")

    print("\nüéâ ALL TESTS PASSED. The script is safe to run.")

except Exception as e:
    print(f"\n‚ùå FATAL ERROR During Verification: {e}")
    import traceback
    traceback.print_exc()


==================================================
FILE: scripts/debug_google_full.py
==================================================

from googlesearch import search
import requests
import random
import time

def check_paper(title):
    print(f"üîé Checking Google for: '{title}'")
    query = f"{title} pdf"
    try:
        # Try finding ANY result first, then PDF
        for r in search(query, num_results=7, advanced=True):
            url = r.url
            print(f"   -> {url}")
            
            # A. ArXiv
            if 'arxiv.org/abs' in url:
                print(f"   ‚úÖ MATCH (ArXiv): {url}")
                return
                
            # B. Extension
            if url.endswith('.pdf'):
                print(f"   ‚úÖ MATCH (Direct): {url}")
                return
            
            # C. HEAD Check
            try:
                h_headers = {'User-Agent': 'Mozilla/5.0'}
                h = requests.head(url, headers=h_headers, timeout=3, allow_redirects=True)
                ct = h.headers.get('Content-Type', '').lower()
                if 'application/pdf' in ct:
                     print(f"   ‚úÖ MATCH (HEAD): {url}")
                     return
            except: pass
            
        print("   ‚ùå No PDF found in top 7.")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")

if __name__ == "__main__":
    titles = [
        "The SONICOM HRTF Dataset",
        "Recent Advances in an Open Software for Numerical HRTF Calculation"
    ]
    for t in titles:
        check_paper(t)
        time.sleep(5)


==================================================
FILE: scripts/debug_ddg_search.py
==================================================

from duckduckgo_search import DDGS
import time

def search_ddg_pdf(title):
    print(f"ü¶Ü DDG Hunting for: '{title}'")
    try:
        results = DDGS().text(f"{title} filetype:pdf", max_results=5)
        if results:
            for r in results:
                print(f"   -> Found: {r['title']}")
                print(f"      URL: {r['href']}")
                if r['href'].lower().endswith('.pdf'):
                    print(f"   ‚úÖ MATCH: {r['href']}")
                    return r['href']
        else:
            print("   ‚ùå No results found.")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    time.sleep(2)
    return None

if __name__ == "__main__":
    titles = [
        "The SONICOM HRTF Dataset",
        "Recent Advances in an Open Software for Numerical HRTF Calculation",
        "Spatially Oriented Format for Acoustics 2.1"
    ]
    
    print("=== TESTING DDG SEARCH ===")
    for t in titles:
        search_ddg_pdf(t)
        print("-" * 40)


==================================================
FILE: scripts/check_models.py
==================================================
from google import genai
import os
from dotenv import load_dotenv

load_dotenv()

try:
    client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
    target_model = "gemini-2.0-flash-lite-001"
    print(f"Testing connectivity for: {target_model}...")
    
    response = client.models.generate_content(
        model=target_model, 
        contents="Say 'System Check OK' if you can hear me."
    )
    print(f"Response: {response.text}")
    print("‚úÖ Model verified successfully.")

except Exception as e:
    print(f"‚ùå Test Failed: {e}")


==================================================
FILE: scripts/debug_google_search.py
==================================================

from googlesearch import search
import time

def search_google_pdf(title):
    print(f"üîç Google Hunting for: '{title}'")
    query = f"{title} filetype:pdf"
    try:
        # Search returns a generator, fetch top 5
        results = search(query, num_results=5, advanced=True)
        found = False
        for r in results:
            print(f"   -> Found: {r.title}")
            print(f"      URL: {r.url}")
            if r.url.lower().endswith('.pdf'):
                print(f"   ‚úÖ MATCH: {r.url}")
                return r.url
        if not found:
             print("   ‚ùå No direct PDF found in top results.")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    time.sleep(5) # Strict backoff to avoid 429
    return None

if __name__ == "__main__":
    titles = [
        "The SONICOM HRTF Dataset",
        "Recent Advances in an Open Software for Numerical HRTF Calculation",
        "Spatially Oriented Format for Acoustics 2.1"
    ]
    
    print("=== TESTING GOOGLE SEARCH ===")
    for t in titles:
        search_google_pdf(t)
        print("-" * 40)


==================================================
FILE: scripts/list_models.py
==================================================
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

print("Listing models...")
for m in genai.list_models():
    if 'generateContent' in m.supported_generation_methods:
        print(m.name)


==================================================
FILE: scripts/debug_unpywall_full.py
==================================================

import pandas as pd
import requests
import json
import random
import time
from unpywall import Unpywall
from unpywall.utils import UnpywallCredentials

# User's email (required for Unpywall)
UnpywallCredentials('vv@scholar-stack.com')

# Debug List: Papers the user identified as "Missing/Paywalled" but should be OA
# 1. The SONICOM HRTF Dataset (AES E-Lib usually) -> unexpected
# 2. 3D Reproduction... (TU Berlin DepositOnce) -> unexpected
# 3. Spatial Audio for Soundscape Design (MDPI) -> unexpected
# 4. Recent Advances (AES) -> unexpected

DEBUG_CASES = [
    {"title": "SONICOM HRTF Dataset", "doi": None, "url": "http://www.aes.org/e-lib/download.cfm?ID=22128"},
    {"title": "MIMO System", "doi": "10.1109/TASLP.2023.3323087", "url": "https://ieeexplore.ieee.org/document/10334061"}, # Checking if DOI helps
    {"title": "Recent Advances", "doi": None, "url": "http://www.aes.org/e-lib/download.cfm?ID=22155"},
    {"title": "Spatial Audio (MDPI)", "doi": "10.3390/app7060627", "url": "https://www.mdpi.com/2076-3417/7/6/627/pdf?version=1497700319"}, # Should be direct
]

def analyze_case(case):
    print(f"\nüîé Analyzing: {case['title']}")
    print(f"   Input URL: {case['url']}")
    
    # 1. Check Unpywall if DOI exists
    if case.get('doi'):
        print(f"   [Unpywall] Checking DOI: {case['doi']}")
        try:
            res = Unpywall.doi([case['doi']])
            if res is not None and not res.empty:
                # Logic from 3_download_library.py
                best_url = res.iloc[0].get('best_oa_location.url_for_pdf')
                fallback_url = res.iloc[0].get('best_oa_location.url')
                first_url = res.iloc[0].get('first_oa_location.url')
                
                print(f"   [Unpywall] Best PDF: {best_url}")
                print(f"   [Unpywall] Fallback: {fallback_url}")
                print(f"   [Unpywall] First OA: {first_url}")
                
            else:
                print("   [Unpywall] No Data Found.")
        except Exception as e:
            print(f"   [Unpywall] Error: {e}")

    # 2. Check URL access with ROTATING HEADERS
    print(f"   [Direct HTTP] Testing connection to: {case['url']}")
    user_agents = [
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    ]
    
    try:
        ua = random.choice(user_agents)
        headers = {
            'User-Agent': ua,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Referer': 'https://scholar.google.com/'
        }
        if 'mdpi.com' in case['url']:
            headers['Upgrade-Insecure-Requests'] = '1'

        r = requests.head(case['url'], headers=headers, timeout=10, allow_redirects=True)
        print(f"   [Direct HTTP] Status: {r.status_code}")
        if r.status_code == 403:
             print("   [Direct HTTP] 403 Forbidden persist? trying GET instead of HEAD...")
             r = requests.get(case['url'], headers=headers, stream=True, timeout=10)
             print(f"   [Direct HTTP GET] Status: {r.status_code}")
             
    except Exception as e:
        print(f"   [Direct HTTP] Connect Fail: {e}")

if __name__ == "__main__":
    print("=== DEBUGGING MISSING PAPERS ===")
    for case in DEBUG_CASES:
        analyze_case(case)


==================================================
FILE: scripts/debug_secondary_search.py
==================================================

import requests
from unpywall import Unpywall
from unpywall.utils import UnpywallCredentials
UnpywallCredentials('vv@scholar-stack.com')

def get_pdf_from_unpywall(doi):
    # Minimal version for debug script
    try:
        res = Unpywall.doi([doi])
        if res is not None and not res.empty:
             best_url = res.iloc[0].get('best_oa_location.url_for_pdf')
             if best_url: return best_url
    except: pass
    return None

def attempt_secondary_search(title):
    print(f"üîé Searching Semantic Scholar for: '{title}'")
    try:
        params = {'query': title, 'limit': 1, 'fields': 'title,openAccessPdf,url,externalIds'}
        r = requests.get('https://api.semanticscholar.org/graph/v1/paper/search', params=params, timeout=10)
        
        if r.status_code == 200:
            data = r.json()
            if data.get('data'):
                paper = data['data'][0]
                print(f"   Note: Found Match: '{paper['title']}'")
                
                # A. Check URL
                pdf_info = paper.get('openAccessPdf')
                if pdf_info and pdf_info.get('url'):
                    print(f"   ‚úÖ [Strategy A] S2 URL: {pdf_info['url']}")
                
                # B. Check ArXiv
                ids = paper.get('externalIds', {})
                if ids.get('ArXiv'):
                    print(f"   ‚úÖ [Strategy B] ArXiv Found: https://arxiv.org/pdf/{ids.get('ArXiv')}.pdf")
                    
                # C. Check DOI -> Unpywall
                if ids.get('DOI'):
                     print(f"   Note: Found DOI {ids.get('DOI')}. Checking Unpywall...")
                     unp_url = get_pdf_from_unpywall(ids.get('DOI'))
                     if unp_url:
                         print(f"   ‚úÖ [Strategy C] Unpywall via New DOI: {unp_url}")
                     else:
                         print("   ‚ùå [Strategy C] Unpywall failed.")
                
            else:
                print("   ‚ùå No paper found.")
        else:
             print(f"   ‚ùå API Error: {r.status_code}")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    return None

if __name__ == "__main__":
    # Test cases from user's "Missing" list
    titles = [
        "The SONICOM HRTF Dataset",
        "Recent Advances in an Open Software for Numerical HRTF Calculation",
        "Spatially Oriented Format for Acoustics 2.1",
        "Comparison of head-related impulse response measurement approaches"
    ]
    
    print("=== TESTING SECONDARY SEARCH ===")
    for t in titles:
        attempt_secondary_search(t)
        print("-" * 40)


==================================================
FILE: scripts/verify_density.py
==================================================

import pandas as pd

import os
try:
    # Look in data/
    csv_path = os.path.join(os.path.dirname(__file__), "../data/research_catalog_categorized.csv")
    df = pd.read_csv(csv_path)
    if 'Search_Vertical' not in df.columns:
        print("Error: Search_Vertical column missing.")
    else:
        # Group
        groups = df.groupby(['Search_Vertical', 'Category']).size()
        
        print("\n--- Density Check ---")
        fail = False
        for (vertical, category), count in groups.items():
            print(f"[{vertical}] -> [{category}]: {count}")
            if category not in ["Miscellaneous", "DISCARD", "Unsorted"] and count < 2:
                print(f"‚ùå VIOLATION: {category} has {count} paper(s)!")
                fail = True
        
        if not fail:
            print("\n‚úÖ All Folders satisfy density rule (>= 2).")
        else:
            print("\n‚ùå Minimum Density Rule Failed.")

except Exception as e:
    print(f"Error: {e}")


==================================================
FILE: scripts/reproduce_fallback.py
==================================================

import requests
from bs4 import BeautifulSoup
import random

def test_download(url, name):
    print(f"Testing {name}: {url}")
    user_agents = [
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    ]
    headers = {'User-Agent': random.choice(user_agents)}
    
    try:
        # 1. Direct GET
        r = requests.get(url, headers=headers, timeout=10, stream=True)
        print(f"   Status: {r.status_code}")
        print(f"   Content-Type: {r.headers.get('Content-Type')}")
        
        # 2. If it's HTML, try to scrape meta tag
        if 'text/html' in r.headers.get('Content-Type', '').lower():
            soup = BeautifulSoup(r.content, 'html.parser')
            meta_pdf = soup.find('meta', attrs={'name': 'citation_pdf_url'})
            if meta_pdf:
                res = meta_pdf['content']
                if 'localhost' in res:
                    res = res.replace('http://localhost:4000', 'https://depositonce.tu-berlin.de')
                    print(f"   [FIXED] Found Meta PDF: {res}")
                else:
                    print(f"   Found Meta PDF: {res}")
            else:
                print("   No Meta PDF tag found.")
                
            # specific scrapers
            if 'depositonce' in url:
                # Look for file download link in DSpace/DepositOnce
                # Common pattern: <a href="/bitstream/...">
                for a in soup.find_all('a', href=True):
                    if 'bitstream' in a['href'] and a['href'].endswith('.pdf'):
                        print(f"   Found Bitstream PDF: {a['href']}")
                        
    except Exception as e:
        print(f"   Error: {e}")
    print("-" * 30)

if __name__ == "__main__":
    test_cases = [
        ("http://depositonce.tu-berlin.de/handle/11303/183", "TU-Berlin"),
        ("https://www.ioa.org.uk/system/files/proceedings/j_hollebon_e_c_hamdan_dr_f_m_fazi_a_comparison_of_the_performance_of_hrtf_models.pdf", "IOA PDF"),
        ("https://research.chalmers.se/en/publication/512402", "Chalmers"),
        ("https://www.mdpi.com/2076-3417/7/6/627/pdf?version=1497700319", "MDPI")
    ]
    
    for url, name in test_cases:
        test_download(url, name)


==================================================
FILE: scripts/debug_download_failures.py
==================================================

import pandas as pd
import requests
import os
from unpywall import Unpywall
from unpywall.utils import UnpywallCredentials
import random
import time
from bs4 import BeautifulSoup

# Set explicit email for Unpywall
UnpywallCredentials('vv@scholar-stack.com')

# Debug target: A few DOIs that failed in the user's run
FAILURES = [
    {"doi": "10.1016/j.heares.2025.109390", "url": "https://doi.org/10.1016/j.heares.2025.109390"}, # Elsevier
    {"doi": "10.1155/2007/70540", "url": "https://doi.org/10.1155/2007/70540"}, # SpringerOpen
    {"doi": "10.3389/frvir.2021.678875", "url": "https://doi.org/10.3389/frvir.2021.678875"} # Frontiers (usually OA)
]

def get_pdf_from_unpywall(doi):
    print(f"   [Unpywall] Querying for {doi}...")
    try:
        # 1. Unpywall requires a LIST of DOIs
        res = Unpywall.doi([doi])
        if res is not None and not res.empty:
             best_url = res.iloc[0].get('best_oa_location.url_for_pdf')
             if best_url: 
                 print(f"   [Unpywall] Found PDF: {best_url}")
                 return best_url
    except Exception as e:
        print(f"   [Unpywall] Error: {e}")
    return None

def try_scrape_meta_tag(url):
    """Attempt to find <meta name='citation_pdf_url'> in the landing page."""
    print(f"   [Scrape] Checking landing page for meta tags: {url}")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            soup = BeautifulSoup(r.content, 'html.parser')
            # Standard Google Scholar tag
            meta_pdf = soup.find('meta', attrs={'name': 'citation_pdf_url'})
            if meta_pdf and meta_pdf.get('content'):
                print(f"   [Scrape] Found <meta citation_pdf_url>: {meta_pdf['content']}")
                return meta_pdf['content']
                
            # DC.identifier (sometimes points to PDF)
            # meta_dc = soup.find('meta', attrs={'name': 'DC.identifier', 'scheme': 'pdf'})
    except Exception as e:
        print(f"   [Scrape] Error: {e}")
    return None

def test_download():
    print("=== DEBUGGING DOWNLOAD LOGIC ===")
    
    for item in FAILURES:
        print(f"\nProcessing: {item['doi']}")
        
        # 1. Unpywall
        pdf_url = get_pdf_from_unpywall(item['doi'])
        
        # 2. Meta Tag Scraping (New Proposed Fix)
        if not pdf_url:
            pdf_url = try_scrape_meta_tag(item['url'])
            
        if pdf_url:
            print(f"   ‚úÖ FINAL DECISION: Download from {pdf_url}")
            # Verify it's actually accessible
            try:
                r = requests.head(pdf_url, timeout=5, allow_redirects=True)
                print(f"   [Verification] Status: {r.status_code}, Type: {r.headers.get('Content-Type')}")
            except:
                print("   [Verification] Failed to connect.")
        else:
            print("   ‚ùå FAILED to find any PDF link.")

if __name__ == "__main__":
    test_download()


==================================================
FILE: PRPs/# 13 Add Timeline.md
==================================================

### **PRP Publication Timeline Visualization**


**Context:**
We want to give users immediate visual feedback on the search results in the Streamlit app *before* they download. We will add a "Publication Timeline" histogram.

**The Task:**

1. **Data Extraction:** Create a helper function that iterates through the list of found papers and extracts the `year` field. Handle `None` or missing years by categorizing them as "Unknown".
2. **Visualization:** Use Streamlit's native `st.bar_chart` or `st.altair_chart` to render a histogram.
* **X-Axis:** Year (sorted chronologically).
* **Y-Axis:** Count of papers.
* **Tooltip:** If using Altair, show the exact count on hover.


3. **UI Placement:** Insert this chart in the main `app.py` workflow immediately after the search completes but *before* the "Download ZIP" button appears.
* Add a subheader: `## Research Timeline`.



**Output:**
Return the Python code to generate the year-distribution dictionary and the Streamlit code to render the chart.

---


==================================================
FILE: PRPs/# Fix 4.md
==================================================

### ** Fix 4 **

**Please rewrite `2_cluster_taxonomy.py` with this exact logic:**
1. **Input:**
* Use `argparse` to accept a required argument: `--topic` (e.g., "Spatial Audio").
* Load `research_catalog.csv`.


2. **The "Bouncer" (Gemini):**
* Update the prompt: *'The user is researching "{topic}". Review these abstracts. If a paper is NOT primarily about {topic}, assign the category "DISCARD". For valid papers, group them into 4-6 technical categories.'*


3. **The Filter:**
* Drop rows where Category is 'DISCARD'.
* Print 'Rejected X off-topic papers.'


4. **The Structure:**
* **Root:** Set the base directory to `./Library/{topic_sanitized}/`.
* Create sub-folders there.


5. **The Output:**
* Add a column `Topic` to the DataFrame and set it to the provided argument.
* Save to `research_catalog_categorized.csv`."
 



==================================================
FILE: PRPs/# 12 add filenaming support.md
==================================================


### **PRP: Filename Customization (The Renamer)**

**Context:**
Users currently receive PDFs with default filenames that are often hard to read. We need to allow users to customize the naming convention of downloaded PDFs via the Streamlit interface.

**The Task:**

1. **Update UI:** Add a selectbox in the Streamlit Sidebar under "Settings" labeled "PDF Filename Format".
* **Options:**
* `Title` (Default)
* `Author - Year - Title`
* `Year - Journal - Title`




2. **Update Logic:** Refactor the `save_pdf()` or `download_paper()` function to respect this setting.
3. **Sanitization (Critical):**
* You must implement a strict string sanitizer. Paper titles often contain illegal characters for file systems (`:`, `/`, `\`, `?`, `*`, `"`, `<`, `>`, `|`).
* Replace these characters with an underscore `_` or a dash `-`.
* Truncate filenames to 255 characters max to prevent OS errors.


4. **Metadata Sync:** Ensure that whatever filename is chosen is updated in the `index.json` and the `Catalog_Summary.md` so the links still work.

**Output:**
Return the updated Streamlit UI code snippet and the refactored PDF saving logic containing the sanitization function.


==================================================
FILE: PRPs/# adding Google Drive.md
==================================================


> **Context:**
>  I want to add a feature to save research papers directly to the user's Google Drive so they can be easily imported into NotebookLM later.
> **Task:**
> Create a new "Save to Drive" feature in the UI and implement the necessary backend logic using the Google Drive API.
> **1. UI Requirements:**
> * **Button Location:** Place a new button immediately to the right of the existing "Download Full Library (ZIP)" button.
> * **Button Style:** Use a secondary style (outline or distinct color) to differentiate it from the direct download. Use a "Google Drive" icon or a "Cloud Upload" icon.
> * **Label:** The button text should read "Save to Drive".
> * **Feedback:** When clicked, show a "Saving..." loading state on the button. On success, show a toast notification: "Saved to 'Research Assistant' folder in Drive."
> 
> 
> **2. Authentication & Scopes (Critical):**
> * Update the existing Firebase Google Auth provider configuration.
> * We need to request an additional scope: `https://www.googleapis.com/auth/drive.file`.
> * *Note:* This scope is "non-sensitive" relative to full Drive access because it only allows the app to access/edit files created *by the app itself*, which is perfect for this use case.
> 
> 
> **3. Logic Flow:**
> * **Check Auth:** When the button is clicked, check if the current user has granted the Drive scope. If not, trigger a re-authentication flow to ask for permission.
> * **Folder Management:** Check if a folder named `_Research_Assistant_Imports` exists in the root of their Drive. If not, create it.
> * **Upload Process:**
> * Take the list of papers (PDFs) that are currently staged for the ZIP download.
> * Loop through them and upload each PDF to the `_Research_Assistant_Imports` folder.
> * Ensure the MIME type is set to `application/pdf` so NotebookLM recognizes them correctly.
> 
> 
> **4. Implementation Details:**
> * Use the Google Drive API v3.
> * Reuse the existing data fetching logic used for the ZIP creator; do not fetch the papers a second time if they are already in memory.
> 
> 



==================================================
FILE: PRPs/# 9_9_7 changing to simpler search.md
==================================================

### PRP: The "Direct Expansion" Refactor

**Role:** Senior Search Architect
**Task:** Delete the `search_via_citation_backdoor` complexity. Replace it with a **High-Fidelity Topic Expansion Search**.

#### 1. Phase 1: High-Quality Topic Expansion (LLM)

* **Goal:** Generate 15-20 specific sub-fields for the User's Topic.
* **Prompt Logic:** "The user is researching **{topic}**. Provide 20 academic synonyms, sub-disciplines, or related technical fields. (e.g., for 'Spatial Audio', include 'Binaural', 'Ambisonics', 'Wave Field Synthesis', 'HRTF', '3D Audio'). Return a clean list."

#### 2. Phase 2: The Direct "AND" Query

* **Logic:** Construct the OpenAlex query to require the **Primary Keyword** AND at least **One Topic Synonym**.
* **Query String:** `("crosstalk cancellation") AND ("Spatial Audio" OR "Binaural" OR "Ambisonics" OR "Wave Field Synthesis" ...)`
* **Why this wins:** This is the specific logic that catches the Choueiri paper (which is about "Crosstalk" in the context of "3D Audio") while killing the DSL papers (which are "Crosstalk" in the context of "Subscriber Lines").

#### 3. Phase 3: The Section-Aware PDF Gate

* **Action:** We still download the PDF and check the **First 2 Pages** for the fuzzy regex of the keyword.
* **Why:** OpenAlex abstracts are still untrustworthy. The API gets us to the right *file*, but the **PDF Auditor** confirms the *content*.

---

### Implementation Block for the Agent

Give this code to the agent. It replaces the entire complex "Backdoor" mess with your streamlined logic.

```python
    def search_via_direct_expansion(self):
        """
        Streamlined Strategy:
        1. Expand 'Topic' into ~20 high-quality sub-fields using LLM.
        2. Query: (Keyword) AND (Topic OR SubField1 OR SubField2...)
        3. Validate: PDF Front-Matter Audit.
        """
        print(f"\nüöÄ STARTING DIRECT EXPANSION SEARCH for: '{self.raw_topic}' + '{self.keywords_list[0]}'")
        
        # --- STEP 1: HIGH-FIDELITY TOPIC EXPANSION ---
        print("   üß† expanding topic scope with LLM...")
        prompt = (
            f"Generate 20 specific academic synonyms, sub-disciplines, or technical fields related to '{self.raw_topic}'. "
            f"Examples: If topic is 'Spatial Audio', include 'Binaural', 'Ambisonics', 'Wave Field Synthesis', 'HRTF'. "
            f"Return ONLY a comma-separated list."
        )
        # Assume self.llm_query handles the API call
        raw_synonyms = self.llm_query(prompt)
        topic_synonyms = [s.strip().replace('"', '') for s in raw_synonyms.split(',') if len(s.strip()) > 3]
        
        print(f"   ‚úÖ Generated {len(topic_synonyms)} Domain Anchors: {topic_synonyms[:5]}...")

        # --- STEP 2: CONSTRUCT THE SUPER-QUERY ---
        # Logic: (Keyword) AND (Topic OR Synonym1 OR Synonym2...)
        # This mathematically eliminates 'Alien Crosstalk' (DSL) because DSL papers won't match the Topic synonyms.
        
        clean_keyword = self.keywords_list[0].replace('"', '')
        
        # Build the OR block for topics
        topic_block = " OR ".join([f'"{t}"' for t in ([self.raw_topic] + topic_synonyms)])
        
        # Final Query
        final_query = f'("{clean_keyword}") AND ({topic_block})'
        
        print(f"   üîé Executing Query: {final_query[:100]}...")
        
        # --- STEP 3: EXECUTE & VALIDATE ---
        filters = "is_oa:true,type:article|conference-paper"
        if self.date_start: filters += f",publication_year:>{self.year_start-1}"
        
        # This calls the standard execution loop which now uses the ROBUST PDF AUDITOR
        self.execute_openalex_query("Direct Expansion", filters, final_query)

```



==================================================
FILE: PRPs/# 9_5 backdoor citations exapnsion.md
==================================================


# Product Requirements Prompt: Implement Citation Backward-Chaining Search

**Role:** Senior Python Engineer / Search Architect
**Task:** Refactor the provided `ResearchCrawler` script to replace the current "Hybrid RAG/Topic" search logic with a new "Citation Backward-Chaining" (Backdoor) discovery algorithm.

## Context

The current script uses a `HybridTreeSearch` (RAG) approach to map user queries to OpenAlex topics. This approach fails for niche or drifting terminology (e.g., "Crosstalk Cancellation" vs "Personal Sound Zones"). We need to replace this with a heuristic approach that finds the "Godfathers" of a field via citation analysis and uses their recent vocabulary to engineer the final search query.

## Core Requirement: The "Backdoor" Algorithm

You must delete the `search_openalex_multi_pass` method and the `HybridTreeSearch` imports. Replace them with a new workflow, `search_via_citation_backdoor`, which implements the following logic:

### Phase 1: The "Junk" Harvest (Find the Ghost)

1. **Search:** Perform a lightweight API call to OpenAlex `works` using the user's raw `topic` and `keywords`.
* *Constraint:* Do not filter for PDFs or Open Access yet. We just need metadata.
* *Params:* `per-page=50`, `select=referenced_works`.


2. **Analyze:** Iterate through these 50 results. Collect every ID found in their `referenced_works` list.
3. **Identify:** Use a `Counter` to find the single most frequently cited paper ID (The "Ghost" paper).

### Phase 2: The Pivot (Find the VIP)

1. **Fetch:** Retrieve the metadata for that "Ghost" paper ID.
2. **Extract:** Identify the primary author (The "VIP") from that paper.

### Phase 3: Terminology Expansion (Learn the Vocabulary)

1. **Query:** Search OpenAlex for works by this VIP Author ID, filtered to `publication_year > 2020` (Recent works).
2. **Extract:** Analyze the **titles** of these recent works. Extract the most frequent 2-word and 3-word phrases (N-grams) that are *not* the original seed keywords.
3. **Output:** A list of "Modern Synonyms" (e.g., discovering "BRIR" from "Crosstalk").

### Phase 4: The Final Dragnet

1. **Construct:** Create a new Boolean OR query string: `(Original Keywords) OR (New Modern Synonyms)`.
2. **Execute:** Pass this new engineered query into the existing `execute_openalex_query` method to perform the actual PDF downloading and strict filtering using the existing infrastructure.

## Technical Specifications & Changes

1. **Remove Dependencies:**
* Remove `from hybrid_search_client import HybridTreeSearch`.
* Remove any code related to `openalex_tree.json` or `chroma_db`.


2. **New Method Implementation:**
* Implement `search_via_citation_backdoor(self)` inside the `ResearchCrawler` class.
* Ensure strict error handling: If Phase 1 yields no results (no citations found), fall back gracefully to a standard text search using the original keywords.


3. **Refine `run` Loop:**
* Update the `run()` method to call `self.search_via_citation_backdoor()` instead of `self.search_openalex_multi_pass()`.


4. **Preserve Existing filters:**
* Do **not** modify `_check_accessibility`, `_pre_filter`, or `_process_batch`. We still need to strictly validate the final PDFs.
* Ensure the "Final Dragnet" (Phase 4) still respects the user's `date_start`, `date_end`, and `is_oa:true` requirements.



## Expected Behavior

If I search for "Crosstalk Cancellation":

1. The script finds 50 mediocre papers.
2. It notices they all cite Edgar Choueiri's 2008 paper.
3. It pivots to Choueiri's profile.
4. It sees his 2024 paper titled "...Binaural Room Impulse Response...".
5. It adds "Binaural Room Impulse Response" to the search.
6. It downloads the Choueiri 2024 paper (which the previous script missed).

## Input Code

[Insert the code I provided above here]

==================================================
FILE: PRPs/# Fix 5.md
==================================================

### **The Code Update**

I need to update Phase 3 and 4 to support a persistent library where multiple topics can coexist.
**Please rewrite `2_cluster_taxonomy.py`:**
1. **Arguments:** Keep the `--topic` argument.
2. **Paths:** Set the root for this batch to `./Library/{args.topic}/`. Use `os.makedirs(..., exist_ok=True)` to allow adding to existing topics.
3. **The 'Golden Path':** Add a column `Directory_Path` to the CSV containing the full relative path for each paper's category.
4. **The Bouncer:** Keep the 'DISCARD' logic to filter irrelevant papers.


**Please rewrite `3_download_library.py`:**
1. **Targeted Logic:** Read `Directory_Path` from the CSV to know exactly where to save each file.
2. **Surgical Cleanup:**
* After downloading, iterate **only** through the unique paths listed in the `Directory_Path` column of the current CSV.
* If one of *those* folders has no PDF files, delete it.
* **Crucial:** Do NOT iterate through the entire `./Library` root. Do not touch other topic folders.


3. **Focused Export:**
* Create a zip file named `Library_{Topic}.zip` (e.g., `Library_Spatial_Audio.zip`) that contains only the folder for the current topic.


4. **Catalog:**
* Generate a markdown catalog named `Catalog_{Topic}.md` inside the topic folder.
* Use `YYYY/MM/DD` date format.






==================================================
FILE: PRPs/# 9_9_9_3.md
==================================================

# PRP: Polish Taxonomy Logic (Stopword Cleanup)

**Context:**
We have successfully refactored `src/2_cluster_taxonomy.py` to use structured JSON output. However, test logs indicate that category names are occasionally being truncated awkwardly (e.g., ending in "and") due to a strict word-count slice.

**Objective:**
Refine the category name cleaning logic to handle trailing stopwords gracefully while maintaining brevity.

**Target File:** `src/2_cluster_taxonomy.py`

## üõ†Ô∏è Engineering Requirements

### 1. New Dependency

* Ensure `re` (regex) is imported at the top of the file (it likely already is, but verify).

### 2. Update Cleaning Logic

In the `cluster_and_categorize` function, inside the loop where `local_map` is populated:

**Locate this current logic:**

```python
# Enforce the "Max 3 Words" rule in code just in case
cat_clean = " ".join(item['category_name'].split()[:4])

```

**Replace it with this Robust Logic:**

```python
# 1. Take the full name from the LLM (trust the schema constraint first)
cat_raw = item['category_name'].strip()

# 2. Safety Truncate: Only chop if it's excessively long (> 6 words), not 4.
# This prevents cutting off meaningful modifiers like "Measurements".
words = cat_raw.split()
if len(words) > 6:
    cat_raw = " ".join(words[:6])

# 3. Stopword Cleanup: Remove trailing connectors that might have been exposed by truncation
# Regex targets: and, or, of, the, for, in, on, with, to
cat_clean = re.sub(r'\s+(and|or|of|the|for|in|on|with|to)$', '', cat_raw, flags=re.IGNORECASE).strip()

local_map[item['id']] = cat_clean

```

### 3. Verification

* Ensure the variable `cat_clean` is the one assigned to `local_map[item['id']]`.
* Ensure no syntax errors are introduced by the regex string.

## ‚úÖ Definition of Done

1. **Logic Update:** The crude `[:4]` slice is replaced by a smarter length check (`>6`).
2. **Stopword Safety:** A category like "Crosstalk Cancellation Implementation and" is automatically cleaned to "Crosstalk Cancellation Implementation".
3. **Stability:** The script runs without regex compilation errors.

==================================================
FILE: PRPs/# Full Security Setup.md
==================================================

### The "Full Security" Setup (`.env`)

 I need to set up the `.env` file correctly for both the search tools and the AI agents.
 1. **Create `.gitignore`:** Ensure `.env` is listed here so I never accidentally publish my keys.
 2. **Create `.env`:** Create this file in the root with the following variables:
 ```bash
 # The Brain (Required for Phase 3)
 GOOGLE_API_KEY=your_google_api_key_here
 
 ``` 

 ```
 # The Search Tools (Required for Phase 2)
 UNPAYWALL_EMAIL=your_email@gmail.com
 
 ```
 
 

 ```
 # Optional Keys (Leave empty if not using yet)
 SEMANTIC_SCHOLAR_KEY=
 CORE_API_KEY=
 ```
 
 ```
 
 
 3. **Update the Script:** Update `1_search_omni.py` to load these variables using `dotenv`. It should use `UNPAYWALL_EMAIL` for the 'Unlocker' step.
 4. **Instructions:** Tell me exactly where to paste my Google API Key once the file is created.
 
 




==================================================
FILE: PRPs/# Phase 2.md
==================================================

### Phase 2:

Write the modular search script named `1_search_omni.py`.
**1. Data Structure (Crucial):**
The script must initialize a pandas DataFrame with **exactly** these columns. Ensure every row adheres to this schema:

* `Title`: (String) Cleaned title.
* `Original_Filename`: (String) Attempt to parse this from the URL (e.g., '1706.03762.pdf'). If not obvious in the URL, set to 'Pending_Header_Check'. **Do NOT invent a filename.**
* `Publication_Date`: (String) Format strictly as **YYYY/MM/DD**. (If source only gives year, default to YYYY/01/01).
* `Category`: (String) Initialize as 'Unsorted'.
* `Description`: (String) Abstract or Summary.
* `Is_Paywalled`: (Boolean) True if no direct PDF link found; False if direct link exists.
* `Is_Downloaded`: (Boolean) Initialize as **False** for all.
* `Source_URL`: (String) Direct PDF link or landing page.
* `DOI`: (String) Digital Object Identifier.

**2. Architecture:**
Create a class `ResearchCrawler` with a method for each source. It should accept `--query`, `--year_start`, and `--count`.
**3. Source Modules (Implement logic for ALL of these):**

* **1. Google Scholar:** Use `scholarly`. **Crucial:** Add a 10-second sleep between requests to avoid IP bans. If it fails, log error and skip.
* **2. Semantic Scholar:** Use the API. Search broadly.
* **3. BASE (Bielefeld):** Use `sickle` to query the BASE OAI-PMH endpoint.
* **4. CORE:** Use the CORE API (requires generic API key logic) or search their open dataset.
* **5. Preprint Servers:**
* **arXiv:** Query specifically in `eess.AS`, `cs.SD`, and `physics.gen-ph`.
* **OSF Preprints:** Use `requests` to hit the OSF API v2 (filter by 'preprint').
* **Zenodo:** Search the Zenodo API (keywords + year).
* **6. Open Access Journals:**
* **DOAJ:** Query the DOAJ public API.
* **PLOS:** Query the PLOS Search API.
* **7. Conference Archives (Scrapers):**
* **DAFx:** Write a `BeautifulSoup` scraper to parse the DAFx archive page for titles matching the query.
* **ISMIR:** Scrape the ISMIR proceedings list.
* **8. The "Unlocker" (For AES/IEEE/Paywalled):**
* For any result found above that lacks a direct PDF link, take its DOI.
* Run the DOI through `pyunpaywall` AND `Open Access Button` API.
* If a free version is found, update `Source_URL` and set `Is_Paywalled` to False.

**4. Output:**

* Combine all results into one Pandas DataFrame.
* **Deduplicate:** Aggressively remove duplicates based on normalized Title/DOI.
* Save to `research_catalog.csv`.
* Print a summary: 'Found [X] papers total: [A] from ArXiv, [B] from Scholar, [C] from BASE...'



==================================================
FILE: PRPs/# Adding UI Strike 3.md
==================================================

### **Strike 3: The Interface (Prompt)**


> "Strike 2 is done. Now, let's build **Strike 3: The User Interface**.
> **Create a file named `app.py` using the `streamlit` library.**
> **Goal:** A browser-based UI that collects inputs and triggers the `4_pipeline_manager.py`.
> **UI Layout & Logic:**
> 1. **Title:** 'Universal Research Librarian'.
> 2. **Sidebar Inputs:**
> * **Topic:** Text Input (Required).
> * **Keywords:** Text Input (Optional).
> * **Author:** Text Input (Optional).
> * **Date Range:** Date Input (Two dates, allow 'None').
> * **Publication:** Text Input (Optional).
> * **Sites:** Multiselect (Options: ArXiv, Scholar, CORE, DOAJ). Default to All.
> * **Paper Count:** Number Input (Default 10, Min 1, Max 150).
> 
> 
> 3. **Action:**
> * Add a big 'Start Research Mission' button.
> * When clicked, use `st.spinner` to show 'Research Agent is working...'.
> * Call `pipeline_manager.run_full_pipeline(...)`.
> 
> 
> 4. **Output:**
> * Display a live log of the process if possible (or just success/fail messages).
> * **Success:** Show a big `st.download_button` labeled 'Download Library' that links to the resulting Zip file.
> * **Preview:** Display the contents of the generated Markdown catalog (`Catalog_{Topic}.md`) directly in the browser so the user can read the summary before downloading."
> 
> 
> 
> 




==================================================
FILE: PRPs/# 14 chron job and email.md
==================================================

### **Feature Implementation: Local Alert System (Real Email Test)**

**Context:**
We are building the "Scholar-Alert" scheduler. We need a fully functional **local test rig** that checks for new papers and sends **REAL notification emails** to the user using Gmail SMTP.

**1. Database Schema (SQLite)**
Create/Update `alerts.db` using `sqlite3`. Ensure the `subscriptions` table exists:

* `id` (Primary Key)
* `user_email` (String) - *Target email address*
* `search_query` (String)
* `search_source` (String)
* `last_run` (Datetime)
* `active` (Boolean)

**2. Streamlit UI Updates (`app.py`)**
Add a "Manage Alerts" section to the Sidebar.

* **Input:** "Save current search as Alert."
* **Logic:** Insert the current search and the user's email into `alerts.db`.
* **Visual:** Show a list of active alerts.

**3. The Scheduler Script (`scheduler_test.py`)**
Create a script that performs the check and sends the email.

**A. The Search Logic**

* Connect to `alerts.db`.
* For every active subscription, run `search_papers()`.
* **Filter:** Keep only papers where `publication_date` > `last_run`.

**B. The Email Logic (Real SMTP)**

* **Library:** Use `smtplib` and `email.message`.
* **Credentials:** distinct variables `SENDER_EMAIL` and `SENDER_APP_PASSWORD` (load these from a `.env` file or constants at the top).
* **Function:** `send_notification_email(to_email, query, papers_list)`
* **Server:** `smtp.gmail.com`
* **Port:** `587` (TLS)
* **Logic:**
1. Login to SMTP server.
2. Construct a proper HTML email.
3. Subject: "New Research Found: [Query Name]"
4. Body: A clean list of the new papers found (Title + Link).
5. Send the email.




* **Error Handling:** Wrap the send logic in a `try/except` block. If the password is wrong or connection fails, print the specific error to the console so we can debug.

**4. The "Time Travel" Helper**
Include a function `reset_dates_for_testing()` in the script that forces all `last_run` dates in the database to **30 days ago**. This allows us to run the script immediately and trigger a "New Paper" condition to verify the email actually sends.

---

### **Crucial Setup Step for You (Before running the code)**

To make this work, you cannot use your normal Gmail login password (Google blocks scripts from doing that). You need an **App Password**:

1. Go to your **Google Account Settings** > **Security**.
2. Enable **2-Step Verification** (if not already on).
3. Search for **"App Passwords"** in the search bar.
4. Create a new one named "ScholarStack Test".
5. Google will give you a 16-character code (e.g., `abcd efgh ijkl mnop`). **This is the password** you will put in your script (or `.env` file).

Run the prompt, get the code, insert that App Password, and the email will arrive in your inbox for real.

==================================================
FILE: PRPs/# 9_9_4.md
==================================================

### PRP: The "Precision Dredge" Refactor

**Role:** Senior AI/Search Engineer

**Task:** Refactor the synonym generation and PDF auditing logic to eliminate semantic drift and PDF parsing errors.

#### 1. Context-Locked Vocabulary (Level 2 Fix)

* **Prompt Update:** "Extract 15 technical synonyms from these titles. RULE: Every synonym MUST be relevant to [Spatial Audio]. If a title is about 'Seawater' or 'Anodes', ignore it. PHRASES MUST BE 3-4 WORDS LONG (e.g., 'Multi-channel inverse filtering' instead of 'Inverse methods')."

#### 2. The "Dragnet" Constraint

* **Logic:** Re-introduce a "Soft Anchor." The final search should be: `(Original Keyword OR Technical Synonyms) AND (Topic OR Topic Synonyms)`.
* *Why:* Since our synonyms are currently too weak ("Active Control"), we need the topic anchor to stop the "Zinc Anode" papers from entering the pool in the first place.

#### 3. Robust PDF Text Extraction

* **Requirement:** Change the PyMuPDF extraction call to:
`page.get_text("text", flags=fitz.TEXT_PRESERVE_WHITESPACE | fitz.TEXT_DEHYPHENATE | fitz.TEXT_MEDIABOX_CLIP)`
* **Stability:** Wrap the extraction in a `try/except` that catches `RuntimeError` specifically for MuPDF syntax errors, allowing the script to skip the graphics and just read the text layer.



==================================================
FILE: PRPs/fast_mode_definition.md
==================================================
# Fast vs. Deep Mode: Implementation Proposal

## 1. Metrics Comparison (1,000 Papers)

| Feature | **Fast Mode** (The Skim) | **Deep Mode** (The Scholar) |
| :--- | :--- | :--- |
| **Est. Duration** | **~15 Minutes** | **~90 - 120 Minutes** |
| **Success Rate** | ~60-70% (Direct Only) | ~90-95% (Deep Web Hunt) |
| **Organization** | Flat Folder (Unsorted) | AI Categorized Folders |
| **Storage (Temp)** | Low | High |

---

## 2. Process Changes

### A. Phase 1: Search (No Change)
Both modes still fetch metadata from OpenAlex/ArXiv. (~5 mins)

### B. Phase 2: AI Clustering
*   **Deep**: Uses LLM provided taxonomy to sort papers into semantic folders. (~15 mins)
*   **Fast**: **CUT**. All papers go into a single "Unsorted" folder (or Year/Journal structure from metadata). Saves 15 mins.

### C. Phase 3: Downloading
*   **Deep**: Tries Direct -> Unpaywall -> Semantic Scholar -> DuckDuckGo -> Google -> Landing Page Scraping.
*   **Fast**: **CUT** all "Search" steps.
    *   Only attempts:
        1.  `Source URL` (Direct link from API)
        2.  `Unpaywall` (DOI lookup)
    *   If these fail, the paper is skipped immediately.

---

## 3. UI Implementation
Add a Radio Button to the Sidebar:

**Research Intensity:**
*   ( ) **‚ö° Fast (Direct Downloads Only)**
    *   *Best for: Quick checks, gathering easy PDFs, saving time.*
*   (‚Ä¢) **üß† Deep (AI Sort + Web Scrape)**
    *   *Best for: Comprehensive libraries, finding obscure papers, organized research.*

---

## 4. Why 15 Minutes?
*   **1000 Papers**:
    *   ~600 will have direct links. @ 2s/paper (4 threads) = **5 mins**.
    *   ~400 will fail instantly. @ 0.1s/paper = **<1 min**.
    *   Search/Overhead = **5 mins**.
    *   **Total**: ~11-15 Minutes.

## Decision
Does this meet your requirements? If yes, I will proceed to implement the UI toggle and backend logic.


==================================================
FILE: PRPs/# 9_6 unit tests.md
==================================================

### `test_crawler_logic.py`

```python
import unittest
from unittest.mock import MagicMock, patch
import json
import sys
import os

# Assuming your main script is named 'research_crawler.py'
# If not, the agent should adjust this import
try:
    from research_crawler import ResearchCrawler
except ImportError:
    # Logic to handle if the file isn't found immediately (for the agent's self-correction)
    print("‚ö†Ô∏è Warning: 'research_crawler.py' not found. Ensure it is in the same directory.")
    sys.exit(1)

class TestCitationBackdoor(unittest.TestCase):
    
    def setUp(self):
        """Setup a crawler instance with dummy data for each test."""
        self.crawler = ResearchCrawler(
            topic="Spatial Audio",
            keywords="crosstalk cancellation",
            author=None, publication=None, 
            date_start="2020-01-01", date_end="2024-01-01",
            count=10, sites=None
        )
        
        # Define fake IDs for the mocking logic
        self.GHOST_ID = "W88888888"  # The seminal paper
        self.VIP_ID = "A99999999"    # The expert author (e.g., Choueiri)
        self.VIP_NAME = "Dr. Audio Expert"

    @patch('research_crawler.requests.Session')
    def test_phase_1_identify_ghost_paper(self, mock_session_cls):
        """Test if the crawler correctly identifies the most cited 'Ghost' paper from a pile of junk."""
        print("\nüß™ TEST: Phase 1 - Identify Ghost Paper")
        
        # 1. Mock the Session and .get() method
        mock_session = mock_session_cls.return_value
        self.crawler.session = mock_session
        
        # 2. Mock Response: 5 "Junk" papers found via keyword search
        # 3 of them cite our GHOST_ID (W88888888). 2 cite random stuff.
        mock_search_response = {
            "results": [
                {"id": "W1", "referenced_works": [self.GHOST_ID, "W_Random_1"]},
                {"id": "W2", "referenced_works": [self.GHOST_ID]},
                {"id": "W3", "referenced_works": ["W_Random_2"]},
                {"id": "W4", "referenced_works": [self.GHOST_ID, "W_Random_3"]},
                {"id": "W5", "referenced_works": ["W_Random_1"]}
            ]
        }
        
        # Configure the mock to return this data
        mock_response_obj = MagicMock()
        mock_response_obj.status_code = 200
        mock_response_obj.json.return_value = mock_search_response
        mock_session.get.return_value = mock_response_obj

        # 3. Run the logic (simulated)
        # We act as the internal logic of the 'search_via_citation_backdoor' method here
        # to verify the counting mechanism specifically.
        
        from collections import Counter
        citation_counter = Counter()
        for work in mock_search_response['results']:
            for ref in work.get('referenced_works', []):
                citation_counter[ref] += 1
        
        top_ghost, count = citation_counter.most_common(1)[0]
        
        # 4. Assertions
        self.assertEqual(top_ghost, self.GHOST_ID, "Failed to identify the correct Ghost ID.")
        self.assertEqual(count, 3, "Incorrect citation count for the Ghost paper.")
        print("‚úÖ Phase 1 Passed: Identified Ghost ID based on citation frequency.")

    @patch('research_crawler.requests.Session')
    def test_phase_3_learn_new_terms(self, mock_session_cls):
        """Test if the crawler correctly extracts N-grams (synonyms) from the VIP's recent titles."""
        print("\nüß™ TEST: Phase 3 - Learn New Terms (N-Gram Extraction)")
        
        mock_session = mock_session_cls.return_value
        self.crawler.session = mock_session
        
        # 1. Mock Response: The VIP's recent papers (2020-2024)
        # Note: They use "Binaural Room Impulse Response" instead of "Crosstalk"
        mock_vip_works = {
            "results": [
                {"title": "High-fidelity Binaural Room Impulse Response dataset"},
                {"title": "Measuring the Binaural Room Impulse Response"},
                {"title": "Personal Sound Zones using beamforming"},
                {"title": "Optimization of Personal Sound Zones"}
            ]
        }
        
        mock_response_obj = MagicMock()
        mock_response_obj.status_code = 200
        mock_response_obj.json.return_value = mock_vip_works
        mock_session.get.return_value = mock_response_obj
        
        # 2. Run N-Gram Logic (Simulated implementation of the crawler's logic)
        import re
        from collections import Counter
        
        phrase_counter = Counter()
        seed_keyword = "crosstalk"
        
        for work in mock_vip_works['results']:
            title = work['title'].lower()
            words = re.findall(r'\w+', title)
            # Bigrams and Trigrams
            for n in [2, 3]:
                for i in range(len(words) - n + 1):
                    phrase = " ".join(words[i:i+n])
                    if seed_keyword not in phrase:
                        phrase_counter[phrase] += 1
        
        # Get top terms
        learned_terms = [p for p, c in phrase_counter.most_common(5)]
        
        # 3. Assertions
        print(f"   Debug: Learned terms -> {learned_terms}")
        self.assertIn("binaural room impulse", learned_terms)
        self.assertIn("personal sound zones", learned_terms)
        print("‚úÖ Phase 3 Passed: Discovered 'Binaural Room Impulse' and 'Personal Sound Zones'.")

    def test_live_integration_sanity_check(self):
        """
        ‚ö†Ô∏è LIVE TEST: Hits the real OpenAlex API.
        This verifies that the 'Crosstalk -> Choueiri' citation path actually exists in reality.
        """
        # Skip if explicitly disabled (e.g., CI/CD), but let Agent run it by default
        if os.getenv("SKIP_LIVE_TESTS"):
            print("\n‚ö†Ô∏è Skipping Live Test (SKIP_LIVE_TESTS is set)")
            return

        print("\nüåç LIVE TEST: Hitting OpenAlex API to verify 'Crosstalk' Citation Chain...")
        
        # 1. Search for "crosstalk cancellation" (small batch)
        url = "https://api.openalex.org/works"
        params = {
            "filter": "title_and_abstract.search:crosstalk cancellation",
            "per-page": 20,
            "select": "referenced_works"
        }
        try:
            resp = self.crawler.session.get(url, params=params, timeout=10)
            if resp.status_code != 200:
                print("‚ùå API Error: Could not reach OpenAlex.")
                return
            
            data = resp.json()
            
            # 2. Count citations
            from collections import Counter
            c = Counter()
            for w in data.get('results', []):
                for ref in w.get('referenced_works', []):
                    c[ref] += 1
            
            if not c:
                print("‚ö†Ô∏è No citations found in live sample. The API might have changed.")
                return

            top_ghost_id = c.most_common(1)[0][0]
            print(f"   Found Top Ghost ID: {top_ghost_id} (Cited {c.most_common(1)[0][1]} times)")

            # 3. Verify the Ghost is relevant (Fetch Author)
            ghost_url = f"https://api.openalex.org/works/{top_ghost_id}"
            ghost_resp = self.crawler.session.get(ghost_url, timeout=10)
            ghost_data = ghost_resp.json()
            
            author_names = [a['author']['display_name'] for a in ghost_data.get('authorships', [])]
            print(f"   Ghost Paper Authors: {author_names}")
            
            # THE MOMENT OF TRUTH: Does Choueiri, Nelson, or Kirkeby appear?
            known_godfathers = ["Choueiri", "Nelson", "Kirkeby", "Takeuchi", "Bauck"]
            found_godfather = any(any(god in name for god in known_godfathers) for name in author_names)
            
            if found_godfather:
                print("‚úÖ SUCCESS: The Backdoor Logic works! Found a known 'Godfather' of the field.")
            else:
                print("‚ö†Ô∏è WARNING: The top cited paper was not by a known Godfather. Logic might need tuning.")
                
        except Exception as e:
            print(f"‚ùå Live Test Failed with Exception: {e}")

if __name__ == '__main__':
    unittest.main()

```

### Instructions for the Agent

1. **Place the File:** Save the code above as `test_crawler_logic.py` in the same folder as `research_crawler.py`.
2. **Run the Tests:** Execute `python test_crawler_logic.py` in the terminal.
3. **Interpret Results:**
* **Phase 1 & 3 Tests:** These should pass instantly. If they fail, there is a logic error in your N-gram extraction or counting loops.
* **Live Test:** This is the most important output.
* If it prints `‚úÖ SUCCESS`, the "Backdoor" strategy is confirmed valid for the current state of the database.
* If it prints `‚ö†Ô∏è WARNING`, the agent should check if "Crosstalk" has drifted so far that even the citations aren't linking back to Choueiri (unlikely, but possible).





==================================================
FILE: PRPs/# 10_1 still working on taxonomy.md
==================================================

### 1. The Strategy: "Forced Adoption"

Currently, if a paper generates a unique category (e.g., "Ambisonic Decoding") but it's the *only* paper in that category, the system marks it as an "orphan" and throws it into Miscellaneous.

**The Fix:** instead of throwing orphans into the trash (Miscellaneous), we will merge them into the **closest existing valid category**.

### 2. The PRP (Product Requirements Prompt)

Copy and paste this PRP into your agent workspace to fix the `src/2_cluster_taxonomy.py` logic.

---

# PRP: Fix "Miscellaneous" Dumping (Orphan Adoption Logic)

**Context:**
The current taxonomy engine is overly aggressive with its "Density Check." If a category has fewer than 2 papers, those papers are currently reassigned to "Miscellaneous." This results in a massive "Miscellaneous" folder containing perfectly good papers that just happened to be in small groups.

**Objective:**
Modify the Orphan Logic. Instead of dumping small groups into "Miscellaneous," we should:

1. **Keep** small categories if they are highly specific (Size = 1 is okay if the name is technical).
2. **Force-Assign** orphans to the "Next Best" category if possible, rather than "Miscellaneous."

**Target File:** `src/2_cluster_taxonomy.py`

## üõ†Ô∏è Engineering Requirements

### 1. Relax Density Thresholds

In `cluster_and_categorize`, locate the section labeled **"Enforce Orphan Rules"** (or similar density check logic).

**Change the Logic to:**

* **Threshold:** Reduce the minimum density from `2` to `1`.
* **Rule:** If a category has at least 1 paper, **KEEP IT**.
* **Reasoning:** It is better to have a folder named "Ambisonic Decoding" with 1 paper than a folder named "Miscellaneous" with 20 unrelated papers.

### 2. The "General" Fallback (The Safety Net)

* **Logic:** Only use "Miscellaneous" if the LLM explicitly returned "General" or failed to output JSON.
* **Implementation:** Remove the code block that iterates through `orphans` and reassigns them to `general_cat`.

### 3. Implementation Plan (Code Replacement)

**Find this block (or similar):**

```python
# Old Logic (DELETE THIS)
counts = Counter(taxonomy_map.values())
orphans = [cat for cat, count in counts.items() if count < 2]
if orphans:
    for doc_id, cat in taxonomy_map.items():
        if cat in orphans:
            taxonomy_map[doc_id] = "Miscellaneous"

```

**Replace with this (KEEP EVERYTHING):**

```python
# New Logic: No Orphan Reassignment
# We accept singleton categories to prevent "Miscellaneous" bloating.
counts = Counter(taxonomy_map.values())
print(f"DEBUG: Category Distribution: {counts}") 
# (No re-assignment code here)

```

## ‚úÖ Definition of Done

1. **Zero False Miscellaneous:** A paper is only in "Miscellaneous" if the LLM truly could not categorize it.
2. **Singleton Folders Allowed:** You will likely see folders with 1 PDF. This is acceptable and preferred over the current behavior.



==================================================
FILE: PRPs/# Phase 3.md
==================================================

### ** Phase 3 **


"Phase 2 is a success! I have a `research_catalog.csv` with 17 papers. Now, let's build **Phase 3: The Smart Architect**.
1. **Create `2_cluster_taxonomy.py**`:
* This script must load `research_catalog.csv`.
* It must use the **Gemini 1.5 Flash** model (via `google-generativeai`) using the `GOOGLE_API_KEY` from our `.env` file.


2. **The AI Logic**:
* Send the list of Titles and Descriptions (Abstracts) to Gemini.
* Ask Gemini to: *'Analyze these papers and create 4-6 logical technical categories (Taxonomy) for a library. Return a JSON mapping of each Paper Title to a Category.'*


3. **The Organization (In Workspace)**:
* Update the `Category` column in the DataFrame based on Gemini's response.
* **Create a root directory named `./Library**` in the current workspace.
* Inside that, create sub-folders for each category (e.g., `./Library/Spatial_Audio_Reconstruction/`).
* Save the updated CSV as `research_catalog_categorized.csv`.


4. **Safety**: Ensure it handles API errors gracefully and uses a wait timer if the abstract list is long."


==================================================
FILE: PRPs/# Adding UI Strike 2.md
==================================================

### **Strike 2: The Orchestrator (Prompt)**

> "Strike 1 is done. Now, let's build **Strike 2: The Orchestrator**.
> **Create a new script named `4_pipeline_manager.py`.**
> **Goal:** This script will act as the master controller. It accepts all the user inputs, runs the underlying scripts (1, 2, and 3) in order using `subprocess`, and returns the final zip file path.
> **Requirements:**
> 1. **Function `run_full_pipeline(...)`:**
> * Arguments: `topic` (required), `keywords`, `author`, `publication`, `date_start`, `date_end`, `sites` (list), `count` (default 10).
> * **Step 1 (Search):** Construct the command for `1_search_omni.py`. Pass all relevant flags. (e.g., `--query` should combine topic + keywords).
> * **Step 2 (Cluster):** Run `2_cluster_taxonomy.py` using `--topic`.
> * **Step 3 (Download):** Run `3_download_library.py`.
> 
> 
> 2. **Autonomous Logic:**
> * Use `subprocess.run(..., check=True)` to execute each step.
> * If any step fails, catch the error and stop the pipeline.
> * Print clear status messages (e.g., '--- Starting Phase 2: Search ---').
> 
> 
> 3. **Output:**
> * The function should return the path to the final zip file (`Library_{Topic}.zip`).
> 
> 
> 4. **Test Block:** Add an `if __name__ == "__main__":` block that allows me to run this manager from the terminal with hardcoded test values to verify it works."
> 
> 


==================================================
FILE: PRPs/# 9_9_5.md
==================================================

### PRP: Domain-Weighted Semantic Expansion

**Role:** Senior AI/Search Architect

**Task:** Refactor the synonym generation to prioritize technical specificity over word count, ensuring the "Backdoor" finds specialized papers like Choueiri's.

#### 1. Title Pre-Filtering (The Junk Wall)

* **Action:** Locally filter the Expert Panel's 150+ titles.
* **Rule:** A title only goes to the LLM if it contains at least one domain word: `[audio, sound, acoustic, loudspeaker, binaural, signal, hrtf, ear, hear, microphone, loudspeaker]`.
* **Goal:** This prevents the "Seawater/Concrete" hallucination by making the non-audio work of the experts invisible to the LLM.

#### 2. Intelligence-Led Extraction (The LLM)

* **Instruction:** "Identify the 15 most specific technical synonyms, acronyms, or methods for '{keyword}'.
* **Rule:** Accept single-word terms if they are domain-specific (e.g., 'Transaural'). If a term is broad (e.g., 'Active Control'), expand it to be specific (e.g., 'Active Sound Control').
* **Constraint:** NO generic filler ('dataset', 'study', 'system'). NO full paper titles."

#### 3. The Dragnet & The Gate

* **Retrieval:** Search `(Original_Keyword OR Technical_Synonyms)`.
* **The Audit:** Use the **Robust PDF Front-Matter Auditor** to verify the presence of the original fuzzy regex (`cross[\s\-]*talk[\s\-]*cancellations?`) in the actual text of the first 2 pages.

---


==================================================
FILE: PRPs/# Fix.md
==================================================

### **The Fix: Smart Cleanup & Readable Catalog**

I need to refine `3_download_library.py` to fix two issues:
1. **Ghost Folder Cleanup (Critical):**
* The script currently zips *all* folders, even empty ones.
* **New Logic:** After the download loop finishes, iterate through `./Library`.
* If a category folder is empty (contains no files), **delete it** from the file system.
* *Then* create the `Library_Export.zip`. This ensures the zip only contains folders with actual papers.


2. **Human-Readable CSV:**
* The current CSV is hard to read.
* **New Logic:** When saving `final_library_catalog.csv`, reorder the columns to put the most important info first:
* `Category`, `Title`, `Publication_Date`, `Original_Filename`, `Source_URL`


* **Sort** the rows by `Category` so related papers are grouped together.
* (Optional) If possible, use a tab-separator (`sep='\t'`) or just standard comma, but ensure newlines in the Description don't break the format.






==================================================
FILE: PRPs/# Adding UI Strike 1.md
==================================================

### ** Strike 1: Upgrade the Search Engine**

> "We are moving to a UI-based application. I need to upgrade `1_search_omni.py` to handle granular inputs.
> **Please rewrite `1_search_omni.py` to accept these new arguments via `argparse`:**
> 1. `--topic` (Required): The main search query.
> 2. `--keywords` (Optional): Additional keywords to append to the query.
> 3. `--author` (Optional): Filter results by this author name.
> 4. `--publication` (Optional): Filter by specific venue/journal.
> 5. `--date_start` and `--date_end` (Optional): Date range filtering.
> 6. `--sites` (Optional List): A comma-separated list of sources to use (options: `arxiv`, `scholar`, `core`, `doaj`). Default to 'all'.
> 
> 
> **Logic Updates:**
> * **Query Construction:** Combine Topic + Keywords + Author into a smart search string optimized for each API.
> * **Source Filtering:** If `--sites` is provided, only call the search functions for those specific APIs.
> * **Date Filtering:** Ensure the results are strictly within the provided date range (checking `date_start` and `date_end`).
> 
> 
> Keep the existing save logic (`research_catalog.csv`)."



==================================================
FILE: PRPs/# 9_9_2 more.md
==================================================


# PRP: Refined Semantic Discovery Logic

**Role:** Senior AI Prompt Engineer
**Task:** Refactor the `get_technical_synonyms_from_llm` method to prevent title-copying and maximize technical "bait" variety.

## 1. Multi-Stage Topic Expansion (Level 1+)

The user wants **more** of these.

* **Requirement:** Increase the topic expansion from 5 to **10-12 terms**.
* **Instruction:** Tell the LLM to include "Signal Processing" and "Acoustic Engineering" sub-disciplines to ensure we catch Choueiri's more mathematical papers.

## 2. Technical Phrase Extraction (Level 2 Fix)

Refactor the prompt for the Expert Vocabulary phase:

* **Constraint 1:** "Do NOT return full paper titles."
* **Constraint 2:** "Return only technical phrases between 2 and 4 words long."
* **Constraint 3:** "Focus on the **Mathematical Methods** and **Hardware Configurations** mentioned (e.g., 'Recursive Filters', 'Stereo Dipole', 'Transaural Synthesis')."
* **Constraint 4:** "Include common abbreviations (e.g., 'CTC', 'XTC', 'BRIR', 'HRTF')."

## 3. The "Broad Net" Final Search

* **Query Construction:** Use the ~10 Topic terms and the ~10 Method terms.
* **Logic:** `(Keyword OR Method1 OR Method2...) AND (Topic1 OR Topic2 OR Topic3...)`

---

### Corrected Implementation Block for the Agent

Give this code to the agent to fix the "Regurgitation" bug:

```python
def get_technical_synonyms_from_llm(self, titles, seed_keyword):
    prompt = (
        f"Goal: Identify 10 high-leverage search terms for the topic '{seed_keyword}'.\n"
        f"Context: Here are 150 titles from top experts in this field:\n"
        f"{' | '.join(titles[:150])}\n\n"
        f"TASKS:\n"
        f"1. Identify the CORE MATHEMATICAL METHODS or FILTER TYPES used.\n"
        f"2. Identify the HARDWARE SETUP terms (e.g., 'loudspeaker array', 'dipole').\n"
        f"3. Identify common ACRONYMS (e.g., CTC, XTC).\n"
        f"\nRULES:\n"
        f"- NO FULL TITLES.\n"
        f"- PHRASES MUST BE 2-4 WORDS MAX.\n"
        f"- RETURN ONLY A COMMA-SEPARATED LIST."
    )
    # Get response and clean it
    raw_response = self.llm_query(prompt)
    synonyms = [s.strip().lower() for s in raw_response.split(',') if len(s.strip().split()) > 1]
    return synonyms[:12] # Return more terms as requested

```


==================================================
FILE: PRPs/# 9_9_6.md
==================================================

### PRP: The "Variable-Constraint" Backdoor

**Role:** Senior Generalist Search Engineer
**Task:** Refactor the Synonym Generation to use the User's Topic as a dynamic filter, eliminating "polysemic drift" (like "Active Control") without hardcoding domain terms.

#### 1. The Dynamic Anchor Prompt

Instead of injecting "Audio" words, inject the `self.raw_topic` variable into the prompt instructions.

* **Prompt Logic:**
"The user is researching **{topic}**. The primary keyword is **{keyword}**.
Below is a list of recent titles from a top expert in this field.
**Constraint:** This expert may work in multiple disciplines. You must **IGNORE** any titles or terms that are not strictly relevant to **{topic}**.
**Task:** Extract 15 technical synonyms, methods, or acronyms for **{keyword}** that appear in the relevant titles.
**Output:** Comma-separated list."

#### 2. Why this works for ANY field:

* **Case A (Current):** Input is "Spatial Audio". LLM sees "Seawater Concrete" title. LLM checks: "Is Seawater relevant to Spatial Audio?" -> No. Discards it.
* **Case B (Future):** Input is "Gene Editing". Expert also writes about "Patent Law". LLM checks: "Is Patent Law relevant to Gene Editing mechanisms?" -> No. Discards it. Keeps "Cas9".

#### 3. Execution (The Dragnet & Gate)

* **Dragnet:** `(Original Keyword OR Anchored_Synonyms)`.
* *Result:* "Active Control" is filtered out or qualified (e.g., "Active Noise Control") by the LLM because "Active Control" alone is too broad for the "Spatial Audio" topic constraint.


* **Gate:** The **PDF Front-Matter Audit** (Section-Aware) remains the final truth, checking for the original keyword.

---

### Implementation Block (General Purpose)

Here is the Python method that uses the variables correctly to sanitize the synonyms without hardcoding.

```python
def get_technical_synonyms_from_llm(self, titles, seed_keyword, user_topic):
    """
    Extracts synonyms using the User's Topic as the semantic guardrail.
    Works for any domain (Audio, Biology, Physics, etc.).
    """
    prompt = (
        f"CONTEXT: The user is researching '{user_topic}'. "
        f"The primary keyword is '{seed_keyword}'.\n"
        f"SOURCE DATA: Here are recent paper titles from a identified expert in this field:\n"
        f"{' | '.join(titles[:150])}\n\n"
        f"TASK: Identify 15 specific technical synonyms, acronyms, or method names for '{seed_keyword}' "
        f"that are used within the domain of '{user_topic}'.\n\n"
        f"RULES:\n"
        f"1. FILTER IRRELEVANCE: The expert may publish in other fields. IGNORE titles unrelated to '{user_topic}'.\n"
        f"2. PRECISION: If a term is broad (like 'Active Control'), qualify it to fit '{user_topic}' (e.g., 'Active Noise Control').\n"
        f"3. FORMAT: Return ONLY a comma-separated list of phrases (2-4 words). No full titles."
    )
    
    # ... call LLM ...

```



==================================================
FILE: PRPs/# Validation test.md
==================================================

### Validation test

> "Excellent. Now, let's perform a full **End-to-End Validation Run** to prove the new 'Persistent Library' architecture works.
> **Please execute this exact sequence in the terminal:**
> 1. **Phase 2 (Search):**
> `./.venv/bin/python3 1_search_omni.py --query "Spatial Audio" --year_start 2023 --count 5`
> 2. **Phase 3 (Cluster):**
> `./.venv/bin/python3 2_cluster_taxonomy.py --topic "Spatial_Audio"`
> 3. **Phase 4 (Download & Export):**
> `./.venv/bin/python3 3_download_library.py`
> 
> 
> **After the scripts finish, run these verification commands and show me the output:**
> 1. `ls -R Library/` -> *(I want to verify that categories are strictly inside `Library/Spatial_Audio/` and NO ghost folders exist at the root).*
> 2. `ls -lh Library_Spatial_Audio.zip` -> *(To prove the focused zip was created).*
> 3. `head -n 20 Library/Spatial_Audio/Catalog_Spatial_Audio.md` -> *(To verify the YYYY/MM/DD date format).*
> 
> 
> If this run succeeds, we are ready to merge."



==================================================
FILE: PRPs/# 10 Add standardized metadata.md
==================================================


### **Refactor Task: Metadata Standardization & Multi-Format Export**

**Context:**
The "Librarian" app currently downloads papers and generates a `catalog.md` file. We are upgrading the metadata engine.
**Constraint:** Do NOT change the downloading or folder organization logic. Only refactor the **metadata dictionary** and the **export file generation**.

**The Goal:**
We need to standardize our internal metadata format and then output that data into **three** specific files for the user:

1. `catalog.md` (Existing feature - must be preserved and updated)
2. `catalog.csv` (New feature - for data analysis)
3. `citations.ris` (New feature - for Zotero/EndNote)

---

### **Step 1: Standardize the Internal Metadata Dictionary**

Ensure your paper objects/dictionaries now strictly use these keys. If data is missing from the API, default to `None` or `""`.

* **Keys:** `title`, `authors` (list of strings), `year` (YYYY), `date` (YYYY-MM-DD), `journal` (or venue), `doi`, `url` (source link), `pdf_url` (direct link), `abstract`, `citation_count`, `filename` (local filename).

---

### **Step 2: Update the Existing Markdown Generator (`catalog.md`)**

You are already generating this file. Update the function to add the new standard keys above. Keep existing keys not covered by the new ones (such as "status"). Make sure the .md version retiains the "Search Settings" section.

* **Format:** Keep the existing table format for readability.
* **Columns:** `| Title | First Author | Year | Journal | Citations | Link |`
* **Rule:** For the "Link" column, use the `url` field formatted as a Markdown link `[Source](url)`.
* **Rule:** For "First Author", only take the first item from the `authors` list and append "et al." if the list length is > 1.
* **Note:** Do not put the `abstract` in the table.

---

### **Step 3: Implement New Export Formats**

#### **A. Generate `catalog.csv**`

Create a function to dump the full metadata into a CSV.

* **Columns:** `Title`, `Authors` (join list with semicolon), `Year`, `Journal`, `DOI`, `Citation_Count`, `URL`, `PDF_Link`, `Filename`, `Abstract`.
* **Critical:** Use a CSV library to strictly handle escaping. The `Abstract` and `Title` fields often contain commas and newlines that will break the file if not quoted correctly.

#### **B. Generate `citations.ris**`

Create a function to generate an RIS file for reference managers.

* **Strict Formatting:**
* Start record: `TY  - JOUR` (Two spaces after TY, one after hyphen)
* End record: `ER  - `


* **Tag Mapping:**
* `TI`: `title`
* `AU`: `authors` (Loop through list: create a separate `AU  - Name` line for **every** author).
* `PY`: `year`
* `JO`: `journal`
* `DO`: `doi`
* `UR`: `url`
* `L1`: `pdf_url` (**Important:** This maps the direct PDF link).
* `AB`: `abstract`



**Output:**
Return the code that takes the list of paper objects and generates the strings for `catalog.md`, `catalog.csv`, and `citations.ris`.

==================================================
FILE: PRPs/# UI Theme.md
==================================================

# PRP: Implement "Intellectual Velocity" UI Theme

**Role:** Expert Streamlit Frontend Developer
**Objective:** Overhaul the visual identity of **ScholarStack** to match the new "Intellectual Velocity" brand guidelines. This involves updating the Streamlit configuration, injecting custom CSS for advanced styling, and integrating the new logo asset.

## 1. Asset Preparation

* **Action:** Create a directory named `src/assets/` if it does not exist.
* **Action:** Expect a logo file (e.g., `logo.png`) to be placed in this folder.
* **Requirement:** Ensure the application can reference images relative to the `src` directory.

## 2. Streamlit Configuration (`.streamlit/config.toml`)

**Task:** Create or overwrite `.streamlit/config.toml` to set the base dark theme and brand colors.

```toml
[theme]
base = "dark"
primaryColor = "#00F0FF"    # Electric Cyan
backgroundColor = "#0A2342" # Deep Oxford Blue
secondaryBackgroundColor = "#152D4F" # Lighter Blue (Sidebars)
textColor = "#F4F6F8"       # Paper White
font = "sans serif"

```

## 3. CSS Injection (`src/app.py`)

**Task:** Create a function `apply_branding()` in `src/app.py` and call it immediately inside `main()`.

**Specifications:**

* **Fonts:** Import 'Inter' (Headings) and 'Merriweather' (Body) from Google Fonts.
* **Headers:** Force all H1-H3 tags to use 'Inter', Bold weight, White text.
* **Body Text:** Force `p`, `li`, and markdown text to use 'Merriweather', Light weight, off-white (`#E0E6ED`).
* **Buttons:** Apply a gradient background (`#00C6D1` to `#00F0FF`) with a "glow" box-shadow effect on hover. Text color must be dark (`#051628`) for contrast.
* **Success Messages:** Override `.stSuccess` to use a transparent Emerald Green background (`rgba(46, 204, 113, 0.15)`).
* **Containers:** Style `stExpander` and dataframes with "Glassmorphism" (5% white opacity background, thin border).

**CSS Code Block to use:**

```python
def apply_branding():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;700&family=Merriweather:wght@300;400&display=swap');

        html, body, [class*="css"] {
            font-family: 'Inter', sans-serif;
        }
        
        h1, h2, h3 {
            font-family: 'Inter', sans-serif;
            font-weight: 700 !important;
            color: #FFFFFF !important;
        }

        p, li, .stMarkdown {
            font-family: 'Merriweather', serif;
            font-weight: 300;
            line-height: 1.6;
            color: #E0E6ED;
        }

        /* Neon Cyan Buttons */
        div.stButton > button {
            background: linear-gradient(90deg, #00C6D1 0%, #00F0FF 100%);
            color: #051628;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            box-shadow: 0 4px 14px rgba(0, 240, 255, 0.3);
        }
        
        /* Glassmorphism Containers */
        div[data-testid="stExpander"] {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 10px;
        }
        </style>
    """, unsafe_allow_html=True)

```

## 4. UI Layout Updates

**Task:** Update the header section in `src/app.py`.

* **Logo:** Display the logo image at the top of the main container.
* *Code:* `st.image("src/assets/logo.png", width=120)` (Adjust width as needed).


* **Title:** Remove the standard `st.title("ScholarStack")` text if the logo contains the text. If the logo is just an icon, keep the title but ensure it aligns with the logo.
* **Sidebar:** Ensure the "Settings" sidebar inherits the `secondaryBackgroundColor`.

## 5. Verification

* Launch the app (`streamlit run src/app.py`).
* Verify the background is Deep Blue (#0A2342).
* Verify buttons glow Cyan (#00F0FF).
* Verify body text is a Serif font (Merriweather).

==================================================
FILE: PRPs/# Phase 4.md
==================================================

### ** Phase 4 **

"Phase 3 is complete. I have the folder structure and categorized CSV. Now, let's build the final **Phase 4: The Physical Librarian**.
1. **Create `3_download_library.py**`:
* Load `research_catalog_categorized.csv`.
* Iterate through every row where `Is_Paywalled` is False.


2. **The Smart Download Logic (Crucial)**:
* Use `requests` to stream the file. **Use a standard browser User-Agent.**
* **Determine Filename:**
* First, check the `Content-Disposition` header in the response for the true filename.
* If missing, parse the filename from the end of the URL.
* **Sanitize:** Remove illegal characters.
* **Fallback:** If the name is generic (like 'download.pdf' or 'view'), append the first 20 chars of the Title to make it unique.


* **Save:** Save to `./Library/{Category}/{Final_Filename}`.
* **Update Catalog:** Update the `Original_Filename` column in the DataFrame with the actual saved name, and set `Is_Downloaded` = True.


3. **The Export Logic (For Firebase)**:
* After the loop finishes, **create a JSON index file** (`index.json`) inside each Category folder listing the papers in that folder.
* **Zip the entire library:** Use `shutil.make_archive` to create `Library_Export.zip` from the `./Library` directory.
* Print: 'READY FOR DOWNLOAD: Library_Export.zip'.


4. **Final Output**: Save the final dataframe to `final_library_catalog.csv`."





==================================================
FILE: PRPs/# 9_7 more backdoor.md
==================================================

# Product Requirements Prompt (PRP)

**Role:** Senior Python Engineer
**Task:** Implement the "Broad Net / Strict Gate" Backdoor Search logic with detailed debug visibility.

## Logic Flow

1. **Backdoor Discovery:**
* Use the "Contextual Probe" (`Original Keyword` AND `User Topic`) to find seed papers.
* Analyze bibliographies to identify the **Top 10 Most Influential Authors** (The Panel).
* **Debug Requirement:** You must print the `display_name` of these 10 authors to the console so the user can verify the expert list.
* **Vocabulary:** Extract the **Top 10** most frequent N-grams (2-3 words) from their recent titles (2020+). These are the "Fishing Synonyms."


2. **The Dragnet (Broad Retrieval):**
* Construct an API query using: `(Original Keyword OR Synonym 1 OR ... Synonym 10) AND (User Topic)`.
* *Purpose:* Use the weak synonyms to pull metadata from the API that might have a truncated index.


3. **The Strict Gate (Local Retention):**
* **Constraint:** Do **NOT** add the synonyms to `self.keywords_list`.
* *Purpose:* The system must strictly enforce that the *Original Keyword* appears in the returned metadata. If a paper is caught via a synonym but lacks the original keyword in its Title/Abstract, it must be rejected by the local filter.



## Implementation Details

* Fetch **Top 10** Authors and **Top 10** Synonyms.
* Ensure the console output clearly lists: `   ‚úÖ Identified Panel of 10 Experts: [Name 1, Name 2...]`.
* Pass the expanded query to the API, but keep the `ResearchCrawler` validation list strict.

---

### Updated Code: `search_via_citation_backdoor`

Replace the method in `research_crawler.py` with this version.

```python
    def search_via_citation_backdoor(self):
        """
        BROAD NET / STRICT GATE Algorithm:
        1. Contextual Probe -> Find 'Seed' papers (Keyword + Topic).
        2. Citation Analysis -> Identify Top 10 Experts (The Panel).
        3. Vocabulary Expansion -> Learn Top 10 Synonyms (Fishing Bait).
        4. Broad Dragnet -> Search API using Synonyms.
        5. Strict Gate -> Local filter rejects papers missing the ORIGINAL keyword.
        """
        print(f"\nüïµÔ∏è STARTING BACKDOOR CITATION SEARCH for: '{self.raw_topic}'")
        
        # --- PHASE 1: THE CONTEXTUAL SEED ---
        clean_topic = self.raw_topic.replace('"', '')
        clean_keyword = self.keywords_list[0].replace('"', '')
        
        # Probe: Keyword AND Topic (e.g., "Crosstalk" AND "Spatial Audio")
        seed_query = f'("{clean_keyword}") AND ("{clean_topic}")'
        print(f"   1. Probing with Context: {seed_query}")
        
        url = "https://api.openalex.org/works"
        params = {
            "filter": f"title_and_abstract.search:{seed_query}",
            "per-page": 50,  
            "select": "referenced_works" 
        }
        
        try:
            r = self.session.get(url, params=params, timeout=10)
            seed_results = r.json().get('results', [])
        except:
            print("   ‚ö†Ô∏è Probe failed. Falling back to standard search.")
            self.execute_openalex_query("Fallback", "is_oa:true", f'"{clean_keyword}"')
            return

        if not seed_results:
            print(f"   ‚ö†Ô∏è No seed papers found for context. Trying keyword only...")
            params["filter"] = f"title_and_abstract.search:{clean_keyword}"
            r = self.session.get(url, params=params, timeout=10)
            seed_results = r.json().get('results', [])
            
        if not seed_results:
             print("   ‚ö†Ô∏è No results found even for keywords.")
             return

        # --- PHASE 2: IDENTIFY THE PANEL (Top 10 Experts) ---
        print("   2. Analyzing Citations to identify the Expert Panel...")
        
        from collections import Counter
        cited_ids_counter = Counter()
        
        for work in seed_results:
            for ref_id in work.get('referenced_works', []):
                cited_ids_counter[ref_id] += 1
        
        # Get Top 30 Ghost Papers (Canon)
        top_ghost_ids = [id for id, count in cited_ids_counter.most_common(30)]
        
        if not top_ghost_ids:
            print("   ‚ö†Ô∏è No citations found to analyze.")
            self.execute_openalex_query("Fallback", "is_oa:true", f'"{clean_keyword}"')
            return

        # Fetch authors of these Ghost Papers
        ghost_ids_str = "|".join(top_ghost_ids)
        r = self.session.get(url, params={"filter": f"openalex_id:{ghost_ids_str}", "select": "authorships"}, timeout=10)
        
        author_counter = Counter()
        author_names = {} # Map ID to Name for display
        
        for work in r.json().get('results', []):
            for authorship in work.get('authorships', []):
                aid = authorship['author']['id']
                name = authorship['author']['display_name']
                author_counter[aid] += 1
                author_names[aid] = name
                
        # SELECT THE PANEL: Top 10 Authors
        top_panel = author_counter.most_common(10)
        panel_ids = [id for id, count in top_panel]
        
        print(f"   ‚úÖ Identified Panel of {len(panel_ids)} Experts:")
        for pid in panel_ids:
            print(f"      - {author_names.get(pid, 'Unknown')} (ID: {pid})")

        # --- PHASE 3: CONSENSUS LEARNING (Top 10 Fishing Terms) ---
        print(f"   3. Harvesting vocabulary from Panel's recent work (2020+)...")
        
        panel_str = "|".join(panel_ids)
        vocab_params = {
            "filter": f"authorships.author.id:{panel_str},publication_year:>2019",
            "per-page": 150, # Get a good sample size
            "select": "title"
        }
        
        r = self.session.get(url, params=vocab_params, timeout=10)
        recent_titles = [w['title'] for w in r.json().get('results', [])]
        
        # N-Gram Extraction
        import re
        phrase_counter = Counter()
        
        for title in recent_titles:
            if not title: continue
            words = re.findall(r'\w+', title.lower())
            for n in [2, 3]:
                for i in range(len(words) - n + 1):
                    phrase = " ".join(words[i:i+n])
                    # Filter: Must not contain seed, >5 chars
                    if clean_keyword.lower() not in phrase and len(phrase) > 5:
                        phrase_counter[phrase] += 1
        
        # EXTRACT TOP 10 TERMS (Broad Net)
        new_synonyms = [f'"{p}"' for p, c in phrase_counter.most_common(50) if c > 1][:10]
        
        print(f"   üß† Learned Fishing Synonyms (Top 10): {new_synonyms}")

        # --- PHASE 4: THE DRAGNET (Broad Net / Strict Gate) ---
        print("   4. Executing Final Engineered Search...")
        
        # 1. The Net (API Query): Use ALL terms to fish
        expansion_query = " OR ".join([f'"{clean_keyword}"'] + new_synonyms)
        final_query = f"({expansion_query}) AND ({clean_topic})"
        
        # 2. The Gate (Local Filter): STRICTLY enforce Original Keyword
        # We do NOT add synonyms to self.keywords_list.
        print(f"   üîí Local Filter remains STRICT: Only papers containing '{clean_keyword}' will survive.")
        
        filters = "is_oa:true,type:article|conference-paper" 
        if self.date_start: filters += f",publication_year:>{self.year_start-1}"
        
        self.execute_openalex_query("Engineered Dragnet", filters, final_query)

```

==================================================
FILE: PRPs/# 9_9_3 more.md
==================================================

### Updated PRP 

**Role:** Search Architect
**Task:** Refactor the Final Dragnet construction to maximize recall by removing the Topic constraint.

**Requirements:**

1. **Drop the Topic Constraint:** In Phase 4 (The Final Dragnet), the API search query must consist **only** of the `(Original Keyword OR Technical Synonyms)`. Do not append `AND Topic`.
2. **Rely on the Gate:** Trust the **Section-Aware PDF Auditor** to do the heavy lifting. Since the auditor only looks for the original keyword in the front-matter of the PDF, it will automatically discard any non-topic papers caught by the broad synonyms.
3. **Synonym Quality:** Ensure the LLM provides **15 technical synonyms** (2-4 words each) to ensure the dragnet is wide enough to find the 100-paper quota.



==================================================
FILE: PRPs/# Phase 1.md
==================================================

### Phase 1: The "Unlimited" Environment

I need to build a comprehensive academic crawler. Update `requirements.txt` to include all these libraries:

* `arxiv` (ArXiv API)
* `semanticscholar` (Semantic Scholar API)
* `scholarly` (Google Scholar wrapper - include rate limiting logic)
* `habanero` (Crossref API for DOI lookup)
* `pyunpaywall` (Unpaywall API to unlock DOIs)
* `sickle` (OAI-PMH client for querying **BASE** and **CORE**)
* `requests` (For OSF, PLOS, DOAJ, and generic APIs)
* `beautifulsoup4` (For scraping DAFx/ISMIR archives directly)
* `pandas`
* `google-generativeai` (For the dynamic taxonomy later)
* `tqdm` (Progress bars)

Install these now.



==================================================
FILE: PRPs/# 9 add OpenAlex API.md
==================================================

You are acting as a Senior Python Developer optimizing the **ScholarStack** project. We are currently facing a critical bottleneck in our search pipeline: the `Crossref -> Unpaywall` check loop is too slow and has a low yield of valid PDFs.

Your task is to integrate the **OpenAlex API** as the primary search source to resolve this. OpenAlex allows server-side filtering for Open Access (`is_oa:true`), which will eliminate the need for thousands of individual HTTP checks.

Please modify `1_search_omni.py` (and create a new utility file if necessary) to implement the following changes:

### 1. Implement the Abstract Reconstructor

OpenAlex stores abstracts as an "Inverted Index" to save space. We need this helper function to reconstruct them into readable text so our Gemini agent can categorize the papers later.

```python
def reconstruct_abstract(inverted_index):
    """
    Reconstructs the abstract from OpenAlex's inverted index format.
    """
    if not inverted_index:
        return ""
    
    # Determine the length of the abstract based on the max index
    max_index = 0
    for positions in inverted_index.values():
        if positions:
            max_index = max(max_index, max(positions))
    
    words = [""] * (max_index + 1)
    
    # Populate the words at their correct positions
    for word, positions in inverted_index.items():
        for pos in positions:
            words[pos] = word
            
    return " ".join(words)

```

### 2. Implement the OpenAlex Search Function

Create a function `search_openalex` that handles pagination and standardizes the output to match our existing dictionary format.

**Requirements:**

* **Filter:** Must use `filter="is_oa:true,has_doi:true"` to ensure we only get valid, free papers.
* **Fields:** Request specific fields to save bandwidth: `title,id,publication_year,open_access,authorships,abstract_inverted_index`.
* **Logic:** Loop through pages until `target_count` is met.

```python
import requests

def search_openalex(query, target_count=50, start_year=None, end_year=None):
    base_url = "https://api.openalex.org/works"
    papers = []
    per_page = 200
    
    # Build filter string
    filters = ["is_oa:true", "has_doi:true"]
    if start_year:
        filters.append(f"publication_year:>{start_year-1}")
    if end_year:
        filters.append(f"publication_year:<{end_year+1}")
    
    filter_str = ",".join(filters)
    current_page = 1
    
    print(f"üìö Querying OpenAlex for: '{query}'...")

    while len(papers) < target_count:
        params = {
            "search": query,
            "filter": filter_str,
            "per-page": per_page,
            "page": current_page,
            "select": "title,id,publication_year,open_access,authorships,abstract_inverted_index"
        }

        try:
            resp = requests.get(base_url, params=params, timeout=10)
            if resp.status_code != 200: 
                break
                
            results = resp.json().get('results', [])
            if not results: 
                break
                
            for item in results:
                pdf_url = item.get('open_access', {}).get('oa_url')
                if not pdf_url: continue

                # Reconstruct abstract
                abstract_text = reconstruct_abstract(item.get('abstract_inverted_index'))

                # Get author
                authors = item.get('authorships', [])
                first_author = authors[0]['author']['display_name'] if authors else "Unknown"

                papers.append({
                    "title": item['title'],
                    "link": pdf_url,
                    "source": "OpenAlex",
                    "year": item.get('publication_year'),
                    "author": first_author,
                    "abstract": abstract_text
                })
                
                if len(papers) >= target_count: break
            
            current_page += 1
            
        except Exception as e:
            print(f"Error: {e}")
            break

    return papers[:target_count]

```

### 3. Integration Logic

Modify the main `run_omni_search` function in `1_search_omni.py`.

* **Priority:** Call `search_openalex` *first*.
* **Fallback:** Only call Semantic Scholar if OpenAlex returns fewer papers than `target_count`.
* **Deprecation:** Remove or comment out the old Crossref + ThreadPoolExecutor logic to clean up the code.

### 4. Self-Validation Protocol (Critical)

You must ensure this script works independently before we integrate it into the web app. Add a `if __name__ == "__main__":` block at the bottom of the file that performs the following "Smoke Test":

1. **Run a Test Search:** Search for the topic "Generative AI" with a target of 5 papers.
2. **Validate Links:** For each returned paper, perform a `requests.head()` check on the PDF link to verify it returns `200 OK`.
3. **Validate Abstracts:** Verify that the `abstract` field is not empty and contains readable text (length > 50 chars).
4. **Report:** Print a formatted report to the console showing:
* Total Papers Found
* Valid Link Count
* Valid Abstract Count
* Average Search Time



**Example Validation Output:**

```text
--- SELF-DIAGNOSTIC REPORT ---
‚úÖ Search Complete: 0.8s
‚úÖ Papers Found: 5/5
‚úÖ Link Health: 5/5 (200 OK)
‚úÖ Abstract Reconstruction: 5/5 Valid
------------------------------

```

**Expected Outcome:**
Provide the updated full code for `1_search_omni.py` that includes the OpenAlex search, the integration logic, and the self-validation block.

==================================================
FILE: PRPs/# 9_9_9_2 taxonomy improve.md
==================================================

# PRP: Refactor Taxonomy Logic to Structured Output

**Context:**
The current implementation of `src/2_cluster_taxonomy.py` relies on manual JSON parsing and regex cleaning (`clean_json_string`), which is fragile. Furthermore, the categorization logic allows "hallucinations" where the LLM assigns categories that do not align with the paper's text, or generates overly verbose category names.

**Objective:**
Refactor the `cluster_and_categorize` function to use **Gemini's Native Structured Output (`response_schema`)**. This will enforce strict JSON generation and require the LLM to provide "evidence" for every category assignment.

**Target File:** `src/2_cluster_taxonomy.py`

## üõ†Ô∏è Engineering Requirements

### 1. Dependency Updates

* Import `typing_extensions` at the top of the file to support schema definitions.

### 2. Schema Definition

Define a strict `TypedDict` schema outside the main function to enforce the output structure:

```python
class PaperClassification(typing_extensions.TypedDict):
    id: str
    category_name: str
    justification_quote: str  # Forces the LLM to prove its work

class TaxonomyResponse(typing_extensions.TypedDict):
    assignments: list[PaperClassification]

```

### 3. Prompt Logic Refactor

Inside `cluster_and_categorize`, specifically within the "Logic for Large Groups (LLM)" loop:

* **Remove:** The legacy `clean_json_string` function call and manual `json.loads` on `response.text`.
* **Update Prompt:** Change the prompt to explicitly request the `justification_quote` (a snippet from the abstract) that supports the categorization.
* **Update API Call:** Modify `model.generate_content` to use the `response_schema` parameter:
```python
response = model.generate_content(
    prompt,
    generation_config=genai.GenerationConfig(
        response_mime_type="application/json",
        response_schema=TaxonomyResponse
    )
)

```



### 4. Implementation Details

* **Input Data:** Continue using `papers_payload` (id, title, description).
* **Processing:** Instead of regex cleaning, directly access `json.loads(response.text)['assignments']`.
* **Sanitization:** Ensure the `category_name` is still truncated to max 4 words programmatically (as a fail-safe), even though the schema encourages brevity.
* **Logging:** Add a `print` statement in the loop to display the `category_name` alongside the `justification_quote` to the console. This serves as a "sanity check" for the user to see *why* a paper was categorized a certain way.

### 5. Cleanup

* Delete the now obsolete `clean_json_string` helper function.

## ‚úÖ Definition of Done

1. The code runs without `json.JSONDecodeError`.
2. Every categorized paper includes an internal "proof" (quote) used by the LLM to make the decision.
3. Category names are concise (Noun Phrases, < 4 words).
4. The fallback logic (retries and "Overview" assignment) remains intact for API failures.

==================================================
FILE: PRPs/# 9_9_1 more.md
==================================================

### PRP: LLM-Augmented Research Crawler

**Role:** Senior AI Systems Architect
**Task:** Refactor the `ResearchCrawler` to use LLM-based semantic expansion at both the Topic and Keyword stages.

#### 1. Semantic Topic Expansion (Pre-Search)

* **Logic:** Use the existing `expand_topic_with_llm` method (or create a better prompt) to turn the raw topic into a Boolean string of 3-4 academic synonyms.
* **Goal:** Increase the recall of the "Expert Panel" by searching for "3D Audio" and "Immersive Sound" simultaneously.

#### 2. Technical Vocabulary Synthesis (Expert-Driven)

* **Action:** Instead of counting N-grams, send the list of 150 titles from the Expert Panel to the LLM.
* **Prompt Logic:** *"I am looking for papers about [Keyword]. Below are recent titles from experts in this field. Identify 10 highly specific technical terms, methods, or filter types used in these titles that are synonymous or closely related to [Keyword]. Exclude generic filler like 'dataset' or 'analysis'."*

#### 3. Consolidated Multi-Term Dragnet

* **The Net:** Construct the final query using the LLM's technical synonyms + the LLM's topic synonyms.
* **The Gate:** Apply the **Robust PDF Front-Matter Audit** (ignoring annotations) to find the fuzzy regex of the *original* keyword.

---

### Implementation Block for the Agent

Give this code to the agent to replace the "N-Gram junk" with LLM-curated technical synonyms.

```python
def get_technical_synonyms_from_llm(self, titles, seed_keyword):
    """Uses LLM to clean the 'junk' out of the panel's vocabulary."""
    if not titles: return []
    
    prompt = (
        f"I am researching '{seed_keyword}'. Here is a list of recent titles from the top experts in this field:\n"
        f"{' | '.join(titles[:100])}\n\n"
        f"Based on these titles, provide a comma-separated list of the 10 most specific technical synonyms, "
        f"mathematical methods, or alternative names for '{seed_keyword}'. "
        f"Strictly avoid generic phrases like 'dataset', 'system', 'audio', or 'study'. "
        f"Return ONLY the comma-separated list."
    )
    
    # Trigger your LLM generation method here
    response = self.llm_query(prompt) 
    synonyms = [s.strip().lower() for s in response.split(',') if len(s.strip()) > 5]
    return synonyms

# --- UPDATED SEARCH FLOW ---
# 1. Topic expansion: "Spatial Audio" -> "3D Audio"
# 2. Expert Probe: Find Nelson, Choueiri, etc.
# 3. Titles -> LLM -> Technical Synonyms (e.g., "Recursive Ambiophonics", "Stereo Dipole")
# 4. Dragnet -> PDF Audit

```



==================================================
FILE: PRPs/# 9_9_9_4.md
==================================================



# PRP: Robust Taxonomy & Heuristic Data Cleaning

**Context:**
The taxonomy engine currently suffers from two issues:

1. **Low-Quality Input:** Some papers have placeholder descriptions (e.g., "n/a", "no abstract", or short copyright notices) which confuse the categorization.
2. **Formatting Artifacts:** The LLM sometimes outputs verbose names or includes punctuation (like brackets) that get chopped awkwardly.

**Objective:**
Improve data hygiene and category naming using **agnostic heuristics** and **stricter prompt instructions**, avoiding any hard-coded phrases or language-specific rules.

**Target File:** `src/2_cluster_taxonomy.py`

## üõ†Ô∏è Engineering Requirements

### 1. Heuristic Data Filter (The "Garbage" Fix)

In `cluster_and_categorize`, inside the loop where `papers_payload` is built:

* **Problem:** We cannot trust that every paper has a valid abstract.
* **Agnostic Solution:** Implement a **Length Check**.
* Check if the `description` string is shorter than **50 characters**.
* **Logic:** A valid academic abstract is virtually always >50 chars. Anything less is likely metadata noise, regardless of the language or source.
* **Action:** If `< 50` chars, overwrite `description` with: `f"Title: {row['Title']}"`. This forces the LLM to categorize based on the Title alone, which is safer than a broken abstract.



### 2. Prompt Refinement (The Formatting Fix)

Update the `prompt` string in the "Logic for Large Groups" section. Instead of asking for arbitrary categories, enforce a **Style Guide**:

* **Instruction:** Add: *"Format category names as concise Noun Phrases (e.g., 'Spatial Audio', not 'Papers about Spatial Audio'). Avoid parenthetical qualifiers."*
* **Constraint:** Keep the "Max 3-4 Words" instruction, as this is a structural constraint, not a content one.

### 3. Agnostic String Cleaning

Update the category cleaning block to be purely syntactic:

* **Import:** Ensure `string` is imported (`import string`).
* **Logic:** Remove the complex regex that targets specific words like "and".
* **Replacement:** Use Python's standard library to strip trailing punctuation/whitespace.
```python
# 1. Trust the LLM's output (constrained by prompt)
cat_raw = item['category_name'].strip()

# 2. Safety Truncate (Generous buffer for long technical terms)
# If > 6 words, it's likely a sentence, so we chop it.
words = cat_raw.split()
if len(words) > 6:
    cat_raw = " ".join(words[:6])

# 3. Universal Cleanup
# Strips any trailing punctuation (brackets, commas, dashes, etc.) from ANY language.
cat_clean = cat_raw.strip(string.punctuation + string.whitespace)

local_map[item['id']] = cat_clean

```



## ‚úÖ Definition of Done

1. **Universal Logic:** The code contains no hard-coded blacklists (no `"International audience"`, no `"and/or/the"`).
2. **Data Safety:** Short/Empty descriptions are automatically handled by the length heuristic.
3. **Clean Output:** Category names are free of trailing punctuation artifacts (e.g., `Category Name,` becomes `Category Name`).

==================================================
FILE: PRPs/# 9_8 more.md
==================================================

### The Real Architecture: "Dredge Metadata, Audit the PDF"

If we cannot trust OpenAlex's metadata to *prove* the paper is relevant, we can only use it to *suggest* it might be. The **only** way to get the Choueiri paper (and the other 90+ missing ones) is to move the "Gate" to the **actual source text of the PDF.**

The tool must stop trying to be "clever" with OpenAlex's broken snippets. It needs to become a **High-Volume Pipe** that fetches everything even remotely related and then runs the "Strict Gate" on the **Full Text of the PDF** itself.

---

# PRP: Refactoring to "Full-Text PDF Validation"

**Role:** Senior Lead Developer / Search Architect
**Task:** Refactor the `ResearchCrawler` to implement a "Broad Metadata Dredge" followed by a "Strict Full-Text PDF Audit."

## 1. The Broad Dredge (Phase 4 Retrieval)

* **Goal:** Maximize Recall. We don't care about noise here; we care about not missing the 100.
* **API Query:** Use the Expanded Boolean query: `("{keywords}" OR "{synonym1}" ... OR "{synonym10}") AND ("{topic}")`.
* **The Change:** **Disable** the strict local keyword filter during the `execute_openalex_query` phase. If a paper matches the API query, **Accept it into the Download Queue.**

## 2. The "Strict Gate" (Full-Text Validation)

The real "crosstalk cancellation" check happens **AFTER** the PDF is in local memory.

* **Requirement:** 1. Download the PDF to a temporary buffer/folder.
2. Extract the **Full Text** from the PDF (using `PyMuPDF` or `pdfplumber`).
3. Run the **Strict Regex Gate** (`cross[\s\-]*talk[\s\-]*cancellations?`) on the **entire document**.
4. **If found:** Keep the paper and add to `research_catalog.csv`.
5. **If not found:** Delete the PDF and discard the entry.

## 3. Backdoor Discovery (Unchanged)

* Identify the **10 Expert Authors** from the bibliography of the initial seed.
* Extract the **Top 15 technical N-grams** from their recent work to power the "Broad Dredge."
* **Debug:** Print the 10 Author names to the console so we can see the "Expert Panel."

---

### Why this is the ONLY way to solve the Choueiri problem:

1. **OpenAlex is the "Finder":** It finds the *existence* of a Choueiri paper because of its citations and topic.
2. **The PDF is the "Prover":** Since OpenAlex's abstract is garbage/truncated, we don't look at it. We go straight to the PDF, find the phrase "crosstalk cancellation" in the 5th sentence (or 5th page), and **confirm** it.

This architecture treats OpenAlex like a phone book (which is all it's good for) and the PDF as the source of truth. This is how you hit your 100-paper quota with 100% precision and zero "missed" papers.



==================================================
FILE: PRPs/# Fix 2.md
==================================================
# Fix 2

The previous cleanup logic failed, and the CSV is unreadable. Please completely rewrite `3_download_library.py` with this strict logic:
1. **The Cleanup (Aggressive):**
* After downloads attempt to finish, iterate through every subfolder in `./Library`.
* Count the number of **files** inside.
* **If a folder is empty OR only contains hidden system files**, delete the folder using `shutil.rmtree`.
* *Only after cleanup*, create the `Library_Export.zip`.


2. **The Output (Human-Readable):**
* Instead of *only* a CSV, generate a file named **`Library_Catalog.md`**.
* **Format:** Group papers by `Category`.
* For each Category, create a Heading (`## Category Name`).
* List each paper as a bullet point:
* **Title** (Year)
* *Status:* [Downloaded/Missing]
* *Filename:* [Original_Filename]
* *Source:* [URL]
* *Abstract:* (First 200 chars...)


3. **Keep the Download Logic:** Maintain the smart filename detection and user-agent logic we established previously.




==================================================
FILE: PRPs/# 9_9_8.md
==================================================

### PRP: Hybrid Topic Expansion Refactor

**Role:** Senior Search Architect
**Task:** Refactor the Topic Expansion logic to capture both high-level synonyms and deep technical sub-fields.

#### 1. The "Dual-Axis" Prompt

Refine the LLM prompt to explicitly request these two categories.

* **Prompt Logic:**
"The user is researching **{topic}**.
1. List 10 **Direct Synonyms** or alternative names for this field (e.g., 'Spatial Audio' -> '3D Audio', 'Immersive Audio').
2. List 10 **Technical Sub-disciplines** or specific frameworks (e.g., 'Ambisonics', 'Wave Field Synthesis').
**Combine** these into a single comma-separated list of 20 terms."



#### 2. The Query Construction (The Net)

* **Logic:** `("Keyword") AND ("Topic" OR "Synonym1" OR "Synonym2" OR "SubDiscipline1" ...)`
* **Result:** This single query catches:
* The "Generalist" paper: *"Crosstalk Cancellation in **3D Audio** Systems"*
* The "Specialist" paper: *"Crosstalk Cancellation in **Ambisonics** Rendering"*



---

### Implementation Block for the Agent

Give this code to the agent. It ensures we don't miss the "3D Audio" whale while fishing for the "Ambisonics" minnows.

```python
    def search_via_direct_expansion(self):
        print(f"\nüöÄ STARTING DIRECT EXPANSION SEARCH for: '{self.raw_topic}' + '{self.keywords_list[0]}'")
        
        # --- STEP 1: HYBRID TOPIC EXPANSION ---
        print("   üß† Expanding Topic Scope (Horizontal Synonyms + Vertical Sub-disciplines)...")
        prompt = (
            f"The user is researching '{self.raw_topic}'. Generate a combined list of 20 terms that include:\n"
            f"1. DIRECT SYNONYMS (e.g., '3D Audio', 'Immersive Sound').\n"
            f"2. TECHNICAL SUB-DISCIPLINES (e.g., 'Ambisonics', 'Wave Field Synthesis', 'Binaural').\n"
            f"Return ONLY a comma-separated list of the top 20 terms."
        )
        
        raw_synonyms = self.llm_query(prompt)
        # Clean and split
        topic_anchors = [s.strip().replace('"', '') for s in raw_synonyms.split(',') if len(s.strip()) > 3]
        
        print(f"   ‚úÖ Generated {len(topic_anchors)} Hybrid Anchors: {topic_anchors[:5]}...")

        # --- STEP 2: CONSTRUCT THE SUPER-QUERY ---
        # Logic: (Keyword) AND (Topic OR Anchor1 OR Anchor2...)
        
        clean_keyword = self.keywords_list[0].replace('"', '')
        
        # Build the huge OR block
        topic_block = " OR ".join([f'"{t}"' for t in ([self.raw_topic] + topic_anchors)])
        
        # Final Query
        final_query = f'("{clean_keyword}") AND ({topic_block})'
        
        # ... execute ...

```



==================================================
FILE: PRPs/# 9_9 more.md
==================================================


### PRP: Refactoring to High-Yield PDF Auditor

**Role:** Senior Data Systems Engineer
**Task:** Refactor the `ResearchCrawler` to fix the thread-crashes and improve "Expert Panel" targeting.

## 1. Deeper Expert Discovery

* **Action:** Increase the "Probe" count from 50 to **200**.
* **Action:** Select the **Top 15** experts instead of 10.
* **Goal:** This forces the inclusion of specialized authors like Choueiri who might be cited less than the "Founding Fathers" like Blauert.

## 2. Technical Synonym Sanitization

* **Filter:** Discard any learned synonym that matches a "Stop Phrase" list (of the, for the, based on, results of).
* **Requirement:** Learned synonyms must be **at least 2 words long** and contain at least one word longer than 6 characters.

## 3. Robust "Front-Matter" PDF Audit

Refactor the PDF check to be "Crash-Proof":

* **Extraction:** Use `page.get_text("text", flags=fitz.TEXT_PRESERVE_WHITESPACE | fitz.TEXT_DEHYPHENATE)`.
* **Stability:** Specifically ignore "Movie" or "Widget" annotations which are triggering the MuPDF errors.
* **Scope:** Search for the **Fuzzy Regex** (`cross[\s\-]*talk[\s\-]*cancellations?`) only in the first **10,000 characters** of the PDF (the Front-Matter).

---

### The Corrected "Front-Matter" Logic for the Agent

Give this specific code to the agent to replace the current failing PDF check:

```python
import fitz  # PyMuPDF

def robust_front_matter_audit(pdf_path, target_pattern):
    """Audits the first ~2 pages of a PDF without crashing on annotations."""
    try:
        # Open with 'repair' logic ignored to prevent 'Movie' annotation crashes
        doc = fitz.open(pdf_path)
        text_block = ""
        
        # Limit to first 2 pages (The "Gate")
        for i in range(min(2, doc.page_count)):
            page = doc.load_page(i)
            # Use 'text' mode to ignore non-textual streams (Movies, Widgets)
            text_block += page.get_text("text")
            
        doc.close()

        # Fuzzy Regex Check (Title/Abstract/Keywords area)
        if re.search(target_pattern, text_block, re.IGNORECASE):
            return True
        return False
    except Exception as e:
        # Log the error but don't stop the script
        print(f"   ‚ö†Ô∏è Skipping corrupt/complex PDF {pdf_path}: {e}")
        return False

```



==================================================
FILE: PRPs/# Fix 3.md
==================================================

### ** Fix 3 **

The cleanup logic is still failing because the `index.json` file makes the folders appear 'not empty.' Also, the date format is wrong.
**Please rewrite the cleanup and output section of `3_download_library.py` with this specific logic:**
1. **Strict Cleanup:**
* Iterate through all category folders in `./Library`.
* Check if the folder contains any files ending in `.pdf`.
* **If NO `.pdf` files exist:** Delete the entire folder (using `shutil.rmtree`), even if `index.json` exists.


2. **Date Formatting:**
* In the `Library_Catalog.md` output, ensure the date is strictly formatted as **YYYY/MM/DD**.
* Do not just show the Year. If the date is missing, use 'Unknown'.


3. **Order of Operations:**
* Run downloads.
* Run the PDF-based cleanup.
* **Only then** zip the remaining folders into `Library_Export.zip`.






==================================================
FILE: PRPs/# 9_9_9.md
==================================================

# Product Requirements Prompt (PRP): Iterative Vertical Search

**Role:** Senior Search Architect
**Task:** Replace the existing "Backdoor" and "Direct Expansion" search methods with a high-recall **Iterative Loop Strategy**.

## 1. Core Logic: "Divide and Conquer"

Instead of sending one massive, complex query to OpenAlex (which causes the API to drop results), the script must execute **8 separate, high-precision searches**.

* **Hypothesis:** `("binaural") AND ("crosstalk cancellation")` yields 100 papers. `("ambisonics") AND ("crosstalk cancellation")` yields 6 papers. Combining them into one query confuses the indexer. Keeping them separate maximizes yield.

## 2. Phase 1: Vertical Identification (LLM)

* **Action:** Query the LLM to identify the **8 High-Yield Search Verticals** for the user's topic.
* **Prompt Requirement:** Explicitly ask for a mix of **Horizontal Synonyms** (e.g., "3D Audio", "Immersive Sound") and **Vertical Sub-disciplines** (e.g., "Binaural", "Ambisonics").
* **Goal:** These 8 terms act as the "Domain Anchors" for the subsequent loops.

## 3. Phase 2: The Execution Loop

* **Action:** Iterate through the list of 8 verticals.
* **Query Construction:** For each vertical, construct a simple, powerful query: `("{Original_Keyword}") AND ("{Vertical_Term}")`.
* **Execution:** Run the standard `execute_openalex_query` for each loop.
* **Deduplication:** The script must handle duplicates automatically (checking `openalex_id` before adding to the catalog) since some papers will appear in multiple verticals.

## 4. Phase 3: The Validation Gate (Unchanged)

* **Action:** Every candidate found in *any* loop is immediately sent to the **Section-Aware PDF Auditor**.
* **Logic:** Download the PDF -> Extract Page 1 & 2 (Text Only) -> Run Fuzzy Regex for the *Original Keyword*.
* **Result:** This ensures that even if a vertical is broad ("3D Audio"), we only keep papers that specifically mention "Crosstalk Cancellation" in the front matter.

---

### Implementation Code Block

Copy and paste this code into your `ResearchCrawler` class to replace the previous search method.

```python
    def search_via_iterative_loop(self):
        """
        STRATEGY: Divide and Conquer.
        Runs separate, targeted searches for distinct sub-fields to maximize recall 
        and bypass OpenAlex query complexity limits.
        """
        clean_keyword = self.keywords_list[0].replace('"', '')
        print(f"\nüöÄ STARTING ITERATIVE LOOP SEARCH for: '{self.raw_topic}' + '{clean_keyword}'")
        
        # --- STEP 1: GENERATE SEARCH VERTICALS ---
        print("   üß† Defining Search Verticals with LLM...")
        prompt = (
            f"The user is researching '{self.raw_topic}'. Identify the 8 most distinct, high-yield 'Search Verticals' "
            f"for finding papers in this field. \n"
            f"INSTRUCTIONS:\n"
            f"1. Include Broad Synonyms (e.g., if topic is Spatial Audio -> '3D Audio', 'Immersive Audio')\n"
            f"2. Include Core Sub-disciplines (e.g., 'Binaural', 'Ambisonics', 'Wave Field Synthesis')\n"
            f"3. Return ONLY a comma-separated list of 8 terms."
        )
        
        # Get verticals and ensure the original topic is included
        raw_response = self.llm_query(prompt)
        verticals = [s.strip().replace('"', '') for s in raw_response.split(',') if len(s.strip()) > 3]
        
        # Ensure the user's raw topic is always the first loop
        if self.raw_topic not in verticals:
            verticals.insert(0, self.raw_topic)
            
        print(f"   ‚úÖ Targeted Verticals: {verticals}")

        # --- STEP 2: EXECUTE LOOP ---
        total_found = 0
        
        for vertical in verticals:
            print(f"\n   üîÑ Loop: ('{clean_keyword}') AND ('{vertical}')")
            
            # Construct simple, high-power query
            query = f'("{clean_keyword}") AND ("{vertical}")'
            
            # Execute standard query 
            # Note: The execute_openalex_query method handles PDF downloading and Deduplication internally.
            filters = "is_oa:true,type:article|conference-paper"
            if self.date_start: filters += f",publication_year:>{self.year_start-1}"
            
            self.execute_openalex_query(f"Vertical: {vertical}", filters, query)
            
        print(f"\n   üèÅ Iterative Loop Complete. Final Catalog Size: {len(self.research_catalog)}")

```

==================================================
FILE: PRPs/# 11 add BibTeX support.md
==================================================

### **PRP: BibTeX Export Support**

**Context:**
We are upgrading `ScholarStack`. Currently, we output a `Catalog_Summary.md` and `index.json` files. We need to add a **BibTeX export** feature to support users who write in LaTeX.

**The Task:**
Implement a `generate_bibtex(papers)` function and integrate it into the final "Packaging" phase of the pipeline.

**Technical Requirements:**

1. **File Creation:** The app must generate a single file named `library.bib` at the root of the export package (Zip/Drive).
2. **Citation Key Generation:** You must generate a unique "Citation Key" for every paper.
* **Format:** `[FirstAuthorLastName][Year][FirstWordOfTitle]` (e.g., `Vaswani2017Attention`).
* **Sanitization:** Ensure the key contains only alphanumeric characters (no spaces or hyphens).
* **Collision Handling:** If a key already exists (e.g., two papers by Smith in 2023), append a suffix (e.g., `Smith2023Deep_a`, `Smith2023Deep_b`).


3. **Entry Format:** Use the standard `@article{...}` structure.
* Map `title`  `title`
* Map `authors`  `author` (Format: `Lastname, Firstname and Lastname, Firstname...`)
* Map `year`  `year`
* Map `journal`  `journal`
* Map `doi`  `doi`
* Map `url`  `url`
* Map `abstract`  `abstract`


4. **Integration:** Ensure this file is included in the final ZIP archive and the Google Drive upload logic.

**Output:**
Return the Python code for the BibTeX generator function and show where to call it within the `package_library()` function.





==================================================
FILE: PRPs/# 9_9_9_1.md
==================================================

# PRP: "Trust-Based" Logic Refactor

**Role:** Senior Search Engineer
**Task:** Refactor the validation logic to maximize yield by removing the "PDF Download" dependency.

## 1. The New "Lightweight" Gate

Remove the `verify_pdf_frontmatter` requirement from the acceptance loop. Replace it with a metadata check:

* **Step 1:** Construct the `audit_blob` from the OpenAlex `title` + `abstract` + `keywords`.
* **Step 2:** Run the **Fuzzy Regex** (`cross[\s\-]*talk[\s\-]*cancellations?`) on this blob.
* **Step 3:** If Match -> **ACCEPT**.
* **Step 4 (The Safety Net):** If No Match (likely due to truncated abstract), but the paper was found via a specific query -> **ACCEPT** (mark as "Keyword Inferred").

## 2. Deduplication is King

* Ensure that we track `seen_ids` globally across all loops.
* If "Binaural" finds Paper A, and "3D Audio" finds Paper A again, the log should show `[Duplicate] Skipped...` rather than processing it twice.

## 3. PDF is for Storage, Not Validation

* Downloading the PDF becomes a **post-acceptance** task (Phase 3). If the download fails (because it's a landing page), we still keep the metadata in the CSV so you know the paper exists.

---

### Implementation Code Block

Give this to the agent. It removes the "PDF Gate" and will likely jump your yield from 17 to 100+ immediately.

```python
    def _process_batch(self, results):
        """
        Refactored Validation:
        1. Deduplicate.
        2. Audit Metadata (Title/Abstract).
        3. If keyword found OR inferred by search -> Accept.
        4. PDF Download happens LATER (don't kill the paper if download fails).
        """
        import re
        
        # Fuzzy regex for the keyword (handles hyphens/spaces)
        # e.g. "crosstalk cancellation" -> "cross[\s\-]*talk[\s\-]*cancellations?"
        primary_key = self.keywords_list[0].replace('"', '').lower()
        fuzzy_pattern = re.sub(r's?\s+', r'[\\s\\-]*', primary_key) + r's?'
        
        for item in results:
            work_id = item['id']
            
            # 1. Global Deduplication
            if work_id in self.seen_ids:
                continue
            self.seen_ids.add(work_id)
            
            # 2. Construct Audit Blob (Title + Abstract + Keywords)
            title = item.get('title', '')
            if not title: continue # Skip works with no title
            
            abstract = self.reconstruct_abstract(item.get('abstract_inverted_index'))
            keywords = " ".join([k.get('display_name', '') for k in item.get('keywords', [])])
            
            audit_blob = f"{title} {abstract} {keywords}".lower()
            
            # 3. The Logic Check
            # We trust the OpenAlex Search Engine mostly, but we verify if possible.
            match_found = re.search(fuzzy_pattern, audit_blob)
            
            if match_found:
                print(f"   [Accepted] {title[:60]}...")
                self._add_final_result(item)
            else:
                # 4. The Choueiri Safety Net
                # If the abstract is missing/truncated, but OpenAlex returned it for this specific query,
                # we assume their full-text index saw something we can't see. WE KEEP IT.
                print(f"   [Accepted (Inferred)] {title[:60]}...")
                self._add_final_result(item)

            # Stop if we hit the limit
            if len(self.research_catalog) >= self.max_results:
                break

```


==================================================
FILE: data/user_settings.json
==================================================
{
  "topic": "Spatial Audio",
  "keywords": "",
  "keyword_logic": "Match Any (OR)",
  "author": "",
  "publication": "",
  "count": 1000,
  "sort_method": "Citations: Most",
  "auto_folders": false,
  "use_keywords_subfolders": false,
  "filename_format": "Title",
  "use_start_date": false,
  "use_end_date": false,
  "date_start": null,
  "date_end": null
}

==================================================
FILE: data/search_history.json
==================================================
[
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": false,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 17:50:50"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 17:08:54"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 13:28:20"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 11:19:41"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 09:46:10"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 08:15:30"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-31 00:01:41"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 23:35:32"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 23:24:04"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 1000,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": false,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 23:21:25"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 5,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:54:19"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 5,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:44:50"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 5,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:44:36"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 25,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:40:19"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 25,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:33:05"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 10,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:22:04"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 10,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:21:46"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 10,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 21:13:26"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 17:47:28"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 17:35:24"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Citations: Most",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 17:18:59"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 10,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 17:14:50"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 10,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 16:52:48"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 5,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 16:46:28"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 16:25:13"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 16:16:56"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 16:03:19"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 15:41:24"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "filename_format": "Title",
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 15:31:05"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 14:39:45"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 14:39:42"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 14:11:32"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 13:40:44"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 12:56:53"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 12:41:13"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 12:41:07"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 12:12:43"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 11:54:48"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 11:35:24"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 10:56:02"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 10:24:04"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 10:22:33"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-30 10:22:30"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation, personal sound zones",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 50,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-29 17:59:42"
  },
  {
    "topic": "Spatial Audio",
    "keywords": "crosstalk cancellation",
    "keyword_logic": "Match Any (OR)",
    "author": "",
    "publication": "",
    "count": 10,
    "sort_method": "Date: Newest",
    "auto_folders": true,
    "use_keywords_subfolders": true,
    "use_start_date": false,
    "use_end_date": false,
    "date_start": null,
    "date_end": null,
    "timestamp": "2025-12-29 17:09:47"
  }
]

==================================================
FILE: openalex-hybrid-search/open_alex_topic_hybrid_search.py
==================================================
import json
import os
import shutil
from typing import List, Dict, Any

import google.generativeai as genai
import chromadb
from chromadb import Documents, EmbeddingFunction, Embeddings
from rank_bm25 import BM25Okapi

# --- 1. Custom Google Gemini Embedding Function ---
class GeminiEmbeddingFunction(EmbeddingFunction):
    """
    Wrapper for Google's 'text-embedding-004'. 
    """
    def __init__(self, api_key: str, model_name: str = "models/text-embedding-004"):
        genai.configure(api_key=api_key)
        self.model_name = model_name

    def __call__(self, input: Documents) -> Embeddings:
        # Batch embedding with 'retrieval_document' task type
        result = genai.embed_content(
            model=self.model_name,
            content=input,
            task_type="retrieval_document",
            title="Taxonomy Node" 
        )
        return result['embedding']

    def embed_query(self, input: str) -> List[float]:
        # Single query embedding with 'retrieval_query' task type
        result = genai.embed_content(
            model=self.model_name,
            content=input,
            task_type="retrieval_query"
        )
        return result['embedding']


# --- 2. Main Hybrid Search Logic with Caching ---
class HybridTreeSearch:
    def __init__(self, google_api_key: str, persist_dir: str = "./tree_chroma_db"):
        self.persist_dir = persist_dir
        self.gemini_ef = GeminiEmbeddingFunction(api_key=google_api_key)
        
        # Initialize Persistent Client
        self.chroma_client = chromadb.PersistentClient(path=self.persist_dir)
        
        # We always initialize the collection reference
        self.collection_name = "taxonomy_tree"
        self.collection = self.chroma_client.get_or_create_collection(
            name=self.collection_name,
            embedding_function=self.gemini_ef
        )
        
        # In-memory stores for Lexical Search (BM25) and fast retrievals
        self.bm25 = None
        self.doc_store = {} 

    def ingest_tree(self, tree_data: Dict[str, Any], force_rebuild: bool = False):
        """
        Flattens tree and builds indices. 
        CACHE LOGIC: Checks if DB is empty or force_rebuild is True.
        """
        
        # 1. Flatten the tree first (we need this for BM25 regardless of Chroma caching)
        print("Flattening tree structure...")
        flat_nodes = []
        self._flatten_tree(tree_data, [], flat_nodes)
        
        # Populate doc_store and prepare text for BM25
        tokenized_corpus = []
        for i, node in enumerate(flat_nodes):
            node_id = str(i)
            self.doc_store[node_id] = node
            
            # Create rich text representation for search
            text_content = f"{node['node_name']} {node['full_path']}"
            tokenized_corpus.append(text_content.lower().split())

        # 2. Build BM25 Index (Fast, always rebuilt in-memory)
        print(f"Building BM25 index for {len(flat_nodes)} nodes...")
        self.bm25 = BM25Okapi(tokenized_corpus)

        # 3. Check ChromaDB Cache
        existing_count = self.collection.count()
        
        if existing_count > 0 and not force_rebuild:
            print(f"‚úÖ Found {existing_count} cached embeddings in ChromaDB. Skipping ingestion.")
            return

        # 4. Ingestion Logic (Only runs if empty or forced)
        if force_rebuild and existing_count > 0:
            print("Force rebuild requested. Clearing existing collection...")
            self.chroma_client.delete_collection(self.collection_name)
            self.collection = self.chroma_client.get_or_create_collection(
                name=self.collection_name, 
                embedding_function=self.gemini_ef
            )

        print(f"üöÄ Generating embeddings for {len(flat_nodes)} nodes using Gemini (this may take a while)...")
        
        ids = []
        documents = []
        metadatas = []

        for i, node in enumerate(flat_nodes):
            node_id = str(i)
            # Text specifically for the Embedding Model
            # We include context to help distinguishing "Plasma" (Blood) vs "Plasma" (Physics)
            text_for_embedding = f"{node['node_name']} (Context: {node['full_path']})"
            
            ids.append(node_id)
            documents.append(text_for_embedding)
            metadatas.append({
                "path": node['full_path'], 
                "name": node['node_name'], 
                "value": str(node['value']) # Metadata must be string, int, float, or bool
            })

        # Batch Upsert to respect API limits
        batch_size = 50
        for i in range(0, len(ids), batch_size):
            self.collection.upsert(
                ids=ids[i:i+batch_size],
                documents=documents[i:i+batch_size],
                metadatas=metadatas[i:i+batch_size]
            )
            print(f"   Processed {min(i+batch_size, len(ids))}/{len(ids)}...")

        print("Ingestion complete.")

    def _flatten_tree(self, node, ancestry, result_list):
        current_path = ancestry + [node['name']]
        full_path_str = " > ".join(current_path)
        
        entry = {
            'node_name': node['name'],
            'full_path': full_path_str,
            'value': node.get('value', 0),
            'id_ref': node.get('id', '')
        }
        result_list.append(entry)

        if 'children' in node:
            for child in node['children']:
                self._flatten_tree(child, current_path, result_list)

    def search(self, query: str, top_k: int = 5):
        """
        Hybrid Search: BM25 + Gemini Embeddings + Reciprocal Rank Fusion
        """
        # A. BM25 Search
        query_tokens = query.lower().split()
        bm25_scores = self.bm25.get_scores(query_tokens)
        
        # Get top 30 BM25 IDs
        bm25_ranked = sorted(enumerate(bm25_scores), key=lambda x: x[1], reverse=True)[:30]
        bm25_ids = [str(idx) for idx, score in bm25_ranked if score > 0]

        # B. Semantic Search (Chroma)
        results = self.collection.query(
            query_texts=[query], # Chroma calls our Gemini class internally
            n_results=30
        )
        semantic_ids = results['ids'][0]

        # C. Reciprocal Rank Fusion (RRF)
        rrf_score = {}
        k_const = 60

        for rank, doc_id in enumerate(bm25_ids):
            rrf_score[doc_id] = rrf_score.get(doc_id, 0) + (1 / (k_const + rank))

        for rank, doc_id in enumerate(semantic_ids):
            rrf_score[doc_id] = rrf_score.get(doc_id, 0) + (1 / (k_const + rank))

        # Sort and retrieve
        sorted_ids = sorted(rrf_score.keys(), key=lambda x: rrf_score[x], reverse=True)
        
        final_results = []
        for doc_id in sorted_ids[:top_k]:
            if doc_id in self.doc_store:
                final_results.append(self.doc_store[doc_id])
            
        return final_results

# --- Usage ---

if __name__ == "__main__":
    # 1. Configuration
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    if not GOOGLE_API_KEY:
        print("Error: GOOGLE_API_KEY environment variable not set.")
        exit()
    FILE_PATH = 'openalex_tree.json'
    
    # 2. Safety Check
    if not os.path.exists(FILE_PATH):
        print(f"Error: '{FILE_PATH}' not found.")
        exit()

    # 3. Load Data
    with open(FILE_PATH, 'r', encoding='utf-8') as f:
        tree_data = json.load(f)

    # 4. Initialize & Ingest (Cached)
    # Set force_rebuild=True only if you changed the JSON file content
    searcher = HybridTreeSearch(GOOGLE_API_KEY)
    searcher.ingest_tree(tree_data, force_rebuild=False)
    
    # 5. Search Loop
    print("\n--- Search System Ready (Type 'q' to exit) ---")
    while True:
        user_query = input("\nQuery: ")
        if user_query.lower() in ['q', 'quit']:
            break
        
        results = searcher.search(user_query)
        
        print(f"Top results for '{user_query}':")
        for i, res in enumerate(results):
            print(f"{i+1}. {res['node_name']}")
            print(f"   Context: {res['full_path']}")

==================================================
FILE: openalex-hybrid-search/quick guide.md
==================================================
## Quick Guide: `open_alex_topic_hybrid_search.py`

This script creates a powerful **Hybrid Search Engine** for your OpenAlex taxonomy tree. It combines:

1. **Lexical Search (BM25):** Finds exact keyword matches (e.g., "Nuclear Physics").
2. **Semantic Search (Gemini + ChromaDB):** Finds conceptual matches (e.g., "Heart Attack" ‚Üí "Myocardial Infarction").
3. **Smart Caching:** Saves the database locally so you don't pay for or wait for embeddings every time you run it.

---

### 1. Prerequisites

You need Python installed and the following libraries:

```bash
pip install google-generativeai chromadb rank-bm25

```

You also need a **Google AI Studio API Key** (Free tier is sufficient).

### 2. Setup

Ensure your folder structure looks like this:

```text
/my_project_folder
  ‚îú‚îÄ‚îÄ open_alex_topic_hybrid_search.py   # The script provided above
  ‚îú‚îÄ‚îÄ openalex_tree.json                 # Your taxonomy data file
  ‚îî‚îÄ‚îÄ tree_chroma_db/                    # (Created automatically after first run)

```

### 3. Configuration

Open the script `open_alex_topic_hybrid_search.py` in your code editor.

Scroll to the bottom `if __name__ == "__main__":` section and replace the placeholder with your actual key:

```python
GOOGLE_API_KEY = "AIzaSy..."  # <-- Paste your Google API Key here

```

### 4. Running the Search

Run the script from your terminal:

```bash
python open_alex_topic_hybrid_search.py

```

**What happens next?**

1. **First Run:** The script will detect that the database is empty. It will flatten your JSON tree and send the nodes to Google Gemini to generate embeddings. This might take a minute or two depending on the size of your tree.
2. **Subsequent Runs:** The script sees the `tree_chroma_db` folder. It **skips** the embedding generation and loads instantly.

### 5. Using the Search

Once loaded, you will see a prompt:

```text
--- Search System Ready (Type 'q' to exit) ---

Query: 

```

Type any term to test the hybrid capability:

* *Exact:* "Nuclear Fusion"
* *Vague:* "Clean energy sources"
* *Concept:* "Study of old coins" (Should find Numismatics or Archaeology)

### 6. Updating the Data

If you change `openalex_tree.json`, the cache will be outdated. To fix this, edit the script's usage section to force a rebuild **once**:

```python
# Change force_rebuild to True for one run
searcher.ingest_tree(tree_data, force_rebuild=True)

```

Run the script, then change it back to `False` to enjoy the caching again.

==================================================
FILE: openalex-hybrid-search/openalex_tree.json
==================================================
{"name": "All Science", "children": [{"name": "Physical Sciences", "children": [{"name": "Physics and Astronomy", "children": [{"name": "Nuclear and High Energy Physics", "children": [{"name": "Magnetic confinement fusion research", "value": 9266920, "id": "https://openalex.org/T10346"}, {"name": "Laser-Plasma Interactions and Diagnostics", "value": 721217, "id": "https://openalex.org/T10384"}, {"name": "Particle Detector Development and Performance", "value": 556179, "id": "https://openalex.org/T11044"}, {"name": "Particle physics theoretical and experimental studies", "value": 444931, "id": "https://openalex.org/T10048"}, {"name": "Quantum Chromodynamics and Particle Interactions", "value": 226085, "id": "https://openalex.org/T10224"}, {"name": "Black Holes and Theoretical Physics", "value": 225713, "id": "https://openalex.org/T10025"}, {"name": "Nuclear physics research studies", "value": 216818, "id": "https://openalex.org/T10093"}, {"name": "High-Energy Particle Collisions Research", "value": 186094, "id": "https://openalex.org/T10527"}, {"name": "Astrophysics and Cosmic Phenomena", "value": 147369, "id": "https://openalex.org/T10818"}, {"name": "Neutrino Physics Research", "value": 83726, "id": "https://openalex.org/T10921"}, {"name": "Dark Matter and Cosmic Phenomena", "value": 81967, "id": "https://openalex.org/T11090"}, {"name": "NMR spectroscopy and applications", "value": 47891, "id": "https://openalex.org/T12603"}, {"name": "Astronomical and nuclear sciences", "value": 14923, "id": "https://openalex.org/T13458"}]}, {"name": "Astronomy and Astrophysics", "children": [{"name": "Superconducting and THz Device Technology", "value": 624321, "id": "https://openalex.org/T11803"}, {"name": "Solar and Space Plasma Dynamics", "value": 466379, "id": "https://openalex.org/T10251"}, {"name": "Astrophysical Phenomena and Observations", "value": 459988, "id": "https://openalex.org/T10744"}, {"name": "Astro and Planetary Science", "value": 312199, "id": "https://openalex.org/T10325"}, {"name": "History and Developments in Astronomy", "value": 301455, "id": "https://openalex.org/T12836"}, {"name": "Stellar, planetary, and galactic studies", "value": 269830, "id": "https://openalex.org/T10039"}, {"name": "Cosmology and Gravitation Theories", "value": 232029, "id": "https://openalex.org/T10095"}, {"name": "Galaxies: Formation, Evolution, Phenomena", "value": 217073, "id": "https://openalex.org/T10026"}, {"name": "Lightning and Electromagnetic Phenomena", "value": 212087, "id": "https://openalex.org/T10787"}, {"name": "Ionosphere and magnetosphere dynamics", "value": 203907, "id": "https://openalex.org/T10159"}, {"name": "Planetary Science and Exploration", "value": 178872, "id": "https://openalex.org/T10406"}, {"name": "Astrophysics and Star Formation Studies", "value": 153108, "id": "https://openalex.org/T10477"}, {"name": "Historical Astronomy and Related Studies", "value": 140682, "id": "https://openalex.org/T13175"}, {"name": "Pulsars and Gravitational Waves Research", "value": 133042, "id": "https://openalex.org/T10463"}, {"name": "Gamma-ray bursts and supernovae", "value": 119759, "id": "https://openalex.org/T11323"}, {"name": "Space exploration and regulation", "value": 94616, "id": "https://openalex.org/T12717"}, {"name": "Space Science and Extraterrestrial Life", "value": 91846, "id": "https://openalex.org/T12788"}, {"name": "Relativity and Gravitational Theory", "value": 82585, "id": "https://openalex.org/T11960"}, {"name": "Radio Astronomy Observations and Technology", "value": 64760, "id": "https://openalex.org/T12450"}, {"name": "Origins and Evolution of Life", "value": 50919, "id": "https://openalex.org/T11445"}, {"name": "Advanced Differential Geometry Research", "value": 25015, "id": "https://openalex.org/T13080"}]}, {"name": "Atomic and Molecular Physics, and Optics", "children": [{"name": "Gyrotron and Vacuum Electronics Research", "value": 539125, "id": "https://openalex.org/T11175"}, {"name": "Atomic and Subatomic Physics Research", "value": 364350, "id": "https://openalex.org/T11993"}, {"name": "Adaptive optics and wavefront sensing", "value": 261603, "id": "https://openalex.org/T11484"}, {"name": "Advanced Frequency and Time Standards", "value": 237438, "id": "https://openalex.org/T12004"}, {"name": "Advanced Chemical Physics Studies", "value": 195209, "id": "https://openalex.org/T10002"}, {"name": "Photorefractive and Nonlinear Optics", "value": 192344, "id": "https://openalex.org/T11050"}, {"name": "Atomic and Molecular Physics", "value": 166027, "id": "https://openalex.org/T10523"}, {"name": "Semiconductor Quantum Structures and Devices", "value": 155439, "id": "https://openalex.org/T10022"}, {"name": "Cold Atom Physics and Bose-Einstein Condensates", "value": 150725, "id": "https://openalex.org/T10425"}, {"name": "Quantum and electron transport phenomena", "value": 142004, "id": "https://openalex.org/T10382"}, {"name": "Quantum Mechanics and Applications", "value": 138746, "id": "https://openalex.org/T10622"}, {"name": "Spectroscopy and Quantum Chemical Studies", "value": 136940, "id": "https://openalex.org/T11177"}, {"name": "Magnetic properties of thin films", "value": 130796, "id": "https://openalex.org/T10049"}, {"name": "Electrical and Electromagnetic Research", "value": 97348, "id": "https://openalex.org/T14311"}, {"name": "Advanced Fiber Laser Technologies", "value": 95788, "id": "https://openalex.org/T10988"}, {"name": "Quantum, superfluid, helium dynamics", "value": 92018, "id": "https://openalex.org/T11965"}, {"name": "Laser-Matter Interactions and Applications", "value": 89091, "id": "https://openalex.org/T10566"}, {"name": "Force Microscopy Techniques and Applications", "value": 87286, "id": "https://openalex.org/T10923"}, {"name": "Topological Materials and Phenomena", "value": 86839, "id": "https://openalex.org/T10657"}, {"name": "Semiconductor materials and interfaces", "value": 72252, "id": "https://openalex.org/T11853"}, {"name": "Photonic Crystals and Applications", "value": 68072, "id": "https://openalex.org/T10666"}, {"name": "Mechanical and Optical Resonators", "value": 64852, "id": "https://openalex.org/T11449"}, {"name": "Color Science and Applications", "value": 61175, "id": "https://openalex.org/T11666"}, {"name": "Electromagnetic Scattering and Analysis", "value": 60428, "id": "https://openalex.org/T10739"}, {"name": "Orbital Angular Momentum in Optics", "value": 56942, "id": "https://openalex.org/T10490"}, {"name": "Quantum optics and atomic interactions", "value": 54773, "id": "https://openalex.org/T11414"}, {"name": "Quantum Mechanics and Non-Hermitian Physics", "value": 53934, "id": "https://openalex.org/T11262"}, {"name": "Surface and Thin Film Phenomena", "value": 50746, "id": "https://openalex.org/T13531"}, {"name": "Quantum many-body systems", "value": 48829, "id": "https://openalex.org/T11804"}, {"name": "Quantum and Classical Electrodynamics", "value": 44962, "id": "https://openalex.org/T11683"}, {"name": "Quantum Electrodynamics and Casimir Effect", "value": 37054, "id": "https://openalex.org/T12220"}, {"name": "Optical and Acousto-Optic Technologies", "value": 34824, "id": "https://openalex.org/T13493"}, {"name": "Dust and Plasma Wave Phenomena", "value": 32334, "id": "https://openalex.org/T11603"}, {"name": "Vacuum and Plasma Arcs", "value": 27635, "id": "https://openalex.org/T12077"}, {"name": "Digital Holography and Microscopy", "value": 24729, "id": "https://openalex.org/T11897"}, {"name": "Strong Light-Matter Interactions", "value": 23777, "id": "https://openalex.org/T12612"}, {"name": "Optical properties and cooling technologies in crystalline materials", "value": 8991, "id": "https://openalex.org/T14363"}]}, {"name": "Condensed Matter Physics", "children": [{"name": "Theoretical and Computational Physics", "value": 478569, "id": "https://openalex.org/T10591"}, {"name": "Physics of Superconductivity and Magnetism", "value": 262942, "id": "https://openalex.org/T10037"}, {"name": "Crystallography and Radiation Phenomena", "value": 262409, "id": "https://openalex.org/T12762"}, {"name": "GaN-based semiconductor devices and materials", "value": 121629, "id": "https://openalex.org/T10099"}, {"name": "Rare-earth and actinide compounds", "value": 102118, "id": "https://openalex.org/T10681"}, {"name": "Advanced Condensed Matter Physics", "value": 51981, "id": "https://openalex.org/T11682"}, {"name": "Micro and Nano Robotics", "value": 45620, "id": "https://openalex.org/T11486"}, {"name": "Superconductivity in MgB2 and Alloys", "value": 19262, "id": "https://openalex.org/T12491"}]}, {"name": "Instrumentation", "children": [{"name": "Astronomy and Astrophysical Research", "value": 328915, "id": "https://openalex.org/T12917"}, {"name": "Advanced Optical Sensing Technologies", "value": 61760, "id": "https://openalex.org/T12153"}]}, {"name": "Radiation", "children": [{"name": "Nuclear Physics and Applications", "value": 214493, "id": "https://openalex.org/T11949"}, {"name": "Radiation Detection and Scintillator Technologies", "value": 141881, "id": "https://openalex.org/T11216"}, {"name": "X-ray Spectroscopy and Fluorescence Analysis", "value": 130692, "id": "https://openalex.org/T11733"}, {"name": "Advanced Radiotherapy Techniques", "value": 121322, "id": "https://openalex.org/T10358"}, {"name": "Advanced X-ray Imaging Techniques", "value": 68820, "id": "https://openalex.org/T11183"}, {"name": "Radioactive Decay and Measurement Techniques", "value": 52919, "id": "https://openalex.org/T13414"}]}, {"name": "Statistical and Nonlinear Physics", "children": [{"name": "Advanced Thermodynamics and Statistical Mechanics", "value": 130956, "id": "https://openalex.org/T11520"}, {"name": "Complex Network Analysis Techniques", "value": 113591, "id": "https://openalex.org/T10064"}, {"name": "Nonlinear Waves and Solitons", "value": 102846, "id": "https://openalex.org/T10248"}, {"name": "Experimental and Theoretical Physics Studies", "value": 101201, "id": "https://openalex.org/T12250"}, {"name": "Quantum chaos and dynamical systems", "value": 80438, "id": "https://openalex.org/T11261"}, {"name": "Noncommutative and Quantum Gravity Theories", "value": 63008, "id": "https://openalex.org/T11415"}, {"name": "Model Reduction and Neural Networks", "value": 56566, "id": "https://openalex.org/T11206"}, {"name": "Scientific Research and Discoveries", "value": 55999, "id": "https://openalex.org/T13126"}, {"name": "Opinion Dynamics and Social Influence", "value": 53312, "id": "https://openalex.org/T12592"}, {"name": "Chaos control and synchronization", "value": 46990, "id": "https://openalex.org/T10244"}, {"name": "Statistical Mechanics and Entropy", "value": 42362, "id": "https://openalex.org/T12261"}, {"name": "Advanced Mathematical Theories and Applications", "value": 42035, "id": "https://openalex.org/T12516"}, {"name": "Nonlinear Photonic Systems", "value": 37822, "id": "https://openalex.org/T11575"}, {"name": "stochastic dynamics and bifurcation", "value": 35996, "id": "https://openalex.org/T11513"}, {"name": "Fusion and Plasma Physics Studies", "value": 30357, "id": "https://openalex.org/T13769"}, {"name": "Complex Systems and Dynamics", "value": 4664, "id": "https://openalex.org/T14299"}]}, {"name": "Acoustics and Ultrasonics", "children": [{"name": "Random lasers and scattering media", "value": 24946, "id": "https://openalex.org/T11996"}]}]}, {"name": "Computer Science", "children": [{"name": "Artificial Intelligence", "children": [{"name": "Geochemistry and Geologic Mapping", "value": 3953226, "id": "https://openalex.org/T12157"}, {"name": "Computational Physics and Python Applications", "value": 408987, "id": "https://openalex.org/T13650"}, {"name": "Natural Language Processing Techniques", "value": 285120, "id": "https://openalex.org/T10181"}, {"name": "Neural Networks and Applications", "value": 246035, "id": "https://openalex.org/T10320"}, {"name": "Data Analysis with R", "value": 223368, "id": "https://openalex.org/T13398"}, {"name": "Advanced Computational Techniques and Applications", "value": 179467, "id": "https://openalex.org/T13734"}, {"name": "Semantic Web and Ontologies", "value": 168657, "id": "https://openalex.org/T10215"}, {"name": "Educational Robotics and Engineering", "value": 161747, "id": "https://openalex.org/T14335"}, {"name": "Linguistic Studies and Language Acquisition", "value": 151922, "id": "https://openalex.org/T13623"}, {"name": "Topic Modeling", "value": 142792, "id": "https://openalex.org/T10028"}, {"name": "Quantum Information and Cryptography", "value": 138124, "id": "https://openalex.org/T10020"}, {"name": "Quantum Computing Algorithms and Architecture", "value": 107233, "id": "https://openalex.org/T10682"}, {"name": "Logic, programming, and type systems", "value": 100018, "id": "https://openalex.org/T10126"}, {"name": "Speech Recognition and Synthesis", "value": 89644, "id": "https://openalex.org/T10201"}, {"name": "Edcuational Technology Systems", "value": 79563, "id": "https://openalex.org/T13559"}, {"name": "Cryptography and Data Security", "value": 75877, "id": "https://openalex.org/T10237"}, {"name": "AI in cancer detection", "value": 74866, "id": "https://openalex.org/T10862"}, {"name": "Privacy-Preserving Technologies in Data", "value": 73505, "id": "https://openalex.org/T10764"}, {"name": "Evolutionary Algorithms and Applications", "value": 72585, "id": "https://openalex.org/T11975"}, {"name": "Logic, Reasoning, and Knowledge", "value": 71862, "id": "https://openalex.org/T11010"}, {"name": "Anomaly Detection Techniques and Applications", "value": 71442, "id": "https://openalex.org/T11512"}, {"name": "Algorithms and Data Compression", "value": 70357, "id": "https://openalex.org/T11269"}, {"name": "Metaheuristic Optimization Algorithms Research", "value": 68319, "id": "https://openalex.org/T10100"}, {"name": "Coding theory and cryptography", "value": 63429, "id": "https://openalex.org/T11130"}, {"name": "Sentiment Analysis and Opinion Mining", "value": 59952, "id": "https://openalex.org/T10664"}, {"name": "Advanced Software Engineering Methodologies", "value": 57782, "id": "https://openalex.org/T10639"}, {"name": "Target Tracking and Data Fusion in Sensor Networks", "value": 56157, "id": "https://openalex.org/T10711"}, {"name": "Fuzzy Logic and Control Systems", "value": 55794, "id": "https://openalex.org/T10820"}, {"name": "Seismology and Earthquake Studies", "value": 55253, "id": "https://openalex.org/T13018"}, {"name": "Speech and dialogue systems", "value": 54943, "id": "https://openalex.org/T12031"}, {"name": "Bayesian Methods and Mixture Models", "value": 54570, "id": "https://openalex.org/T11901"}, {"name": "Computer Science and Engineering", "value": 53247, "id": "https://openalex.org/T13674"}, {"name": "Bayesian Modeling and Causal Inference", "value": 53160, "id": "https://openalex.org/T11303"}, {"name": "Intelligent Tutoring Systems and Adaptive Learning", "value": 52964, "id": "https://openalex.org/T11902"}, {"name": "Multi-Agent Systems and Negotiation", "value": 52728, "id": "https://openalex.org/T10456"}, {"name": "Solar Radiation and Photovoltaics", "value": 51774, "id": "https://openalex.org/T11276"}, {"name": "AI-based Problem Solving and Planning", "value": 49223, "id": "https://openalex.org/T10906"}, {"name": "Reinforcement Learning in Robotics", "value": 47817, "id": "https://openalex.org/T10462"}, {"name": "Adversarial Robustness in Machine Learning", "value": 47369, "id": "https://openalex.org/T11689"}, {"name": "Advanced Graph Neural Networks", "value": 44921, "id": "https://openalex.org/T11273"}, {"name": "AI in Service Interactions", "value": 44506, "id": "https://openalex.org/T12128"}, {"name": "Artificial Intelligence in Games", "value": 44047, "id": "https://openalex.org/T11574"}, {"name": "Advanced Text Analysis Techniques", "value": 43575, "id": "https://openalex.org/T13083"}, {"name": "Educational Technology and Pedagogy", "value": 42155, "id": "https://openalex.org/T12260"}, {"name": "Organizational and Employee Performance", "value": 41268, "id": "https://openalex.org/T14064"}, {"name": "Cryptographic Implementations and Security", "value": 40983, "id": "https://openalex.org/T10951"}, {"name": "Hate Speech and Cyberbullying Detection", "value": 40344, "id": "https://openalex.org/T12262"}, {"name": "Domain Adaptation and Few-Shot Learning", "value": 40205, "id": "https://openalex.org/T11307"}, {"name": "Internet Traffic Analysis and Secure E-voting", "value": 37957, "id": "https://openalex.org/T11598"}, {"name": "Cognitive Science and Mapping", "value": 37951, "id": "https://openalex.org/T12805"}, {"name": "Explainable Artificial Intelligence (XAI)", "value": 37575, "id": "https://openalex.org/T12026"}, {"name": "Security and Verification in Computing", "value": 37136, "id": "https://openalex.org/T11424"}, {"name": "Machine Learning and Data Classification", "value": 37077, "id": "https://openalex.org/T12535"}, {"name": "Advanced Clustering Algorithms Research", "value": 35644, "id": "https://openalex.org/T10637"}, {"name": "Machine Learning in Healthcare", "value": 35594, "id": "https://openalex.org/T13702"}, {"name": "Psychiatry, Mental Health, Neuroscience", "value": 33504, "id": "https://openalex.org/T14381"}, {"name": "Machine Learning and Algorithms", "value": 33489, "id": "https://openalex.org/T12072"}, {"name": "Imbalanced Data Classification Techniques", "value": 33093, "id": "https://openalex.org/T11652"}, {"name": "Text and Document Classification Technologies", "value": 33086, "id": "https://openalex.org/T11550"}, {"name": "Law, AI, and Intellectual Property", "value": 30529, "id": "https://openalex.org/T13851"}, {"name": "Neural Networks and Reservoir Computing", "value": 30461, "id": "https://openalex.org/T12611"}, {"name": "Diverse Interdisciplinary Research Studies", "value": 27189, "id": "https://openalex.org/T13898"}, {"name": "Statistical and Computational Modeling", "value": 26350, "id": "https://openalex.org/T14351"}, {"name": "Authorship Attribution and Profiling", "value": 22941, "id": "https://openalex.org/T12380"}, {"name": "Gaussian Processes and Bayesian Inference", "value": 21814, "id": "https://openalex.org/T12814"}, {"name": "Stochastic Gradient Optimization Techniques", "value": 21482, "id": "https://openalex.org/T11612"}, {"name": "Data Stream Mining Techniques", "value": 19367, "id": "https://openalex.org/T12761"}, {"name": "Text Readability and Simplification", "value": 18469, "id": "https://openalex.org/T13629"}, {"name": "Cognitive Computing and Networks", "value": 16634, "id": "https://openalex.org/T13062"}, {"name": "Wireless Signal Modulation Classification", "value": 16516, "id": "https://openalex.org/T12131"}, {"name": "Machine Learning and ELM", "value": 16269, "id": "https://openalex.org/T12676"}, {"name": "Artificial Intelligence Applications", "value": 15005, "id": "https://openalex.org/T13904"}, {"name": "Mathematical Control Systems and Analysis", "value": 14729, "id": "https://openalex.org/T13935"}, {"name": "Advanced Technologies in Various Fields", "value": 12614, "id": "https://openalex.org/T14413"}, {"name": "Intuitionistic Fuzzy Systems Applications", "value": 7734, "id": "https://openalex.org/T14175"}, {"name": "AI and Multimedia in Education", "value": 3850, "id": "https://openalex.org/T13567"}, {"name": "Experience-Based Knowledge Management", "value": 2551, "id": "https://openalex.org/T13514"}]}, {"name": "Information Systems", "children": [{"name": "Research Data Management Practices", "value": 328488, "id": "https://openalex.org/T11937"}, {"name": "Educational Methods and Media Use", "value": 306332, "id": "https://openalex.org/T13602"}, {"name": "Higher Education and Teaching Methods", "value": 154606, "id": "https://openalex.org/T14430"}, {"name": "Blockchain Technology Applications and Security", "value": 132218, "id": "https://openalex.org/T10270"}, {"name": "Web and Library Services", "value": 131582, "id": "https://openalex.org/T12863"}, {"name": "Cloud Computing and Resource Management", "value": 120819, "id": "https://openalex.org/T10101"}, {"name": "Service-Oriented Architecture and Web Services", "value": 113614, "id": "https://openalex.org/T10679"}, {"name": "Education and Learning Interventions", "value": 99189, "id": "https://openalex.org/T13565"}, {"name": "Software Engineering Research", "value": 98944, "id": "https://openalex.org/T10260"}, {"name": "Educational Innovations and Technology", "value": 93640, "id": "https://openalex.org/T12395"}, {"name": "Educational Systems and Policies", "value": 90257, "id": "https://openalex.org/T14409"}, {"name": "Library Collection Development and Digital Resources", "value": 90184, "id": "https://openalex.org/T11813"}, {"name": "Software Engineering Techniques and Practices", "value": 88188, "id": "https://openalex.org/T10430"}, {"name": "Information and Cyber Security", "value": 87490, "id": "https://openalex.org/T10734"}, {"name": "Library Science and Information Systems", "value": 86850, "id": "https://openalex.org/T14330"}, {"name": "QR Code Applications and Technologies", "value": 85648, "id": "https://openalex.org/T13270"}, {"name": "Educational Innovations and Challenges", "value": 82218, "id": "https://openalex.org/T12408"}, {"name": "Data Mining Algorithms and Applications", "value": 81101, "id": "https://openalex.org/T10538"}, {"name": "Mobile Learning in Education", "value": 72998, "id": "https://openalex.org/T11370"}, {"name": "Blockchain Technology in Education and Learning", "value": 69781, "id": "https://openalex.org/T13913"}, {"name": "Educational Technology and Assessment", "value": 68199, "id": "https://openalex.org/T14025"}, {"name": "Recommender Systems and Techniques", "value": 66784, "id": "https://openalex.org/T10203"}, {"name": "Multimedia Learning Systems", "value": 53802, "id": "https://openalex.org/T14216"}, {"name": "Web Data Mining and Analysis", "value": 53337, "id": "https://openalex.org/T12016"}, {"name": "Educational Methods and Teacher Development", "value": 52413, "id": "https://openalex.org/T13386"}, {"name": "Data Mining and Machine Learning Applications", "value": 51677, "id": "https://openalex.org/T13373"}, {"name": "Advanced Decision-Making Techniques", "value": 51402, "id": "https://openalex.org/T13832"}, {"name": "Technology and Data Analysis", "value": 51402, "id": "https://openalex.org/T14484"}, {"name": "ICT in Developing Communities", "value": 50989, "id": "https://openalex.org/T13194"}, {"name": "Big Data and Digital Economy", "value": 49070, "id": "https://openalex.org/T14347"}, {"name": "Information Science and Libraries", "value": 48224, "id": "https://openalex.org/T13166"}, {"name": "Economic Growth and Development", "value": 48169, "id": "https://openalex.org/T13867"}, {"name": "Mobile and Web Applications", "value": 46806, "id": "https://openalex.org/T12799"}, {"name": "Educational Technology in Learning", "value": 42922, "id": "https://openalex.org/T14498"}, {"name": "Innovative Educational Technologies", "value": 40836, "id": "https://openalex.org/T13016"}, {"name": "Scientific Research and Philosophical Inquiry", "value": 40744, "id": "https://openalex.org/T14345"}, {"name": "Healthcare during COVID-19 Pandemic", "value": 40542, "id": "https://openalex.org/T14071"}, {"name": "Cybercrime and Law Enforcement Studies", "value": 38435, "id": "https://openalex.org/T12519"}, {"name": "Chemical and Environmental Engineering Research", "value": 36843, "id": "https://openalex.org/T14215"}, {"name": "Spam and Phishing Detection", "value": 36488, "id": "https://openalex.org/T11644"}, {"name": "Digital and Cyber Forensics", "value": 34271, "id": "https://openalex.org/T12034"}, {"name": "Digital literacy in education", "value": 33901, "id": "https://openalex.org/T12338"}, {"name": "User Authentication and Security Systems", "value": 33546, "id": "https://openalex.org/T11800"}, {"name": "Cloud Data Security Solutions", "value": 32761, "id": "https://openalex.org/T11614"}, {"name": "English Language Learning and Teaching", "value": 32739, "id": "https://openalex.org/T14516"}, {"name": "Environmental Engineering and Cultural Studies", "value": 31362, "id": "https://openalex.org/T14387"}, {"name": "Digital Rights Management and Security", "value": 30822, "id": "https://openalex.org/T13999"}, {"name": "Information Retrieval and Search Behavior", "value": 30052, "id": "https://openalex.org/T10286"}, {"name": "Information Systems Education and Curriculum Development", "value": 28904, "id": "https://openalex.org/T13034"}, {"name": "Educational Challenges and Innovations", "value": 28331, "id": "https://openalex.org/T14403"}, {"name": "Technology and Security Systems", "value": 28195, "id": "https://openalex.org/T14042"}, {"name": "Information Retrieval and Data Mining", "value": 25821, "id": "https://openalex.org/T14435"}, {"name": "Cryptography and Residue Arithmetic", "value": 22535, "id": "https://openalex.org/T11693"}, {"name": "Library Science and Information", "value": 22375, "id": "https://openalex.org/T13673"}, {"name": "Information Architecture and Usability", "value": 18463, "id": "https://openalex.org/T13874"}, {"name": "Web Applications and Data Management", "value": 18258, "id": "https://openalex.org/T12601"}, {"name": "Advanced Computational Techniques in Science and Engineering", "value": 18194, "id": "https://openalex.org/T13608"}, {"name": "COVID-19 Digital Contact Tracing", "value": 17208, "id": "https://openalex.org/T12943"}, {"name": "Internet of Things and AI", "value": 17016, "id": "https://openalex.org/T13038"}, {"name": "Web visibility and informetrics", "value": 14681, "id": "https://openalex.org/T13976"}, {"name": "Digital Education and Society", "value": 14357, "id": "https://openalex.org/T13081"}, {"name": "Web Application Security Vulnerabilities", "value": 13995, "id": "https://openalex.org/T12479"}, {"name": "Engineering Education and Technology", "value": 12661, "id": "https://openalex.org/T13482"}, {"name": "Bioethics and Human Rights Issues", "value": 12179, "id": "https://openalex.org/T14307"}, {"name": "Expert finding and Q&A systems", "value": 10948, "id": "https://openalex.org/T13274"}, {"name": "Artificial Intelligence in Education", "value": 10481, "id": "https://openalex.org/T14414"}, {"name": "Diverse Research and Applications", "value": 7612, "id": "https://openalex.org/T14431"}, {"name": "Educational Technology and Optimization", "value": 6859, "id": "https://openalex.org/T13964"}, {"name": "Thoreau and American Literature", "value": 6303, "id": "https://openalex.org/T14029"}, {"name": "Innovations in Education and Learning Technologies", "value": 5923, "id": "https://openalex.org/T14519"}, {"name": "Educational Methods and Technology", "value": 5188, "id": "https://openalex.org/T13873"}, {"name": "Educational Management and Quality", "value": 4779, "id": "https://openalex.org/T14103"}, {"name": "Advanced Technology in Applications", "value": 3717, "id": "https://openalex.org/T14155"}, {"name": "AI and Big Data Applications", "value": 3526, "id": "https://openalex.org/T13647"}, {"name": "Education, Technology, and Economics", "value": 3419, "id": "https://openalex.org/T13932"}, {"name": "Artificial Intelligence and Decision Support Systems", "value": 2699, "id": "https://openalex.org/T14174"}, {"name": "Educational Technology and E-Learning", "value": 2646, "id": "https://openalex.org/T14496"}, {"name": "Educational and Technological Research", "value": 1168, "id": "https://openalex.org/T13676"}]}, {"name": "Computer Science Applications", "children": [{"name": "History of Computing Technologies", "value": 314458, "id": "https://openalex.org/T12797"}, {"name": "E-Learning and Knowledge Management", "value": 94603, "id": "https://openalex.org/T14246"}, {"name": "Online Learning and Analytics", "value": 87501, "id": "https://openalex.org/T11122"}, {"name": "Open Education and E-Learning", "value": 82286, "id": "https://openalex.org/T12171"}, {"name": "Teaching and Learning Programming", "value": 73433, "id": "https://openalex.org/T10533"}, {"name": "Open Source Software Innovations", "value": 34290, "id": "https://openalex.org/T11675"}, {"name": "IoT-based Control Systems", "value": 22711, "id": "https://openalex.org/T13541"}, {"name": "Mobile Crowdsensing and Crowdsourcing", "value": 20843, "id": "https://openalex.org/T11704"}, {"name": "Digital Media and Philosophy", "value": 12815, "id": "https://openalex.org/T14114"}, {"name": "Scientific Research and Technology", "value": 11235, "id": "https://openalex.org/T14100"}]}, {"name": "Computer Vision and Pattern Recognition", "children": [{"name": "Image Processing and 3D Reconstruction", "value": 233055, "id": "https://openalex.org/T14339"}, {"name": "Music Technology and Sound Studies", "value": 147806, "id": "https://openalex.org/T11349"}, {"name": "Advanced Image and Video Retrieval Techniques", "value": 116095, "id": "https://openalex.org/T10627"}, {"name": "Robotic Path Planning Algorithms", "value": 108965, "id": "https://openalex.org/T10586"}, {"name": "Advanced Vision and Imaging", "value": 102192, "id": "https://openalex.org/T10531"}, {"name": "Image and Signal Denoising Methods", "value": 89468, "id": "https://openalex.org/T10688"}, {"name": "Advanced Neural Network Applications", "value": 87471, "id": "https://openalex.org/T10036"}, {"name": "Medical Image Segmentation Techniques", "value": 80800, "id": "https://openalex.org/T10052"}, {"name": "Video Surveillance and Tracking Methods", "value": 79036, "id": "https://openalex.org/T10331"}, {"name": "Data Visualization and Analytics", "value": 77810, "id": "https://openalex.org/T10799"}, {"name": "Image Retrieval and Classification Techniques", "value": 76101, "id": "https://openalex.org/T10824"}, {"name": "Face and Expression Recognition", "value": 72397, "id": "https://openalex.org/T10057"}, {"name": "Augmented Reality Applications", "value": 70525, "id": "https://openalex.org/T10888"}, {"name": "Advanced Steganography and Watermarking Techniques", "value": 69610, "id": "https://openalex.org/T10388"}, {"name": "Optical measurement and interference techniques", "value": 68387, "id": "https://openalex.org/T10638"}, {"name": "Handwritten Text Recognition Techniques", "value": 67884, "id": "https://openalex.org/T10601"}, {"name": "Context-Aware Activity Recognition Systems", "value": 66796, "id": "https://openalex.org/T10444"}, {"name": "Advanced Data Compression Techniques", "value": 65376, "id": "https://openalex.org/T10901"}, {"name": "Chaos-based Image/Signal Encryption", "value": 54644, "id": "https://openalex.org/T11017"}, {"name": "Face recognition and analysis", "value": 52781, "id": "https://openalex.org/T11448"}, {"name": "Video Analysis and Summarization", "value": 46868, "id": "https://openalex.org/T11439"}, {"name": "Human Pose and Action Recognition", "value": 45664, "id": "https://openalex.org/T10812"}, {"name": "Multimodal Machine Learning Applications", "value": 45307, "id": "https://openalex.org/T11714"}, {"name": "Generative Adversarial Networks and Image Synthesis", "value": 41630, "id": "https://openalex.org/T10775"}, {"name": "Image Enhancement Techniques", "value": 40948, "id": "https://openalex.org/T11019"}, {"name": "Advanced Image Processing Techniques", "value": 38193, "id": "https://openalex.org/T11105"}, {"name": "Graph Theory and Algorithms", "value": 36016, "id": "https://openalex.org/T12292"}, {"name": "Image and Video Quality Assessment", "value": 31040, "id": "https://openalex.org/T11165"}, {"name": "Digital Imaging for Blood Diseases", "value": 29670, "id": "https://openalex.org/T12874"}, {"name": "Image and Object Detection Techniques", "value": 27804, "id": "https://openalex.org/T12549"}, {"name": "Visual Attention and Saliency Detection", "value": 25418, "id": "https://openalex.org/T11605"}, {"name": "Digital Image Processing Techniques", "value": 25386, "id": "https://openalex.org/T12923"}, {"name": "Digital Media Forensic Detection", "value": 22781, "id": "https://openalex.org/T12357"}, {"name": "Currency Recognition and Detection", "value": 18278, "id": "https://openalex.org/T14319"}, {"name": "Image and Video Stabilization", "value": 8053, "id": "https://openalex.org/T13579"}]}, {"name": "Computer Networks and Communications", "children": [{"name": "Cultural Insights and Digital Impacts", "value": 216380, "id": "https://openalex.org/T13807"}, {"name": "Distributed and Parallel Computing Systems", "value": 193947, "id": "https://openalex.org/T10715"}, {"name": "Network Security and Intrusion Detection", "value": 133045, "id": "https://openalex.org/T10400"}, {"name": "Sensor Technology and Measurement Systems", "value": 130882, "id": "https://openalex.org/T12564"}, {"name": "Energy Efficient Wireless Sensor Networks", "value": 114189, "id": "https://openalex.org/T10080"}, {"name": "Advanced Database Systems and Queries", "value": 102489, "id": "https://openalex.org/T10317"}, {"name": "IoT and Edge/Fog Computing", "value": 89111, "id": "https://openalex.org/T10273"}, {"name": "Mobile Agent-Based Network Management", "value": 86390, "id": "https://openalex.org/T12203"}, {"name": "Media and Digital Communication", "value": 85396, "id": "https://openalex.org/T13745"}, {"name": "Distributed systems and fault tolerance", "value": 84731, "id": "https://openalex.org/T10772"}, {"name": "Wireless Communication Networks Research", "value": 84415, "id": "https://openalex.org/T10575"}, {"name": "Advanced Data Storage Technologies", "value": 82697, "id": "https://openalex.org/T11181"}, {"name": "Software System Performance and Reliability", "value": 79873, "id": "https://openalex.org/T12127"}, {"name": "Nonlinear Dynamics and Pattern Formation", "value": 78459, "id": "https://openalex.org/T11187"}, {"name": "Mobile Ad Hoc Networks", "value": 72555, "id": "https://openalex.org/T10246"}, {"name": "Network Traffic and Congestion Control", "value": 71387, "id": "https://openalex.org/T10138"}, {"name": "Interconnection Networks and Systems", "value": 70019, "id": "https://openalex.org/T10829"}, {"name": "Cooperative Communication and Network Coding", "value": 58576, "id": "https://openalex.org/T10796"}, {"name": "Software-Defined Networks and 5G", "value": 57496, "id": "https://openalex.org/T10714"}, {"name": "Distributed Control Multi-Agent Systems", "value": 53713, "id": "https://openalex.org/T10249"}, {"name": "Peer-to-Peer Network Technologies", "value": 48186, "id": "https://openalex.org/T10742"}, {"name": "Educational Research and Pedagogy", "value": 45932, "id": "https://openalex.org/T13836"}, {"name": "Constraint Satisfaction and Optimization", "value": 43892, "id": "https://openalex.org/T11596"}, {"name": "Caching and Content Delivery", "value": 43555, "id": "https://openalex.org/T11478"}, {"name": "Wireless Networks and Protocols", "value": 37843, "id": "https://openalex.org/T11158"}, {"name": "Cognitive Radio Networks and Spectrum Sensing", "value": 34836, "id": "https://openalex.org/T10579"}, {"name": "Opportunistic and Delay-Tolerant Networks", "value": 30660, "id": "https://openalex.org/T11896"}, {"name": "Internet of Things and Social Network Interactions", "value": 30320, "id": "https://openalex.org/T13924"}, {"name": "Wireless Sensor Networks for Data Analysis", "value": 29681, "id": "https://openalex.org/T14353"}, {"name": "Optimization and Search Problems", "value": 29615, "id": "https://openalex.org/T12288"}, {"name": "Error Correcting Code Techniques", "value": 28937, "id": "https://openalex.org/T11321"}, {"name": "Bluetooth and Wireless Communication Technologies", "value": 27926, "id": "https://openalex.org/T12801"}, {"name": "Neural Networks Stability and Synchronization", "value": 27623, "id": "https://openalex.org/T11347"}, {"name": "Network Time Synchronization Technologies", "value": 23335, "id": "https://openalex.org/T12216"}, {"name": "Security in Wireless Sensor Networks", "value": 22914, "id": "https://openalex.org/T11498"}, {"name": "Advanced Authentication Protocols Security", "value": 22085, "id": "https://openalex.org/T11504"}, {"name": "Cybersecurity and Information Systems", "value": 20002, "id": "https://openalex.org/T13983"}, {"name": "Distributed Sensor Networks and Detection Algorithms", "value": 16432, "id": "https://openalex.org/T12879"}, {"name": "Advanced Statistical Modeling Techniques", "value": 13483, "id": "https://openalex.org/T13748"}, {"name": "Age of Information Optimization", "value": 6919, "id": "https://openalex.org/T13553"}, {"name": "Technology and Education Systems", "value": 5297, "id": "https://openalex.org/T14455"}, {"name": "Smart Systems and Machine Learning", "value": 4934, "id": "https://openalex.org/T13693"}, {"name": "Advanced Technologies and Applied Computing", "value": 4189, "id": "https://openalex.org/T13345"}]}, {"name": "Hardware and Architecture", "children": [{"name": "Parallel Computing and Optimization Techniques", "value": 183557, "id": "https://openalex.org/T10054"}, {"name": "Embedded Systems Design Techniques", "value": 86021, "id": "https://openalex.org/T10904"}, {"name": "VLSI and Analog Circuit Testing", "value": 54123, "id": "https://openalex.org/T11032"}, {"name": "Real-Time Systems Scheduling", "value": 48760, "id": "https://openalex.org/T10933"}, {"name": "Physical Unclonable Functions (PUFs) and Hardware Security", "value": 20069, "id": "https://openalex.org/T12122"}, {"name": "Network Packet Processing and Optimization", "value": 19533, "id": "https://openalex.org/T12326"}, {"name": "Cloud Computing and Remote Desktop Technologies", "value": 10373, "id": "https://openalex.org/T14067"}, {"name": "Energy Efficiency in Computing", "value": 2236, "id": "https://openalex.org/T14098"}]}, {"name": "Computational Theory and Mathematics", "children": [{"name": "Computational Drug Discovery Methods", "value": 166371, "id": "https://openalex.org/T10211"}, {"name": "Mathematics, Computing, and Information Processing", "value": 141577, "id": "https://openalex.org/T13523"}, {"name": "Matrix Theory and Algorithms", "value": 118294, "id": "https://openalex.org/T10792"}, {"name": "Advanced Mathematical Modeling in Engineering", "value": 103000, "id": "https://openalex.org/T12100"}, {"name": "Computability, Logic, AI Algorithms", "value": 98837, "id": "https://openalex.org/T12002"}, {"name": "Formal Methods in Verification", "value": 85312, "id": "https://openalex.org/T10142"}, {"name": "Advanced Graph Theory Research", "value": 74873, "id": "https://openalex.org/T10374"}, {"name": "Advanced Algebra and Logic", "value": 72698, "id": "https://openalex.org/T11727"}, {"name": "Optimization and Variational Analysis", "value": 56342, "id": "https://openalex.org/T10545"}, {"name": "Rough Sets and Fuzzy Logic", "value": 52380, "id": "https://openalex.org/T11063"}, {"name": "semigroups and automata theory", "value": 51935, "id": "https://openalex.org/T11567"}, {"name": "Polynomial and algebraic computation", "value": 49918, "id": "https://openalex.org/T11435"}, {"name": "Cellular Automata and Applications", "value": 41285, "id": "https://openalex.org/T12162"}, {"name": "Advanced Multi-Objective Optimization Algorithms", "value": 41220, "id": "https://openalex.org/T10848"}, {"name": "Numerical Methods and Algorithms", "value": 38950, "id": "https://openalex.org/T11697"}, {"name": "Topological and Geometric Data Analysis", "value": 35050, "id": "https://openalex.org/T12536"}, {"name": "Petri Nets in System Modeling", "value": 33903, "id": "https://openalex.org/T11125"}, {"name": "Complexity and Algorithms in Graphs", "value": 33867, "id": "https://openalex.org/T10720"}, {"name": "Graph Labeling and Dimension Problems", "value": 26031, "id": "https://openalex.org/T12541"}, {"name": "Modeling and Simulation Systems", "value": 22220, "id": "https://openalex.org/T13286"}, {"name": "Contact Mechanics and Variational Inequalities", "value": 20383, "id": "https://openalex.org/T12809"}, {"name": "Chaos, Complexity, and Education", "value": 13585, "id": "https://openalex.org/T12469"}, {"name": "Quantum-Dot Cellular Automata", "value": 11323, "id": "https://openalex.org/T13182"}, {"name": "Adaptive Dynamic Programming Control", "value": 9723, "id": "https://openalex.org/T12794"}]}, {"name": "Signal Processing", "children": [{"name": "Speech and Audio Processing", "value": 104595, "id": "https://openalex.org/T10860"}, {"name": "Data Management and Algorithms", "value": 91920, "id": "https://openalex.org/T11106"}, {"name": "Music and Audio Processing", "value": 79902, "id": "https://openalex.org/T11309"}, {"name": "Advanced Malware Detection Techniques", "value": 68431, "id": "https://openalex.org/T11241"}, {"name": "Blind Source Separation Techniques", "value": 55632, "id": "https://openalex.org/T11447"}, {"name": "Biometric Identification and Security", "value": 48167, "id": "https://openalex.org/T10828"}, {"name": "Time Series Analysis and Forecasting", "value": 44021, "id": "https://openalex.org/T12205"}, {"name": "Video Coding and Compression Technologies", "value": 42701, "id": "https://openalex.org/T10741"}, {"name": "Digital Filter Design and Implementation", "value": 36134, "id": "https://openalex.org/T11034"}, {"name": "Direction-of-Arrival Estimation Techniques", "value": 22867, "id": "https://openalex.org/T10931"}]}, {"name": "Computer Graphics and Computer-Aided Design", "children": [{"name": "Digital Media and Visual Art", "value": 94598, "id": "https://openalex.org/T14254"}, {"name": "Computer Graphics and Visualization Techniques", "value": 74645, "id": "https://openalex.org/T10481"}, {"name": "Computational Geometry and Mesh Generation", "value": 58289, "id": "https://openalex.org/T10996"}, {"name": "Transportation Systems and Safety", "value": 19901, "id": "https://openalex.org/T13615"}]}, {"name": "Human-Computer Interaction", "children": [{"name": "Virtual Reality Applications and Impacts", "value": 69718, "id": "https://openalex.org/T10648"}, {"name": "Hand Gesture Recognition Systems", "value": 47733, "id": "https://openalex.org/T11398"}, {"name": "Digital Communication and Language", "value": 44736, "id": "https://openalex.org/T13155"}, {"name": "Innovative Human-Technology Interaction", "value": 44608, "id": "https://openalex.org/T10803"}, {"name": "Usability and User Interface Design", "value": 42603, "id": "https://openalex.org/T10470"}, {"name": "Interactive and Immersive Displays", "value": 41925, "id": "https://openalex.org/T10789"}, {"name": "Gaze Tracking and Assistive Technology", "value": 40818, "id": "https://openalex.org/T11707"}, {"name": "Persona Design and Applications", "value": 14214, "id": "https://openalex.org/T14074"}]}, {"name": "Software", "children": [{"name": "Software Testing and Debugging Techniques", "value": 65864, "id": "https://openalex.org/T10743"}, {"name": "Engineering and Information Technology", "value": 60587, "id": "https://openalex.org/T13681"}, {"name": "Model-Driven Software Engineering Techniques", "value": 53503, "id": "https://openalex.org/T11450"}, {"name": "Software Reliability and Analysis Research", "value": 35953, "id": "https://openalex.org/T12423"}, {"name": "Spreadsheets and End-User Computing", "value": 15892, "id": "https://openalex.org/T13197"}]}]}, {"name": "Engineering", "children": [{"name": "Aerospace Engineering", "children": [{"name": "Military Technology and Strategies", "value": 1996639, "id": "https://openalex.org/T14423"}, {"name": "Particle accelerators and beam dynamics", "value": 1471554, "id": "https://openalex.org/T11367"}, {"name": "Nuclear reactor physics and engineering", "value": 311449, "id": "https://openalex.org/T10597"}, {"name": "Human auditory perception and evaluation", "value": 162135, "id": "https://openalex.org/T13638"}, {"name": "Antenna Design and Analysis", "value": 146007, "id": "https://openalex.org/T10069"}, {"name": "Aluminum Alloy Microstructure Properties", "value": 87134, "id": "https://openalex.org/T10670"}, {"name": "Robotics and Sensor-Based Localization", "value": 83468, "id": "https://openalex.org/T10191"}, {"name": "Calibration and Measurement Techniques", "value": 82958, "id": "https://openalex.org/T12019"}, {"name": "Spacecraft and Cryogenic Technologies", "value": 81430, "id": "https://openalex.org/T13200"}, {"name": "Spacecraft Design and Technology", "value": 78470, "id": "https://openalex.org/T12449"}, {"name": "GNSS positioning and interference", "value": 68581, "id": "https://openalex.org/T10655"}, {"name": "Wind Energy Research and Development", "value": 67888, "id": "https://openalex.org/T10680"}, {"name": "Rocket and propulsion systems research", "value": 67342, "id": "https://openalex.org/T12513"}, {"name": "Combustion and Detonation Processes", "value": 66160, "id": "https://openalex.org/T11619"}, {"name": "Inertial Sensor and Navigation", "value": 64990, "id": "https://openalex.org/T11325"}, {"name": "Air Traffic Management and Optimization", "value": 57334, "id": "https://openalex.org/T11489"}, {"name": "High-Temperature Coating Behaviors", "value": 53171, "id": "https://openalex.org/T10626"}, {"name": "Antenna Design and Optimization", "value": 52603, "id": "https://openalex.org/T11946"}, {"name": "Satellite Communication Systems", "value": 51970, "id": "https://openalex.org/T12042"}, {"name": "Aerodynamics and Acoustics in Jet Flows", "value": 51201, "id": "https://openalex.org/T11008"}, {"name": "Infrared Target Detection Methodologies", "value": 50229, "id": "https://openalex.org/T12389"}, {"name": "Aerospace and Aviation Technology", "value": 48639, "id": "https://openalex.org/T12125"}, {"name": "Advanced Antenna and Metasurface Technologies", "value": 48589, "id": "https://openalex.org/T11383"}, {"name": "Turbomachinery Performance and Optimization", "value": 48175, "id": "https://openalex.org/T10944"}, {"name": "Aerodynamics and Fluid Dynamics Research", "value": 47368, "id": "https://openalex.org/T12081"}, {"name": "Synthetic Aperture Radar (SAR) Applications and Techniques", "value": 45264, "id": "https://openalex.org/T10801"}, {"name": "Radar Systems and Signal Processing", "value": 43684, "id": "https://openalex.org/T10891"}, {"name": "Space Satellite Systems and Control", "value": 43634, "id": "https://openalex.org/T11701"}, {"name": "Spacecraft Dynamics and Control", "value": 39639, "id": "https://openalex.org/T11082"}, {"name": "Space Exploration and Technology", "value": 38922, "id": "https://openalex.org/T14214"}, {"name": "UAV Applications and Optimization", "value": 36204, "id": "https://openalex.org/T11133"}, {"name": "Advanced SAR Imaging Techniques", "value": 35238, "id": "https://openalex.org/T11038"}, {"name": "Aerospace Engineering and Control Systems", "value": 34700, "id": "https://openalex.org/T13855"}, {"name": "Nuclear Engineering Thermal-Hydraulics", "value": 34529, "id": "https://openalex.org/T12560"}, {"name": "Electromagnetic Launch and Propulsion Technology", "value": 33410, "id": "https://openalex.org/T12699"}, {"name": "Biomimetic flight and propulsion mechanisms", "value": 31750, "id": "https://openalex.org/T11170"}, {"name": "Guidance and Control Systems", "value": 30981, "id": "https://openalex.org/T12158"}, {"name": "Aerospace Engineering and Energy Systems", "value": 28929, "id": "https://openalex.org/T12719"}, {"name": "Radio Wave Propagation Studies", "value": 25757, "id": "https://openalex.org/T13121"}, {"name": "Aeroelasticity and Vibration Control", "value": 24123, "id": "https://openalex.org/T11096"}, {"name": "Icing and De-icing Technologies", "value": 23251, "id": "https://openalex.org/T12696"}, {"name": "Plasma and Flow Control in Aerodynamics", "value": 22838, "id": "https://openalex.org/T12007"}, {"name": "Military Defense Systems Analysis", "value": 21895, "id": "https://openalex.org/T13371"}, {"name": "Advanced Control and Stabilization in Aerospace Systems", "value": 7729, "id": "https://openalex.org/T13257"}]}, {"name": "Electrical and Electronic Engineering", "children": [{"name": "Magnetic Field Sensors Techniques", "value": 1016350, "id": "https://openalex.org/T12692"}, {"name": "Plasma Diagnostics and Applications", "value": 977948, "id": "https://openalex.org/T10781"}, {"name": "Laser Design and Applications", "value": 869113, "id": "https://openalex.org/T12760"}, {"name": "Magneto-Optical Properties and Applications", "value": 277189, "id": "https://openalex.org/T12510"}, {"name": "Particle Accelerators and Free-Electron Lasers", "value": 270319, "id": "https://openalex.org/T10559"}, {"name": "Advanced Power Generation Technologies", "value": 242432, "id": "https://openalex.org/T13856"}, {"name": "Photonic and Optical Devices", "value": 204165, "id": "https://openalex.org/T10299"}, {"name": "Semiconductor materials and devices", "value": 172344, "id": "https://openalex.org/T10472"}, {"name": "Electrostatic Discharge in Electronics", "value": 171208, "id": "https://openalex.org/T12495"}, {"name": "Advancements in Battery Materials", "value": 167568, "id": "https://openalex.org/T10018"}, {"name": "Semiconductor Lasers and Optical Devices", "value": 150583, "id": "https://openalex.org/T11429"}, {"name": "Fuel Cells and Related Materials", "value": 137414, "id": "https://openalex.org/T10409"}, {"name": "Electromagnetic Compatibility and Measurements", "value": 128401, "id": "https://openalex.org/T11851"}, {"name": "Silicon and Solar Cell Technologies", "value": 124704, "id": "https://openalex.org/T10624"}, {"name": "Advanced Fiber Optic Sensors", "value": 123933, "id": "https://openalex.org/T10205"}, {"name": "Smart Grid Energy Management", "value": 114773, "id": "https://openalex.org/T10603"}, {"name": "Perovskite Materials and Applications", "value": 114241, "id": "https://openalex.org/T10247"}, {"name": "Gas Sensing Nanomaterials and Sensors", "value": 110451, "id": "https://openalex.org/T10461"}, {"name": "Optical Network Technologies", "value": 106821, "id": "https://openalex.org/T10232"}, {"name": "Microwave Engineering and Waveguides", "value": 105744, "id": "https://openalex.org/T10262"}, {"name": "Electric Motor Design and Analysis", "value": 103147, "id": "https://openalex.org/T10278"}, {"name": "Advanced Electrical Measurement Techniques", "value": 100617, "id": "https://openalex.org/T12300"}, {"name": "Chalcogenide Semiconductor Thin Films", "value": 100534, "id": "https://openalex.org/T10590"}, {"name": "Molecular Junctions and Nanostructures", "value": 97363, "id": "https://openalex.org/T10913"}, {"name": "Advancements in Semiconductor Devices and Circuit Design", "value": 95607, "id": "https://openalex.org/T10558"}, {"name": "Electrochemical sensors and biosensors", "value": 95035, "id": "https://openalex.org/T10212"}, {"name": "Power Systems and Technologies", "value": 92032, "id": "https://openalex.org/T14276"}, {"name": "Advanced Memory and Neural Computing", "value": 91096, "id": "https://openalex.org/T10502"}, {"name": "Advanced DC-DC Converters", "value": 88601, "id": "https://openalex.org/T10175"}, {"name": "Electric Vehicles and Infrastructure", "value": 87764, "id": "https://openalex.org/T10768"}, {"name": "Advanced Measurement and Detection Methods", "value": 87197, "id": "https://openalex.org/T14257"}, {"name": "Advanced MIMO Systems Optimization", "value": 86180, "id": "https://openalex.org/T10148"}, {"name": "Advanced Battery Materials and Technologies", "value": 84947, "id": "https://openalex.org/T10281"}, {"name": "Advanced Wireless Communication Techniques", "value": 79282, "id": "https://openalex.org/T10125"}, {"name": "Power Transformer Diagnostics and Insulation", "value": 78183, "id": "https://openalex.org/T11343"}, {"name": "Integrated Energy Systems Optimization", "value": 77633, "id": "https://openalex.org/T11185"}, {"name": "Organic Electronics and Photovoltaics", "value": 77256, "id": "https://openalex.org/T10045"}, {"name": "Photonic Crystal and Fiber Optics", "value": 77087, "id": "https://openalex.org/T10846"}, {"name": "Indoor and Outdoor Localization Technologies", "value": 76122, "id": "https://openalex.org/T10326"}, {"name": "Electric Power System Optimization", "value": 75203, "id": "https://openalex.org/T10424"}, {"name": "Thin-Film Transistor Technologies", "value": 74487, "id": "https://openalex.org/T10623"}, {"name": "Engineering and Technology Innovations", "value": 73411, "id": "https://openalex.org/T12899"}, {"name": "Radio Frequency Integrated Circuit Design", "value": 72177, "id": "https://openalex.org/T10187"}, {"name": "Silicon Carbide Semiconductor Technologies", "value": 70946, "id": "https://openalex.org/T10361"}, {"name": "Multilevel Inverters and Converters", "value": 66999, "id": "https://openalex.org/T10228"}, {"name": "Advanced MEMS and NEMS Technologies", "value": 65361, "id": "https://openalex.org/T10369"}, {"name": "Energy Load and Power Forecasting", "value": 65057, "id": "https://openalex.org/T11052"}, {"name": "IPv6, Mobility, Handover, Networks, Security", "value": 63722, "id": "https://openalex.org/T10651"}, {"name": "Electronic Packaging and Soldering Technologies", "value": 62605, "id": "https://openalex.org/T10460"}, {"name": "Power System Optimization and Stability", "value": 61050, "id": "https://openalex.org/T10305"}, {"name": "IoT-based Smart Home Systems", "value": 59411, "id": "https://openalex.org/T12222"}, {"name": "Advanced Photonic Communication Systems", "value": 58742, "id": "https://openalex.org/T10767"}, {"name": "Advanced Optical Network Technologies", "value": 58593, "id": "https://openalex.org/T10847"}, {"name": "Low-power high-performance VLSI design", "value": 57083, "id": "https://openalex.org/T10363"}, {"name": "Power Line Communications and Noise", "value": 55893, "id": "https://openalex.org/T12146"}, {"name": "Terahertz technology and applications", "value": 55664, "id": "https://openalex.org/T10752"}, {"name": "Solid State Laser Technologies", "value": 54942, "id": "https://openalex.org/T11127"}, {"name": "Energy Harvesting in Wireless Networks", "value": 51729, "id": "https://openalex.org/T11392"}, {"name": "Advanced Semiconductor Detectors and Materials", "value": 51038, "id": "https://openalex.org/T11637"}, {"name": "graph theory and CDMA systems", "value": 51020, "id": "https://openalex.org/T11797"}, {"name": "Integrated Circuits and Semiconductor Failure Analysis", "value": 50924, "id": "https://openalex.org/T14117"}, {"name": "Organic Light-Emitting Diodes Research", "value": 50596, "id": "https://openalex.org/T10611"}, {"name": "Vehicular Ad Hoc Networks (VANETs)", "value": 48751, "id": "https://openalex.org/T10761"}, {"name": "Advancements in Photolithography Techniques", "value": 48197, "id": "https://openalex.org/T11338"}, {"name": "CCD and CMOS Imaging Sensors", "value": 47408, "id": "https://openalex.org/T11992"}, {"name": "Electrohydrodynamics and Fluid Dynamics", "value": 47004, "id": "https://openalex.org/T12776"}, {"name": "Radiation Effects in Electronics", "value": 46433, "id": "https://openalex.org/T11005"}, {"name": "Advanced battery technologies research", "value": 45475, "id": "https://openalex.org/T11690"}, {"name": "Power Quality and Harmonics", "value": 44595, "id": "https://openalex.org/T10573"}, {"name": "Optimal Power Flow Distribution", "value": 44229, "id": "https://openalex.org/T10454"}, {"name": "HVDC Systems and Fault Protection", "value": 42952, "id": "https://openalex.org/T11102"}, {"name": "Sensorless Control of Electric Motors", "value": 42669, "id": "https://openalex.org/T10504"}, {"name": "Aerosol Filtration and Electrostatic Precipitation", "value": 42547, "id": "https://openalex.org/T12163"}, {"name": "Optical Systems and Laser Technology", "value": 42222, "id": "https://openalex.org/T14158"}, {"name": "Electromagnetic Simulation and Numerical Methods", "value": 42023, "id": "https://openalex.org/T11263"}, {"name": "Electromagnetic Compatibility and Noise Suppression", "value": 41872, "id": "https://openalex.org/T11444"}, {"name": "Optical Wireless Communication Technologies", "value": 41861, "id": "https://openalex.org/T10851"}, {"name": "Electrodeposition and Electroless Coatings", "value": 41526, "id": "https://openalex.org/T11200"}, {"name": "Green IT and Sustainability", "value": 40369, "id": "https://openalex.org/T12238"}, {"name": "Electric Power Systems and Control", "value": 39214, "id": "https://openalex.org/T13093"}, {"name": "solar cell performance optimization", "value": 38937, "id": "https://openalex.org/T12309"}, {"name": "3D IC and TSV technologies", "value": 38203, "id": "https://openalex.org/T11527"}, {"name": "Smart Grid and Power Systems", "value": 37945, "id": "https://openalex.org/T12451"}, {"name": "Advanced Wireless Network Optimization", "value": 37855, "id": "https://openalex.org/T11409"}, {"name": "Advanced Machining and Optimization Techniques", "value": 37326, "id": "https://openalex.org/T11451"}, {"name": "Advancements in PLL and VCO Technologies", "value": 34852, "id": "https://openalex.org/T11417"}, {"name": "Millimeter-Wave Propagation and Modeling", "value": 33895, "id": "https://openalex.org/T10936"}, {"name": "Advanced Wireless Communication Technologies", "value": 33698, "id": "https://openalex.org/T11458"}, {"name": "VLSI and FPGA Design Techniques", "value": 33451, "id": "https://openalex.org/T11522"}, {"name": "Wireless Power Transfer Systems", "value": 31482, "id": "https://openalex.org/T11249"}, {"name": "Wind Turbine Control Systems", "value": 30413, "id": "https://openalex.org/T10740"}, {"name": "High-Voltage Power Transmission Systems", "value": 28833, "id": "https://openalex.org/T14502"}, {"name": "Electrical and Bioimpedance Tomography", "value": 26462, "id": "https://openalex.org/T11778"}, {"name": "Wireless Communication Security Techniques", "value": 26213, "id": "https://openalex.org/T10964"}, {"name": "Microwave and Dielectric Measurement Techniques", "value": 25057, "id": "https://openalex.org/T11607"}, {"name": "Electrical Fault Detection and Protection", "value": 24630, "id": "https://openalex.org/T12737"}, {"name": "Advanced Power Amplifier Design", "value": 24519, "id": "https://openalex.org/T11248"}, {"name": "PAPR reduction in OFDM", "value": 24352, "id": "https://openalex.org/T11873"}, {"name": "Nanomaterials and Printing Technologies", "value": 22776, "id": "https://openalex.org/T11523"}, {"name": "Electrowetting and Microfluidic Technologies", "value": 21316, "id": "https://openalex.org/T12452"}, {"name": "Microwave Dielectric Ceramics Synthesis", "value": 21203, "id": "https://openalex.org/T12155"}, {"name": "Ferroelectric and Negative Capacitance Devices", "value": 17641, "id": "https://openalex.org/T12808"}, {"name": "Ultra-Wideband Communications Technology", "value": 17467, "id": "https://openalex.org/T12024"}, {"name": "IoT Networks and Protocols", "value": 17344, "id": "https://openalex.org/T12079"}, {"name": "Islanding Detection in Power Systems", "value": 15883, "id": "https://openalex.org/T13183"}, {"name": "Frequency Control in Power Systems", "value": 14290, "id": "https://openalex.org/T12277"}, {"name": "Electrokinetic Soil Remediation Techniques", "value": 13936, "id": "https://openalex.org/T13046"}, {"name": "Electricity Theft Detection Techniques", "value": 12696, "id": "https://openalex.org/T13429"}, {"name": "Full-Duplex Wireless Communications", "value": 12281, "id": "https://openalex.org/T12791"}, {"name": "Electrical and Thermal Properties of Materials", "value": 10727, "id": "https://openalex.org/T13251"}, {"name": "Space Technology and Applications", "value": 9798, "id": "https://openalex.org/T13436"}, {"name": "Electrophoretic Deposition in Materials Science", "value": 9505, "id": "https://openalex.org/T14382"}, {"name": "Advanced Signal Processing Techniques", "value": 8550, "id": "https://openalex.org/T13816"}, {"name": "Arduino and IoT Applications", "value": 8172, "id": "https://openalex.org/T13420"}, {"name": "Electromagnetic Effects on Materials", "value": 8144, "id": "https://openalex.org/T13440"}, {"name": "Embedded Systems and FPGA Applications", "value": 5696, "id": "https://openalex.org/T13292"}, {"name": "Advanced Data and IoT Technologies", "value": 3472, "id": "https://openalex.org/T13918"}]}, {"name": "Computational Mechanics", "children": [{"name": "Physics and Engineering Research Articles", "value": 402882, "id": "https://openalex.org/T12565"}, {"name": "Fluid Dynamics and Turbulent Flows", "value": 180117, "id": "https://openalex.org/T10360"}, {"name": "Computational Fluid Dynamics and Aerodynamics", "value": 106154, "id": "https://openalex.org/T10173"}, {"name": "Astronomical Observations and Instrumentation", "value": 104642, "id": "https://openalex.org/T14163"}, {"name": "Advanced Numerical Analysis Techniques", "value": 99871, "id": "https://openalex.org/T11245"}, {"name": "Combustion and flame dynamics", "value": 93369, "id": "https://openalex.org/T10553"}, {"name": "Ion-surface interactions and analysis", "value": 74550, "id": "https://openalex.org/T12166"}, {"name": "Advanced Numerical Methods in Computational Mathematics", "value": 74113, "id": "https://openalex.org/T10339"}, {"name": "Laser Material Processing Techniques", "value": 68073, "id": "https://openalex.org/T10732"}, {"name": "Granular flow and fluidized beds", "value": 66243, "id": "https://openalex.org/T10615"}, {"name": "Fluid Dynamics Simulations and Interactions", "value": 60910, "id": "https://openalex.org/T11694"}, {"name": "Sparse and Compressive Sensing Techniques", "value": 54544, "id": "https://openalex.org/T10500"}, {"name": "Surface Roughness and Optical Measurements", "value": 52811, "id": "https://openalex.org/T13049"}, {"name": "Lattice Boltzmann Simulation Studies", "value": 50031, "id": "https://openalex.org/T11751"}, {"name": "Fluid Dynamics and Vibration Analysis", "value": 49119, "id": "https://openalex.org/T11254"}, {"name": "Radiative Heat Transfer Studies", "value": 48043, "id": "https://openalex.org/T12304"}, {"name": "3D Shape Modeling and Analysis", "value": 42810, "id": "https://openalex.org/T10719"}, {"name": "Advanced Adaptive Filtering Techniques", "value": 38948, "id": "https://openalex.org/T11233"}, {"name": "Cyclone Separators and Fluid Dynamics", "value": 38056, "id": "https://openalex.org/T12540"}, {"name": "Fluid Dynamics and Heat Transfer", "value": 37682, "id": "https://openalex.org/T11382"}, {"name": "Fluid dynamics and aerodynamics studies", "value": 34612, "id": "https://openalex.org/T13951"}, {"name": "Fluid Dynamics and Thin Films", "value": 33205, "id": "https://openalex.org/T12141"}, {"name": "Laser and Thermal Forming Techniques", "value": 26232, "id": "https://openalex.org/T13965"}, {"name": "Field-Flow Fractionation Techniques", "value": 24980, "id": "https://openalex.org/T12850"}, {"name": "Heat Transfer and Numerical Methods", "value": 23004, "id": "https://openalex.org/T13116"}, {"name": "Heat and Mass Transfer in Porous Media", "value": 20841, "id": "https://openalex.org/T12063"}, {"name": "Heat transfer and supercritical fluids", "value": 18954, "id": "https://openalex.org/T12567"}, {"name": "Extenics and Innovation Methods", "value": 6567, "id": "https://openalex.org/T14262"}, {"name": "Diverse Scientific and Engineering Research", "value": 4963, "id": "https://openalex.org/T13307"}, {"name": "Water and Wastewater Treatment", "value": 2815, "id": "https://openalex.org/T14252"}]}, {"name": "Ocean Engineering", "children": [{"name": "Satellite Image Processing and Photogrammetry", "value": 320198, "id": "https://openalex.org/T12983"}, {"name": "Reservoir Engineering and Simulation Methods", "value": 144413, "id": "https://openalex.org/T11801"}, {"name": "Marine Biology and Environmental Chemistry", "value": 108122, "id": "https://openalex.org/T12071"}, {"name": "Water resources management and optimization", "value": 106788, "id": "https://openalex.org/T10969"}, {"name": "Drilling and Well Engineering", "value": 106459, "id": "https://openalex.org/T10892"}, {"name": "Geophysical Methods and Applications", "value": 69540, "id": "https://openalex.org/T11609"}, {"name": "Enhanced Oil Recovery Techniques", "value": 63057, "id": "https://openalex.org/T10491"}, {"name": "Maritime Navigation and Safety", "value": 62403, "id": "https://openalex.org/T11622"}, {"name": "Underwater Vehicles and Communication Systems", "value": 61799, "id": "https://openalex.org/T11192"}, {"name": "Marine and Offshore Engineering Studies", "value": 61366, "id": "https://openalex.org/T14164"}, {"name": "Oil and Gas Production Techniques", "value": 55694, "id": "https://openalex.org/T13050"}, {"name": "Geophysics and Sensor Technology", "value": 50704, "id": "https://openalex.org/T13885"}, {"name": "Evacuation and Crowd Dynamics", "value": 49684, "id": "https://openalex.org/T11500"}, {"name": "Particle Dynamics in Fluid Flows", "value": 48515, "id": "https://openalex.org/T12350"}, {"name": "Offshore Engineering and Technologies", "value": 43130, "id": "https://openalex.org/T13925"}, {"name": "Ship Hydrodynamics and Maneuverability", "value": 42445, "id": "https://openalex.org/T11604"}, {"name": "Engineering and Environmental Studies", "value": 40965, "id": "https://openalex.org/T13190"}, {"name": "Wave and Wind Energy Systems", "value": 39135, "id": "https://openalex.org/T11250"}, {"name": "Coal Properties and Utilization", "value": 33616, "id": "https://openalex.org/T11284"}, {"name": "Marine and Coastal Research", "value": 29310, "id": "https://openalex.org/T14412"}, {"name": "Stonefly species taxonomy and ecology", "value": 19626, "id": "https://openalex.org/T13578"}, {"name": "Automated Road and Building Extraction", "value": 11122, "id": "https://openalex.org/T13282"}, {"name": "Wetland Management and Conservation", "value": 8921, "id": "https://openalex.org/T14359"}]}, {"name": "Mechanical Engineering", "children": [{"name": "Advanced Measurement and Metrology Techniques", "value": 279784, "id": "https://openalex.org/T11583"}, {"name": "Engineering and Materials Science Studies", "value": 206984, "id": "https://openalex.org/T12959"}, {"name": "Extraction and Separation Processes", "value": 138748, "id": "https://openalex.org/T11091"}, {"name": "Advanced machining processes and optimization", "value": 106391, "id": "https://openalex.org/T10188"}, {"name": "Metallurgical Processes and Thermodynamics", "value": 105518, "id": "https://openalex.org/T11126"}, {"name": "Mineral Processing and Grinding", "value": 101721, "id": "https://openalex.org/T12282"}, {"name": "Aluminum Alloys Composites Properties", "value": 95697, "id": "https://openalex.org/T10717"}, {"name": "Hydraulic and Pneumatic Systems", "value": 94320, "id": "https://openalex.org/T11372"}, {"name": "Microstructure and Mechanical Properties of Steels", "value": 93902, "id": "https://openalex.org/T10386"}, {"name": "Tribology and Lubrication Engineering", "value": 87900, "id": "https://openalex.org/T11138"}, {"name": "Hydraulic Fracturing and Reservoir Analysis", "value": 87012, "id": "https://openalex.org/T10635"}, {"name": "Metal Forming Simulation Techniques", "value": 85881, "id": "https://openalex.org/T10700"}, {"name": "Welding Techniques and Residual Stresses", "value": 84196, "id": "https://openalex.org/T10834"}, {"name": "Heat Transfer and Optimization", "value": 79256, "id": "https://openalex.org/T10998"}, {"name": "Design Education and Practice", "value": 77756, "id": "https://openalex.org/T10672"}, {"name": "Structural Analysis of Composite Materials", "value": 73096, "id": "https://openalex.org/T12897"}, {"name": "Non-Destructive Testing Techniques", "value": 72361, "id": "https://openalex.org/T12169"}, {"name": "Mechanical Engineering and Vibrations Research", "value": 69380, "id": "https://openalex.org/T12907"}, {"name": "Additive Manufacturing Materials and Processes", "value": 65915, "id": "https://openalex.org/T10705"}, {"name": "Modular Robots and Swarm Intelligence", "value": 64554, "id": "https://openalex.org/T12784"}, {"name": "Advanced materials and composites", "value": 63506, "id": "https://openalex.org/T12099"}, {"name": "Intermetallics and Advanced Alloy Properties", "value": 63309, "id": "https://openalex.org/T11100"}, {"name": "Railway Engineering and Dynamics", "value": 60644, "id": "https://openalex.org/T10842"}, {"name": "Catalysis and Hydrodesulfurization Studies", "value": 59132, "id": "https://openalex.org/T11351"}, {"name": "Refrigeration and Air Conditioning Technologies", "value": 59004, "id": "https://openalex.org/T11529"}, {"name": "Heat Transfer and Boiling Studies", "value": 55993, "id": "https://openalex.org/T10850"}, {"name": "Gear and Bearing Dynamics Analysis", "value": 55542, "id": "https://openalex.org/T11062"}, {"name": "Metallic Glasses and Amorphous Alloys", "value": 55212, "id": "https://openalex.org/T10633"}, {"name": "Carbon Dioxide Capture Technologies", "value": 54837, "id": "https://openalex.org/T10967"}, {"name": "Advanced Welding Techniques Analysis", "value": 50662, "id": "https://openalex.org/T10723"}, {"name": "Fiber-reinforced polymer composites", "value": 50390, "id": "https://openalex.org/T11664"}, {"name": "High Temperature Alloys and Creep", "value": 50340, "id": "https://openalex.org/T10840"}, {"name": "Advanced Materials and Mechanics", "value": 47082, "id": "https://openalex.org/T11737"}, {"name": "Tree Root and Stability Studies", "value": 45802, "id": "https://openalex.org/T12729"}, {"name": "Iron and Steelmaking Processes", "value": 45004, "id": "https://openalex.org/T11837"}, {"name": "Lubricants and Their Additives", "value": 44078, "id": "https://openalex.org/T11557"}, {"name": "Mechanical Failure Analysis and Simulation", "value": 43686, "id": "https://openalex.org/T13213"}, {"name": "Industrial Engineering and Technologies", "value": 40552, "id": "https://openalex.org/T13045"}, {"name": "Heat Transfer Mechanisms", "value": 40341, "id": "https://openalex.org/T11945"}, {"name": "Mining and Gasification Technologies", "value": 39807, "id": "https://openalex.org/T13094"}, {"name": "Phase Change Materials Research", "value": 39524, "id": "https://openalex.org/T10938"}, {"name": "Epoxy Resin Curing Processes", "value": 37902, "id": "https://openalex.org/T11145"}, {"name": "Industrial Gas Emission Control", "value": 37822, "id": "https://openalex.org/T12425"}, {"name": "Membrane Separation and Gas Transport", "value": 37402, "id": "https://openalex.org/T11362"}, {"name": "Cellular and Composite Structures", "value": 37185, "id": "https://openalex.org/T10707"}, {"name": "Engineering Structural Analysis Methods", "value": 36940, "id": "https://openalex.org/T12581"}, {"name": "Mechanical and Thermal Properties Analysis", "value": 36369, "id": "https://openalex.org/T13312"}, {"name": "Thermodynamic and Exergetic Analyses of Power and Cooling Systems", "value": 35231, "id": "https://openalex.org/T10568"}, {"name": "High Entropy Alloys Studies", "value": 35147, "id": "https://openalex.org/T11143"}, {"name": "Induction Heating and Inverter Technology", "value": 34810, "id": "https://openalex.org/T12898"}, {"name": "Materials Engineering and Processing", "value": 33888, "id": "https://openalex.org/T13140"}, {"name": "Structural Integrity and Reliability Analysis", "value": 33319, "id": "https://openalex.org/T12086"}, {"name": "Injection Molding Process and Properties", "value": 30938, "id": "https://openalex.org/T12080"}, {"name": "Coal Combustion and Slurry Processing", "value": 30832, "id": "https://openalex.org/T13584"}, {"name": "Innovative Energy Harvesting Technologies", "value": 30342, "id": "https://openalex.org/T11230"}, {"name": "Powder Metallurgy Techniques and Materials", "value": 30239, "id": "https://openalex.org/T12932"}, {"name": "Teleoperation and Haptic Systems", "value": 29550, "id": "https://openalex.org/T11687"}, {"name": "Material Science and Thermodynamics", "value": 28716, "id": "https://openalex.org/T13685"}, {"name": "Thermodynamic and Structural Properties of Metals and Alloys", "value": 28598, "id": "https://openalex.org/T13645"}, {"name": "Adsorption and Cooling Systems", "value": 27676, "id": "https://openalex.org/T11774"}, {"name": "Belt Conveyor Systems Engineering", "value": 27429, "id": "https://openalex.org/T13341"}, {"name": "Agricultural Engineering and Mechanization", "value": 26985, "id": "https://openalex.org/T12201"}, {"name": "Bauxite Residue and Utilization", "value": 26933, "id": "https://openalex.org/T12774"}, {"name": "Advancements in Materials Engineering", "value": 25461, "id": "https://openalex.org/T14096"}, {"name": "Advanced Thermodynamic Systems and Engines", "value": 24756, "id": "https://openalex.org/T12139"}, {"name": "IoT and GPS-based Vehicle Safety Systems", "value": 22401, "id": "https://openalex.org/T12406"}, {"name": "Transport Systems and Technology", "value": 20779, "id": "https://openalex.org/T14304"}, {"name": "Electrical Contact Performance and Analysis", "value": 19984, "id": "https://openalex.org/T12371"}, {"name": "Waste Management and Environmental Impact", "value": 18190, "id": "https://openalex.org/T13790"}, {"name": "Surface Treatment and Residual Stress", "value": 15966, "id": "https://openalex.org/T12106"}, {"name": "Solar Energy Systems and Technologies", "value": 15575, "id": "https://openalex.org/T13298"}, {"name": "Power Line Inspection Robots", "value": 15043, "id": "https://openalex.org/T13715"}, {"name": "Polymer Science and Applications", "value": 15019, "id": "https://openalex.org/T14454"}, {"name": "Surface Treatment and Coatings", "value": 14623, "id": "https://openalex.org/T13470"}, {"name": "Control Systems in Engineering", "value": 12522, "id": "https://openalex.org/T13644"}, {"name": "Mechatronics Education and Applications", "value": 11774, "id": "https://openalex.org/T13827"}, {"name": "Mechanical Engineering Research and Applications", "value": 9703, "id": "https://openalex.org/T13451"}, {"name": "Ranque-Hilsch vortex tube", "value": 5717, "id": "https://openalex.org/T13640"}, {"name": "Heat Transfer and Mathematical Modeling", "value": 5716, "id": "https://openalex.org/T13020"}]}, {"name": "Civil and Structural Engineering", "children": [{"name": "Civil and Structural Engineering Research", "value": 243217, "id": "https://openalex.org/T13031"}, {"name": "Engineering Applied Research", "value": 221392, "id": "https://openalex.org/T14156"}, {"name": "Structural Engineering and Vibration Analysis", "value": 145002, "id": "https://openalex.org/T12487"}, {"name": "Structural Health Monitoring Techniques", "value": 123207, "id": "https://openalex.org/T10534"}, {"name": "Concrete and Cement Materials Research", "value": 116094, "id": "https://openalex.org/T10033"}, {"name": "Asphalt Pavement Performance Evaluation", "value": 103572, "id": "https://openalex.org/T10264"}, {"name": "Geotechnical Engineering and Underground Structures", "value": 99639, "id": "https://openalex.org/T12233"}, {"name": "Structural Load-Bearing Analysis", "value": 97631, "id": "https://openalex.org/T10713"}, {"name": "Geotechnical and construction materials studies", "value": 85522, "id": "https://openalex.org/T13236"}, {"name": "Geotechnical Engineering and Soil Stabilization", "value": 83964, "id": "https://openalex.org/T11375"}, {"name": "Infrastructure Maintenance and Monitoring", "value": 77478, "id": "https://openalex.org/T11606"}, {"name": "Soil and Unsaturated Flow", "value": 76494, "id": "https://openalex.org/T10716"}, {"name": "Tunneling and Rock Mechanics", "value": 67828, "id": "https://openalex.org/T12482"}, {"name": "Concrete Corrosion and Durability", "value": 67285, "id": "https://openalex.org/T11850"}, {"name": "Seismic Performance and Analysis", "value": 64615, "id": "https://openalex.org/T10160"}, {"name": "Innovative concrete reinforcement materials", "value": 64022, "id": "https://openalex.org/T10687"}, {"name": "Water Systems and Optimization", "value": 62994, "id": "https://openalex.org/T11220"}, {"name": "Structural Analysis and Optimization", "value": 61869, "id": "https://openalex.org/T11870"}, {"name": "Grouting, Rheology, and Soil Mechanics", "value": 59501, "id": "https://openalex.org/T13596"}, {"name": "Soil Mechanics and Vehicle Dynamics", "value": 56884, "id": "https://openalex.org/T11978"}, {"name": "Geodetic Measurements and Engineering Structures", "value": 50973, "id": "https://openalex.org/T13511"}, {"name": "Hydraulic flow and structures", "value": 49399, "id": "https://openalex.org/T12022"}, {"name": "Geotechnical Engineering and Soil Mechanics", "value": 49035, "id": "https://openalex.org/T10233"}, {"name": "Vibration Control and Rheological Fluids", "value": 45707, "id": "https://openalex.org/T10690"}, {"name": "Urban Transport Systems Analysis", "value": 43781, "id": "https://openalex.org/T13601"}, {"name": "Masonry and Concrete Structural Analysis", "value": 43765, "id": "https://openalex.org/T11352"}, {"name": "Structural Response to Dynamic Loads", "value": 40915, "id": "https://openalex.org/T11874"}, {"name": "Construction Engineering and Safety", "value": 38846, "id": "https://openalex.org/T13808"}, {"name": "Topology Optimization in Engineering", "value": 37585, "id": "https://openalex.org/T11115"}, {"name": "Dam Engineering and Safety", "value": 36560, "id": "https://openalex.org/T12293"}, {"name": "Structural Engineering and Materials Analysis", "value": 36353, "id": "https://openalex.org/T12940"}, {"name": "Fire effects on concrete materials", "value": 34025, "id": "https://openalex.org/T12102"}, {"name": "Transportation Safety and Impact Analysis", "value": 33200, "id": "https://openalex.org/T14445"}, {"name": "Infrastructure Resilience and Vulnerability Analysis", "value": 25591, "id": "https://openalex.org/T11807"}, {"name": "Thermal Radiation and Cooling Technologies", "value": 23854, "id": "https://openalex.org/T12442"}, {"name": "Transportation Systems and Logistics", "value": 22448, "id": "https://openalex.org/T13527"}, {"name": "Concrete Properties and Behavior", "value": 21356, "id": "https://openalex.org/T12152"}, {"name": "Tailings Management and Properties", "value": 18875, "id": "https://openalex.org/T12865"}, {"name": "Seismic and Structural Analysis of Tall Buildings", "value": 18799, "id": "https://openalex.org/T13852"}, {"name": "Earthquake and Tsunami Effects", "value": 18780, "id": "https://openalex.org/T14146"}, {"name": "Geotechnical and Mining Engineering", "value": 9850, "id": "https://openalex.org/T13941"}, {"name": "Bladed Disk Vibration Dynamics", "value": 9071, "id": "https://openalex.org/T12435"}]}, {"name": "Biomedical Engineering", "children": [{"name": "Superconducting Materials and Applications", "value": 242846, "id": "https://openalex.org/T11808"}, {"name": "Photocathodes and Microchannel Plates", "value": 228951, "id": "https://openalex.org/T13418"}, {"name": "Biofuel production and bioconversion", "value": 141206, "id": "https://openalex.org/T10171"}, {"name": "Advanced Chemical Sensor Technologies", "value": 133397, "id": "https://openalex.org/T11667"}, {"name": "Bone Tissue Engineering Materials", "value": 128788, "id": "https://openalex.org/T10059"}, {"name": "Advanced Sensor and Energy Harvesting Materials", "value": 109957, "id": "https://openalex.org/T10338"}, {"name": "Muscle activation and electromyography studies", "value": 101188, "id": "https://openalex.org/T10784"}, {"name": "Biomedical and Engineering Education", "value": 94802, "id": "https://openalex.org/T13280"}, {"name": "Thermochemical Biomass Conversion Processes", "value": 93787, "id": "https://openalex.org/T10088"}, {"name": "Phase Equilibria and Thermodynamics", "value": 88274, "id": "https://openalex.org/T10402"}, {"name": "Nanofluid Flow and Heat Transfer", "value": 86476, "id": "https://openalex.org/T10104"}, {"name": "Biodiesel Production and Applications", "value": 85885, "id": "https://openalex.org/T10507"}, {"name": "Acoustic Wave Phenomena Research", "value": 83870, "id": "https://openalex.org/T10822"}, {"name": "Advanced Surface Polishing Techniques", "value": 79567, "id": "https://openalex.org/T11301"}, {"name": "Analog and Mixed-Signal Circuit Design", "value": 79388, "id": "https://openalex.org/T10323"}, {"name": "3D Printing in Biomedical Research", "value": 79230, "id": "https://openalex.org/T11190"}, {"name": "Mechanical Circulatory Support Devices", "value": 77550, "id": "https://openalex.org/T10675"}, {"name": "Microfluidic and Capillary Electrophoresis Applications", "value": 74272, "id": "https://openalex.org/T10412"}, {"name": "Acoustic Wave Resonator Technologies", "value": 73570, "id": "https://openalex.org/T11160"}, {"name": "Advanced X-ray and CT Imaging", "value": 69697, "id": "https://openalex.org/T12386"}, {"name": "Metal Extraction and Bioleaching", "value": 67919, "id": "https://openalex.org/T11073"}, {"name": "Optical Polarization and Ellipsometry", "value": 67647, "id": "https://openalex.org/T12050"}, {"name": "Nanoplatforms for cancer theranostics", "value": 63149, "id": "https://openalex.org/T10782"}, {"name": "Innovative Microfluidic and Catalytic Techniques Innovation", "value": 62755, "id": "https://openalex.org/T11407"}, {"name": "Plasmonic and Surface Plasmon Research", "value": 60781, "id": "https://openalex.org/T10295"}, {"name": "Ultrasound and Hyperthermia Applications", "value": 59664, "id": "https://openalex.org/T10958"}, {"name": "Anatomy and Medical Technology", "value": 57595, "id": "https://openalex.org/T11984"}, {"name": "Lignin and Wood Chemistry", "value": 56869, "id": "https://openalex.org/T11208"}, {"name": "Elasticity and Material Modeling", "value": 56846, "id": "https://openalex.org/T11366"}, {"name": "Advanced Theoretical and Applied Studies in Material Sciences and Geometry", "value": 54595, "id": "https://openalex.org/T13267"}, {"name": "Non-Invasive Vital Sign Monitoring", "value": 53665, "id": "https://openalex.org/T11196"}, {"name": "Lower Extremity Biomechanics and Pathologies", "value": 50433, "id": "https://openalex.org/T11018"}, {"name": "Advanced Materials Characterization Techniques", "value": 50195, "id": "https://openalex.org/T13552"}, {"name": "Microfluidic and Bio-sensing Technologies", "value": 48070, "id": "https://openalex.org/T11255"}, {"name": "Slime Mold and Myxomycetes Research", "value": 47741, "id": "https://openalex.org/T13362"}, {"name": "Photoacoustic and Ultrasonic Imaging", "value": 46101, "id": "https://openalex.org/T12015"}, {"name": "Robotic Locomotion and Control", "value": 45966, "id": "https://openalex.org/T10879"}, {"name": "Fluid Dynamics and Mixing", "value": 45252, "id": "https://openalex.org/T10864"}, {"name": "Medical Imaging and Analysis", "value": 45223, "id": "https://openalex.org/T14510"}, {"name": "Biosensors and Analytical Detection", "value": 44225, "id": "https://openalex.org/T11393"}, {"name": "Mechanics and Biomechanics Studies", "value": 43663, "id": "https://openalex.org/T13752"}, {"name": "Artificial Immune Systems Applications", "value": 42345, "id": "https://openalex.org/T12391"}, {"name": "Prosthetics and Rehabilitation Robotics", "value": 41690, "id": "https://openalex.org/T11023"}, {"name": "Nanopore and Nanochannel Transport Studies", "value": 41592, "id": "https://openalex.org/T11582"}, {"name": "Sports Dynamics and Biomechanics", "value": 41005, "id": "https://openalex.org/T12677"}, {"name": "Optical Coherence Tomography Applications", "value": 39909, "id": "https://openalex.org/T11569"}, {"name": "Catalysis for Biomass Conversion", "value": 39692, "id": "https://openalex.org/T11009"}, {"name": "Nanofabrication and Lithography Techniques", "value": 39170, "id": "https://openalex.org/T12224"}, {"name": "Wireless Body Area Networks", "value": 38491, "id": "https://openalex.org/T11932"}, {"name": "Characterization and Applications of Magnetic Nanoparticles", "value": 37660, "id": "https://openalex.org/T12405"}, {"name": "Soft Robotics and Applications", "value": 37437, "id": "https://openalex.org/T10868"}, {"name": "Nanowire Synthesis and Applications", "value": 37077, "id": "https://openalex.org/T11272"}, {"name": "Graphene and Nanomaterials Applications", "value": 35947, "id": "https://openalex.org/T12627"}, {"name": "Nanotechnology research and applications", "value": 34790, "id": "https://openalex.org/T14089"}, {"name": "Membrane-based Ion Separation Techniques", "value": 34357, "id": "https://openalex.org/T12074"}, {"name": "SAS software applications and methods", "value": 32605, "id": "https://openalex.org/T13820"}, {"name": "Advanced Sensor Technologies Research", "value": 28138, "id": "https://openalex.org/T13928"}, {"name": "Advanced optical system design", "value": 26972, "id": "https://openalex.org/T11517"}, {"name": "Nonlinear Optical Materials Studies", "value": 25299, "id": "https://openalex.org/T11788"}, {"name": "Dielectric materials and actuators", "value": 25107, "id": "https://openalex.org/T11608"}, {"name": "Environmental remediation with nanomaterials", "value": 24135, "id": "https://openalex.org/T12078"}, {"name": "Near-Field Optical Microscopy", "value": 23678, "id": "https://openalex.org/T12466"}, {"name": "Microwave Imaging and Scattering Analysis", "value": 22912, "id": "https://openalex.org/T11739"}, {"name": "Surface Chemistry and Catalysis", "value": 22625, "id": "https://openalex.org/T12285"}, {"name": "Polymer-Based Agricultural Enhancements", "value": 22396, "id": "https://openalex.org/T12642"}, {"name": "Chemical Looping and Thermochemical Processes", "value": 19353, "id": "https://openalex.org/T11802"}, {"name": "Laser-Ablation Synthesis of Nanoparticles", "value": 18078, "id": "https://openalex.org/T13232"}, {"name": "Molecular Communication and Nanonetworks", "value": 17551, "id": "https://openalex.org/T13052"}, {"name": "Gait Recognition and Analysis", "value": 17374, "id": "https://openalex.org/T12740"}, {"name": "Ergonomics and Human Factors", "value": 14768, "id": "https://openalex.org/T13722"}, {"name": "Intravenous Infusion Technology and Safety", "value": 13199, "id": "https://openalex.org/T14189"}, {"name": "Subcritical and Supercritical Water Processes", "value": 12855, "id": "https://openalex.org/T12706"}]}, {"name": "Industrial and Manufacturing Engineering", "children": [{"name": "Manufacturing Process and Optimization", "value": 241627, "id": "https://openalex.org/T11159"}, {"name": "Flexible and Reconfigurable Manufacturing Systems", "value": 122367, "id": "https://openalex.org/T11741"}, {"name": "Scheduling and Optimization Algorithms", "value": 100003, "id": "https://openalex.org/T10551"}, {"name": "Industrial Vision Systems and Defect Detection", "value": 99139, "id": "https://openalex.org/T12111"}, {"name": "Advanced Manufacturing and Logistics Optimization", "value": 96263, "id": "https://openalex.org/T11814"}, {"name": "Engineering Technology and Methodologies", "value": 86983, "id": "https://openalex.org/T13113"}, {"name": "Maritime Ports and Logistics", "value": 80789, "id": "https://openalex.org/T11223"}, {"name": "Digital Transformation in Industry", "value": 80173, "id": "https://openalex.org/T10763"}, {"name": "Railway Systems and Energy Efficiency", "value": 49735, "id": "https://openalex.org/T11568"}, {"name": "Vehicle Routing Optimization Methods", "value": 44897, "id": "https://openalex.org/T10567"}, {"name": "Transport and Logistics Innovations", "value": 43345, "id": "https://openalex.org/T12984"}, {"name": "Sustainable Industrial Ecology", "value": 33397, "id": "https://openalex.org/T12746"}, {"name": "Assembly Line Balancing Optimization", "value": 26798, "id": "https://openalex.org/T12782"}, {"name": "Optimization and Packing Problems", "value": 23242, "id": "https://openalex.org/T12176"}, {"name": "Robotic Process Automation Applications", "value": 7760, "id": "https://openalex.org/T13287"}, {"name": "Diverse Industrial Engineering Technologies", "value": 7629, "id": "https://openalex.org/T13290"}, {"name": "Applied Advanced Technologies", "value": 3927, "id": "https://openalex.org/T13027"}]}, {"name": "Control and Systems Engineering", "children": [{"name": "Thermal Analysis in Power Transmission", "value": 185041, "id": "https://openalex.org/T12804"}, {"name": "Fault Detection and Control Systems", "value": 141390, "id": "https://openalex.org/T10876"}, {"name": "Industrial Technology and Control Systems", "value": 128657, "id": "https://openalex.org/T14474"}, {"name": "Advanced Control Systems Optimization", "value": 120856, "id": "https://openalex.org/T10791"}, {"name": "Simulation and Modeling Applications", "value": 114863, "id": "https://openalex.org/T14270"}, {"name": "Advanced Algorithms and Applications", "value": 109266, "id": "https://openalex.org/T13717"}, {"name": "Pulsed Power Technology Applications", "value": 107556, "id": "https://openalex.org/T11920"}, {"name": "Advanced Sensor and Control Systems", "value": 103689, "id": "https://openalex.org/T14225"}, {"name": "Microgrid Control and Optimization", "value": 100561, "id": "https://openalex.org/T10223"}, {"name": "Vibration and Dynamic Analysis", "value": 86578, "id": "https://openalex.org/T12206"}, {"name": "Adaptive Control of Nonlinear Systems", "value": 78691, "id": "https://openalex.org/T10040"}, {"name": "Stability and Control of Uncertain Systems", "value": 73117, "id": "https://openalex.org/T10046"}, {"name": "Process Optimization and Integration", "value": 66175, "id": "https://openalex.org/T11053"}, {"name": "Robotic Mechanisms and Dynamics", "value": 64813, "id": "https://openalex.org/T10571"}, {"name": "Advanced Data Processing Techniques", "value": 58622, "id": "https://openalex.org/T14470"}, {"name": "Machine Fault Diagnosis Techniques", "value": 57874, "id": "https://openalex.org/T10220"}, {"name": "Real-time simulation and control systems", "value": 57863, "id": "https://openalex.org/T12810"}, {"name": "Traffic control and management", "value": 57195, "id": "https://openalex.org/T10524"}, {"name": "Control Systems and Identification", "value": 57121, "id": "https://openalex.org/T11236"}, {"name": "Robot Manipulation and Learning", "value": 54612, "id": "https://openalex.org/T10653"}, {"name": "Smart Grid Security and Resilience", "value": 53538, "id": "https://openalex.org/T10917"}, {"name": "Industrial Automation and Control Systems", "value": 53301, "id": "https://openalex.org/T13344"}, {"name": "Stability and Controllability of Differential Equations", "value": 52738, "id": "https://openalex.org/T11110"}, {"name": "Dynamics and Control of Mechanical Systems", "value": 51363, "id": "https://openalex.org/T11394"}, {"name": "Robotics and Automated Systems", "value": 48788, "id": "https://openalex.org/T13382"}, {"name": "Mining Techniques and Economics", "value": 45678, "id": "https://openalex.org/T13065"}, {"name": "Magnetic Bearings and Levitation Dynamics", "value": 43636, "id": "https://openalex.org/T11602"}, {"name": "Iterative Learning Control Systems", "value": 39914, "id": "https://openalex.org/T11749"}, {"name": "Embedded Systems and FPGA Design", "value": 38618, "id": "https://openalex.org/T12941"}, {"name": "Power Systems Fault Detection", "value": 36588, "id": "https://openalex.org/T10972"}, {"name": "Engineering and Test Systems", "value": 31582, "id": "https://openalex.org/T13293"}, {"name": "Human Motion and Animation", "value": 31211, "id": "https://openalex.org/T12290"}, {"name": "Control and Dynamics of Mobile Robots", "value": 30471, "id": "https://openalex.org/T11615"}, {"name": "Advanced Research in Systems and Signal Processing", "value": 30437, "id": "https://openalex.org/T14420"}, {"name": "Advanced Control Systems Design", "value": 28563, "id": "https://openalex.org/T11081"}, {"name": "Wireless Sensor Networks and IoT", "value": 26897, "id": "https://openalex.org/T13535"}, {"name": "Elevator Systems and Control", "value": 26429, "id": "https://openalex.org/T14011"}, {"name": "Optimization and Mathematical Programming", "value": 25916, "id": "https://openalex.org/T12709"}, {"name": "Military Strategy and Technology", "value": 24055, "id": "https://openalex.org/T12888"}, {"name": "Systems Engineering Methodologies and Applications", "value": 21076, "id": "https://openalex.org/T12000"}, {"name": "Control and Stability of Dynamical Systems", "value": 19650, "id": "https://openalex.org/T12772"}, {"name": "Piezoelectric Actuators and Control", "value": 19413, "id": "https://openalex.org/T11525"}, {"name": "Extremum Seeking Control Systems", "value": 6627, "id": "https://openalex.org/T14083"}, {"name": "Aerospace Engineering and Applications", "value": 5988, "id": "https://openalex.org/T13954"}]}, {"name": "Mechanics of Materials", "children": [{"name": "Hydrocarbon exploration and reservoir analysis", "value": 180156, "id": "https://openalex.org/T10399"}, {"name": "Metallurgy and Material Forming", "value": 138856, "id": "https://openalex.org/T11201"}, {"name": "Metal and Thin Film Mechanics", "value": 134771, "id": "https://openalex.org/T10377"}, {"name": "Fatigue and fracture mechanics", "value": 109620, "id": "https://openalex.org/T10396"}, {"name": "Geotechnical and Geomechanical Engineering", "value": 107557, "id": "https://openalex.org/T13619"}, {"name": "Mechanical Behavior of Composites", "value": 90210, "id": "https://openalex.org/T10219"}, {"name": "Geomechanics and Mining Engineering", "value": 88548, "id": "https://openalex.org/T13772"}, {"name": "Ultrasonics and Acoustic Wave Propagation", "value": 87211, "id": "https://openalex.org/T10662"}, {"name": "Composite Structure Analysis and Optimization", "value": 81522, "id": "https://openalex.org/T10221"}, {"name": "Laser-induced spectroscopy and plasma", "value": 75945, "id": "https://openalex.org/T11854"}, {"name": "Rock Mechanics and Modeling", "value": 67760, "id": "https://openalex.org/T10161"}, {"name": "Muon and positron interactions and applications", "value": 66687, "id": "https://openalex.org/T12579"}, {"name": "Numerical methods in engineering", "value": 66441, "id": "https://openalex.org/T10514"}, {"name": "Engineering Diagnostics and Reliability", "value": 64536, "id": "https://openalex.org/T13891"}, {"name": "Energetic Materials and Combustion", "value": 62622, "id": "https://openalex.org/T10806"}, {"name": "Material Properties and Processing", "value": 58589, "id": "https://openalex.org/T12971"}, {"name": "Flow Measurement and Analysis", "value": 51692, "id": "https://openalex.org/T12537"}, {"name": "Adhesion, Friction, and Surface Interactions", "value": 51503, "id": "https://openalex.org/T11799"}, {"name": "Forest Biomass Utilization and Management", "value": 51451, "id": "https://openalex.org/T12118"}, {"name": "Tribology and Wear Analysis", "value": 45938, "id": "https://openalex.org/T12362"}, {"name": "Cavitation Phenomena in Pumps", "value": 45838, "id": "https://openalex.org/T11202"}, {"name": "Mechanical stress and fatigue analysis", "value": 42147, "id": "https://openalex.org/T12252"}, {"name": "Thermography and Photoacoustic Techniques", "value": 41597, "id": "https://openalex.org/T11856"}, {"name": "Composite Material Mechanics", "value": 36754, "id": "https://openalex.org/T11558"}, {"name": "Freezing and Crystallization Processes", "value": 34673, "id": "https://openalex.org/T14479"}, {"name": "Elasticity and Wave Propagation", "value": 33199, "id": "https://openalex.org/T13261"}, {"name": "Thermoelastic and Magnetoelastic Phenomena", "value": 19788, "id": "https://openalex.org/T11565"}, {"name": "Soil, Finite Element Methods", "value": 17728, "id": "https://openalex.org/T13862"}, {"name": "Railway Systems and Materials Science", "value": 9762, "id": "https://openalex.org/T14204"}]}, {"name": "Safety, Risk, Reliability and Quality", "children": [{"name": "Nuclear and radioactivity studies", "value": 154859, "id": "https://openalex.org/T13923"}, {"name": "Traffic and Road Safety", "value": 89843, "id": "https://openalex.org/T10370"}, {"name": "Geoscience and Mining Technology", "value": 69854, "id": "https://openalex.org/T14392"}, {"name": "Technology Assessment and Management", "value": 64869, "id": "https://openalex.org/T14306"}, {"name": "Evaluation and Optimization Models", "value": 61376, "id": "https://openalex.org/T14368"}, {"name": "Reliability and Maintenance Optimization", "value": 49379, "id": "https://openalex.org/T10780"}, {"name": "Fire dynamics and safety research", "value": 47541, "id": "https://openalex.org/T11317"}, {"name": "Geotechnical Engineering and Analysis", "value": 42775, "id": "https://openalex.org/T11046"}, {"name": "Fire Detection and Safety Systems", "value": 32549, "id": "https://openalex.org/T12597"}, {"name": "Power System Reliability and Maintenance", "value": 28360, "id": "https://openalex.org/T11941"}, {"name": "Safety Systems Engineering in Autonomy", "value": 24225, "id": "https://openalex.org/T13295"}, {"name": "Industrial and Mining Safety", "value": 7381, "id": "https://openalex.org/T14091"}]}, {"name": "Building and Construction", "children": [{"name": "BIM and Construction Integration", "value": 149221, "id": "https://openalex.org/T11006"}, {"name": "Building Energy and Comfort Optimization", "value": 137534, "id": "https://openalex.org/T10121"}, {"name": "Structural Behavior of Reinforced Concrete", "value": 115914, "id": "https://openalex.org/T10479"}, {"name": "Innovations in Concrete and Construction Materials", "value": 79240, "id": "https://openalex.org/T12190"}, {"name": "Traffic Prediction and Management Techniques", "value": 70812, "id": "https://openalex.org/T11344"}, {"name": "Dyeing and Modifying Textile Fibers", "value": 61533, "id": "https://openalex.org/T11511"}, {"name": "3D Modeling in Geospatial Applications", "value": 61274, "id": "https://openalex.org/T12698"}, {"name": "Wood Treatment and Properties", "value": 59587, "id": "https://openalex.org/T10484"}, {"name": "Urban and Freight Transport Logistics", "value": 59265, "id": "https://openalex.org/T12306"}, {"name": "Anaerobic Digestion and Biogas Production", "value": 59062, "id": "https://openalex.org/T10284"}, {"name": "Sustainable Building Design and Assessment", "value": 52756, "id": "https://openalex.org/T11988"}, {"name": "Urban Design and Spatial Analysis", "value": 50106, "id": "https://openalex.org/T12325"}, {"name": "Recycling and utilization of industrial and municipal waste in materials production", "value": 46356, "id": "https://openalex.org/T11672"}, {"name": "Recycled Aggregate Concrete Performance", "value": 42830, "id": "https://openalex.org/T11847"}, {"name": "Mining and Resource Management", "value": 42770, "id": "https://openalex.org/T11933"}, {"name": "Underground infrastructure and sustainability", "value": 42586, "id": "https://openalex.org/T13689"}, {"name": "Smart Parking Systems Research", "value": 35215, "id": "https://openalex.org/T12546"}, {"name": "Hygrothermal properties of building materials", "value": 29125, "id": "https://openalex.org/T12105"}, {"name": "Sustainable Design and Development", "value": 23397, "id": "https://openalex.org/T13477"}, {"name": "Building energy efficiency and sustainability", "value": 22998, "id": "https://openalex.org/T13263"}, {"name": "Construction Management and Sustainability", "value": 11016, "id": "https://openalex.org/T12239"}, {"name": "Blasting Impact and Analysis", "value": 2636, "id": "https://openalex.org/T14456"}]}, {"name": "Media Technology", "children": [{"name": "ICT Impact and Policies", "value": 148696, "id": "https://openalex.org/T11499"}, {"name": "Experimental Learning in Engineering", "value": 105901, "id": "https://openalex.org/T11283"}, {"name": "Engineering Education and Curriculum Development", "value": 72809, "id": "https://openalex.org/T12124"}, {"name": "Remote-Sensing Image Classification", "value": 61223, "id": "https://openalex.org/T10689"}, {"name": "Advanced Optical Imaging Technologies", "value": 46503, "id": "https://openalex.org/T11408"}, {"name": "Smart Cities and Technologies", "value": 46131, "id": "https://openalex.org/T11479"}, {"name": "Image Processing Techniques and Applications", "value": 38839, "id": "https://openalex.org/T13114"}, {"name": "RFID technology advancements", "value": 36780, "id": "https://openalex.org/T10986"}, {"name": "Advanced Image Fusion Techniques", "value": 31397, "id": "https://openalex.org/T11659"}, {"name": "Telecommunications and Broadcasting Technologies", "value": 30037, "id": "https://openalex.org/T13905"}, {"name": "Vehicle License Plate Recognition", "value": 24507, "id": "https://openalex.org/T12707"}, {"name": "Diverse Cultural Media Analysis", "value": 4306, "id": "https://openalex.org/T14145"}]}, {"name": "Architecture", "children": [{"name": "Architecture and Computational Design", "value": 129461, "id": "https://openalex.org/T13518"}, {"name": "Architecture, Modernity, and Design", "value": 91446, "id": "https://openalex.org/T12188"}, {"name": "Engineering Education and Pedagogy", "value": 33891, "id": "https://openalex.org/T13682"}, {"name": "Real estate and construction management", "value": 24734, "id": "https://openalex.org/T14390"}]}, {"name": "Automotive Engineering", "children": [{"name": "Advanced Battery Technologies Research", "value": 127668, "id": "https://openalex.org/T10663"}, {"name": "Additive Manufacturing and 3D Printing Technologies", "value": 116416, "id": "https://openalex.org/T10783"}, {"name": "Vehicle emissions and performance", "value": 108520, "id": "https://openalex.org/T12095"}, {"name": "Transportation and Mobility Innovations", "value": 83638, "id": "https://openalex.org/T11942"}, {"name": "Vehicle Dynamics and Control Systems", "value": 64805, "id": "https://openalex.org/T10805"}, {"name": "Autonomous Vehicle Technology and Safety", "value": 50315, "id": "https://openalex.org/T11099"}, {"name": "Electric and Hybrid Vehicle Technologies", "value": 49160, "id": "https://openalex.org/T10808"}, {"name": "Spatial Cognition and Navigation", "value": 46852, "id": "https://openalex.org/T11904"}, {"name": "Engine and Fuel Emissions", "value": 35529, "id": "https://openalex.org/T13990"}, {"name": "Vehicle Noise and Vibration Control", "value": 26831, "id": "https://openalex.org/T12759"}, {"name": "Brake Systems and Friction Analysis", "value": 21167, "id": "https://openalex.org/T12197"}, {"name": "Technical Engine Diagnostics and Monitoring", "value": 14909, "id": "https://openalex.org/T13858"}]}, {"name": "General Engineering", "children": [{"name": "Civil and Geotechnical Engineering Research", "value": 72230, "id": "https://openalex.org/T14446"}]}]}, {"name": "Environmental Science", "children": [{"name": "Ecological Modeling", "children": [{"name": "Species Distribution and Climate Change", "value": 976489, "id": "https://openalex.org/T10895"}, {"name": "Evaluation Methods in Various Fields", "value": 46576, "id": "https://openalex.org/T13955"}, {"name": "Erosion and Abrasive Machining", "value": 18662, "id": "https://openalex.org/T12092"}]}, {"name": "Management, Monitoring, Policy and Law", "children": [{"name": "American Environmental and Regional History", "value": 502259, "id": "https://openalex.org/T12837"}, {"name": "Finance, Taxation, and Governance", "value": 163838, "id": "https://openalex.org/T13760"}, {"name": "Environmental Sustainability and Education", "value": 154413, "id": "https://openalex.org/T12165"}, {"name": "Landslides and related hazards", "value": 143210, "id": "https://openalex.org/T10535"}, {"name": "Coastal and Marine Management", "value": 118872, "id": "https://openalex.org/T12414"}, {"name": "Rural Development and Agriculture", "value": 105783, "id": "https://openalex.org/T12348"}, {"name": "Urban Arborization and Environmental Studies", "value": 95637, "id": "https://openalex.org/T13801"}, {"name": "Rangeland Management and Livestock Ecology", "value": 92029, "id": "https://openalex.org/T12467"}, {"name": "International Maritime Law Issues", "value": 77939, "id": "https://openalex.org/T12652"}, {"name": "Environmental and Biological Research in Conflict Zones", "value": 73138, "id": "https://openalex.org/T14372"}, {"name": "Sustainable Development and Environmental Policy", "value": 68908, "id": "https://openalex.org/T12013"}, {"name": "Business and Economic Development", "value": 68558, "id": "https://openalex.org/T12922"}, {"name": "Environmental Education and Sustainability", "value": 66693, "id": "https://openalex.org/T10898"}, {"name": "Environmental Conservation and Management", "value": 65647, "id": "https://openalex.org/T13438"}, {"name": "Urban Planning and Valuation", "value": 54909, "id": "https://openalex.org/T13920"}, {"name": "Environmental and Social Impact Assessments", "value": 46779, "id": "https://openalex.org/T12227"}, {"name": "Korean Urban and Social Studies", "value": 46618, "id": "https://openalex.org/T13729"}, {"name": "Coastal Management and Development", "value": 43779, "id": "https://openalex.org/T14408"}, {"name": "Mexican Socioeconomic and Environmental Dynamics", "value": 43445, "id": "https://openalex.org/T14452"}, {"name": "International Environmental Law and Policies", "value": 39006, "id": "https://openalex.org/T13756"}, {"name": "Soil and Land Suitability Analysis", "value": 31400, "id": "https://openalex.org/T13058"}, {"name": "Urban Planning and Landscape Design", "value": 26807, "id": "https://openalex.org/T13654"}, {"name": "Environmental and sustainability education", "value": 25946, "id": "https://openalex.org/T13557"}, {"name": "Environmental and Sediment Control", "value": 23144, "id": "https://openalex.org/T14106"}, {"name": "Conservation, Ecology, Wildlife Education", "value": 18728, "id": "https://openalex.org/T13967"}, {"name": "Sustainable Development and Environmental Management", "value": 18661, "id": "https://openalex.org/T12883"}, {"name": "Education, Technology, and Ethics", "value": 16335, "id": "https://openalex.org/T14341"}, {"name": "Sustainable Development and Policies", "value": 16294, "id": "https://openalex.org/T13893"}, {"name": "Socioeconomic and Demographic Analysis", "value": 14932, "id": "https://openalex.org/T14019"}, {"name": "Water and Land Management", "value": 12991, "id": "https://openalex.org/T13082"}, {"name": "Environmental Sustainability and Technology", "value": 11337, "id": "https://openalex.org/T13432"}, {"name": "Analysis of environmental and stochastic processes", "value": 4970, "id": "https://openalex.org/T13244"}, {"name": "Whitehead's Philosophy and Applications", "value": 4809, "id": "https://openalex.org/T13933"}, {"name": "Advanced Scientific Techniques and Applications", "value": 4563, "id": "https://openalex.org/T13592"}]}, {"name": "Environmental Engineering", "children": [{"name": "Soil Moisture and Remote Sensing", "value": 354015, "id": "https://openalex.org/T11312"}, {"name": "Photovoltaic Systems and Sustainability", "value": 105999, "id": "https://openalex.org/T12838"}, {"name": "Remote Sensing and LiDAR Applications", "value": 102377, "id": "https://openalex.org/T11164"}, {"name": "Groundwater flow and contamination studies", "value": 89290, "id": "https://openalex.org/T10894"}, {"name": "Air Quality Monitoring and Forecasting", "value": 80122, "id": "https://openalex.org/T12120"}, {"name": "Wind and Air Flow Studies", "value": 70282, "id": "https://openalex.org/T11371"}, {"name": "Environmental Impact and Sustainability", "value": 69625, "id": "https://openalex.org/T10435"}, {"name": "Soil Geostatistics and Mapping", "value": 63727, "id": "https://openalex.org/T10770"}, {"name": "Urban Heat Island Mitigation", "value": 60007, "id": "https://openalex.org/T10766"}, {"name": "CO2 Sequestration and Geologic Interactions", "value": 59532, "id": "https://openalex.org/T11302"}, {"name": "Maritime Transport Emissions and Efficiency", "value": 54868, "id": "https://openalex.org/T12126"}, {"name": "Urban Stormwater Management Solutions", "value": 46442, "id": "https://openalex.org/T11119"}, {"name": "Microbial Fuel Cells and Bioremediation", "value": 42932, "id": "https://openalex.org/T11231"}, {"name": "Groundwater and Watershed Analysis", "value": 33075, "id": "https://openalex.org/T12543"}, {"name": "Hydrological Forecasting Using AI", "value": 32255, "id": "https://openalex.org/T11490"}, {"name": "Environmental and Industrial Safety", "value": 21471, "id": "https://openalex.org/T13517"}, {"name": "Microbial Applications in Construction Materials", "value": 17547, "id": "https://openalex.org/T12247"}, {"name": "Sustainability and Ecological Systems Analysis", "value": 17132, "id": "https://openalex.org/T12643"}, {"name": "Environmental and Air Quality Management", "value": 4108, "id": "https://openalex.org/T13148"}]}, {"name": "Environmental Chemistry", "children": [{"name": "Methane Hydrates and Related Phenomena", "value": 327799, "id": "https://openalex.org/T10995"}, {"name": "Aquatic Ecosystems and Phytoplankton Dynamics", "value": 192148, "id": "https://openalex.org/T10236"}, {"name": "Chemistry and Chemical Engineering", "value": 128951, "id": "https://openalex.org/T13180"}, {"name": "Soil and Water Nutrient Dynamics", "value": 70343, "id": "https://openalex.org/T11311"}, {"name": "Arsenic contamination and mitigation", "value": 52324, "id": "https://openalex.org/T10710"}, {"name": "Mine drainage and remediation techniques", "value": 51522, "id": "https://openalex.org/T11923"}, {"name": "Marine Toxins and Detection Methods", "value": 48810, "id": "https://openalex.org/T11985"}, {"name": "Turfgrass Adaptation and Management", "value": 31212, "id": "https://openalex.org/T12822"}, {"name": "Environmental Chemistry and Analysis", "value": 29368, "id": "https://openalex.org/T13092"}, {"name": "Per- and polyfluoroalkyl substances research", "value": 29120, "id": "https://openalex.org/T11869"}, {"name": "Sustainable Agricultural Systems Analysis", "value": 26718, "id": "https://openalex.org/T12896"}]}, {"name": "Global and Planetary Change", "children": [{"name": "Amphibian and Reptile Biology", "value": 260974, "id": "https://openalex.org/T10332"}, {"name": "Marine and fisheries research", "value": 191934, "id": "https://openalex.org/T10230"}, {"name": "Atmospheric and Environmental Gas Dynamics", "value": 151822, "id": "https://openalex.org/T11588"}, {"name": "Climate variability and models", "value": 148167, "id": "https://openalex.org/T10029"}, {"name": "Forest Management and Policy", "value": 139456, "id": "https://openalex.org/T11753"}, {"name": "Atmospheric aerosols and clouds", "value": 118342, "id": "https://openalex.org/T10347"}, {"name": "Fire effects on ecosystems", "value": 109193, "id": "https://openalex.org/T10555"}, {"name": "Radioactive contamination and transfer", "value": 105923, "id": "https://openalex.org/T11089"}, {"name": "Land Use and Ecosystem Services", "value": 104045, "id": "https://openalex.org/T10226"}, {"name": "Plant Water Relations and Carbon Dynamics", "value": 100627, "id": "https://openalex.org/T10266"}, {"name": "Flood Risk Assessment and Management", "value": 95084, "id": "https://openalex.org/T10930"}, {"name": "Marine Ecology and Invasive Species", "value": 89661, "id": "https://openalex.org/T12213"}, {"name": "Impact of Light on Environment and Health", "value": 81749, "id": "https://openalex.org/T11963"}, {"name": "Marine Bivalve and Aquaculture Studies", "value": 76397, "id": "https://openalex.org/T11088"}, {"name": "Conservation, Biodiversity, and Resource Management", "value": 74797, "id": "https://openalex.org/T10319"}, {"name": "Hydrology and Drought Analysis", "value": 51873, "id": "https://openalex.org/T11186"}, {"name": "Diverse Scientific Research in Ukraine", "value": 50371, "id": "https://openalex.org/T13318"}, {"name": "Advanced Aircraft Design and Technologies", "value": 41573, "id": "https://openalex.org/T11524"}, {"name": "Sustainability and Climate Change Governance", "value": 34451, "id": "https://openalex.org/T10119"}, {"name": "COVID-19 impact on air quality", "value": 34395, "id": "https://openalex.org/T12916"}, {"name": "Science and Climate Studies", "value": 28504, "id": "https://openalex.org/T14329"}, {"name": "Environmental Changes in China", "value": 27477, "id": "https://openalex.org/T13203"}, {"name": "Climate Change and Environmental Impact", "value": 27296, "id": "https://openalex.org/T13530"}, {"name": "Climate Change and Geoengineering", "value": 27275, "id": "https://openalex.org/T12615"}, {"name": "Ecosystem dynamics and resilience", "value": 23186, "id": "https://openalex.org/T13377"}, {"name": "Climate Change and Sustainable Development", "value": 15196, "id": "https://openalex.org/T14296"}, {"name": "Ukraine: War, Education, Health", "value": 11985, "id": "https://openalex.org/T13424"}, {"name": "Scientific Research and Studies", "value": 6780, "id": "https://openalex.org/T13997"}, {"name": "Literature, Politics, and Exile Studies", "value": 6061, "id": "https://openalex.org/T13507"}, {"name": "Academic Research and Education Studies", "value": 3952, "id": "https://openalex.org/T14279"}]}, {"name": "Ecology", "children": [{"name": "Parasite Biology and Host Interactions", "value": 216203, "id": "https://openalex.org/T10815"}, {"name": "Plant Ecology and Soil Science", "value": 198693, "id": "https://openalex.org/T14468"}, {"name": "Avian ecology and behavior", "value": 182618, "id": "https://openalex.org/T10089"}, {"name": "Ecology and biodiversity studies", "value": 170496, "id": "https://openalex.org/T14039"}, {"name": "Aquatic Invertebrate Ecology and Behavior", "value": 170155, "id": "https://openalex.org/T12097"}, {"name": "Freshwater macroinvertebrate diversity and ecology", "value": 169544, "id": "https://openalex.org/T10669"}, {"name": "Microbial Community Ecology and Physiology", "value": 163231, "id": "https://openalex.org/T11791"}, {"name": "Wildlife Ecology and Conservation", "value": 159860, "id": "https://openalex.org/T10199"}, {"name": "Crustacean biology and ecology", "value": 157108, "id": "https://openalex.org/T11004"}, {"name": "Bacteriophages and microbial interactions", "value": 138020, "id": "https://openalex.org/T11048"}, {"name": "Animal Ecology and Behavior Studies", "value": 137183, "id": "https://openalex.org/T11913"}, {"name": "Remote Sensing in Agriculture", "value": 121618, "id": "https://openalex.org/T10111"}, {"name": "Marine animal studies overview", "value": 115439, "id": "https://openalex.org/T10659"}, {"name": "Coral and Marine Ecosystems Studies", "value": 100112, "id": "https://openalex.org/T10341"}, {"name": "Peatlands and Wetlands Ecology", "value": 95872, "id": "https://openalex.org/T12091"}, {"name": "Forest Insect Ecology and Management", "value": 92954, "id": "https://openalex.org/T11691"}, {"name": "Physiological and biochemical adaptations", "value": 89077, "id": "https://openalex.org/T11056"}, {"name": "Hydrology and Sediment Transport Processes", "value": 87896, "id": "https://openalex.org/T10577"}, {"name": "Polar Research and Ecology", "value": 78472, "id": "https://openalex.org/T12180"}, {"name": "Isotope Analysis in Ecology", "value": 76899, "id": "https://openalex.org/T12073"}, {"name": "Agriculture Sustainability and Environmental Impact", "value": 74413, "id": "https://openalex.org/T11259"}, {"name": "Rangeland and Wildlife Management", "value": 73540, "id": "https://openalex.org/T13388"}, {"name": "Coastal wetland ecosystem dynamics", "value": 70741, "id": "https://openalex.org/T10779"}, {"name": "Research studies in Vietnam", "value": 61717, "id": "https://openalex.org/T13882"}, {"name": "Environmental DNA in Biodiversity Studies", "value": 60132, "id": "https://openalex.org/T12640"}, {"name": "Environmental and Cultural Studies in Latin America and Beyond", "value": 56935, "id": "https://openalex.org/T14472"}, {"name": "Environmental Quality and Pollution", "value": 53420, "id": "https://openalex.org/T13909"}, {"name": "Aquatic Ecosystems and Biodiversity", "value": 41644, "id": "https://openalex.org/T13490"}, {"name": "Oil Palm Production and Sustainability", "value": 41135, "id": "https://openalex.org/T12703"}, {"name": "Wildlife-Road Interactions and Conservation", "value": 39853, "id": "https://openalex.org/T12644"}, {"name": "Environmental and biological studies", "value": 34420, "id": "https://openalex.org/T13548"}, {"name": "Marine and Coastal Ecosystems", "value": 31004, "id": "https://openalex.org/T13485"}, {"name": "Water Resources and Management", "value": 19478, "id": "https://openalex.org/T14177"}]}, {"name": "Nature and Landscape Conservation", "children": [{"name": "Ecology, Conservation, and Geographical Studies", "value": 213267, "id": "https://openalex.org/T13394"}, {"name": "Fish Ecology and Management Studies", "value": 196193, "id": "https://openalex.org/T10302"}, {"name": "Ichthyology and Marine Biology", "value": 181615, "id": "https://openalex.org/T11387"}, {"name": "Forest ecology and management", "value": 129797, "id": "https://openalex.org/T11880"}, {"name": "Fish biology, ecology, and behavior", "value": 120669, "id": "https://openalex.org/T12014"}, {"name": "Ecology and Vegetation Dynamics Studies", "value": 113423, "id": "https://openalex.org/T10005"}, {"name": "Urban and spatial planning", "value": 82124, "id": "https://openalex.org/T11955"}, {"name": "Turtle Biology and Conservation", "value": 53878, "id": "https://openalex.org/T11656"}, {"name": "Seedling growth and survival studies", "value": 39899, "id": "https://openalex.org/T12870"}, {"name": "Wildlife Conservation and Criminology Analyses", "value": 39095, "id": "https://openalex.org/T12965"}, {"name": "Environmental Philosophy and Ethics", "value": 22949, "id": "https://openalex.org/T12819"}, {"name": "Aerospace, Electronics, Mathematical Modeling", "value": 13544, "id": "https://openalex.org/T13732"}]}, {"name": "Industrial and Manufacturing Engineering", "children": [{"name": "Water Quality Monitoring and Analysis", "value": 194759, "id": "https://openalex.org/T14249"}, {"name": "Recycling and Waste Management Techniques", "value": 101418, "id": "https://openalex.org/T12017"}, {"name": "Municipal Solid Waste Management", "value": 65321, "id": "https://openalex.org/T11108"}, {"name": "Chemical Synthesis and Characterization", "value": 60037, "id": "https://openalex.org/T12524"}, {"name": "Phosphorus and nutrient management", "value": 50024, "id": "https://openalex.org/T12186"}, {"name": "Wastewater Treatment and Reuse", "value": 41105, "id": "https://openalex.org/T11781"}, {"name": "Constructed Wetlands for Wastewater Treatment", "value": 37551, "id": "https://openalex.org/T11624"}, {"name": "Landfill Environmental Impact Studies", "value": 31606, "id": "https://openalex.org/T11952"}, {"name": "Waste Management and Recycling", "value": 29958, "id": "https://openalex.org/T14179"}]}, {"name": "Water Science and Technology", "children": [{"name": "Water Quality and Resources Studies", "value": 180443, "id": "https://openalex.org/T12773"}, {"name": "Hydrology and Watershed Management Studies", "value": 156885, "id": "https://openalex.org/T10330"}, {"name": "Geography and Environmental Studies", "value": 106808, "id": "https://openalex.org/T12577"}, {"name": "Adsorption and biosorption for pollutant removal", "value": 106683, "id": "https://openalex.org/T10016"}, {"name": "Water Quality and Pollution Assessment", "value": 100196, "id": "https://openalex.org/T11634"}, {"name": "Membrane Separation Technologies", "value": 92013, "id": "https://openalex.org/T10197"}, {"name": "Water Quality Monitoring Technologies", "value": 80882, "id": "https://openalex.org/T12697"}, {"name": "Environmental and Agricultural Sciences", "value": 73096, "id": "https://openalex.org/T14157"}, {"name": "Minerals Flotation and Separation Techniques", "value": 71314, "id": "https://openalex.org/T11401"}, {"name": "Environmental Science and Water Management", "value": 69628, "id": "https://openalex.org/T14178"}, {"name": "Water-Energy-Food Nexus Studies", "value": 57889, "id": "https://openalex.org/T12724"}, {"name": "Water Resource Management and Quality", "value": 56783, "id": "https://openalex.org/T14232"}, {"name": "Advanced oxidation water treatment", "value": 52516, "id": "https://openalex.org/T10210"}, {"name": "Integrated Water Resources Management", "value": 47541, "id": "https://openalex.org/T13375"}, {"name": "Fluoride Effects and Removal", "value": 41517, "id": "https://openalex.org/T11969"}, {"name": "Agriculture, Water, and Health", "value": 35783, "id": "https://openalex.org/T14323"}, {"name": "Fecal contamination and water quality", "value": 31161, "id": "https://openalex.org/T11331"}, {"name": "Coagulation and Flocculation Studies", "value": 22345, "id": "https://openalex.org/T11188"}, {"name": "Heavy Metal Pollution Remediation", "value": 20934, "id": "https://openalex.org/T12780"}, {"name": "Environmental and Analytical Chemistry Studies", "value": 13007, "id": "https://openalex.org/T13793"}, {"name": "Water Resources and Sustainability", "value": 10415, "id": "https://openalex.org/T12911"}, {"name": "Sustainability, Environment, and Optimization Algorithms", "value": 5179, "id": "https://openalex.org/T13663"}, {"name": "Physical Activity and Education Research", "value": 4828, "id": "https://openalex.org/T13804"}, {"name": "Scientific Research Methodologies and Applications", "value": 2223, "id": "https://openalex.org/T14069"}]}, {"name": "Health, Toxicology and Mutagenesis", "children": [{"name": "Air Quality and Health Impacts", "value": 154848, "id": "https://openalex.org/T10190"}, {"name": "Educational Reforms and Innovations", "value": 102604, "id": "https://openalex.org/T12705"}, {"name": "Toxic Organic Pollutants Impact", "value": 101447, "id": "https://openalex.org/T10122"}, {"name": "Climate Change and Health Impacts", "value": 84923, "id": "https://openalex.org/T11244"}, {"name": "Environmental Toxicology and Ecotoxicology", "value": 81940, "id": "https://openalex.org/T10447"}, {"name": "Mercury impact and mitigation studies", "value": 68234, "id": "https://openalex.org/T10819"}, {"name": "Public Health and Environmental Issues", "value": 66588, "id": "https://openalex.org/T14169"}, {"name": "Heavy Metal Exposure and Toxicity", "value": 64793, "id": "https://openalex.org/T10790"}, {"name": "Urban Green Space and Health", "value": 63564, "id": "https://openalex.org/T10692"}, {"name": "Effects and risks of endocrine disrupting chemicals", "value": 63325, "id": "https://openalex.org/T10686"}, {"name": "Health, Environment, Cognitive Aging", "value": 58524, "id": "https://openalex.org/T14393"}, {"name": "Insects and Parasite Interactions", "value": 52447, "id": "https://openalex.org/T14324"}, {"name": "Indoor Air Quality and Microbial Exposure", "value": 43858, "id": "https://openalex.org/T11002"}, {"name": "Water Treatment and Disinfection", "value": 41602, "id": "https://openalex.org/T11493"}, {"name": "Chromium effects and bioremediation", "value": 39761, "id": "https://openalex.org/T11972"}, {"name": "Chemical Analysis and Environmental Impact", "value": 21602, "id": "https://openalex.org/T13563"}]}, {"name": "Pollution", "children": [{"name": "Heavy metals in environment", "value": 114993, "id": "https://openalex.org/T10139"}, {"name": "Microplastics and Plastic Pollution", "value": 100476, "id": "https://openalex.org/T10753"}, {"name": "Energy and Environment Impacts", "value": 96811, "id": "https://openalex.org/T11336"}, {"name": "Wastewater Treatment and Nitrogen Removal", "value": 94868, "id": "https://openalex.org/T10564"}, {"name": "Pesticide and Herbicide Environmental Studies", "value": 66552, "id": "https://openalex.org/T11180"}, {"name": "Pharmaceutical and Antibiotic Environmental Impacts", "value": 65127, "id": "https://openalex.org/T10419"}, {"name": "Microbial bioremediation and biosurfactants", "value": 56906, "id": "https://openalex.org/T10324"}, {"name": "Smart Materials for Construction", "value": 47921, "id": "https://openalex.org/T12682"}, {"name": "Oil Spill Detection and Mitigation", "value": 40762, "id": "https://openalex.org/T12316"}, {"name": "Environmental Policies and Emissions", "value": 34109, "id": "https://openalex.org/T13916"}, {"name": "Thallium and Germanium Studies", "value": 14382, "id": "https://openalex.org/T14120"}]}]}, {"name": "Materials Science", "children": [{"name": "Materials Chemistry", "children": [{"name": "Crystallization and Solubility Studies", "value": 778386, "id": "https://openalex.org/T11881"}, {"name": "X-ray Diffraction in Crystallography", "value": 282524, "id": "https://openalex.org/T12613"}, {"name": "Catalytic Processes in Materials Science", "value": 212632, "id": "https://openalex.org/T10192"}, {"name": "Enzyme Structure and Function", "value": 172528, "id": "https://openalex.org/T11162"}, {"name": "High voltage insulation and dielectric phenomena", "value": 167096, "id": "https://openalex.org/T10511"}, {"name": "Thermal properties of materials", "value": 154652, "id": "https://openalex.org/T11277"}, {"name": "Graphene research and applications", "value": 131101, "id": "https://openalex.org/T10083"}, {"name": "Machine Learning in Materials Science", "value": 124328, "id": "https://openalex.org/T11948"}, {"name": "Solid-state spectroscopy and crystallography", "value": 120167, "id": "https://openalex.org/T11878"}, {"name": "Corrosion Behavior and Inhibition", "value": 117709, "id": "https://openalex.org/T10310"}, {"name": "Luminescence Properties of Advanced Materials", "value": 107379, "id": "https://openalex.org/T10097"}, {"name": "Graphite, nuclear technology, radiation studies", "value": 106267, "id": "https://openalex.org/T13465"}, {"name": "Carbon Nanotubes in Composites", "value": 104119, "id": "https://openalex.org/T10074"}, {"name": "ZnO doping and properties", "value": 102366, "id": "https://openalex.org/T10090"}, {"name": "Diamond and Carbon-based Materials Research", "value": 99262, "id": "https://openalex.org/T10478"}, {"name": "Nuclear Materials and Properties", "value": 98646, "id": "https://openalex.org/T11242"}, {"name": "Ferroelectric and Piezoelectric Materials", "value": 97730, "id": "https://openalex.org/T10107"}, {"name": "Porphyrin and Phthalocyanine Chemistry", "value": 94092, "id": "https://openalex.org/T10903"}, {"name": "Nanoparticles: synthesis and applications", "value": 92407, "id": "https://openalex.org/T10079"}, {"name": "2D Materials and Applications", "value": 80686, "id": "https://openalex.org/T10275"}, {"name": "Quantum Dots Synthesis And Properties", "value": 80320, "id": "https://openalex.org/T10321"}, {"name": "Metal Alloys Wear and Properties", "value": 75040, "id": "https://openalex.org/T12427"}, {"name": "Lanthanide and Transition Metal Complexes", "value": 73927, "id": "https://openalex.org/T11279"}, {"name": "Thermal and Kinetic Analysis", "value": 68551, "id": "https://openalex.org/T12358"}, {"name": "Microstructure and mechanical properties", "value": 66302, "id": "https://openalex.org/T10204"}, {"name": "Material Dynamics and Properties", "value": 64937, "id": "https://openalex.org/T10474"}, {"name": "Advancements in Solid Oxide Fuel Cells", "value": 64929, "id": "https://openalex.org/T10311"}, {"name": "Mesoporous Materials and Catalysis", "value": 64480, "id": "https://openalex.org/T10735"}, {"name": "Advanced Thermoelectric Materials and Devices", "value": 62948, "id": "https://openalex.org/T10440"}, {"name": "Polyoxometalates: Synthesis and Applications", "value": 62020, "id": "https://openalex.org/T11286"}, {"name": "High-Velocity Impact and Material Behavior", "value": 61076, "id": "https://openalex.org/T11699"}, {"name": "Hydrogen Storage and Materials", "value": 54874, "id": "https://openalex.org/T10811"}, {"name": "Material Selection and Properties", "value": 51209, "id": "https://openalex.org/T12938"}, {"name": "Fusion materials and technologies", "value": 50089, "id": "https://openalex.org/T10592"}, {"name": "Silicon Nanostructures and Photoluminescence", "value": 49613, "id": "https://openalex.org/T11169"}, {"name": "Silicone and Siloxane Chemistry", "value": 49091, "id": "https://openalex.org/T12420"}, {"name": "Metallurgy and Material Science", "value": 48978, "id": "https://openalex.org/T14184"}, {"name": "Magnetic Properties and Synthesis of Ferrites", "value": 47015, "id": "https://openalex.org/T10922"}, {"name": "Pickering emulsions and particle stabilization", "value": 46098, "id": "https://openalex.org/T11915"}, {"name": "Luminescence and Fluorescent Materials", "value": 45111, "id": "https://openalex.org/T11240"}, {"name": "Shape Memory Alloy Transformations", "value": 43897, "id": "https://openalex.org/T10865"}, {"name": "Solidification and crystal growth phenomena", "value": 43038, "id": "https://openalex.org/T11087"}, {"name": "MXene and MAX Phase Materials", "value": 41751, "id": "https://openalex.org/T12046"}, {"name": "Electronic and Structural Properties of Oxides", "value": 39909, "id": "https://openalex.org/T12588"}, {"name": "Phase-change materials and chalcogenides", "value": 39660, "id": "https://openalex.org/T11315"}, {"name": "Photochromic and Fluorescence Chemistry", "value": 38908, "id": "https://openalex.org/T11708"}, {"name": "Quasicrystal Structures and Properties", "value": 37829, "id": "https://openalex.org/T11887"}, {"name": "Boron and Carbon Nanomaterials Research", "value": 36915, "id": "https://openalex.org/T11341"}, {"name": "Material Properties and Failure Mechanisms", "value": 35414, "id": "https://openalex.org/T14076"}, {"name": "Advanced Nanomaterials in Catalysis", "value": 33891, "id": "https://openalex.org/T12302"}, {"name": "Titanium Alloys Microstructure and Properties", "value": 32187, "id": "https://openalex.org/T11442"}, {"name": "Anodic Oxide Films and Nanostructures", "value": 30814, "id": "https://openalex.org/T12340"}, {"name": "Carbon and Quantum Dots Applications", "value": 30769, "id": "https://openalex.org/T11342"}, {"name": "Copper-based nanomaterials and applications", "value": 30036, "id": "https://openalex.org/T11907"}, {"name": "Nuclear materials and radiation effects", "value": 29552, "id": "https://openalex.org/T12506"}, {"name": "Covalent Organic Framework Applications", "value": 28493, "id": "https://openalex.org/T12038"}, {"name": "Nanocluster Synthesis and Applications", "value": 27554, "id": "https://openalex.org/T12149"}, {"name": "Chemical and Physical Properties of Materials", "value": 27063, "id": "https://openalex.org/T13104"}, {"name": "Ultrasound and Cavitation Phenomena", "value": 25818, "id": "https://openalex.org/T11842"}, {"name": "Block Copolymer Self-Assembly", "value": 25291, "id": "https://openalex.org/T11471"}, {"name": "Layered Double Hydroxides Synthesis and Applications", "value": 25115, "id": "https://openalex.org/T11940"}, {"name": "Thermal Expansion and Ionic Conductivity", "value": 24802, "id": "https://openalex.org/T12875"}, {"name": "Structural mechanics and materials", "value": 23771, "id": "https://openalex.org/T13159"}, {"name": "Nonlocal and gradient elasticity in micro/nano structures", "value": 21397, "id": "https://openalex.org/T11646"}, {"name": "Magnesium Oxide Properties and Applications", "value": 19716, "id": "https://openalex.org/T13039"}, {"name": "Radiation Shielding Materials Analysis", "value": 13947, "id": "https://openalex.org/T12299"}, {"name": "Nanoporous metals and alloys", "value": 10102, "id": "https://openalex.org/T13463"}, {"name": "Dielectric properties of ceramics", "value": 5385, "id": "https://openalex.org/T13249"}, {"name": "Advanced Materials and Semiconductor Technologies", "value": 4302, "id": "https://openalex.org/T13889"}]}, {"name": "Biomaterials", "children": [{"name": "Diatoms and Algae Research", "value": 320271, "id": "https://openalex.org/T12012"}, {"name": "Clay minerals and soil interactions", "value": 203160, "id": "https://openalex.org/T11852"}, {"name": "biodegradable polymer synthesis and properties", "value": 126666, "id": "https://openalex.org/T10661"}, {"name": "Nanoparticle-Based Drug Delivery", "value": 81808, "id": "https://openalex.org/T10063"}, {"name": "Electrospun Nanofibers in Biomedical Applications", "value": 81140, "id": "https://openalex.org/T10729"}, {"name": "Advanced Cellulose Research Studies", "value": 64129, "id": "https://openalex.org/T10610"}, {"name": "Phytochemistry and Bioactive Compounds", "value": 63314, "id": "https://openalex.org/T13185"}, {"name": "Magnesium Alloys: Properties and Applications", "value": 55401, "id": "https://openalex.org/T10530"}, {"name": "Calcium Carbonate Crystallization and Inhibition", "value": 52508, "id": "https://openalex.org/T11278"}, {"name": "Nanocomposite Films for Food Packaging", "value": 46230, "id": "https://openalex.org/T10488"}, {"name": "Supramolecular Self-Assembly in Materials", "value": 42990, "id": "https://openalex.org/T11419"}, {"name": "Silk-based biomaterials and applications", "value": 39183, "id": "https://openalex.org/T11966"}, {"name": "Collagen: Extraction and Characterization", "value": 35110, "id": "https://openalex.org/T12085"}]}, {"name": "Surfaces, Coatings and Films", "children": [{"name": "Electron and X-Ray Spectroscopy Techniques", "value": 243988, "id": "https://openalex.org/T12039"}, {"name": "Surface Modification and Superhydrophobicity", "value": 71620, "id": "https://openalex.org/T10313"}, {"name": "Optical Coatings and Gratings", "value": 52492, "id": "https://openalex.org/T11723"}, {"name": "Polymer Surface Interaction Studies", "value": 42516, "id": "https://openalex.org/T10859"}]}, {"name": "General Materials Science", "children": [{"name": "Material Properties and Applications", "value": 180460, "id": "https://openalex.org/T13129"}, {"name": "Engineering and Material Science Research", "value": 84695, "id": "https://openalex.org/T13917"}, {"name": "Metallurgical and Alloy Processes", "value": 34032, "id": "https://openalex.org/T14128"}]}, {"name": "Polymers and Plastics", "children": [{"name": "Conducting polymers and applications", "value": 128094, "id": "https://openalex.org/T10660"}, {"name": "Textile materials and evaluations", "value": 127816, "id": "https://openalex.org/T11595"}, {"name": "Synthesis and properties of polymers", "value": 93989, "id": "https://openalex.org/T12084"}, {"name": "Polymer crystallization and properties", "value": 70250, "id": "https://openalex.org/T10389"}, {"name": "Natural Fiber Reinforced Composites", "value": 69899, "id": "https://openalex.org/T10513"}, {"name": "Polymer Nanocomposites and Properties", "value": 69878, "id": "https://openalex.org/T10501"}, {"name": "Transition Metal Oxide Nanomaterials", "value": 49619, "id": "https://openalex.org/T11128"}, {"name": "Polymer composites and self-healing", "value": 46901, "id": "https://openalex.org/T10810"}, {"name": "Polymer Science and PVC", "value": 38650, "id": "https://openalex.org/T13171"}, {"name": "Flame retardant materials and properties", "value": 37034, "id": "https://openalex.org/T11360"}, {"name": "Dendrimers and Hyperbranched Polymers", "value": 31478, "id": "https://openalex.org/T11686"}, {"name": "Polymer Foaming and Composites", "value": 19162, "id": "https://openalex.org/T12628"}, {"name": "Polymer Nanocomposite Synthesis and Irradiation", "value": 17434, "id": "https://openalex.org/T12416"}, {"name": "Polymer Synthesis and Characterization", "value": 7371, "id": "https://openalex.org/T14303"}]}, {"name": "Ceramics and Composites", "children": [{"name": "Advanced ceramic materials synthesis", "value": 124470, "id": "https://openalex.org/T10132"}, {"name": "Glass properties and applications", "value": 124304, "id": "https://openalex.org/T10544"}]}, {"name": "Electronic, Optical and Magnetic Materials", "children": [{"name": "Liquid Crystal Research Advancements", "value": 98423, "id": "https://openalex.org/T10306"}, {"name": "Supercapacitor Materials and Fabrication", "value": 98014, "id": "https://openalex.org/T10179"}, {"name": "Magnetism in coordination complexes", "value": 96791, "id": "https://openalex.org/T10612"}, {"name": "Magnetic and transport properties of perovskites and related materials", "value": 77223, "id": "https://openalex.org/T10607"}, {"name": "Magnetic Properties and Applications", "value": 75761, "id": "https://openalex.org/T11222"}, {"name": "Gold and Silver Nanoparticles Synthesis and Applications", "value": 73896, "id": "https://openalex.org/T10131"}, {"name": "Metamaterials and Metasurfaces Applications", "value": 64778, "id": "https://openalex.org/T10245"}, {"name": "Crystal Structures and Properties", "value": 53753, "id": "https://openalex.org/T10939"}, {"name": "Magnetic Properties of Alloys", "value": 49993, "id": "https://openalex.org/T11782"}, {"name": "Multiferroics and related materials", "value": 45934, "id": "https://openalex.org/T10886"}, {"name": "Organic and Molecular Conductors Research", "value": 45047, "id": "https://openalex.org/T11758"}, {"name": "Nonlinear Optical Materials Research", "value": 42933, "id": "https://openalex.org/T11025"}, {"name": "Iron-based superconductors research", "value": 38241, "id": "https://openalex.org/T11766"}, {"name": "Copper Interconnects and Reliability", "value": 37531, "id": "https://openalex.org/T11661"}, {"name": "Electromagnetic wave absorption materials", "value": 31787, "id": "https://openalex.org/T11224"}, {"name": "Heusler alloys: electronic and magnetic properties", "value": 22849, "id": "https://openalex.org/T12200"}, {"name": "Ga2O3 and related materials", "value": 20776, "id": "https://openalex.org/T12529"}]}, {"name": "Metals and Alloys", "children": [{"name": "Hydrogen embrittlement and corrosion behaviors in metals", "value": 62419, "id": "https://openalex.org/T10736"}]}]}, {"name": "Earth and Planetary Sciences", "children": [{"name": "Paleontology", "children": [{"name": "Subterranean biodiversity and taxonomy", "value": 468691, "id": "https://openalex.org/T11926"}, {"name": "Evolution and Paleontology Studies", "value": 257690, "id": "https://openalex.org/T11354"}, {"name": "Paleontology and Stratigraphy of Fossils", "value": 160789, "id": "https://openalex.org/T10109"}, {"name": "Archaeology and ancient environmental studies", "value": 151939, "id": "https://openalex.org/T10087"}, {"name": "Marine Invertebrate Physiology and Ecology", "value": 122260, "id": "https://openalex.org/T12142"}, {"name": "Paleontology and Evolutionary Biology", "value": 116475, "id": "https://openalex.org/T10955"}, {"name": "Scarabaeidae Beetle Taxonomy and Biogeography", "value": 67019, "id": "https://openalex.org/T12637"}]}, {"name": "Atmospheric Science", "children": [{"name": "Geology and Paleoclimatology Research", "value": 382119, "id": "https://openalex.org/T10017"}, {"name": "Tree-ring climate responses", "value": 211229, "id": "https://openalex.org/T11594"}, {"name": "Atmospheric chemistry and aerosols", "value": 160652, "id": "https://openalex.org/T10075"}, {"name": "Cryospheric studies and observations", "value": 141410, "id": "https://openalex.org/T10644"}, {"name": "Remote Sensing and Land Use", "value": 127218, "id": "https://openalex.org/T13890"}, {"name": "Meteorological Phenomena and Simulations", "value": 124402, "id": "https://openalex.org/T10466"}, {"name": "Atmospheric Ozone and Climate", "value": 119120, "id": "https://openalex.org/T11320"}, {"name": "Arctic and Antarctic ice dynamics", "value": 85098, "id": "https://openalex.org/T11459"}, {"name": "nanoparticles nucleation surface interactions", "value": 74133, "id": "https://openalex.org/T12202"}, {"name": "Climate change and permafrost", "value": 71346, "id": "https://openalex.org/T11333"}, {"name": "Tropical and Extratropical Cyclones Research", "value": 66293, "id": "https://openalex.org/T11483"}, {"name": "Precipitation Measurement and Analysis", "value": 64978, "id": "https://openalex.org/T11234"}, {"name": "Earth Systems and Cosmic Evolution", "value": 29745, "id": "https://openalex.org/T13811"}]}, {"name": "Geophysics", "children": [{"name": "Geological and Geochemical Analysis", "value": 358363, "id": "https://openalex.org/T10001"}, {"name": "Seismic Waves and Analysis", "value": 209250, "id": "https://openalex.org/T11757"}, {"name": "Seismic Imaging and Inversion Techniques", "value": 195403, "id": "https://openalex.org/T10271"}, {"name": "earthquake and tectonic studies", "value": 189895, "id": "https://openalex.org/T10110"}, {"name": "Geophysical and Geoelectrical Methods", "value": 182249, "id": "https://openalex.org/T10572"}, {"name": "High-pressure geophysics and materials", "value": 175199, "id": "https://openalex.org/T10413"}, {"name": "Earthquake Detection and Analysis", "value": 136298, "id": "https://openalex.org/T12424"}, {"name": "Geological and Geophysical Studies Worldwide", "value": 88347, "id": "https://openalex.org/T13205"}, {"name": "Geological and Tectonic Studies in Latin America", "value": 63640, "id": "https://openalex.org/T13404"}, {"name": "Geological Formations and Processes Exploration", "value": 63074, "id": "https://openalex.org/T12821"}]}, {"name": "Oceanography", "children": [{"name": "Geophysics and Gravity Measurements", "value": 301494, "id": "https://openalex.org/T11405"}, {"name": "Oceanographic and Atmospheric Processes", "value": 236100, "id": "https://openalex.org/T10255"}, {"name": "Marine Biology and Ecology Research", "value": 223059, "id": "https://openalex.org/T10765"}, {"name": "Marine and coastal ecosystems", "value": 147712, "id": "https://openalex.org/T10032"}, {"name": "Marine and environmental studies", "value": 138582, "id": "https://openalex.org/T14047"}, {"name": "Marine and coastal plant biology", "value": 122170, "id": "https://openalex.org/T10643"}, {"name": "Underwater Acoustics Research", "value": 96205, "id": "https://openalex.org/T11698"}, {"name": "Ocean Waves and Remote Sensing", "value": 60604, "id": "https://openalex.org/T11061"}, {"name": "Ocean Acidification Effects and Responses", "value": 39830, "id": "https://openalex.org/T12806"}]}, {"name": "Geology", "children": [{"name": "Geological Studies and Exploration", "value": 148757, "id": "https://openalex.org/T13193"}, {"name": "Geological and Geophysical Studies", "value": 126154, "id": "https://openalex.org/T13177"}, {"name": "3D Surveying and Cultural Heritage", "value": 124505, "id": "https://openalex.org/T11211"}, {"name": "Environmental Monitoring and Data Management", "value": 51695, "id": "https://openalex.org/T14427"}, {"name": "Geotourism and Geoheritage Conservation", "value": 30317, "id": "https://openalex.org/T12456"}]}, {"name": "Earth-Surface Processes", "children": [{"name": "Geological formations and processes", "value": 147078, "id": "https://openalex.org/T10965"}, {"name": "Coastal and Marine Dynamics", "value": 89639, "id": "https://openalex.org/T10647"}, {"name": "Building materials and conservation", "value": 62168, "id": "https://openalex.org/T11643"}, {"name": "Aeolian processes and effects", "value": 52457, "id": "https://openalex.org/T12383"}, {"name": "Aquatic and Environmental Studies", "value": 47802, "id": "https://openalex.org/T13785"}, {"name": "Karst Systems and Hydrogeology", "value": 41419, "id": "https://openalex.org/T12083"}]}, {"name": "Geochemistry and Petrology", "children": [{"name": "Geological Modeling and Analysis", "value": 128700, "id": "https://openalex.org/T13067"}, {"name": "Mineralogy and Gemology Studies", "value": 118598, "id": "https://openalex.org/T13443"}, {"name": "Geochemistry and Elemental Analysis", "value": 81127, "id": "https://openalex.org/T11740"}, {"name": "Groundwater and Isotope Geochemistry", "value": 65038, "id": "https://openalex.org/T10398"}, {"name": "Coal and Its By-products", "value": 31032, "id": "https://openalex.org/T12218"}, {"name": "Cold Fusion and Nuclear Reactions", "value": 25607, "id": "https://openalex.org/T13209"}]}, {"name": "Space and Planetary Science", "children": [{"name": "Archaeological Research and Protection", "value": 100689, "id": "https://openalex.org/T12364"}]}]}, {"name": "Chemistry", "children": [{"name": "Physical and Theoretical Chemistry", "children": [{"name": "History and advancements in chemistry", "value": 302220, "id": "https://openalex.org/T13297"}, {"name": "Various Chemistry Research Topics", "value": 165017, "id": "https://openalex.org/T12327"}, {"name": "Photochemistry and Electron Transfer Studies", "value": 83113, "id": "https://openalex.org/T11129"}, {"name": "thermodynamics and calorimetric analyses", "value": 70698, "id": "https://openalex.org/T13539"}, {"name": "Advanced Physical and Chemical Molecular Interactions", "value": 50548, "id": "https://openalex.org/T12044"}, {"name": "Electrostatics and Colloid Interactions", "value": 46614, "id": "https://openalex.org/T12274"}, {"name": "Crystallography and molecular interactions", "value": 44508, "id": "https://openalex.org/T10798"}, {"name": "Chemical Reactions and Mechanisms", "value": 43059, "id": "https://openalex.org/T13253"}]}, {"name": "Organic Chemistry", "children": [{"name": "Chemistry and Stereochemistry Studies", "value": 293863, "id": "https://openalex.org/T12527"}, {"name": "Wood and Agarwood Research", "value": 179140, "id": "https://openalex.org/T13568"}, {"name": "Inorganic and Organometallic Chemistry", "value": 164908, "id": "https://openalex.org/T11746"}, {"name": "Chemical synthesis and alkaloids", "value": 157950, "id": "https://openalex.org/T13124"}, {"name": "Chemical Synthesis and Reactions", "value": 117301, "id": "https://openalex.org/T11831"}, {"name": "Organometallic Complex Synthesis and Catalysis", "value": 115846, "id": "https://openalex.org/T10092"}, {"name": "Carbohydrate Chemistry and Synthesis", "value": 104999, "id": "https://openalex.org/T10835"}, {"name": "Synthesis and biological activity", "value": 93885, "id": "https://openalex.org/T10274"}, {"name": "Synthesis and Characterization of Heterocyclic Compounds", "value": 92649, "id": "https://openalex.org/T14099"}, {"name": "Chemical Thermodynamics and Molecular Structure", "value": 88340, "id": "https://openalex.org/T12852"}, {"name": "Synthetic Organic Chemistry Methods", "value": 87835, "id": "https://openalex.org/T11549"}, {"name": "Advanced Polymer Synthesis and Characterization", "value": 77495, "id": "https://openalex.org/T10405"}, {"name": "Asymmetric Synthesis and Catalysis", "value": 73057, "id": "https://openalex.org/T10013"}, {"name": "Surfactants and Colloidal Systems", "value": 70984, "id": "https://openalex.org/T10721"}, {"name": "Catalytic C\u2013H Functionalization Methods", "value": 67823, "id": "https://openalex.org/T10354"}, {"name": "Synthesis and Reactions of Organic Compounds", "value": 66252, "id": "https://openalex.org/T14459"}, {"name": "Chemical Reaction Mechanisms", "value": 64865, "id": "https://openalex.org/T12191"}, {"name": "Synthesis and Biological Evaluation", "value": 63999, "id": "https://openalex.org/T13160"}, {"name": "Organophosphorus compounds synthesis", "value": 63571, "id": "https://openalex.org/T11748"}, {"name": "Organic Chemistry Cycloaddition Reactions", "value": 62009, "id": "https://openalex.org/T12893"}, {"name": "Oxidative Organic Chemistry Reactions", "value": 61738, "id": "https://openalex.org/T11989"}, {"name": "Radical Photochemical Reactions", "value": 54307, "id": "https://openalex.org/T10701"}, {"name": "Cyclopropane Reaction Mechanisms", "value": 53029, "id": "https://openalex.org/T11611"}, {"name": "Free Radicals and Antioxidants", "value": 52740, "id": "https://openalex.org/T13013"}, {"name": "Fullerene Chemistry and Applications", "value": 52077, "id": "https://openalex.org/T10956"}, {"name": "Click Chemistry and Applications", "value": 49875, "id": "https://openalex.org/T11440"}, {"name": "Catalytic Cross-Coupling Reactions", "value": 49746, "id": "https://openalex.org/T10548"}, {"name": "Edible Oils Quality and Analysis", "value": 47976, "id": "https://openalex.org/T10909"}, {"name": "Coordination Chemistry and Organometallics", "value": 47893, "id": "https://openalex.org/T12228"}, {"name": "Nanomaterials for catalytic reactions", "value": 44968, "id": "https://openalex.org/T12240"}, {"name": "Organometallic Compounds Synthesis and Characterization", "value": 42943, "id": "https://openalex.org/T12458"}, {"name": "Synthesis and Properties of Aromatic Compounds", "value": 42687, "id": "https://openalex.org/T11298"}, {"name": "Multicomponent Synthesis of Heterocycles", "value": 39573, "id": "https://openalex.org/T10817"}, {"name": "Synthesis and Catalytic Reactions", "value": 39516, "id": "https://openalex.org/T12251"}, {"name": "Plant-Derived Bioactive Compounds", "value": 38411, "id": "https://openalex.org/T14297"}, {"name": "Organoboron and organosilicon chemistry", "value": 37956, "id": "https://openalex.org/T11441"}, {"name": "Sulfur-Based Synthesis Techniques", "value": 36770, "id": "https://openalex.org/T12189"}, {"name": "Supramolecular Chemistry and Complexes", "value": 34638, "id": "https://openalex.org/T10578"}, {"name": "Photopolymerization techniques and applications", "value": 33397, "id": "https://openalex.org/T12570"}, {"name": "Synthesis and Reactivity of Sulfur-Containing Compounds", "value": 32076, "id": "https://openalex.org/T13304"}, {"name": "Catalytic Alkyne Reactions", "value": 26715, "id": "https://openalex.org/T10871"}, {"name": "Quinazolinone synthesis and applications", "value": 26317, "id": "https://openalex.org/T12318"}, {"name": "Microwave-Assisted Synthesis and Applications", "value": 26153, "id": "https://openalex.org/T12270"}, {"name": "Structural and Chemical Analysis of Organic and Inorganic Compounds", "value": 25898, "id": "https://openalex.org/T12410"}, {"name": "Synthesis of heterocyclic compounds", "value": 25749, "id": "https://openalex.org/T13208"}, {"name": "Synthesis and Reactivity of Heterocycles", "value": 22456, "id": "https://openalex.org/T13230"}, {"name": "Antimicrobial agents and applications", "value": 19736, "id": "https://openalex.org/T12526"}, {"name": "N-Heterocyclic Carbenes in Organic and Inorganic Chemistry", "value": 19463, "id": "https://openalex.org/T11790"}, {"name": "Axial and Atropisomeric Chirality Synthesis", "value": 18889, "id": "https://openalex.org/T13115"}, {"name": "Ferrocene Chemistry and Applications", "value": 18807, "id": "https://openalex.org/T13833"}, {"name": "Synthesis of \u03b2-Lactam Compounds", "value": 17483, "id": "https://openalex.org/T13489"}, {"name": "Synthesis and pharmacology of benzodiazepine derivatives", "value": 17173, "id": "https://openalex.org/T13105"}, {"name": "Organic Chemistry Synthesis Methods", "value": 16888, "id": "https://openalex.org/T13859"}, {"name": "Synthesis of Tetrazole Derivatives", "value": 14649, "id": "https://openalex.org/T13265"}, {"name": "Phosphorus compounds and reactions", "value": 14461, "id": "https://openalex.org/T13239"}, {"name": "Advanced Synthetic Organic Chemistry", "value": 13461, "id": "https://openalex.org/T13649"}, {"name": "Synthesis and Characterization of Pyrroles", "value": 11382, "id": "https://openalex.org/T12562"}, {"name": "Polydiacetylene-based materials and applications", "value": 10661, "id": "https://openalex.org/T14318"}, {"name": "Synthesis of Indole Derivatives", "value": 10066, "id": "https://openalex.org/T12973"}, {"name": "Cyclization and Aryne Chemistry", "value": 9909, "id": "https://openalex.org/T12653"}, {"name": "Chemical synthesis and pharmacological studies", "value": 8519, "id": "https://openalex.org/T13876"}]}, {"name": "Spectroscopy", "children": [{"name": "Analytical Chemistry and Chromatography", "value": 274601, "id": "https://openalex.org/T10908"}, {"name": "Mass Spectrometry Techniques and Applications", "value": 226257, "id": "https://openalex.org/T10683"}, {"name": "Molecular spectroscopy and chirality", "value": 107339, "id": "https://openalex.org/T12748"}, {"name": "Spectroscopy and Laser Applications", "value": 106325, "id": "https://openalex.org/T11111"}, {"name": "Advanced Proteomics Techniques and Applications", "value": 80851, "id": "https://openalex.org/T10519"}, {"name": "Advanced NMR Techniques and Applications", "value": 78053, "id": "https://openalex.org/T11809"}, {"name": "Molecular Sensors and Ion Detection", "value": 69828, "id": "https://openalex.org/T10532"}, {"name": "Molecular Spectroscopy and Structure", "value": 58005, "id": "https://openalex.org/T12967"}, {"name": "Adsorption, diffusion, and thermodynamic properties of materials", "value": 30225, "id": "https://openalex.org/T13604"}, {"name": "Aerogels and thermal insulation", "value": 29012, "id": "https://openalex.org/T12195"}, {"name": "Organic and Inorganic Chemical Reactions", "value": 15369, "id": "https://openalex.org/T14068"}, {"name": "Diffusion Coefficients in Liquids", "value": 6990, "id": "https://openalex.org/T13675"}]}, {"name": "Electrochemistry", "children": [{"name": "Electrochemical Analysis and Applications", "value": 160288, "id": "https://openalex.org/T11434"}]}, {"name": "Inorganic Chemistry", "children": [{"name": "Radioactive element chemistry and processing", "value": 139997, "id": "https://openalex.org/T10973"}, {"name": "Metal-Organic Frameworks: Synthesis and Applications", "value": 114525, "id": "https://openalex.org/T10096"}, {"name": "Inorganic Fluorides and Related Compounds", "value": 105780, "id": "https://openalex.org/T12646"}, {"name": "Zeolite Catalysis and Synthesis", "value": 78170, "id": "https://openalex.org/T10353"}, {"name": "Asymmetric Hydrogenation and Catalysis", "value": 76179, "id": "https://openalex.org/T11281"}, {"name": "Inorganic Chemistry and Materials", "value": 70517, "id": "https://openalex.org/T12557"}, {"name": "Crystal structures of chemical compounds", "value": 67656, "id": "https://openalex.org/T10464"}, {"name": "Synthesis and characterization of novel inorganic/organometallic compounds", "value": 57363, "id": "https://openalex.org/T10807"}, {"name": "Pigment Synthesis and Properties", "value": 43942, "id": "https://openalex.org/T13217"}, {"name": "Metal-Catalyzed Oxygenation Mechanisms", "value": 34173, "id": "https://openalex.org/T11747"}, {"name": "Vanadium and Halogenation Chemistry", "value": 26127, "id": "https://openalex.org/T12136"}, {"name": "Coconut Research and Applications", "value": 22775, "id": "https://openalex.org/T13361"}]}, {"name": "Analytical Chemistry", "children": [{"name": "Analytical chemistry methods development", "value": 130446, "id": "https://openalex.org/T10180"}, {"name": "Spectroscopy and Chemometric Analyses", "value": 109588, "id": "https://openalex.org/T10640"}, {"name": "Analytical Methods in Pharmaceuticals", "value": 83758, "id": "https://openalex.org/T11460"}, {"name": "Petroleum Processing and Analysis", "value": 62403, "id": "https://openalex.org/T11630"}, {"name": "Dye analysis and toxicity", "value": 47058, "id": "https://openalex.org/T13325"}, {"name": "Chromatography in Natural Products", "value": 32536, "id": "https://openalex.org/T13128"}, {"name": "Heavy Metals in Plants", "value": 29352, "id": "https://openalex.org/T13079"}]}]}, {"name": "Mathematics", "children": [{"name": "Theoretical Computer Science", "children": [{"name": "History and Theory of Mathematics", "value": 220450, "id": "https://openalex.org/T12170"}]}, {"name": "Geometry and Topology", "children": [{"name": "Mathematics and Applications", "value": 138541, "id": "https://openalex.org/T12504"}, {"name": "Algebraic Geometry and Number Theory", "value": 104412, "id": "https://openalex.org/T10061"}, {"name": "Algebraic structures and combinatorial models", "value": 91078, "id": "https://openalex.org/T10287"}, {"name": "Morphological variations and asymmetry", "value": 84536, "id": "https://openalex.org/T12417"}, {"name": "Geometric and Algebraic Topology", "value": 79846, "id": "https://openalex.org/T10304"}, {"name": "Advanced Topology and Set Theory", "value": 55466, "id": "https://openalex.org/T11151"}, {"name": "Advanced Differential Equations and Dynamical Systems", "value": 51182, "id": "https://openalex.org/T12396"}, {"name": "Graph theory and applications", "value": 43585, "id": "https://openalex.org/T11476"}, {"name": "Geometry and complex manifolds", "value": 36460, "id": "https://openalex.org/T12351"}, {"name": "Fixed Point Theorems Analysis", "value": 34774, "id": "https://openalex.org/T11777"}, {"name": "Analytic and geometric function theory", "value": 33859, "id": "https://openalex.org/T11822"}]}, {"name": "Statistics and Probability", "children": [{"name": "Probability and Statistical Research", "value": 125753, "id": "https://openalex.org/T13500"}, {"name": "Advanced Statistical Methods and Models", "value": 90855, "id": "https://openalex.org/T11871"}, {"name": "Statistical Methods and Inference", "value": 82600, "id": "https://openalex.org/T10136"}, {"name": "Statistical Methods in Clinical Trials", "value": 69411, "id": "https://openalex.org/T11235"}, {"name": "Census and Population Estimation", "value": 67642, "id": "https://openalex.org/T13546"}, {"name": "Statistics Education and Methodologies", "value": 61186, "id": "https://openalex.org/T11875"}, {"name": "Statistical Distribution Estimation and Applications", "value": 58881, "id": "https://openalex.org/T10968"}, {"name": "Cognitive and developmental aspects of mathematical skills", "value": 54149, "id": "https://openalex.org/T11345"}, {"name": "Statistical Methods and Bayesian Inference", "value": 50142, "id": "https://openalex.org/T10243"}, {"name": "Advanced Causal Inference Techniques", "value": 41028, "id": "https://openalex.org/T10845"}, {"name": "Approximation Theory and Sequence Spaces", "value": 30932, "id": "https://openalex.org/T12062"}, {"name": "Random Matrices and Applications", "value": 30239, "id": "https://openalex.org/T11716"}, {"name": "Statistical Methods and Applications", "value": 29752, "id": "https://openalex.org/T13141"}, {"name": "Markov Chains and Monte Carlo Methods", "value": 27657, "id": "https://openalex.org/T12056"}, {"name": "Fuzzy Systems and Optimization", "value": 20829, "id": "https://openalex.org/T12135"}, {"name": "Benford\u2019s Law and Fraud Detection", "value": 20276, "id": "https://openalex.org/T13720"}, {"name": "Survey Sampling and Estimation Techniques", "value": 15156, "id": "https://openalex.org/T13030"}, {"name": "Statistical Methods in Epidemiology", "value": 10046, "id": "https://openalex.org/T14374"}, {"name": "Education, Psychology, and Complexity Research", "value": 3014, "id": "https://openalex.org/T13680"}, {"name": "Probabilistic Statistics in Medicine", "value": 1918, "id": "https://openalex.org/T13797"}]}, {"name": "Applied Mathematics", "children": [{"name": "Mathematics Education and Pedagogy", "value": 109003, "id": "https://openalex.org/T12522"}, {"name": "Geometric Analysis and Curvature Flows", "value": 84643, "id": "https://openalex.org/T10229"}, {"name": "Gas Dynamics and Kinetic Theory", "value": 81853, "id": "https://openalex.org/T11012"}, {"name": "Nonlinear Partial Differential Equations", "value": 54035, "id": "https://openalex.org/T10194"}, {"name": "Holomorphic and Operator Theory", "value": 52371, "id": "https://openalex.org/T10884"}, {"name": "Nonlinear Differential Equations Analysis", "value": 50171, "id": "https://openalex.org/T10541"}, {"name": "Differential Equations and Boundary Problems", "value": 48269, "id": "https://openalex.org/T12589"}, {"name": "Algebraic and Geometric Analysis", "value": 48180, "id": "https://openalex.org/T12037"}, {"name": "Mathematical functions and polynomials", "value": 41014, "id": "https://openalex.org/T11191"}, {"name": "Navier-Stokes equation solutions", "value": 36166, "id": "https://openalex.org/T10940"}, {"name": "Point processes and geometric inequalities", "value": 35043, "id": "https://openalex.org/T11830"}, {"name": "Advanced Harmonic Analysis Research", "value": 33776, "id": "https://openalex.org/T11049"}, {"name": "Mathematical Analysis and Transform Methods", "value": 29112, "id": "https://openalex.org/T11210"}, {"name": "Mathematical Inequalities and Applications", "value": 27917, "id": "https://openalex.org/T11564"}, {"name": "Meromorphic and Entire Functions", "value": 24487, "id": "https://openalex.org/T12812"}, {"name": "Functional Equations Stability Results", "value": 24458, "id": "https://openalex.org/T12508"}, {"name": "Statistical and numerical algorithms", "value": 23423, "id": "https://openalex.org/T13487"}]}, {"name": "Modeling and Simulation", "children": [{"name": "COVID-19 epidemiological studies", "value": 97182, "id": "https://openalex.org/T10410"}, {"name": "Fractional Differential Equations Solutions", "value": 75573, "id": "https://openalex.org/T10288"}, {"name": "Mathematics Education and Programs", "value": 37801, "id": "https://openalex.org/T14079"}, {"name": "Mathematical Biology Tumor Growth", "value": 35495, "id": "https://openalex.org/T11829"}, {"name": "Advanced Research in Science and Engineering", "value": 15345, "id": "https://openalex.org/T13771"}, {"name": "Mathematical and Computational Methods", "value": 7772, "id": "https://openalex.org/T13806"}]}, {"name": "Algebra and Number Theory", "children": [{"name": "Advanced Topics in Algebra", "value": 89370, "id": "https://openalex.org/T11673"}, {"name": "Rings, Modules, and Algebras", "value": 52300, "id": "https://openalex.org/T11703"}, {"name": "Analytic Number Theory Research", "value": 52009, "id": "https://openalex.org/T11166"}, {"name": "Advanced Mathematical Identities", "value": 35165, "id": "https://openalex.org/T11428"}, {"name": "Commutative Algebra and Its Applications", "value": 25157, "id": "https://openalex.org/T12069"}]}, {"name": "Mathematical Physics", "children": [{"name": "Mathematical Dynamics and Fractals", "value": 84104, "id": "https://openalex.org/T10588"}, {"name": "Homotopy and Cohomology in Algebraic Topology", "value": 74003, "id": "https://openalex.org/T10896"}, {"name": "Advanced Algebra and Geometry", "value": 64173, "id": "https://openalex.org/T11680"}, {"name": "Spectral Theory in Mathematical Physics", "value": 62752, "id": "https://openalex.org/T11022"}, {"name": "Stochastic processes and statistical mechanics", "value": 57501, "id": "https://openalex.org/T11152"}, {"name": "Numerical methods in inverse problems", "value": 55274, "id": "https://openalex.org/T11205"}, {"name": "advanced mathematical theories", "value": 48830, "id": "https://openalex.org/T13234"}, {"name": "Advanced Mathematical Physics Problems", "value": 42231, "id": "https://openalex.org/T11654"}, {"name": "Advanced Banach Space Theory", "value": 41350, "id": "https://openalex.org/T11545"}, {"name": "Advanced Operator Algebra Research", "value": 41309, "id": "https://openalex.org/T10899"}, {"name": "Mathematical and Theoretical Analysis", "value": 31615, "id": "https://openalex.org/T13400"}, {"name": "Advanced Mathematical Theories", "value": 21334, "id": "https://openalex.org/T14500"}]}, {"name": "Numerical Analysis", "children": [{"name": "Numerical methods for differential equations", "value": 67721, "id": "https://openalex.org/T11416"}, {"name": "Differential Equations and Numerical Methods", "value": 59174, "id": "https://openalex.org/T12727"}, {"name": "Advanced Optimization Algorithms Research", "value": 52806, "id": "https://openalex.org/T10963"}, {"name": "Iterative Methods for Nonlinear Equations", "value": 27421, "id": "https://openalex.org/T12661"}, {"name": "Mathematical Approximation and Integration", "value": 22402, "id": "https://openalex.org/T12404"}]}, {"name": "Discrete Mathematics and Combinatorics", "children": [{"name": "Finite Group Theory Research", "value": 60346, "id": "https://openalex.org/T10849"}, {"name": "Advanced Combinatorial Mathematics", "value": 46342, "id": "https://openalex.org/T10948"}, {"name": "Limits and Structures in Graph Theory", "value": 30904, "id": "https://openalex.org/T11329"}, {"name": "Modeling, Simulation, and Optimization", "value": 17140, "id": "https://openalex.org/T14082"}]}, {"name": "Computational Mathematics", "children": [{"name": "Tensor decomposition and applications", "value": 21290, "id": "https://openalex.org/T12303"}]}]}, {"name": "Chemical Engineering", "children": [{"name": "Bioengineering", "children": [{"name": "Analytical Chemistry and Sensors", "value": 175961, "id": "https://openalex.org/T11472"}]}, {"name": "Fluid Flow and Transfer Processes", "children": [{"name": "Advanced Combustion Engine Technologies", "value": 110352, "id": "https://openalex.org/T10117"}, {"name": "Rheology and Fluid Dynamics Studies", "value": 81917, "id": "https://openalex.org/T11379"}, {"name": "Thermodynamic properties of mixtures", "value": 53618, "id": "https://openalex.org/T10962"}, {"name": "Molten salt chemistry and electrochemical processes", "value": 23124, "id": "https://openalex.org/T11947"}]}, {"name": "Catalysis", "children": [{"name": "Catalysis and Oxidation Reactions", "value": 90039, "id": "https://openalex.org/T11825"}, {"name": "Ionic liquids properties and applications", "value": 63721, "id": "https://openalex.org/T10480"}, {"name": "Catalysts for Methane Reforming", "value": 57953, "id": "https://openalex.org/T10495"}, {"name": "Ammonia Synthesis and Nitrogen Reduction", "value": 40038, "id": "https://openalex.org/T12112"}]}, {"name": "Filtration and Separation", "children": [{"name": "Chemical and Physical Properties in Aqueous Solutions", "value": 56318, "id": "https://openalex.org/T11936"}]}, {"name": "Chemical Health and Safety", "children": [{"name": "Chemical Safety and Risk Management", "value": 46489, "id": "https://openalex.org/T13840"}]}, {"name": "Process Chemistry and Technology", "children": [{"name": "Carbon dioxide utilization in catalysis", "value": 40677, "id": "https://openalex.org/T11593"}, {"name": "Odor and Emission Control Technologies", "value": 37314, "id": "https://openalex.org/T11821"}]}]}, {"name": "Energy", "children": [{"name": "Renewable Energy, Sustainability and the Environment", "children": [{"name": "Global Energy and Sustainability Research", "value": 166120, "id": "https://openalex.org/T12639"}, {"name": "Advanced Photocatalysis Techniques", "value": 149793, "id": "https://openalex.org/T10078"}, {"name": "Electrocatalysts for Energy Conversion", "value": 137620, "id": "https://openalex.org/T10030"}, {"name": "Algal biology and biofuel production", "value": 119946, "id": "https://openalex.org/T10476"}, {"name": "Environmental and Ecological Studies", "value": 109743, "id": "https://openalex.org/T13870"}, {"name": "TiO2 Photocatalysis and Solar Cells", "value": 83507, "id": "https://openalex.org/T10024"}, {"name": "Solar Thermal and Photovoltaic Systems", "value": 74125, "id": "https://openalex.org/T10905"}, {"name": "Energy, Environment, and Transportation Policies", "value": 72262, "id": "https://openalex.org/T12617"}, {"name": "Photovoltaic System Optimization Techniques", "value": 68479, "id": "https://openalex.org/T10468"}, {"name": "Energy, Environment, Agriculture Analysis", "value": 62835, "id": "https://openalex.org/T13691"}, {"name": "Renewable energy and sustainable power systems", "value": 60984, "id": "https://openalex.org/T12271"}, {"name": "Energy Efficiency and Management", "value": 55303, "id": "https://openalex.org/T11954"}, {"name": "Iron oxide chemistry and applications", "value": 52360, "id": "https://openalex.org/T11877"}, {"name": "Geothermal Energy Systems and Applications", "value": 47450, "id": "https://openalex.org/T11225"}, {"name": "Renewable Energy and Sustainability", "value": 39527, "id": "https://openalex.org/T14481"}, {"name": "CO2 Reduction Techniques and Catalysts", "value": 36216, "id": "https://openalex.org/T11784"}, {"name": "Metalloenzymes and iron-sulfur proteins", "value": 35226, "id": "https://openalex.org/T11626"}, {"name": "Solar-Powered Water Purification Methods", "value": 35160, "id": "https://openalex.org/T12008"}, {"name": "Oil, Gas, and Environmental Issues", "value": 16558, "id": "https://openalex.org/T14224"}, {"name": "Mechanical Systems and Engineering", "value": 11203, "id": "https://openalex.org/T13746"}, {"name": "Energy and Environmental Sustainability", "value": 2506, "id": "https://openalex.org/T13331"}, {"name": "Energy, Economy, and Technology Trends", "value": 2119, "id": "https://openalex.org/T13975"}]}, {"name": "General Energy", "children": [{"name": "Global Energy Security and Policy", "value": 115323, "id": "https://openalex.org/T12129"}]}, {"name": "Energy Engineering and Power Technology", "children": [{"name": "Hybrid Renewable Energy Systems", "value": 84742, "id": "https://openalex.org/T11007"}, {"name": "Power Systems and Renewable Energy", "value": 76149, "id": "https://openalex.org/T14444"}]}, {"name": "Fuel Technology", "children": [{"name": "Coal and Coke Industries Research", "value": 48919, "id": "https://openalex.org/T14428"}]}, {"name": "Nuclear Energy and Engineering", "children": [{"name": "Advanced Energy Technologies and Civil Engineering Innovations", "value": 10937, "id": "https://openalex.org/T14327"}]}]}]}, {"name": "Life Sciences", "children": [{"name": "Agricultural and Biological Sciences", "children": [{"name": "Plant Science", "children": [{"name": "Mycorrhizal Fungi and Plant Interactions", "value": 3201153, "id": "https://openalex.org/T10451"}, {"name": "Wheat and Barley Genetics and Pathology", "value": 550945, "id": "https://openalex.org/T10733"}, {"name": "Mediterranean and Iberian flora and fauna", "value": 332828, "id": "https://openalex.org/T12455"}, {"name": "Botany and Plant Ecology Studies", "value": 299951, "id": "https://openalex.org/T12618"}, {"name": "Botany, Ecology, and Taxonomy Studies", "value": 290821, "id": "https://openalex.org/T13015"}, {"name": "Plant pathogens and resistance mechanisms", "value": 235283, "id": "https://openalex.org/T12771"}, {"name": "Genetic and Environmental Crop Studies", "value": 208653, "id": "https://openalex.org/T12115"}, {"name": "Plant Physiology and Cultivation Studies", "value": 208258, "id": "https://openalex.org/T11546"}, {"name": "Horticultural and Viticultural Research", "value": 180692, "id": "https://openalex.org/T11796"}, {"name": "Phytochemistry and Biological Activities", "value": 167271, "id": "https://openalex.org/T11613"}, {"name": "Ethnobotanical and Medicinal Plants Studies", "value": 148961, "id": "https://openalex.org/T10431"}, {"name": "Plant Virus Research Studies", "value": 137816, "id": "https://openalex.org/T10494"}, {"name": "Plant Pathogens and Resistance", "value": 135102, "id": "https://openalex.org/T11771"}, {"name": "Botanical Studies and Applications", "value": 131608, "id": "https://openalex.org/T13238"}, {"name": "Rice Cultivation and Yield Improvement", "value": 131152, "id": "https://openalex.org/T12045"}, {"name": "Plant Molecular Biology Research", "value": 112454, "id": "https://openalex.org/T10184"}, {"name": "Agricultural pest management studies", "value": 109868, "id": "https://openalex.org/T13125"}, {"name": "Agriculture, Plant Science, Crop Management", "value": 106847, "id": "https://openalex.org/T13246"}, {"name": "Chromosomal and Genetic Variations", "value": 105045, "id": "https://openalex.org/T10434"}, {"name": "Legume Nitrogen Fixing Symbiosis", "value": 103045, "id": "https://openalex.org/T11470"}, {"name": "Nematode management and characterization studies", "value": 95702, "id": "https://openalex.org/T11179"}, {"name": "Smart Agriculture and AI", "value": 93725, "id": "https://openalex.org/T10616"}, {"name": "Banana Cultivation and Research", "value": 91369, "id": "https://openalex.org/T12795"}, {"name": "Ecology and Conservation Studies", "value": 89129, "id": "https://openalex.org/T14009"}, {"name": "Plant Pathogenic Bacteria Studies", "value": 87618, "id": "https://openalex.org/T11578"}, {"name": "Plant-Microbe Interactions and Immunity", "value": 87306, "id": "https://openalex.org/T10076"}, {"name": "Mycotoxins in Agriculture and Food", "value": 85280, "id": "https://openalex.org/T10520"}, {"name": "Insect Pest Control Strategies", "value": 84970, "id": "https://openalex.org/T11065"}, {"name": "Plant nutrient uptake and metabolism", "value": 84206, "id": "https://openalex.org/T11247"}, {"name": "Soybean genetics and cultivation", "value": 81786, "id": "https://openalex.org/T12571"}, {"name": "Plant Stress Responses and Tolerance", "value": 73529, "id": "https://openalex.org/T10014"}, {"name": "Flowering Plant Growth and Cultivation", "value": 71207, "id": "https://openalex.org/T12834"}, {"name": "Garlic and Onion Studies", "value": 69063, "id": "https://openalex.org/T11979"}, {"name": "Cassava research and cyanide", "value": 68104, "id": "https://openalex.org/T12305"}, {"name": "Phytochemistry Medicinal Plant Applications", "value": 67582, "id": "https://openalex.org/T12657"}, {"name": "Phytoplasmas and Hemiptera pathogens", "value": 65269, "id": "https://openalex.org/T11750"}, {"name": "Pesticide Exposure and Toxicity", "value": 64765, "id": "https://openalex.org/T10875"}, {"name": "Growth and nutrition in plants", "value": 62115, "id": "https://openalex.org/T12113"}, {"name": "Organic Food and Agriculture", "value": 61984, "id": "https://openalex.org/T11066"}, {"name": "GABA and Rice Research", "value": 61276, "id": "https://openalex.org/T13142"}, {"name": "Berry genetics and cultivation research", "value": 61111, "id": "https://openalex.org/T12605"}, {"name": "Peanut Plant Research Studies", "value": 60198, "id": "https://openalex.org/T12855"}, {"name": "Plant Disease Resistance and Genetics", "value": 59809, "id": "https://openalex.org/T12858"}, {"name": "Seed Germination and Physiology", "value": 59502, "id": "https://openalex.org/T11098"}, {"name": "Sugarcane Cultivation and Processing", "value": 57376, "id": "https://openalex.org/T12431"}, {"name": "Medicinal Plant Research", "value": 56768, "id": "https://openalex.org/T14521"}, {"name": "Leaf Properties and Growth Measurement", "value": 55669, "id": "https://openalex.org/T14365"}, {"name": "Research in Cotton Cultivation", "value": 55635, "id": "https://openalex.org/T12243"}, {"name": "Polysaccharides and Plant Cell Walls", "value": 55545, "id": "https://openalex.org/T10869"}, {"name": "Plant and Biological Electrophysiology Studies", "value": 54358, "id": "https://openalex.org/T12813"}, {"name": "Weed Control and Herbicide Applications", "value": 53020, "id": "https://openalex.org/T10774"}, {"name": "Postharvest Quality and Shelf Life Management", "value": 52864, "id": "https://openalex.org/T10473"}, {"name": "Greenhouse Technology and Climate Control", "value": 50394, "id": "https://openalex.org/T12093"}, {"name": "Plant Micronutrient Interactions and Effects", "value": 50113, "id": "https://openalex.org/T11418"}, {"name": "Agricultural Practices and Plant Genetics", "value": 49294, "id": "https://openalex.org/T13008"}, {"name": "Plant Parasitism and Resistance", "value": 48481, "id": "https://openalex.org/T12475"}, {"name": "Plant Surface Properties and Treatments", "value": 48434, "id": "https://openalex.org/T12161"}, {"name": "Genetics and Plant Breeding", "value": 46513, "id": "https://openalex.org/T11229"}, {"name": "Light effects on plants", "value": 45237, "id": "https://openalex.org/T11268"}, {"name": "Genetically Modified Organisms Research", "value": 44560, "id": "https://openalex.org/T11426"}, {"name": "Plant responses to elevated CO2", "value": 43674, "id": "https://openalex.org/T11760"}, {"name": "Plant responses to water stress", "value": 41673, "id": "https://openalex.org/T12472"}, {"name": "Agriculture and Farm Safety", "value": 40890, "id": "https://openalex.org/T12732"}, {"name": "Enzyme-mediated dye degradation", "value": 40564, "id": "https://openalex.org/T11136"}, {"name": "Plant chemical constituents analysis", "value": 39272, "id": "https://openalex.org/T11973"}, {"name": "Natural Compound Pharmacology Studies", "value": 37679, "id": "https://openalex.org/T12087"}, {"name": "Urban Agriculture and Sustainability", "value": 36963, "id": "https://openalex.org/T12253"}, {"name": "Plant Genetic and Mutation Studies", "value": 35270, "id": "https://openalex.org/T12828"}, {"name": "Allelopathy and phytotoxic interactions", "value": 34437, "id": "https://openalex.org/T12058"}, {"name": "Phytase and its Applications", "value": 33380, "id": "https://openalex.org/T12991"}, {"name": "Linguistic and Cultural Studies", "value": 31547, "id": "https://openalex.org/T14195"}, {"name": "Plant Growth Enhancement Techniques", "value": 30406, "id": "https://openalex.org/T12407"}, {"name": "Date Palm Research Studies", "value": 30305, "id": "https://openalex.org/T12894"}, {"name": "Aluminum toxicity and tolerance in plants and animals", "value": 29941, "id": "https://openalex.org/T12211"}, {"name": "Plant Disease Management Techniques", "value": 29822, "id": "https://openalex.org/T12660"}, {"name": "Sunflower and Safflower Cultivation", "value": 29407, "id": "https://openalex.org/T12742"}, {"name": "Phytochemistry and biological activity of medicinal plants", "value": 28864, "id": "https://openalex.org/T12346"}, {"name": "Moringa oleifera research and applications", "value": 25802, "id": "https://openalex.org/T12721"}, {"name": "Silicon Effects in Agriculture", "value": 25019, "id": "https://openalex.org/T12344"}, {"name": "Phytochemistry and biological activities of Ficus species", "value": 24568, "id": "https://openalex.org/T13422"}, {"name": "Powdery Mildew Fungal Diseases", "value": 23179, "id": "https://openalex.org/T13214"}, {"name": "Bamboo properties and applications", "value": 23128, "id": "https://openalex.org/T12665"}, {"name": "Sesame and Sesamin Research", "value": 17315, "id": "https://openalex.org/T13218"}, {"name": "Agriculture and Social Issues", "value": 16853, "id": "https://openalex.org/T14398"}, {"name": "Animal Nutrition and Health", "value": 16311, "id": "https://openalex.org/T12944"}, {"name": "Indigenous Knowledge Systems and Agriculture", "value": 12886, "id": "https://openalex.org/T13934"}, {"name": "Cynara cardunculus studies", "value": 9597, "id": "https://openalex.org/T13992"}, {"name": "Cultural and Social Dynamics", "value": 8422, "id": "https://openalex.org/T13390"}, {"name": "Bioactive Compounds in Plants", "value": 6547, "id": "https://openalex.org/T14194"}, {"name": "Shallot Cultivation and Analysis", "value": 5593, "id": "https://openalex.org/T13688"}]}, {"name": "Insect Science", "children": [{"name": "Forest Ecology and Biodiversity Studies", "value": 362223, "id": "https://openalex.org/T12713"}, {"name": "Insect-Plant Interactions and Control", "value": 158747, "id": "https://openalex.org/T10135"}, {"name": "Insect and Pesticide Research", "value": 110164, "id": "https://openalex.org/T11641"}, {"name": "Mollusks and Parasites Studies", "value": 108355, "id": "https://openalex.org/T12234"}, {"name": "Insect behavior and control techniques", "value": 82951, "id": "https://openalex.org/T12043"}, {"name": "Biological Control of Invasive Species", "value": 73328, "id": "https://openalex.org/T12701"}, {"name": "Bee Products Chemical Analysis", "value": 61989, "id": "https://openalex.org/T11386"}, {"name": "Forensic Entomology and Diptera Studies", "value": 55822, "id": "https://openalex.org/T11706"}, {"name": "Entomopathogenic Microorganisms in Pest Control", "value": 54780, "id": "https://openalex.org/T11436"}, {"name": "Insect Utilization and Effects", "value": 49808, "id": "https://openalex.org/T12336"}, {"name": "Insect symbiosis and bacterial influences", "value": 36497, "id": "https://openalex.org/T12134"}, {"name": "Research on scale insects", "value": 34867, "id": "https://openalex.org/T12968"}, {"name": "Insect Pheromone Research and Control", "value": 31627, "id": "https://openalex.org/T12321"}, {"name": "Silkworms and Sericulture Research", "value": 30165, "id": "https://openalex.org/T14048"}]}, {"name": "Ecology, Evolution, Behavior and Systematics", "children": [{"name": "Agriculture and Rural Development Research", "value": 319944, "id": "https://openalex.org/T13396"}, {"name": "Plant Taxonomy and Phylogenetics", "value": 289316, "id": "https://openalex.org/T12568"}, {"name": "Plant Diversity and Evolution", "value": 283003, "id": "https://openalex.org/T10385"}, {"name": "Plant and animal studies", "value": 279245, "id": "https://openalex.org/T10487"}, {"name": "Coleoptera Taxonomy and Distribution", "value": 271220, "id": "https://openalex.org/T11494"}, {"name": "Bat Biology and Ecology Studies", "value": 181374, "id": "https://openalex.org/T11228"}, {"name": "Bryophyte Studies and Records", "value": 157929, "id": "https://openalex.org/T11836"}, {"name": "Plant Ecology and Taxonomy Studies", "value": 149026, "id": "https://openalex.org/T13168"}, {"name": "Fern and Epiphyte Biology", "value": 146170, "id": "https://openalex.org/T12359"}, {"name": "Invertebrate Taxonomy and Ecology", "value": 125805, "id": "https://openalex.org/T14399"}, {"name": "Fossil Insects in Amber", "value": 113541, "id": "https://openalex.org/T12001"}, {"name": "Botanical Research and Chemistry", "value": 103096, "id": "https://openalex.org/T13506"}, {"name": "Lichen and fungal ecology", "value": 99032, "id": "https://openalex.org/T11528"}, {"name": "Diptera species taxonomy and behavior", "value": 96683, "id": "https://openalex.org/T12606"}, {"name": "Hemiptera Insect Studies", "value": 90715, "id": "https://openalex.org/T12329"}, {"name": "Cephalopods and Marine Biology", "value": 89649, "id": "https://openalex.org/T12596"}, {"name": "Hymenoptera taxonomy and phylogeny", "value": 86982, "id": "https://openalex.org/T12132"}, {"name": "Entomological Studies and Ecology", "value": 86226, "id": "https://openalex.org/T14378"}, {"name": "Orthoptera Research and Taxonomy", "value": 85936, "id": "https://openalex.org/T13269"}, {"name": "Animal Behavior and Reproduction", "value": 79052, "id": "https://openalex.org/T10174"}, {"name": "Study of Mite Species", "value": 72215, "id": "https://openalex.org/T12361"}, {"name": "Agriculture, Soil, Plant Science", "value": 64291, "id": "https://openalex.org/T14137"}, {"name": "Coleoptera: Cerambycidae studies", "value": 63717, "id": "https://openalex.org/T13781"}, {"name": "Collembola Taxonomy and Ecology Studies", "value": 54197, "id": "https://openalex.org/T13950"}, {"name": "Plant and fungal interactions", "value": 52055, "id": "https://openalex.org/T12934"}, {"name": "Vector-Borne Animal Diseases", "value": 47148, "id": "https://openalex.org/T12733"}, {"name": "Climate change impacts on agriculture", "value": 45584, "id": "https://openalex.org/T10439"}, {"name": "Fungal Plant Pathogen Control", "value": 42575, "id": "https://openalex.org/T11900"}, {"name": "Botany and Geology in Latin America and Caribbean", "value": 42113, "id": "https://openalex.org/T14310"}, {"name": "Water management and technologies", "value": 42080, "id": "https://openalex.org/T14160"}, {"name": "Agricultural Systems and Practices", "value": 33618, "id": "https://openalex.org/T13899"}, {"name": "Biocrusts and Microbial Ecology", "value": 26454, "id": "https://openalex.org/T12832"}, {"name": "Tardigrade Biology and Ecology", "value": 15534, "id": "https://openalex.org/T13679"}]}, {"name": "Aquatic Science", "children": [{"name": "Fish Biology and Ecology Studies", "value": 197151, "id": "https://openalex.org/T12319"}, {"name": "Aquaculture Nutrition and Growth", "value": 136199, "id": "https://openalex.org/T10450"}, {"name": "Echinoderm biology and ecology", "value": 54493, "id": "https://openalex.org/T12841"}, {"name": "Aquatic life and conservation", "value": 52814, "id": "https://openalex.org/T13892"}, {"name": "Seaweed-derived Bioactive Compounds", "value": 39404, "id": "https://openalex.org/T11390"}, {"name": "Engineering and Agricultural Innovations", "value": 33145, "id": "https://openalex.org/T12710"}, {"name": "Innovations in Aquaponics and Hydroponics Systems", "value": 13603, "id": "https://openalex.org/T13391"}]}, {"name": "Animal Science and Zoology", "children": [{"name": "Animal Nutrition and Physiology", "value": 186905, "id": "https://openalex.org/T10152"}, {"name": "Meat and Animal Product Quality", "value": 144318, "id": "https://openalex.org/T10333"}, {"name": "Animal Virus Infections Studies", "value": 80170, "id": "https://openalex.org/T11495"}, {"name": "Livestock and Poultry Management", "value": 56950, "id": "https://openalex.org/T13294"}, {"name": "Rabbits: Nutrition, Reproduction, Health", "value": 54974, "id": "https://openalex.org/T12674"}, {"name": "Effects of Environmental Stressors on Livestock", "value": 52049, "id": "https://openalex.org/T12365"}, {"name": "Pharmacological Effects and Assays", "value": 34386, "id": "https://openalex.org/T13338"}, {"name": "Coccidia and coccidiosis research", "value": 30822, "id": "https://openalex.org/T12691"}]}, {"name": "Food Science", "children": [{"name": "Probiotics and Fermented Foods", "value": 142451, "id": "https://openalex.org/T10141"}, {"name": "Culinary Culture and Tourism", "value": 125012, "id": "https://openalex.org/T11925"}, {"name": "Food Quality and Safety Studies", "value": 113489, "id": "https://openalex.org/T12385"}, {"name": "Salmonella and Campylobacter epidemiology", "value": 109387, "id": "https://openalex.org/T10486"}, {"name": "Potato Plant Research", "value": 104089, "id": "https://openalex.org/T11745"}, {"name": "Essential Oils and Antimicrobial Activity", "value": 97506, "id": "https://openalex.org/T10225"}, {"name": "Food Industry and Aquatic Biology", "value": 95089, "id": "https://openalex.org/T14010"}, {"name": "Food and Agricultural Sciences", "value": 93697, "id": "https://openalex.org/T14127"}, {"name": "Botanical Research and Applications", "value": 89523, "id": "https://openalex.org/T12330"}, {"name": "Agricultural and Food Production Studies", "value": 80307, "id": "https://openalex.org/T14272"}, {"name": "Fermentation and Sensory Analysis", "value": 76141, "id": "https://openalex.org/T10750"}, {"name": "Seed and Plant Biochemistry", "value": 64099, "id": "https://openalex.org/T12403"}, {"name": "Pesticide Residue Analysis and Safety", "value": 61167, "id": "https://openalex.org/T11423"}, {"name": "Food Safety and Hygiene", "value": 60659, "id": "https://openalex.org/T11957"}, {"name": "Proteins in Food Systems", "value": 54886, "id": "https://openalex.org/T10411"}, {"name": "Polysaccharides Composition and Applications", "value": 54763, "id": "https://openalex.org/T12192"}, {"name": "Food, Nutrition, and Cultural Practices", "value": 47185, "id": "https://openalex.org/T14124"}, {"name": "Animal Diversity and Health Studies", "value": 40939, "id": "https://openalex.org/T13540"}, {"name": "Food Waste Reduction and Sustainability", "value": 40041, "id": "https://openalex.org/T12583"}, {"name": "Sensory Analysis and Statistical Methods", "value": 37772, "id": "https://openalex.org/T12114"}, {"name": "Radiation Effects and Dosimetry", "value": 37536, "id": "https://openalex.org/T12468"}, {"name": "Food Chemistry and Fat Analysis", "value": 33446, "id": "https://openalex.org/T12349"}, {"name": "Food Drying and Modeling", "value": 32577, "id": "https://openalex.org/T10650"}, {"name": "Nutrition, Health, and Society Studies", "value": 31194, "id": "https://openalex.org/T14242"}, {"name": "Food Supply Chain Traceability", "value": 28800, "id": "https://openalex.org/T12486"}, {"name": "Agricultural safety and regulations", "value": 24084, "id": "https://openalex.org/T13165"}, {"name": "Microencapsulation and Drying Processes", "value": 23407, "id": "https://openalex.org/T12048"}, {"name": "Advanced Scientific Research Methods", "value": 22611, "id": "https://openalex.org/T14438"}, {"name": "Mining and Industrial Processes", "value": 18824, "id": "https://openalex.org/T13857"}, {"name": "Agricultural and Biological Research", "value": 17056, "id": "https://openalex.org/T12181"}, {"name": "Ziziphus Jujuba Studies and Applications", "value": 14901, "id": "https://openalex.org/T13670"}, {"name": "Melamine detection and toxicity", "value": 6049, "id": "https://openalex.org/T13871"}]}, {"name": "Soil Science", "children": [{"name": "Soil Carbon and Nitrogen Dynamics", "value": 130027, "id": "https://openalex.org/T10004"}, {"name": "Plant Growth and Agriculture Techniques", "value": 85313, "id": "https://openalex.org/T12754"}, {"name": "Soil erosion and sediment transport", "value": 82237, "id": "https://openalex.org/T10889"}, {"name": "Soil and Environmental Studies", "value": 64456, "id": "https://openalex.org/T13102"}, {"name": "Agricultural risk and resilience", "value": 61083, "id": "https://openalex.org/T11886"}, {"name": "Soil Management and Crop Yield", "value": 59862, "id": "https://openalex.org/T12792"}, {"name": "Irrigation Practices and Water Management", "value": 59567, "id": "https://openalex.org/T11404"}, {"name": "Land Rights and Reforms", "value": 58165, "id": "https://openalex.org/T11789"}, {"name": "Agricultural Science and Fertilization", "value": 43117, "id": "https://openalex.org/T12294"}, {"name": "Composting and Vermicomposting Techniques", "value": 33485, "id": "https://openalex.org/T11275"}, {"name": "Soil Science and Environmental Management", "value": 16620, "id": "https://openalex.org/T13740"}, {"name": "Humic Substances and Bio-Organic Studies", "value": 9354, "id": "https://openalex.org/T14054"}]}, {"name": "General Agricultural and Biological Sciences", "children": [{"name": "Diverse Educational Innovations Studies", "value": 125861, "id": "https://openalex.org/T12904"}, {"name": "Agricultural Economics and Policy", "value": 122095, "id": "https://openalex.org/T12033"}, {"name": "Agricultural Economics and Practices", "value": 108426, "id": "https://openalex.org/T13508"}, {"name": "Plant and soil sciences", "value": 97378, "id": "https://openalex.org/T13838"}, {"name": "Agriculture and Biological Studies", "value": 87024, "id": "https://openalex.org/T14018"}, {"name": "Rural development and sustainability", "value": 76241, "id": "https://openalex.org/T12098"}, {"name": "Agricultural Innovations and Practices", "value": 69876, "id": "https://openalex.org/T10367"}, {"name": "Agriculture and Agroindustry Studies", "value": 56694, "id": "https://openalex.org/T13010"}, {"name": "Agriculture, Land Use, Rural Development", "value": 53736, "id": "https://openalex.org/T11862"}, {"name": "Bioeconomy and Sustainability Development", "value": 40813, "id": "https://openalex.org/T13240"}, {"name": "Agricultural Development and Management", "value": 33097, "id": "https://openalex.org/T13478"}, {"name": "Educational Research and Science Teaching", "value": 32816, "id": "https://openalex.org/T13468"}, {"name": "Natural Products and Applications", "value": 25557, "id": "https://openalex.org/T14505"}, {"name": "Agriculture Market Analysis Ukraine", "value": 20474, "id": "https://openalex.org/T13630"}, {"name": "Fisheries and Aquaculture Studies", "value": 19257, "id": "https://openalex.org/T14405"}, {"name": "Agricultural Research and Practices", "value": 14775, "id": "https://openalex.org/T13678"}, {"name": "Banking, Crisis Management, COVID-19 Impact", "value": 13345, "id": "https://openalex.org/T13288"}, {"name": "Food Security and Socioeconomic Dynamics", "value": 13042, "id": "https://openalex.org/T14269"}, {"name": "Agricultural and Financial Auditing", "value": 12882, "id": "https://openalex.org/T13054"}, {"name": "Latin American rural development", "value": 11834, "id": "https://openalex.org/T13011"}]}, {"name": "Agronomy and Crop Science", "children": [{"name": "Ruminant Nutrition and Digestive Physiology", "value": 124850, "id": "https://openalex.org/T10098"}, {"name": "Crop Yield and Soil Fertility", "value": 119254, "id": "https://openalex.org/T12310"}, {"name": "Reproductive Physiology in Livestock", "value": 104828, "id": "https://openalex.org/T10584"}, {"name": "Animal Disease Management and Epidemiology", "value": 81246, "id": "https://openalex.org/T11560"}, {"name": "Bioenergy crop production and management", "value": 75726, "id": "https://openalex.org/T12003"}, {"name": "Milk Quality and Mastitis in Dairy Cows", "value": 70659, "id": "https://openalex.org/T11226"}, {"name": "Agronomic Practices and Intercropping Systems", "value": 62766, "id": "https://openalex.org/T12436"}, {"name": "Livestock Management and Performance Improvement", "value": 38350, "id": "https://openalex.org/T13358"}, {"name": "Agricultural Productivity and Crop Improvement", "value": 37442, "id": "https://openalex.org/T13628"}, {"name": "Livestock Farming and Management", "value": 35385, "id": "https://openalex.org/T14499"}, {"name": "Agricultural Development and Policies", "value": 21490, "id": "https://openalex.org/T13378"}]}, {"name": "Forestry", "children": [{"name": "Agricultural and Food Sciences", "value": 121576, "id": "https://openalex.org/T14256"}, {"name": "Pasture and Agricultural Systems", "value": 107498, "id": "https://openalex.org/T13591"}, {"name": "African Botany and Ecology Studies", "value": 86843, "id": "https://openalex.org/T12630"}, {"name": "Agroforestry and silvopastoral systems", "value": 32547, "id": "https://openalex.org/T13009"}, {"name": "Agricultural and Rural Development Research", "value": 29864, "id": "https://openalex.org/T13668"}, {"name": "Logistics and Infrastructure Analysis", "value": 20921, "id": "https://openalex.org/T14367"}, {"name": "Forest Ecology and Conservation", "value": 15617, "id": "https://openalex.org/T14050"}]}, {"name": "Horticulture", "children": [{"name": "Cocoa and Sweet Potato Agronomy", "value": 42208, "id": "https://openalex.org/T13069"}]}]}, {"name": "Biochemistry, Genetics and Molecular Biology", "children": [{"name": "Biophysics", "children": [{"name": "Cell Image Analysis Techniques", "value": 1104312, "id": "https://openalex.org/T12859"}, {"name": "Spectroscopy Techniques in Biomedical and Chemical Research", "value": 74264, "id": "https://openalex.org/T11324"}, {"name": "Electron Spin Resonance Studies", "value": 71830, "id": "https://openalex.org/T12381"}, {"name": "Advanced Fluorescence Microscopy Techniques", "value": 63942, "id": "https://openalex.org/T10540"}, {"name": "Electromagnetic Fields and Biological Effects", "value": 52198, "id": "https://openalex.org/T10874"}, {"name": "Chemical and Physical Studies", "value": 17177, "id": "https://openalex.org/T14488"}]}, {"name": "Molecular Biology", "children": [{"name": "Genomics and Phylogenetic Studies", "value": 461738, "id": "https://openalex.org/T10015"}, {"name": "Gene expression and cancer classification", "value": 384391, "id": "https://openalex.org/T10885"}, {"name": "Genetics, Bioinformatics, and Biomedical Research", "value": 313008, "id": "https://openalex.org/T13937"}, {"name": "Nuclear Structure and Function", "value": 279139, "id": "https://openalex.org/T11841"}, {"name": "Machine Learning in Bioinformatics", "value": 274609, "id": "https://openalex.org/T12254"}, {"name": "Plant tissue culture and regeneration", "value": 171211, "id": "https://openalex.org/T10240"}, {"name": "RNA and protein synthesis mechanisms", "value": 161877, "id": "https://openalex.org/T10521"}, {"name": "Protist diversity and phylogeny", "value": 158068, "id": "https://openalex.org/T11879"}, {"name": "Photosynthetic Processes and Mechanisms", "value": 154613, "id": "https://openalex.org/T10303"}, {"name": "Mitochondrial Function and Pathology", "value": 154430, "id": "https://openalex.org/T10301"}, {"name": "Developmental Biology and Gene Regulation", "value": 154243, "id": "https://openalex.org/T10268"}, {"name": "DNA and Nucleic Acid Chemistry", "value": 149085, "id": "https://openalex.org/T10432"}, {"name": "Single-cell and spatial transcriptomics", "value": 146559, "id": "https://openalex.org/T11289"}, {"name": "Chemical Synthesis and Analysis", "value": 146448, "id": "https://openalex.org/T10911"}, {"name": "Glycosylation and Glycoproteins Research", "value": 144084, "id": "https://openalex.org/T10602"}, {"name": "Advanced biosensing and bioanalysis techniques", "value": 139482, "id": "https://openalex.org/T10207"}, {"name": "Gut microbiota and health", "value": 138233, "id": "https://openalex.org/T10066"}, {"name": "Protein Structure and Dynamics", "value": 133144, "id": "https://openalex.org/T10044"}, {"name": "Epigenetics and DNA Methylation", "value": 131699, "id": "https://openalex.org/T10269"}, {"name": "Biomedical Text Mining and Ontologies", "value": 130118, "id": "https://openalex.org/T11710"}, {"name": "Molecular Biology Techniques and Applications", "value": 120661, "id": "https://openalex.org/T11970"}, {"name": "Lipid Membrane Structure and Behavior", "value": 119039, "id": "https://openalex.org/T10407"}, {"name": "DNA Repair Mechanisms", "value": 117200, "id": "https://openalex.org/T10123"}, {"name": "RNA modifications and cancer", "value": 115493, "id": "https://openalex.org/T11482"}, {"name": "Microbial Metabolic Engineering and Bioproduction", "value": 110451, "id": "https://openalex.org/T10932"}, {"name": "Ion channel regulation and function", "value": 110130, "id": "https://openalex.org/T10493"}, {"name": "RNA Interference and Gene Delivery", "value": 109769, "id": "https://openalex.org/T10725"}, {"name": "CRISPR and Genetic Engineering", "value": 109256, "id": "https://openalex.org/T10878"}, {"name": "Receptor Mechanisms and Signaling", "value": 108260, "id": "https://openalex.org/T11178"}, {"name": "Geomagnetism and Paleomagnetism Studies", "value": 106728, "id": "https://openalex.org/T11786"}, {"name": "Fungal and yeast genetics research", "value": 106580, "id": "https://openalex.org/T10497"}, {"name": "RNA Research and Splicing", "value": 104474, "id": "https://openalex.org/T10604"}, {"name": "Bacillus and Francisella bacterial research", "value": 100893, "id": "https://openalex.org/T11515"}, {"name": "Metabolomics and Mass Spectrometry Studies", "value": 97697, "id": "https://openalex.org/T10836"}, {"name": "Bioinformatics and Genomic Networks", "value": 96009, "id": "https://openalex.org/T10887"}, {"name": "Enzyme Catalysis and Immobilization", "value": 94728, "id": "https://openalex.org/T10404"}, {"name": "Retinal Development and Disorders", "value": 89411, "id": "https://openalex.org/T10691"}, {"name": "Plant Reproductive Biology", "value": 89397, "id": "https://openalex.org/T11927"}, {"name": "Genomics and Chromatin Dynamics", "value": 87258, "id": "https://openalex.org/T10222"}, {"name": "Muscle Physiology and Disorders", "value": 86831, "id": "https://openalex.org/T10441"}, {"name": "Viral Infectious Diseases and Gene Expression in Insects", "value": 83863, "id": "https://openalex.org/T11663"}, {"name": "Insect Resistance and Genetics", "value": 82753, "id": "https://openalex.org/T11075"}, {"name": "Pluripotent Stem Cells Research", "value": 80145, "id": "https://openalex.org/T10505"}, {"name": "Identification and Quantification in Food", "value": 78416, "id": "https://openalex.org/T12388"}, {"name": "Natural product bioactivities and synthesis", "value": 76351, "id": "https://openalex.org/T11385"}, {"name": "Ubiquitin and proteasome pathways", "value": 75925, "id": "https://openalex.org/T11041"}, {"name": "Angiogenesis and VEGF in Cancer", "value": 74392, "id": "https://openalex.org/T10422"}, {"name": "Extracellular vesicles in disease", "value": 74216, "id": "https://openalex.org/T10773"}, {"name": "Bioactive natural compounds", "value": 74039, "id": "https://openalex.org/T12257"}, {"name": "DNA and Biological Computing", "value": 68010, "id": "https://openalex.org/T12029"}, {"name": "Plant and Fungal Species Descriptions", "value": 66875, "id": "https://openalex.org/T14049"}, {"name": "Peroxisome Proliferator-Activated Receptors", "value": 66483, "id": "https://openalex.org/T11072"}, {"name": "Yeasts and Rust Fungi Studies", "value": 65811, "id": "https://openalex.org/T12668"}, {"name": "Plant-derived Lignans Synthesis and Bioactivity", "value": 65574, "id": "https://openalex.org/T12360"}, {"name": "Cell death mechanisms and regulation", "value": 64815, "id": "https://openalex.org/T10294"}, {"name": "Plant biochemistry and biosynthesis", "value": 63961, "id": "https://openalex.org/T11882"}, {"name": "Gene Regulatory Network Analysis", "value": 63806, "id": "https://openalex.org/T10621"}, {"name": "Bacterial biofilms and quorum sensing", "value": 63372, "id": "https://openalex.org/T10593"}, {"name": "Protein Hydrolysis and Bioactive Peptides", "value": 63353, "id": "https://openalex.org/T11561"}, {"name": "bioluminescence and chemiluminescence research", "value": 63146, "id": "https://openalex.org/T12561"}, {"name": "Heat shock proteins research", "value": 62746, "id": "https://openalex.org/T10934"}, {"name": "Retinoids in leukemia and cellular processes", "value": 62051, "id": "https://openalex.org/T11559"}, {"name": "Biochemical and Molecular Research", "value": 61493, "id": "https://openalex.org/T12827"}, {"name": "Sexual Differentiation and Disorders", "value": 61361, "id": "https://openalex.org/T11956"}, {"name": "Metabolism, Diabetes, and Cancer", "value": 58569, "id": "https://openalex.org/T11339"}, {"name": "dental development and anomalies", "value": 56010, "id": "https://openalex.org/T11919"}, {"name": "Amyloidosis: Diagnosis, Treatment, Outcomes", "value": 54543, "id": "https://openalex.org/T11305"}, {"name": "Biopolymer Synthesis and Applications", "value": 54185, "id": "https://openalex.org/T14285"}, {"name": "Renal and related cancers", "value": 53926, "id": "https://openalex.org/T12140"}, {"name": "Protein Kinase Regulation and GTPase Signaling", "value": 53648, "id": "https://openalex.org/T10169"}, {"name": "Polyamine Metabolism and Applications", "value": 53635, "id": "https://openalex.org/T11924"}, {"name": "Cancer therapeutics and mechanisms", "value": 53297, "id": "https://openalex.org/T11845"}, {"name": "Plant Toxicity and Pharmacological Properties", "value": 53297, "id": "https://openalex.org/T12756"}, {"name": "Ion Transport and Channel Regulation", "value": 53143, "id": "https://openalex.org/T10724"}, {"name": "Congenital heart defects research", "value": 52323, "id": "https://openalex.org/T11677"}, {"name": "Steroid Chemistry and Biochemistry", "value": 51582, "id": "https://openalex.org/T13736"}, {"name": "Melanoma and MAPK Pathways", "value": 50579, "id": "https://openalex.org/T11533"}, {"name": "S100 Proteins and Annexins", "value": 48982, "id": "https://openalex.org/T12030"}, {"name": "Inflammasome and immune disorders", "value": 48974, "id": "https://openalex.org/T11078"}, {"name": "Porphyrin Metabolism and Disorders", "value": 47547, "id": "https://openalex.org/T12441"}, {"name": "Nicotinic Acetylcholine Receptors Study", "value": 47524, "id": "https://openalex.org/T11818"}, {"name": "Connexins and lens biology", "value": 47463, "id": "https://openalex.org/T11480"}, {"name": "Bone Metabolism and Diseases", "value": 47267, "id": "https://openalex.org/T11219"}, {"name": "Plant Gene Expression Analysis", "value": 47201, "id": "https://openalex.org/T11237"}, {"name": "PI3K/AKT/mTOR signaling in cancer", "value": 46406, "id": "https://openalex.org/T10952"}, {"name": "Prion Diseases and Protein Misfolding", "value": 46074, "id": "https://openalex.org/T11335"}, {"name": "Phytochemical Studies and Bioactivities", "value": 43969, "id": "https://openalex.org/T12215"}, {"name": "Bioactive Natural Diterpenoids Research", "value": 43573, "id": "https://openalex.org/T12530"}, {"name": "Genomics, phytochemicals, and oxidative stress", "value": 42865, "id": "https://openalex.org/T11332"}, {"name": "RNA regulation and disease", "value": 42341, "id": "https://openalex.org/T12610"}, {"name": "Protein purification and stability", "value": 42117, "id": "https://openalex.org/T11124"}, {"name": "Nitrogen and Sulfur Effects on Brassica", "value": 40642, "id": "https://openalex.org/T12566"}, {"name": "Fibroblast Growth Factor Research", "value": 40618, "id": "https://openalex.org/T12287"}, {"name": "Cancer-related gene regulation", "value": 39901, "id": "https://openalex.org/T13157"}, {"name": "Biochemical and Structural Characterization", "value": 38967, "id": "https://openalex.org/T13326"}, {"name": "TGF-\u03b2 signaling in diseases", "value": 38382, "id": "https://openalex.org/T11501"}, {"name": "Enzyme function and inhibition", "value": 37661, "id": "https://openalex.org/T12412"}, {"name": "Heme Oxygenase-1 and Carbon Monoxide", "value": 37605, "id": "https://openalex.org/T11848"}, {"name": "Wnt/\u03b2-catenin signaling in development and cancer", "value": 37507, "id": "https://openalex.org/T10929"}, {"name": "Circular RNAs in diseases", "value": 36973, "id": "https://openalex.org/T11765"}, {"name": "Histone Deacetylase Inhibitors Research", "value": 36801, "id": "https://openalex.org/T11736"}, {"name": "Signaling Pathways in Disease", "value": 36584, "id": "https://openalex.org/T12620"}, {"name": "Microbial metabolism and enzyme function", "value": 36283, "id": "https://openalex.org/T12688"}, {"name": "Advanced Biosensing Techniques and Applications", "value": 36133, "id": "https://openalex.org/T12867"}, {"name": "vaccines and immunoinformatics approaches", "value": 36050, "id": "https://openalex.org/T12576"}, {"name": "Protein Tyrosine Phosphatases", "value": 35302, "id": "https://openalex.org/T12104"}, {"name": "Hedgehog Signaling Pathway Studies", "value": 34869, "id": "https://openalex.org/T12009"}, {"name": "ATP Synthase and ATPases Research", "value": 34437, "id": "https://openalex.org/T12763"}, {"name": "Phenothiazines and Benzothiazines Synthesis and Activities", "value": 34202, "id": "https://openalex.org/T13454"}, {"name": "Glutathione Transferases and Polymorphisms", "value": 33690, "id": "https://openalex.org/T12187"}, {"name": "Cancer and biochemical research", "value": 32687, "id": "https://openalex.org/T14135"}, {"name": "Sphingolipid Metabolism and Signaling", "value": 32090, "id": "https://openalex.org/T11308"}, {"name": "Protein Interaction Studies and Fluorescence Analysis", "value": 32046, "id": "https://openalex.org/T11908"}, {"name": "Protein Degradation and Inhibitors", "value": 31620, "id": "https://openalex.org/T12534"}, {"name": "Phytochemical compounds biological activities", "value": 29950, "id": "https://openalex.org/T12685"}, {"name": "Planarian Biology and Electrostimulation", "value": 29580, "id": "https://openalex.org/T12789"}, {"name": "Biological Activity of Diterpenoids and Biflavonoids", "value": 29167, "id": "https://openalex.org/T13221"}, {"name": "Fractal and DNA sequence analysis", "value": 28937, "id": "https://openalex.org/T12946"}, {"name": "Ginseng Biological Effects and Applications", "value": 28783, "id": "https://openalex.org/T11889"}, {"name": "Diffusion and Search Dynamics", "value": 27974, "id": "https://openalex.org/T13187"}, {"name": "Redox biology and oxidative stress", "value": 24837, "id": "https://openalex.org/T11884"}, {"name": "Pharmacological Receptor Mechanisms and Effects", "value": 22518, "id": "https://openalex.org/T13047"}, {"name": "Pineapple and bromelain studies", "value": 22204, "id": "https://openalex.org/T13725"}, {"name": "Studies on Chitinases and Chitosanases", "value": 20817, "id": "https://openalex.org/T12683"}, {"name": "Medicinal Plants and Bioactive Compounds", "value": 20771, "id": "https://openalex.org/T13651"}, {"name": "Phosphodiesterase function and regulation", "value": 20444, "id": "https://openalex.org/T12434"}, {"name": "14-3-3 protein interactions", "value": 19864, "id": "https://openalex.org/T13526"}, {"name": "Chromatin Remodeling and Cancer", "value": 18344, "id": "https://openalex.org/T12820"}, {"name": "Kruppel-like factors research", "value": 16885, "id": "https://openalex.org/T13426"}, {"name": "Biological Research and Disease Studies", "value": 15575, "id": "https://openalex.org/T14065"}, {"name": "FOXO transcription factor regulation", "value": 15317, "id": "https://openalex.org/T12835"}, {"name": "Coenzyme Q10 studies and effects", "value": 15307, "id": "https://openalex.org/T13012"}, {"name": "Mechanisms of cancer metastasis", "value": 14064, "id": "https://openalex.org/T13437"}, {"name": "Connective Tissue Growth Factor Research", "value": 13209, "id": "https://openalex.org/T13223"}, {"name": "Synthesis and bioactivity of alkaloids", "value": 11530, "id": "https://openalex.org/T13188"}]}, {"name": "Genetics", "children": [{"name": "Lepidoptera: Biology and Taxonomy", "value": 408810, "id": "https://openalex.org/T11974"}, {"name": "Genetic Mapping and Diversity in Plants and Animals", "value": 280480, "id": "https://openalex.org/T11468"}, {"name": "Genetic diversity and population structure", "value": 262762, "id": "https://openalex.org/T10012"}, {"name": "Genetic and phenotypic traits in livestock", "value": 168663, "id": "https://openalex.org/T10594"}, {"name": "Insect and Arachnid Ecology and Behavior", "value": 166384, "id": "https://openalex.org/T10702"}, {"name": "Virus-based gene therapy research", "value": 135125, "id": "https://openalex.org/T10613"}, {"name": "Spider Taxonomy and Behavior Studies", "value": 133262, "id": "https://openalex.org/T12447"}, {"name": "Bacterial Genetics and Biotechnology", "value": 127512, "id": "https://openalex.org/T10120"}, {"name": "Nutrition, Genetics, and Disease", "value": 125943, "id": "https://openalex.org/T13984"}, {"name": "Estrogen and related hormone effects", "value": 122691, "id": "https://openalex.org/T10756"}, {"name": "Inflammatory Bowel Disease", "value": 110503, "id": "https://openalex.org/T10134"}, {"name": "Animal Genetics and Reproduction", "value": 97155, "id": "https://openalex.org/T12929"}, {"name": "Diabetes and associated disorders", "value": 95083, "id": "https://openalex.org/T11171"}, {"name": "Genetic Associations and Epidemiology", "value": 87210, "id": "https://openalex.org/T10261"}, {"name": "Venomous Animal Envenomation and Studies", "value": 83495, "id": "https://openalex.org/T11353"}, {"name": "Evolution and Genetic Dynamics", "value": 73641, "id": "https://openalex.org/T11764"}, {"name": "Cleft Lip and Palate Research", "value": 72017, "id": "https://openalex.org/T11374"}, {"name": "Genomic variations and chromosomal abnormalities", "value": 69571, "id": "https://openalex.org/T11213"}, {"name": "Digestive system and related health", "value": 69162, "id": "https://openalex.org/T13199"}, {"name": "Yersinia bacterium, plague, ectoparasites research", "value": 67405, "id": "https://openalex.org/T12232"}, {"name": "Human-Animal Interaction Studies", "value": 63399, "id": "https://openalex.org/T11214"}, {"name": "Connective tissue disorders research", "value": 61875, "id": "https://openalex.org/T11310"}, {"name": "Forensic and Genetic Research", "value": 61537, "id": "https://openalex.org/T10751"}, {"name": "Genomics and Rare Diseases", "value": 58695, "id": "https://openalex.org/T11642"}, {"name": "BRCA gene mutations in cancer", "value": 58187, "id": "https://openalex.org/T10769"}, {"name": "High Altitude and Hypoxia", "value": 58048, "id": "https://openalex.org/T11968"}, {"name": "Genetic and Clinical Aspects of Sex Determination and Chromosomal Abnormalities", "value": 57380, "id": "https://openalex.org/T11077"}, {"name": "Advances in Cucurbitaceae Research", "value": 56569, "id": "https://openalex.org/T12370"}, {"name": "Genetics and Neurodevelopmental Disorders", "value": 55997, "id": "https://openalex.org/T11772"}, {"name": "Craniofacial Disorders and Treatments", "value": 49287, "id": "https://openalex.org/T11679"}, {"name": "Genetic and Kidney Cyst Diseases", "value": 49191, "id": "https://openalex.org/T11412"}, {"name": "Blood disorders and treatments", "value": 45271, "id": "https://openalex.org/T12919"}, {"name": "Genetic Syndromes and Imprinting", "value": 40661, "id": "https://openalex.org/T11928"}, {"name": "Dermatological and Skeletal Disorders", "value": 40090, "id": "https://openalex.org/T12924"}, {"name": "Race, Genetics, and Society", "value": 36895, "id": "https://openalex.org/T12749"}, {"name": "Genetic and rare skin diseases.", "value": 35202, "id": "https://openalex.org/T12355"}, {"name": "Genetics and Physical Performance", "value": 23787, "id": "https://openalex.org/T13354"}, {"name": "Ocular Disorders and Treatments", "value": 22488, "id": "https://openalex.org/T12989"}, {"name": "Dermatoglyphics and Human Traits", "value": 15745, "id": "https://openalex.org/T14333"}, {"name": "Genome Rearrangement Algorithms", "value": 11733, "id": "https://openalex.org/T13664"}]}, {"name": "Cell Biology", "children": [{"name": "Plant Pathogens and Fungal Diseases", "value": 249670, "id": "https://openalex.org/T10825"}, {"name": "Microtubule and mitosis dynamics", "value": 105678, "id": "https://openalex.org/T10492"}, {"name": "melanin and skin pigmentation", "value": 90994, "id": "https://openalex.org/T11144"}, {"name": "Muscle metabolism and nutrition", "value": 79509, "id": "https://openalex.org/T11399"}, {"name": "Cellular transport and secretion", "value": 77187, "id": "https://openalex.org/T10617"}, {"name": "Cellular Mechanics and Interactions", "value": 69236, "id": "https://openalex.org/T10379"}, {"name": "Hemoglobin structure and function", "value": 62520, "id": "https://openalex.org/T12094"}, {"name": "Proteoglycans and glycosaminoglycans research", "value": 60356, "id": "https://openalex.org/T11131"}, {"name": "Skin and Cellular Biology Research", "value": 56408, "id": "https://openalex.org/T11650"}, {"name": "Biotin and Related Studies", "value": 53810, "id": "https://openalex.org/T13127"}, {"name": "Endoplasmic Reticulum Stress and Disease", "value": 45569, "id": "https://openalex.org/T11150"}, {"name": "Myofascial pain diagnosis and treatment", "value": 34429, "id": "https://openalex.org/T12712"}, {"name": "Zebrafish Biomedical Research Applications", "value": 32113, "id": "https://openalex.org/T11685"}, {"name": "Hippo pathway signaling and YAP/TAZ", "value": 27777, "id": "https://openalex.org/T12065"}, {"name": "Caveolin-1 and cellular processes", "value": 22431, "id": "https://openalex.org/T12793"}, {"name": "Aldose Reductase and Taurine", "value": 21774, "id": "https://openalex.org/T12533"}, {"name": "Calpain Protease Function and Regulation", "value": 13146, "id": "https://openalex.org/T13637"}]}, {"name": "Structural Biology", "children": [{"name": "Advanced Electron Microscopy Techniques and Applications", "value": 197772, "id": "https://openalex.org/T10857"}]}, {"name": "Clinical Biochemistry", "children": [{"name": "Metabolism and Genetic Disorders", "value": 194350, "id": "https://openalex.org/T11027"}, {"name": "Bacterial Identification and Susceptibility Testing", "value": 66154, "id": "https://openalex.org/T12167"}, {"name": "Advanced Glycation End Products research", "value": 45632, "id": "https://openalex.org/T11142"}, {"name": "Paraoxonase enzyme and polymorphisms", "value": 9569, "id": "https://openalex.org/T12975"}]}, {"name": "Cancer Research", "children": [{"name": "Cancer, Hypoxia, and Metabolism", "value": 139679, "id": "https://openalex.org/T10631"}, {"name": "MicroRNA in disease regulation", "value": 138504, "id": "https://openalex.org/T10062"}, {"name": "Cancer-related molecular mechanisms research", "value": 131636, "id": "https://openalex.org/T10515"}, {"name": "Breast Cancer Treatment Studies", "value": 109422, "id": "https://openalex.org/T10183"}, {"name": "Cancer Genomics and Diagnostics", "value": 97031, "id": "https://openalex.org/T11287"}, {"name": "Carcinogens and Genotoxicity Assessment", "value": 86839, "id": "https://openalex.org/T10433"}, {"name": "Sesquiterpenes and Asteraceae Studies", "value": 77404, "id": "https://openalex.org/T11547"}, {"name": "Cancer, Lipids, and Metabolism", "value": 74636, "id": "https://openalex.org/T12465"}, {"name": "Protease and Inhibitor Mechanisms", "value": 69145, "id": "https://openalex.org/T10620"}, {"name": "NF-\u03baB Signaling Pathways", "value": 32181, "id": "https://openalex.org/T11591"}, {"name": "Synthesis and Biological Activity", "value": 23191, "id": "https://openalex.org/T13971"}, {"name": "Beetle Biology and Toxicology Studies", "value": 19055, "id": "https://openalex.org/T13943"}, {"name": "Myxozoan Parasites in Aquatic Species", "value": 12733, "id": "https://openalex.org/T13350"}]}, {"name": "Molecular Medicine", "children": [{"name": "Antibiotic Resistance in Bacteria", "value": 133102, "id": "https://openalex.org/T10147"}, {"name": "Hydrogels: synthesis, properties, applications", "value": 50022, "id": "https://openalex.org/T10343"}, {"name": "Curcumin's Biomedical Applications", "value": 32518, "id": "https://openalex.org/T11319"}]}, {"name": "Physiology", "children": [{"name": "Reproductive biology and impacts on aquatic species", "value": 121524, "id": "https://openalex.org/T11505"}, {"name": "Adenosine and Purinergic Signaling", "value": 51607, "id": "https://openalex.org/T11193"}, {"name": "Magnetic and Electromagnetic Effects", "value": 47976, "id": "https://openalex.org/T12976"}, {"name": "Calcium signaling and nucleotide metabolism", "value": 13062, "id": "https://openalex.org/T13415"}]}, {"name": "Biotechnology", "children": [{"name": "Enzyme Production and Characterization", "value": 116039, "id": "https://openalex.org/T11617"}, {"name": "Marine Sponges and Natural Products", "value": 98070, "id": "https://openalex.org/T11340"}, {"name": "Cancer Research and Treatments", "value": 88332, "id": "https://openalex.org/T12996"}, {"name": "Microbial Metabolism and Applications", "value": 51745, "id": "https://openalex.org/T12673"}, {"name": "Listeria monocytogenes in Food Safety", "value": 50546, "id": "https://openalex.org/T10900"}, {"name": "Microbial Inactivation Methods", "value": 41576, "id": "https://openalex.org/T11455"}, {"name": "Transgenic Plants and Applications", "value": 39841, "id": "https://openalex.org/T12856"}, {"name": "Biochemical and biochemical processes", "value": 19931, "id": "https://openalex.org/T14150"}]}, {"name": "Biochemistry", "children": [{"name": "Environmental Science and Technology", "value": 110442, "id": "https://openalex.org/T13711"}, {"name": "Amino Acid Enzymes and Metabolism", "value": 86121, "id": "https://openalex.org/T12770"}, {"name": "Eicosanoids and Hypertension Pharmacology", "value": 59322, "id": "https://openalex.org/T12910"}, {"name": "Lipid metabolism and biosynthesis", "value": 43680, "id": "https://openalex.org/T11844"}, {"name": "Sulfur Compounds in Biology", "value": 40882, "id": "https://openalex.org/T11481"}, {"name": "Traditional and Medicinal Uses of Annonaceae", "value": 33304, "id": "https://openalex.org/T12497"}, {"name": "Biochemical Acid Research Studies", "value": 26565, "id": "https://openalex.org/T12915"}]}, {"name": "Endocrinology", "children": [{"name": "Escherichia coli research studies", "value": 79572, "id": "https://openalex.org/T10943"}, {"name": "Vibrio bacteria research studies", "value": 78104, "id": "https://openalex.org/T11684"}, {"name": "Diphtheria, Corynebacterium, and Tetanus", "value": 70135, "id": "https://openalex.org/T12499"}, {"name": "Infections and bacterial resistance", "value": 63971, "id": "https://openalex.org/T12824"}, {"name": "Legionella and Acanthamoeba research", "value": 37686, "id": "https://openalex.org/T11916"}, {"name": "Plant and Fungal Interactions Research", "value": 27973, "id": "https://openalex.org/T13220"}, {"name": "Enterobacteriaceae and Cronobacter Research", "value": 27490, "id": "https://openalex.org/T13849"}]}, {"name": "Aging", "children": [{"name": "Genetics, Aging, and Longevity in Model Organisms", "value": 76173, "id": "https://openalex.org/T10676"}]}, {"name": "Developmental Biology", "children": [{"name": "Animal Vocal Communication and Behavior", "value": 62597, "id": "https://openalex.org/T11665"}, {"name": "Congenital limb and hand anomalies", "value": 29764, "id": "https://openalex.org/T13107"}]}]}, {"name": "Neuroscience", "children": [{"name": "Cellular and Molecular Neuroscience", "children": [{"name": "Neuroscience and Neuropharmacology Research", "value": 219284, "id": "https://openalex.org/T10077"}, {"name": "Neurobiology and Insect Physiology Research", "value": 122848, "id": "https://openalex.org/T10423"}, {"name": "Neuropeptides and Animal Physiology", "value": 112424, "id": "https://openalex.org/T10814"}, {"name": "Neurotransmitter Receptor Influence on Behavior", "value": 92651, "id": "https://openalex.org/T10056"}, {"name": "Genetic Neurodegenerative Diseases", "value": 82148, "id": "https://openalex.org/T10949"}, {"name": "Photoreceptor and optogenetics research", "value": 73365, "id": "https://openalex.org/T12236"}, {"name": "Neuroscience and Neural Engineering", "value": 71934, "id": "https://openalex.org/T11601"}, {"name": "Cerebrospinal fluid and hydrocephalus", "value": 65764, "id": "https://openalex.org/T11406"}, {"name": "Nerve injury and regeneration", "value": 60138, "id": "https://openalex.org/T10483"}, {"name": "Axon Guidance and Neuronal Signaling", "value": 30066, "id": "https://openalex.org/T12061"}, {"name": "Hereditary Neurological Disorders", "value": 26000, "id": "https://openalex.org/T12331"}, {"name": "Nuclear Receptors and Signaling", "value": 21786, "id": "https://openalex.org/T13991"}, {"name": "Antioxidants, Aging, Portulaca oleracea", "value": 20406, "id": "https://openalex.org/T13446"}]}, {"name": "Cognitive Neuroscience", "children": [{"name": "EEG and Brain-Computer Interfaces", "value": 157507, "id": "https://openalex.org/T10429"}, {"name": "Autism Spectrum Disorder Research", "value": 141362, "id": "https://openalex.org/T10106"}, {"name": "Neural dynamics and brain function", "value": 136360, "id": "https://openalex.org/T10581"}, {"name": "Visual perception and processing mechanisms", "value": 118305, "id": "https://openalex.org/T10427"}, {"name": "Functional Brain Connectivity Studies", "value": 114415, "id": "https://openalex.org/T10241"}, {"name": "Hearing Loss and Rehabilitation", "value": 97723, "id": "https://openalex.org/T10283"}, {"name": "Sleep and Wakefulness Research", "value": 82059, "id": "https://openalex.org/T10985"}, {"name": "Neurobiology of Language and Bilingualism", "value": 77587, "id": "https://openalex.org/T10465"}, {"name": "Neural and Behavioral Psychology Studies", "value": 76916, "id": "https://openalex.org/T10042"}, {"name": "Memory and Neural Mechanisms", "value": 70905, "id": "https://openalex.org/T10448"}, {"name": "Neuroscience, Education and Cognitive Function", "value": 70118, "id": "https://openalex.org/T13106"}, {"name": "Tactile and Sensory Interactions", "value": 62330, "id": "https://openalex.org/T10914"}, {"name": "Neuroscience and Music Perception", "value": 62146, "id": "https://openalex.org/T10788"}, {"name": "Pain Management and Placebo Effect", "value": 55516, "id": "https://openalex.org/T12035"}, {"name": "Motor Control and Adaptation", "value": 47783, "id": "https://openalex.org/T10982"}, {"name": "Psychology of Moral and Emotional Judgment", "value": 47267, "id": "https://openalex.org/T12520"}, {"name": "Face Recognition and Perception", "value": 45157, "id": "https://openalex.org/T11094"}, {"name": "Memory Processes and Influences", "value": 42465, "id": "https://openalex.org/T10918"}, {"name": "Neuroethics, Human Enhancement, Biomedical Innovations", "value": 39597, "id": "https://openalex.org/T11953"}, {"name": "Aesthetic Perception and Analysis", "value": 33534, "id": "https://openalex.org/T12650"}, {"name": "Hemispheric Asymmetry in Neuroscience", "value": 33384, "id": "https://openalex.org/T12621"}, {"name": "Cognitive Science and Education Research", "value": 30589, "id": "https://openalex.org/T14394"}, {"name": "Embodied and Extended Cognition", "value": 25222, "id": "https://openalex.org/T11883"}, {"name": "Free Will and Agency", "value": 23332, "id": "https://openalex.org/T11997"}, {"name": "Spatial Neglect and Hemispheric Dysfunction", "value": 21970, "id": "https://openalex.org/T12608"}, {"name": "Mind wandering and attention", "value": 17400, "id": "https://openalex.org/T13219"}, {"name": "Hallucinations in medical conditions", "value": 14458, "id": "https://openalex.org/T13397"}, {"name": "Undergraduate Neuroscience Education and Research", "value": 6326, "id": "https://openalex.org/T14411"}]}, {"name": "Neurology", "children": [{"name": "Neurology and Historical Studies", "value": 146890, "id": "https://openalex.org/T12854"}, {"name": "Vestibular and auditory disorders", "value": 100232, "id": "https://openalex.org/T10542"}, {"name": "Neurological Disorders and Treatments", "value": 88595, "id": "https://openalex.org/T13796"}, {"name": "Neuroinflammation and Neurodegeneration Mechanisms", "value": 79047, "id": "https://openalex.org/T11266"}, {"name": "Transcranial Magnetic Stimulation Studies", "value": 52493, "id": "https://openalex.org/T10614"}, {"name": "Neurological Disease Mechanisms and Treatments", "value": 50674, "id": "https://openalex.org/T14144"}, {"name": "Brain Tumor Detection and Classification", "value": 46040, "id": "https://openalex.org/T12702"}, {"name": "Barrier Structure and Function Studies", "value": 29727, "id": "https://openalex.org/T11872"}, {"name": "Neurological diseases and metabolism", "value": 25402, "id": "https://openalex.org/T13481"}, {"name": "Vagus Nerve Stimulation Research", "value": 16487, "id": "https://openalex.org/T12580"}]}, {"name": "Behavioral Neuroscience", "children": [{"name": "Stress Responses and Cortisol", "value": 103052, "id": "https://openalex.org/T10529"}]}, {"name": "Endocrine and Autonomic Systems", "children": [{"name": "Circadian rhythm and melatonin", "value": 91874, "id": "https://openalex.org/T10342"}, {"name": "Neuroscience of respiration and sleep", "value": 79657, "id": "https://openalex.org/T11456"}, {"name": "Regulation of Appetite and Obesity", "value": 71191, "id": "https://openalex.org/T10489"}]}, {"name": "Sensory Systems", "children": [{"name": "Olfactory and Sensory Function Studies", "value": 88883, "id": "https://openalex.org/T10971"}, {"name": "Hearing, Cochlea, Tinnitus, Genetics", "value": 74889, "id": "https://openalex.org/T10334"}, {"name": "Ion Channels and Receptors", "value": 43853, "id": "https://openalex.org/T11204"}]}, {"name": "Developmental Neuroscience", "children": [{"name": "Anesthesia and Neurotoxicity Research", "value": 65347, "id": "https://openalex.org/T12963"}, {"name": "Neurogenesis and neuroplasticity mechanisms", "value": 61271, "id": "https://openalex.org/T10608"}, {"name": "Williams Syndrome Research", "value": 23953, "id": "https://openalex.org/T13258"}]}, {"name": "Biological Psychiatry", "children": [{"name": "Tryptophan and brain disorders", "value": 61573, "id": "https://openalex.org/T11337"}]}]}, {"name": "Immunology and Microbiology", "children": [{"name": "Immunology", "children": [{"name": "Immune Cell Function and Interaction", "value": 162437, "id": "https://openalex.org/T11020"}, {"name": "Immunotherapy and Immune Responses", "value": 134847, "id": "https://openalex.org/T10580"}, {"name": "Immune Response and Inflammation", "value": 114428, "id": "https://openalex.org/T10371"}, {"name": "T-cell and B-cell Immunology", "value": 110140, "id": "https://openalex.org/T10031"}, {"name": "Immunodeficiency and Autoimmune Disorders", "value": 99272, "id": "https://openalex.org/T11725"}, {"name": "Aquaculture disease management and microbiota", "value": 93767, "id": "https://openalex.org/T10506"}, {"name": "Reproductive System and Pregnancy", "value": 83787, "id": "https://openalex.org/T11510"}, {"name": "Psoriasis: Treatment and Pathogenesis", "value": 68243, "id": "https://openalex.org/T10469"}, {"name": "interferon and immune responses", "value": 61795, "id": "https://openalex.org/T11668"}, {"name": "T-cell and Retrovirus Studies", "value": 60293, "id": "https://openalex.org/T12159"}, {"name": "Toxin Mechanisms and Immunotoxins", "value": 54521, "id": "https://openalex.org/T12477"}, {"name": "Immune cells in cancer", "value": 53503, "id": "https://openalex.org/T11313"}, {"name": "Mast cells and histamine", "value": 51218, "id": "https://openalex.org/T11346"}, {"name": "Complement system in diseases", "value": 49754, "id": "https://openalex.org/T10993"}, {"name": "Neutrophil, Myeloperoxidase and Oxidative Mechanisms", "value": 49029, "id": "https://openalex.org/T11597"}, {"name": "Atherosclerosis and Cardiovascular Diseases", "value": 48907, "id": "https://openalex.org/T12955"}, {"name": "Biosimilars and Bioanalytical Methods", "value": 39174, "id": "https://openalex.org/T12255"}, {"name": "Invertebrate Immune Response Mechanisms", "value": 37340, "id": "https://openalex.org/T11403"}, {"name": "Phagocytosis and Immune Regulation", "value": 30930, "id": "https://openalex.org/T12672"}, {"name": "Immunotoxicology and immune responses", "value": 28391, "id": "https://openalex.org/T14072"}, {"name": "Galectins and Cancer Biology", "value": 24904, "id": "https://openalex.org/T12387"}, {"name": "Immune responses and vaccinations", "value": 23494, "id": "https://openalex.org/T13410"}, {"name": "IL-33, ST2, and ILC Pathways", "value": 21819, "id": "https://openalex.org/T12528"}, {"name": "Macrophage Migration Inhibitory Factor", "value": 18872, "id": "https://openalex.org/T13254"}, {"name": "Biomarkers in Disease Mechanisms", "value": 17878, "id": "https://openalex.org/T14245"}, {"name": "Inflammation biomarkers and pathways", "value": 10396, "id": "https://openalex.org/T14165"}]}, {"name": "Virology", "children": [{"name": "HIV Research and Treatment", "value": 135360, "id": "https://openalex.org/T10112"}, {"name": "Rabies epidemiology and control", "value": 56619, "id": "https://openalex.org/T11780"}, {"name": "Poxvirus research and outbreaks", "value": 37011, "id": "https://openalex.org/T11767"}]}, {"name": "Microbiology", "children": [{"name": "Microbial infections and disease research", "value": 106333, "id": "https://openalex.org/T11688"}, {"name": "Reproductive tract infections research", "value": 101213, "id": "https://openalex.org/T10428"}, {"name": "Bacterial Infections and Vaccines", "value": 97810, "id": "https://openalex.org/T10873"}, {"name": "Antimicrobial Peptides and Activities", "value": 55480, "id": "https://openalex.org/T11103"}, {"name": "Medical Device Sterilization and Disinfection", "value": 29949, "id": "https://openalex.org/T12744"}, {"name": "Alexander von Humboldt Studies", "value": 24630, "id": "https://openalex.org/T13980"}]}, {"name": "Parasitology", "children": [{"name": "Vector-borne infectious diseases", "value": 104915, "id": "https://openalex.org/T10296"}, {"name": "Parasites and Host Interactions", "value": 103755, "id": "https://openalex.org/T10695"}, {"name": "Toxoplasma gondii Research Studies", "value": 87706, "id": "https://openalex.org/T11155"}, {"name": "Parasitic Infections and Diagnostics", "value": 67805, "id": "https://openalex.org/T11086"}, {"name": "Bird parasitology and diseases", "value": 38771, "id": "https://openalex.org/T12178"}, {"name": "Leptospirosis research and findings", "value": 36311, "id": "https://openalex.org/T12223"}, {"name": "Bartonella species infections research", "value": 16507, "id": "https://openalex.org/T12833"}]}, {"name": "Applied Microbiology and Biotechnology", "children": [{"name": "Antibiotic Use and Resistance", "value": 72026, "id": "https://openalex.org/T10897"}, {"name": "Tannin, Tannase and Anticancer Activities", "value": 11787, "id": "https://openalex.org/T13817"}]}]}, {"name": "Pharmacology, Toxicology and Pharmaceutics", "children": [{"name": "Pharmaceutical Science", "children": [{"name": "Fluorine in Organic Chemistry", "value": 104815, "id": "https://openalex.org/T10947"}, {"name": "Chemical Reactions and Isotopes", "value": 93046, "id": "https://openalex.org/T13561"}, {"name": "Drug Solubulity and Delivery Systems", "value": 61074, "id": "https://openalex.org/T10256"}, {"name": "Advancements in Transdermal Drug Delivery", "value": 49656, "id": "https://openalex.org/T10704"}, {"name": "Advanced Drug Delivery Systems", "value": 43502, "id": "https://openalex.org/T10920"}]}, {"name": "Pharmacology", "children": [{"name": "Pharmacogenetics and Drug Metabolism", "value": 82498, "id": "https://openalex.org/T10375"}, {"name": "Pharmacological Effects of Natural Compounds", "value": 77165, "id": "https://openalex.org/T12817"}, {"name": "Drug-Induced Hepatotoxicity and Protection", "value": 70590, "id": "https://openalex.org/T11465"}, {"name": "Plant-based Medicinal Research", "value": 66736, "id": "https://openalex.org/T13095"}, {"name": "Pharmacy and Medical Practices", "value": 57836, "id": "https://openalex.org/T13970"}, {"name": "Pharmaceutical industry and healthcare", "value": 50848, "id": "https://openalex.org/T11649"}, {"name": "Alkaloids: synthesis and pharmacology", "value": 32558, "id": "https://openalex.org/T12649"}, {"name": "Ginger and Zingiberaceae research", "value": 30618, "id": "https://openalex.org/T12347"}, {"name": "Medicinal Plant Pharmacodynamics Research", "value": 26529, "id": "https://openalex.org/T14331"}, {"name": "Piperaceae Chemical and Biological Studies", "value": 24621, "id": "https://openalex.org/T13037"}, {"name": "Psidium guajava Extracts and Applications", "value": 22153, "id": "https://openalex.org/T14360"}, {"name": "Hops Chemistry and Applications", "value": 16457, "id": "https://openalex.org/T13798"}, {"name": "Phytochemistry and Bioactivity Studies", "value": 14744, "id": "https://openalex.org/T13719"}, {"name": "Hibiscus Plant Research Studies", "value": 14375, "id": "https://openalex.org/T13322"}, {"name": "Medical and Pharmaceutic Studies", "value": 6935, "id": "https://openalex.org/T14108"}]}, {"name": "Toxicology", "children": [{"name": "Forensic Toxicology and Drug Analysis", "value": 41640, "id": "https://openalex.org/T10800"}, {"name": "Bioactive Compounds and Antitumor Agents", "value": 33891, "id": "https://openalex.org/T12356"}, {"name": "Pharmacovigilance and Adverse Drug Reactions", "value": 28857, "id": "https://openalex.org/T11943"}, {"name": "Organoselenium and organotellurium chemistry", "value": 20431, "id": "https://openalex.org/T11931"}]}, {"name": "Drug Discovery", "children": [{"name": "Pharmacology and Nanomedicine Research", "value": 11450, "id": "https://openalex.org/T13202"}]}]}]}, {"name": "Social Sciences", "children": [{"name": "Economics, Econometrics and Finance", "children": [{"name": "Economics and Econometrics", "children": [{"name": "Diverse Scientific and Economic Studies", "value": 2905284, "id": "https://openalex.org/T13370"}, {"name": "Healthcare Policy and Management", "value": 275229, "id": "https://openalex.org/T10391"}, {"name": "Historical Economic and Social Studies", "value": 213001, "id": "https://openalex.org/T10605"}, {"name": "Business, Innovation, and Economy", "value": 210736, "id": "https://openalex.org/T13255"}, {"name": "Historical and socio-economic studies of Spain and related regions", "value": 183754, "id": "https://openalex.org/T12641"}, {"name": "Health Systems, Economic Evaluations, Quality of Life", "value": 181823, "id": "https://openalex.org/T10804"}, {"name": "Cinema and Media Studies", "value": 178437, "id": "https://openalex.org/T10758"}, {"name": "Fiscal Policy and Economic Growth", "value": 167404, "id": "https://openalex.org/T11770"}, {"name": "Diverse academic and cultural studies", "value": 151127, "id": "https://openalex.org/T14491"}, {"name": "Balkan and Eastern European Studies", "value": 145768, "id": "https://openalex.org/T14008"}, {"name": "Economic theories and models", "value": 139302, "id": "https://openalex.org/T12137"}, {"name": "Housing Market and Economics", "value": 129353, "id": "https://openalex.org/T10632"}, {"name": "Insurance and Financial Risk Management", "value": 120264, "id": "https://openalex.org/T12394"}, {"name": "Economic Theory and Institutions", "value": 117320, "id": "https://openalex.org/T10785"}, {"name": "Regional Development and Management Studies", "value": 116908, "id": "https://openalex.org/T13407"}, {"name": "Economic Growth and Fiscal Policies", "value": 114593, "id": "https://openalex.org/T12446"}, {"name": "Climate Change Policy and Economics", "value": 113907, "id": "https://openalex.org/T10471"}, {"name": "Economic Growth and Productivity", "value": 107986, "id": "https://openalex.org/T10393"}, {"name": "Market Dynamics and Volatility", "value": 99228, "id": "https://openalex.org/T11059"}, {"name": "Complex Systems and Time Series Analysis", "value": 94345, "id": "https://openalex.org/T11270"}, {"name": "COVID-19 Pandemic Impacts", "value": 90512, "id": "https://openalex.org/T11711"}, {"name": "Taxation and Compliance Studies", "value": 88374, "id": "https://openalex.org/T11257"}, {"name": "Labor market dynamics and wage inequality", "value": 87000, "id": "https://openalex.org/T10208"}, {"name": "Sports Analytics and Performance", "value": 86779, "id": "https://openalex.org/T11674"}, {"name": "Energy, Environment, Economic Growth", "value": 85794, "id": "https://openalex.org/T10438"}, {"name": "Microfinance and Financial Inclusion", "value": 84544, "id": "https://openalex.org/T10987"}, {"name": "Economic and Environmental Valuation", "value": 78442, "id": "https://openalex.org/T10841"}, {"name": "Pharmaceutical Economics and Policy", "value": 78127, "id": "https://openalex.org/T11792"}, {"name": "Law, Economics, and Judicial Systems", "value": 77633, "id": "https://openalex.org/T11762"}, {"name": "HIV/AIDS Impact and Responses", "value": 74912, "id": "https://openalex.org/T14334"}, {"name": "Regional Economic and Spatial Analysis", "value": 71554, "id": "https://openalex.org/T14051"}, {"name": "Merger and Competition Analysis", "value": 69386, "id": "https://openalex.org/T11043"}, {"name": "Firm Innovation and Growth", "value": 65805, "id": "https://openalex.org/T12851"}, {"name": "European Socioeconomic and Political Studies", "value": 65415, "id": "https://openalex.org/T14404"}, {"name": "Indian Economic and Social Development", "value": 63310, "id": "https://openalex.org/T13894"}, {"name": "Defense, Military, and Policy Studies", "value": 62362, "id": "https://openalex.org/T12825"}, {"name": "Innovation Policy and R&D", "value": 57387, "id": "https://openalex.org/T12722"}, {"name": "Fiscal Policies and Political Economy", "value": 56794, "id": "https://openalex.org/T11621"}, {"name": "German Economic Analysis & Policies", "value": 53117, "id": "https://openalex.org/T13389"}, {"name": "Economic and Technological Innovation", "value": 51040, "id": "https://openalex.org/T14143"}, {"name": "Game Theory and Voting Systems", "value": 49774, "id": "https://openalex.org/T10991"}, {"name": "Economics of Agriculture and Food Markets", "value": 48461, "id": "https://openalex.org/T11898"}, {"name": "Economic and Fiscal Studies", "value": 48384, "id": "https://openalex.org/T13042"}, {"name": "Economic and Business Studies", "value": 47497, "id": "https://openalex.org/T14129"}, {"name": "Diverse Perspectives in Modern Studies", "value": 45733, "id": "https://openalex.org/T13713"}, {"name": "Economic and Business Development Strategies", "value": 45469, "id": "https://openalex.org/T13278"}, {"name": "Polish socio-economic development", "value": 44570, "id": "https://openalex.org/T12052"}, {"name": "Regional Economics and Spatial Analysis", "value": 41503, "id": "https://openalex.org/T11014"}, {"name": "Italy: Economic History and Contemporary Issues", "value": 40295, "id": "https://openalex.org/T14094"}, {"name": "Economic and Financial Impacts of Cancer", "value": 37072, "id": "https://openalex.org/T12708"}, {"name": "Economic and Industrial Development", "value": 35428, "id": "https://openalex.org/T13547"}, {"name": "Diverse Specialized Academic Research", "value": 34040, "id": "https://openalex.org/T14325"}, {"name": "Brazilian History and Foreign Policy", "value": 34031, "id": "https://openalex.org/T13472"}, {"name": "Economic Sanctions and International Relations", "value": 30581, "id": "https://openalex.org/T13007"}, {"name": "Legal and Constitutional Studies", "value": 29986, "id": "https://openalex.org/T13138"}, {"name": "Global Socioeconomic and Political Dynamics", "value": 29229, "id": "https://openalex.org/T14113"}, {"name": "Spatial and Panel Data Analysis", "value": 28409, "id": "https://openalex.org/T11911"}, {"name": "Geochemistry and Geochronology of Asian Mineral Deposits", "value": 26761, "id": "https://openalex.org/T13442"}, {"name": "Globalization, Economics, and Policies", "value": 26749, "id": "https://openalex.org/T14503"}, {"name": "New Zealand Economic and Social Studies", "value": 25863, "id": "https://openalex.org/T14231"}, {"name": "Economic Analysis and Policy", "value": 25750, "id": "https://openalex.org/T14424"}, {"name": "Labor Market and Education", "value": 22412, "id": "https://openalex.org/T13411"}, {"name": "Global Politics and Economy", "value": 21967, "id": "https://openalex.org/T14213"}, {"name": "Impulse Buying and Technology Impacts", "value": 21475, "id": "https://openalex.org/T14294"}, {"name": "Occupational and Professional Licensing Regulation", "value": 20471, "id": "https://openalex.org/T14230"}, {"name": "Regional resilience and development", "value": 20443, "id": "https://openalex.org/T13588"}, {"name": "Economic Policies and Impacts", "value": 17232, "id": "https://openalex.org/T13825"}, {"name": "Economic, Social, and Health Studies", "value": 15959, "id": "https://openalex.org/T14370"}, {"name": "Unemployment and Economic Growth", "value": 15577, "id": "https://openalex.org/T13399"}, {"name": "Belt and Road Initiative", "value": 14441, "id": "https://openalex.org/T13949"}, {"name": "Global Economic and Social Development", "value": 12302, "id": "https://openalex.org/T14501"}, {"name": "Socio-economic Development and Sustainability", "value": 9456, "id": "https://openalex.org/T13237"}, {"name": "Economic Development and Regional Competitiveness", "value": 7597, "id": "https://openalex.org/T14066"}, {"name": "Ayn Rand and Bront\u00eb studies", "value": 6975, "id": "https://openalex.org/T14223"}, {"name": "Public Administration, ICT, and Policy Development", "value": 6972, "id": "https://openalex.org/T14467"}, {"name": "Herbal Medicine and Trade Cooperation", "value": 6049, "id": "https://openalex.org/T14261"}, {"name": "Socioeconomics of Resources and Conservation", "value": 5143, "id": "https://openalex.org/T13961"}, {"name": "Politics, Economics, and Education Policy", "value": 2437, "id": "https://openalex.org/T13387"}, {"name": "Diverse Global Economic and Educational Challenges", "value": 941, "id": "https://openalex.org/T13227"}]}, {"name": "General Economics, Econometrics and Finance", "children": [{"name": "Global trade and economics", "value": 230383, "id": "https://openalex.org/T10128"}, {"name": "Economic Theory and Policy", "value": 192118, "id": "https://openalex.org/T11742"}, {"name": "Monetary Policy and Economic Impact", "value": 145174, "id": "https://openalex.org/T10007"}, {"name": "Economic Issues in Ukraine", "value": 111477, "id": "https://openalex.org/T13172"}, {"name": "Aviation Industry Analysis and Trends", "value": 65271, "id": "https://openalex.org/T11599"}, {"name": "Economic Zones and Regional Development", "value": 58903, "id": "https://openalex.org/T13473"}, {"name": "Economic Development and Digital Transformation", "value": 43246, "id": "https://openalex.org/T13498"}, {"name": "Natural Resources and Economic Development", "value": 39390, "id": "https://openalex.org/T11823"}, {"name": "Economic, financial, and policy analysis", "value": 36835, "id": "https://openalex.org/T14112"}, {"name": "Digital Transformation in Law", "value": 23841, "id": "https://openalex.org/T13475"}, {"name": "Economic Systems and Logistics Management", "value": 9253, "id": "https://openalex.org/T13499"}, {"name": "Digital Transformation in Financial Services", "value": 6711, "id": "https://openalex.org/T13346"}]}, {"name": "Finance", "children": [{"name": "Global Financial Crisis and Policies", "value": 178639, "id": "https://openalex.org/T10503"}, {"name": "Banking stability, regulation, efficiency", "value": 161031, "id": "https://openalex.org/T10127"}, {"name": "Financial Markets and Investment Strategies", "value": 144488, "id": "https://openalex.org/T10047"}, {"name": "Housing, Finance, and Neoliberalism", "value": 129688, "id": "https://openalex.org/T11817"}, {"name": "Stochastic processes and financial applications", "value": 113197, "id": "https://openalex.org/T10067"}, {"name": "European Monetary and Fiscal Policies", "value": 87320, "id": "https://openalex.org/T14166"}, {"name": "Financial Crisis of the 21st Century", "value": 87280, "id": "https://openalex.org/T14101"}, {"name": "Healthcare Systems and Reforms", "value": 65702, "id": "https://openalex.org/T11531"}, {"name": "Financial Risk and Volatility Modeling", "value": 53633, "id": "https://openalex.org/T10282"}, {"name": "Community Development and Social Impact", "value": 49017, "id": "https://openalex.org/T14464"}, {"name": "Credit Risk and Financial Regulations", "value": 44968, "id": "https://openalex.org/T11496"}, {"name": "Global Financial Regulation and Crises", "value": 41022, "id": "https://openalex.org/T13074"}, {"name": "Capital Investment and Risk Analysis", "value": 40058, "id": "https://openalex.org/T11976"}, {"name": "Sustainable Finance and Green Bonds", "value": 31105, "id": "https://openalex.org/T13146"}, {"name": "finance, banking, and market dynamics", "value": 9605, "id": "https://openalex.org/T14154"}, {"name": "Finance, Markets, and Regulation", "value": 9585, "id": "https://openalex.org/T14317"}]}]}, {"name": "Arts and Humanities", "children": [{"name": "Philosophy", "children": [{"name": "Hermeneutics and Narrative Identity", "value": 1646238, "id": "https://openalex.org/T13497"}, {"name": "Classical Philosophy and Thought", "value": 214133, "id": "https://openalex.org/T11463"}, {"name": "Linguistics and Discourse Analysis", "value": 209812, "id": "https://openalex.org/T12119"}, {"name": "Nietzsche, Schopenhauer, and Hegel", "value": 127155, "id": "https://openalex.org/T14059"}, {"name": "Memory, History, Trauma, Identity", "value": 122879, "id": "https://openalex.org/T12927"}, {"name": "Mental Health and Psychiatry", "value": 113774, "id": "https://openalex.org/T12308"}, {"name": "Medieval Philosophy and Theology", "value": 93588, "id": "https://openalex.org/T12857"}, {"name": "Cultural, Media, and Literary Studies", "value": 91777, "id": "https://openalex.org/T12623"}, {"name": "Religious Studies and Spiritual Practices", "value": 89355, "id": "https://openalex.org/T13005"}, {"name": "Spanish Culture and Identity", "value": 85863, "id": "https://openalex.org/T12743"}, {"name": "Augustinian Studies and Theology", "value": 76875, "id": "https://openalex.org/T13887"}, {"name": "Medieval and Classical Philosophy", "value": 74755, "id": "https://openalex.org/T12511"}, {"name": "Theology and Philosophy of Evil", "value": 71315, "id": "https://openalex.org/T13144"}, {"name": "Technology, Environment, Urban Planning", "value": 69326, "id": "https://openalex.org/T14401"}, {"name": "Kantian Philosophy and Modern Interpretations", "value": 68846, "id": "https://openalex.org/T13712"}, {"name": "Indian History and Philosophy", "value": 58673, "id": "https://openalex.org/T13902"}, {"name": "Education Practices and Challenges", "value": 53917, "id": "https://openalex.org/T12164"}, {"name": "Philosophical Ethics and Theory", "value": 52697, "id": "https://openalex.org/T10297"}, {"name": "Rhetoric and Communication Studies", "value": 51198, "id": "https://openalex.org/T11982"}, {"name": "Epistemology, Ethics, and Metaphysics", "value": 49682, "id": "https://openalex.org/T11477"}, {"name": "Seventeenth-Century Political and Philosophical Thought", "value": 47163, "id": "https://openalex.org/T12517"}, {"name": "Media, Religion, Digital Communication", "value": 45334, "id": "https://openalex.org/T13277"}, {"name": "Philosophy, Ethics, and Existentialism", "value": 41647, "id": "https://openalex.org/T12366"}, {"name": "Spanish Philosophy and Literature", "value": 38650, "id": "https://openalex.org/T13462"}, {"name": "War, Ethics, and Justification", "value": 37548, "id": "https://openalex.org/T12957"}, {"name": "Philosophy and Historical Thought", "value": 36712, "id": "https://openalex.org/T13931"}, {"name": "South Asian Studies and Diaspora", "value": 36277, "id": "https://openalex.org/T12949"}, {"name": "Pragmatism in Philosophy and Education", "value": 33948, "id": "https://openalex.org/T12133"}, {"name": "Utopian, Dystopian, and Speculative Fiction", "value": 32224, "id": "https://openalex.org/T12507"}, {"name": "Cultural Studies and Interdisciplinary Research", "value": 31343, "id": "https://openalex.org/T13301"}, {"name": "Wittgensteinian philosophy and applications", "value": 30912, "id": "https://openalex.org/T12558"}, {"name": "Philosophical and Theoretical Analysis", "value": 30343, "id": "https://openalex.org/T13545"}, {"name": "Philosophical and Cultural Analysis", "value": 27228, "id": "https://openalex.org/T12726"}, {"name": "Rousseau and Enlightenment Thought", "value": 25334, "id": "https://openalex.org/T13153"}, {"name": "Polish-Jewish Holocaust Memory Studies", "value": 23499, "id": "https://openalex.org/T13225"}, {"name": "Kierkegaardian Philosophy and Influence", "value": 22836, "id": "https://openalex.org/T14148"}, {"name": "Scientific and Historical Analyses", "value": 22417, "id": "https://openalex.org/T13908"}, {"name": "Walter Benjamin Studies Compilation", "value": 15975, "id": "https://openalex.org/T13264"}, {"name": "Reformed Theology and Governance", "value": 15912, "id": "https://openalex.org/T13661"}, {"name": "Violence, Religion, and Philosophy", "value": 15524, "id": "https://openalex.org/T14314"}, {"name": "Karl Barth and Christian Theology", "value": 13561, "id": "https://openalex.org/T12440"}, {"name": "Simone de Beauvoir and Sartre", "value": 12938, "id": "https://openalex.org/T13087"}, {"name": "Study and Philosophy of Religion", "value": 12816, "id": "https://openalex.org/T13150"}, {"name": "Ethics, Aesthetics, and Art", "value": 11816, "id": "https://openalex.org/T14092"}, {"name": "Marxism and Critical Theory", "value": 11114, "id": "https://openalex.org/T14278"}, {"name": "Literary, Cultural, Historical Analysis", "value": 7097, "id": "https://openalex.org/T14460"}, {"name": "Philosophy and Literary Analysis", "value": 6676, "id": "https://openalex.org/T13940"}, {"name": "Cultural Identity and Representation", "value": 6062, "id": "https://openalex.org/T13788"}, {"name": "Education, Philosophy, and Society", "value": 3935, "id": "https://openalex.org/T14024"}]}, {"name": "Literature and Literary Theory", "children": [{"name": "German Literature and Culture Studies", "value": 609128, "id": "https://openalex.org/T11893"}, {"name": "Historical and Literary Analyses", "value": 190015, "id": "https://openalex.org/T14149"}, {"name": "Spanish Literature and Culture Studies", "value": 188221, "id": "https://openalex.org/T12977"}, {"name": "Literature and Culture Studies", "value": 171000, "id": "https://openalex.org/T13028"}, {"name": "Comparative Literary Analysis and Criticism", "value": 145030, "id": "https://openalex.org/T13466"}, {"name": "Second Language Learning and Teaching", "value": 137222, "id": "https://openalex.org/T12542"}, {"name": "Early Modern Spanish Literature", "value": 125675, "id": "https://openalex.org/T11794"}, {"name": "Linguistics and Education Research", "value": 120605, "id": "https://openalex.org/T12184"}, {"name": "Themes in Literature Analysis", "value": 118789, "id": "https://openalex.org/T12678"}, {"name": "Digital Humanities and Scholarship", "value": 114399, "id": "https://openalex.org/T12377"}, {"name": "Shakespeare, Adaptation, and Literary Criticism", "value": 114184, "id": "https://openalex.org/T12912"}, {"name": "Folklore, Mythology, and Literature Studies", "value": 113206, "id": "https://openalex.org/T12586"}, {"name": "Literature, Culture, and Criticism", "value": 111595, "id": "https://openalex.org/T13179"}, {"name": "French Literature and Poetry", "value": 107762, "id": "https://openalex.org/T13704"}, {"name": "Poetry Analysis and Criticism", "value": 104432, "id": "https://openalex.org/T12398"}, {"name": "American and British Literature Analysis", "value": 74652, "id": "https://openalex.org/T13174"}, {"name": "Discourse Analysis in Language Studies", "value": 73484, "id": "https://openalex.org/T10366"}, {"name": "German Colonialism and Identity Studies", "value": 70334, "id": "https://openalex.org/T12972"}, {"name": "Literature and Cultural Memory", "value": 68533, "id": "https://openalex.org/T14193"}, {"name": "Literature: history, themes, analysis", "value": 67076, "id": "https://openalex.org/T10011"}, {"name": "Cultural and Social Studies in Latin America", "value": 57296, "id": "https://openalex.org/T14172"}, {"name": "Contemporary Literature and Criticism", "value": 56275, "id": "https://openalex.org/T12130"}, {"name": "Literacy, Media, and Education", "value": 53964, "id": "https://openalex.org/T11935"}, {"name": "Postcolonial and Cultural Literary Studies", "value": 53634, "id": "https://openalex.org/T11717"}, {"name": "Turkish Literature and Culture", "value": 53320, "id": "https://openalex.org/T13450"}, {"name": "French Literature and Critical Theory", "value": 53106, "id": "https://openalex.org/T12559"}, {"name": "French Literature and Criticism", "value": 44552, "id": "https://openalex.org/T13667"}, {"name": "Literature, Film, and Journalism Analysis", "value": 43628, "id": "https://openalex.org/T14192"}, {"name": "Narrative Theory and Analysis", "value": 43463, "id": "https://openalex.org/T12461"}, {"name": "Crime and Detective Fiction Studies", "value": 38925, "id": "https://openalex.org/T13145"}, {"name": "Ecocriticism and Environmental Literature", "value": 36376, "id": "https://openalex.org/T12457"}, {"name": "Media Influence and Health", "value": 33567, "id": "https://openalex.org/T12214"}, {"name": "Modernist Literature and Criticism", "value": 32737, "id": "https://openalex.org/T12974"}, {"name": "Bach Studies and Logistics Development", "value": 30403, "id": "https://openalex.org/T14046"}, {"name": "Latin American Literature Analysis", "value": 30141, "id": "https://openalex.org/T13427"}, {"name": "Literary Theory and Cultural Hermeneutics", "value": 29977, "id": "https://openalex.org/T13024"}, {"name": "Short Stories in Global Literature", "value": 28759, "id": "https://openalex.org/T13433"}, {"name": "Samuel Beckett and Modernism", "value": 26193, "id": "https://openalex.org/T13245"}, {"name": "Moravian Church and William Blake", "value": 25744, "id": "https://openalex.org/T13733"}, {"name": "American Literature and Humor Studies", "value": 22623, "id": "https://openalex.org/T14217"}, {"name": "Comparative and World Literature", "value": 21314, "id": "https://openalex.org/T13778"}, {"name": "Joseph Conrad and Literature", "value": 21140, "id": "https://openalex.org/T13329"}, {"name": "Autobiographical and Biographical Writing", "value": 20747, "id": "https://openalex.org/T13474"}, {"name": "Borges, Kipling, and Jewish Identity", "value": 17356, "id": "https://openalex.org/T14247"}, {"name": "Semiotics and Representation Studies", "value": 15542, "id": "https://openalex.org/T13250"}, {"name": "Literature, Magical Realism, Garc\u00eda M\u00e1rquez", "value": 14577, "id": "https://openalex.org/T13486"}, {"name": "Evelyn Waugh and Hans Urs von Balthasar Studies", "value": 14128, "id": "https://openalex.org/T14001"}, {"name": "Franz Kafka Literary Studies", "value": 13328, "id": "https://openalex.org/T14385"}, {"name": "American Jewish Fiction Analysis", "value": 10697, "id": "https://openalex.org/T13259"}, {"name": "Thomas Hardy Literature Studies", "value": 9968, "id": "https://openalex.org/T13672"}, {"name": "Modern American Literature Studies", "value": 5981, "id": "https://openalex.org/T14305"}, {"name": "Diverse Cultural and Social Studies", "value": 5824, "id": "https://openalex.org/T13837"}, {"name": "Postmodernism in Literature and Education", "value": 3269, "id": "https://openalex.org/T13666"}]}, {"name": "Music", "children": [{"name": "Musicology and Musical Analysis", "value": 461019, "id": "https://openalex.org/T10941"}, {"name": "Diverse Musicological Studies", "value": 178825, "id": "https://openalex.org/T13996"}, {"name": "Music History and Culture", "value": 127896, "id": "https://openalex.org/T11113"}, {"name": "Diverse Music Education Insights", "value": 109610, "id": "https://openalex.org/T11425"}, {"name": "Theater, Performance, and Music History", "value": 57971, "id": "https://openalex.org/T13330"}]}, {"name": "Museology", "children": [{"name": "Libraries and Information Services", "value": 459790, "id": "https://openalex.org/T14380"}, {"name": "Historical Art and Culture Studies", "value": 160609, "id": "https://openalex.org/T13922"}, {"name": "Fashion and Cultural Textiles", "value": 124705, "id": "https://openalex.org/T12514"}, {"name": "Museums and Cultural Heritage", "value": 93241, "id": "https://openalex.org/T11462"}, {"name": "Cultural and Sociopolitical Studies", "value": 91352, "id": "https://openalex.org/T13367"}, {"name": "Photographic and Visual Arts", "value": 61756, "id": "https://openalex.org/T13268"}, {"name": "Crafts, Textile, and Design", "value": 49448, "id": "https://openalex.org/T13316"}, {"name": "Literature, Culture, and Aesthetics", "value": 25902, "id": "https://openalex.org/T14035"}, {"name": "Cultural and Communication Design Research", "value": 3452, "id": "https://openalex.org/T13515"}]}, {"name": "Religious studies", "children": [{"name": "Biblical Studies and Interpretation", "value": 391800, "id": "https://openalex.org/T10362"}, {"name": "Indian and Buddhist Studies", "value": 172971, "id": "https://openalex.org/T11563"}, {"name": "Theology and Canon Law Studies", "value": 165797, "id": "https://openalex.org/T13178"}, {"name": "Pentecostalism and Christianity Studies", "value": 138384, "id": "https://openalex.org/T13636"}, {"name": "Religion, Theology, and Education", "value": 130444, "id": "https://openalex.org/T14321"}, {"name": "Christian Theology and Mission", "value": 99886, "id": "https://openalex.org/T13347"}, {"name": "Caribbean and African Literature and Culture", "value": 84239, "id": "https://openalex.org/T12470"}, {"name": "Hispanic-African Historical Relations", "value": 41988, "id": "https://openalex.org/T14343"}, {"name": "Contemporary Christian Leadership and Education", "value": 36149, "id": "https://openalex.org/T13072"}, {"name": "Islamic Thought and Society Studies", "value": 34752, "id": "https://openalex.org/T13815"}, {"name": "Early Modern Women Writers", "value": 32165, "id": "https://openalex.org/T13356"}, {"name": "Religion, Gender, and Enlightenment", "value": 27389, "id": "https://openalex.org/T14426"}, {"name": "Medical Research and Islamic Perspectives", "value": 11416, "id": "https://openalex.org/T14132"}, {"name": "Cultural Studies and Colonialism", "value": 2499, "id": "https://openalex.org/T13818"}, {"name": "Diverse Philosophical and Cultural Studies", "value": 2120, "id": "https://openalex.org/T14063"}]}, {"name": "History", "children": [{"name": "Reformation and Early Modern Christianity", "value": 366432, "id": "https://openalex.org/T12409"}, {"name": "European Political History Analysis", "value": 288020, "id": "https://openalex.org/T12454"}, {"name": "French Historical and Cultural Studies", "value": 248913, "id": "https://openalex.org/T12909"}, {"name": "Medical History and Innovations", "value": 229691, "id": "https://openalex.org/T12990"}, {"name": "Historical Studies on Reproduction, Gender, Health, and Societal Changes", "value": 209140, "id": "https://openalex.org/T13332"}, {"name": "Scottish History and National Identity", "value": 197483, "id": "https://openalex.org/T14109"}, {"name": "Renaissance and Early Modern Studies", "value": 197392, "id": "https://openalex.org/T12076"}, {"name": "Historical and Archaeological Studies", "value": 197080, "id": "https://openalex.org/T13593"}, {"name": "Historical and Religious Studies of Rome", "value": 181652, "id": "https://openalex.org/T14451"}, {"name": "Medical History and Research", "value": 168959, "id": "https://openalex.org/T12575"}, {"name": "German History and Society", "value": 167594, "id": "https://openalex.org/T13484"}, {"name": "American Sports and Literature", "value": 153526, "id": "https://openalex.org/T14518"}, {"name": "Classical Studies and Legal History", "value": 134638, "id": "https://openalex.org/T13845"}, {"name": "Libraries, Manuscripts, and Books", "value": 120149, "id": "https://openalex.org/T14386"}, {"name": "Mormonism, Religion, and History", "value": 109319, "id": "https://openalex.org/T13750"}, {"name": "History of Medicine Studies", "value": 108936, "id": "https://openalex.org/T12324"}, {"name": "Historical and Contemporary Political Dynamics", "value": 103201, "id": "https://openalex.org/T13938"}, {"name": "Historical Studies on Spain", "value": 92954, "id": "https://openalex.org/T12739"}, {"name": "Historical Studies of British Isles", "value": 92529, "id": "https://openalex.org/T14355"}, {"name": "Historical and Cultural Studies of Poland", "value": 91724, "id": "https://openalex.org/T12886"}, {"name": "Media, Journalism, and Communication History", "value": 91014, "id": "https://openalex.org/T13766"}, {"name": "Oral History, Memory, Narrative Analysis", "value": 83702, "id": "https://openalex.org/T13590"}, {"name": "Spanish History and Politics", "value": 80654, "id": "https://openalex.org/T13006"}, {"name": "History of Education in Spain", "value": 77618, "id": "https://openalex.org/T13392"}, {"name": "Medieval and Early Modern Iberia", "value": 68647, "id": "https://openalex.org/T13089"}, {"name": "Photography and Visual Culture", "value": 65847, "id": "https://openalex.org/T12868"}, {"name": "Historical Architecture and Urbanism", "value": 64390, "id": "https://openalex.org/T13519"}, {"name": "North African History and Literature", "value": 63380, "id": "https://openalex.org/T12585"}, {"name": "Travel Writing and Literature", "value": 55729, "id": "https://openalex.org/T13575"}, {"name": "Catholicism and Religious Studies", "value": 51203, "id": "https://openalex.org/T12862"}, {"name": "Medieval History and Crusades", "value": 49642, "id": "https://openalex.org/T12999"}, {"name": "Historical Studies in Central America", "value": 36806, "id": "https://openalex.org/T14312"}, {"name": "Cultural History and Identity Formation", "value": 29623, "id": "https://openalex.org/T13863"}, {"name": "Ottoman and Turkish Studies", "value": 28406, "id": "https://openalex.org/T13848"}, {"name": "History of Education Research in Brazil", "value": 26962, "id": "https://openalex.org/T12382"}, {"name": "American Political and Social Dynamics", "value": 26748, "id": "https://openalex.org/T13333"}, {"name": "Amazonian Archaeology and Ethnohistory", "value": 26641, "id": "https://openalex.org/T13302"}, {"name": "Philosophy, History, and Historiography", "value": 26587, "id": "https://openalex.org/T12777"}, {"name": "American Literature and Culture", "value": 25701, "id": "https://openalex.org/T14494"}, {"name": "History, Culture, and Diplomacy", "value": 21505, "id": "https://openalex.org/T13231"}, {"name": "History of Medicine and Tropical Health", "value": 19943, "id": "https://openalex.org/T12778"}, {"name": "Biographical and Historical Analysis", "value": 19126, "id": "https://openalex.org/T13495"}, {"name": "Sephardic Jews and Inquisition Studies", "value": 11068, "id": "https://openalex.org/T13577"}, {"name": "History of Emotions Research", "value": 10424, "id": "https://openalex.org/T13708"}]}, {"name": "History and Philosophy of Science", "children": [{"name": "Historical Studies and Socio-cultural Analysis", "value": 343798, "id": "https://openalex.org/T13641"}, {"name": "History of Science and Natural History", "value": 126423, "id": "https://openalex.org/T12471"}, {"name": "History of Science and Medicine", "value": 101420, "id": "https://openalex.org/T14475"}, {"name": "Academic Writing and Publishing", "value": 93959, "id": "https://openalex.org/T12648"}, {"name": "Philosophy and History of Science", "value": 89848, "id": "https://openalex.org/T10778"}, {"name": "Historical Philosophy and Science", "value": 89134, "id": "https://openalex.org/T11137"}, {"name": "Philosophy, Science, and History", "value": 78764, "id": "https://openalex.org/T13558"}, {"name": "Historical Studies in Science", "value": 59340, "id": "https://openalex.org/T14442"}, {"name": "Sports Science and Education", "value": 57893, "id": "https://openalex.org/T13359"}, {"name": "Twentieth Century Scientific Developments", "value": 57407, "id": "https://openalex.org/T12445"}, {"name": "Publishing and Scholarly Communication", "value": 43566, "id": "https://openalex.org/T13516"}, {"name": "Evolution and Science Education", "value": 43403, "id": "https://openalex.org/T12182"}, {"name": "Literary Analysis and Cultural Studies", "value": 32914, "id": "https://openalex.org/T14151"}, {"name": "Cybernetics and Technology in Society", "value": 28217, "id": "https://openalex.org/T13308"}, {"name": "Diverse Historical and Scientific Studies", "value": 26341, "id": "https://openalex.org/T14517"}, {"name": "Giambattista Vico and Joyce", "value": 11302, "id": "https://openalex.org/T14131"}, {"name": "Graphic Design and Typography", "value": 10728, "id": "https://openalex.org/T13757"}, {"name": "Aviation History and Innovations", "value": 5152, "id": "https://openalex.org/T14116"}, {"name": "Interdisciplinary Studies: Technology, Society, and Humanities", "value": 2321, "id": "https://openalex.org/T14266"}]}, {"name": "Classics", "children": [{"name": "Historical, Literary, and Cultural Studies", "value": 331631, "id": "https://openalex.org/T13167"}, {"name": "Byzantine Studies and History", "value": 187778, "id": "https://openalex.org/T12266"}, {"name": "Medieval Literature and History", "value": 182011, "id": "https://openalex.org/T10595"}, {"name": "Renaissance Literature and Culture", "value": 95179, "id": "https://openalex.org/T14469"}, {"name": "Medieval Iberian Studies", "value": 93316, "id": "https://openalex.org/T13195"}]}, {"name": "Archeology", "children": [{"name": "Archaeological and Historical Studies", "value": 285422, "id": "https://openalex.org/T11857"}, {"name": "Archaeology and Historical Studies", "value": 285202, "id": "https://openalex.org/T13372"}, {"name": "Medieval European History and Architecture", "value": 246885, "id": "https://openalex.org/T14388"}, {"name": "Ancient Mediterranean Archaeology and History", "value": 243025, "id": "https://openalex.org/T13068"}, {"name": "Ancient and Medieval Archaeology Studies", "value": 222139, "id": "https://openalex.org/T13621"}, {"name": "Maritime and Coastal Archaeology", "value": 207111, "id": "https://openalex.org/T12624"}, {"name": "Ancient Egypt and Archaeology", "value": 146739, "id": "https://openalex.org/T12555"}, {"name": "Ancient Near East History", "value": 124570, "id": "https://openalex.org/T12307"}, {"name": "Cultural Heritage Materials Analysis", "value": 124313, "id": "https://openalex.org/T11212"}, {"name": "Medieval Architecture and Archaeology", "value": 121530, "id": "https://openalex.org/T13714"}, {"name": "Cultural Heritage Management and Preservation", "value": 120144, "id": "https://openalex.org/T11846"}, {"name": "Cultural Identity and Heritage", "value": 119056, "id": "https://openalex.org/T13070"}, {"name": "Historical, Religious, and Philosophical Studies", "value": 104363, "id": "https://openalex.org/T13198"}, {"name": "Historical and Architectural Studies", "value": 101570, "id": "https://openalex.org/T14506"}, {"name": "Archaeological and Geological Studies", "value": 87532, "id": "https://openalex.org/T13831"}, {"name": "Paleopathology and ancient diseases", "value": 83734, "id": "https://openalex.org/T13409"}, {"name": "Forensic Anthropology and Bioarchaeology Studies", "value": 81871, "id": "https://openalex.org/T10992"}, {"name": "Historical Studies of Medieval Iberia", "value": 77828, "id": "https://openalex.org/T14197"}, {"name": "Architecture and Cultural Influences", "value": 43989, "id": "https://openalex.org/T13599"}, {"name": "Landscape and Cultural Studies", "value": 25904, "id": "https://openalex.org/T13339"}]}, {"name": "Language and Linguistics", "children": [{"name": "Linguistics and language evolution", "value": 282227, "id": "https://openalex.org/T12768"}, {"name": "Medieval European Literature and History", "value": 240182, "id": "https://openalex.org/T14021"}, {"name": "Linguistic research and analysis", "value": 239577, "id": "https://openalex.org/T12373"}, {"name": "EFL/ESL Teaching and Learning", "value": 211917, "id": "https://openalex.org/T10021"}, {"name": "Translation Studies and Practices", "value": 165040, "id": "https://openalex.org/T10759"}, {"name": "Spanish Linguistics and Language Studies", "value": 163689, "id": "https://openalex.org/T12341"}, {"name": "Linguistic Education and Pedagogy", "value": 148416, "id": "https://openalex.org/T14081"}, {"name": "Lexicography and Language Studies", "value": 137767, "id": "https://openalex.org/T12353"}, {"name": "Historical Linguistics and Language Studies", "value": 129591, "id": "https://openalex.org/T13156"}, {"name": "Linguistics and Cultural Studies", "value": 110589, "id": "https://openalex.org/T13122"}, {"name": "Syntax, Semantics, Linguistic Variation", "value": 107702, "id": "https://openalex.org/T10034"}, {"name": "Language, Linguistics, Cultural Analysis", "value": 102725, "id": "https://openalex.org/T13912"}, {"name": "Linguistics, Language Diversity, and Identity", "value": 101240, "id": "https://openalex.org/T14006"}, {"name": "Language, Discourse, Communication Strategies", "value": 74108, "id": "https://openalex.org/T10383"}, {"name": "linguistics and terminology studies", "value": 57212, "id": "https://openalex.org/T12881"}, {"name": "Linguistics and Language Analysis", "value": 55374, "id": "https://openalex.org/T13538"}, {"name": "Linguistics and Language Studies", "value": 49661, "id": "https://openalex.org/T13260"}, {"name": "Subtitles and Audiovisual Media", "value": 33650, "id": "https://openalex.org/T13310"}, {"name": "Classical Studies and Philology", "value": 18863, "id": "https://openalex.org/T14170"}, {"name": "Umberto Eco and Semiotics", "value": 2226, "id": "https://openalex.org/T13606"}]}, {"name": "Conservation", "children": [{"name": "Historical Art and Architecture Studies", "value": 199322, "id": "https://openalex.org/T14191"}, {"name": "Digital and Traditional Archives Management", "value": 133766, "id": "https://openalex.org/T11657"}, {"name": "Architecture, Design, and Social History", "value": 71844, "id": "https://openalex.org/T14357"}, {"name": "Architectural and Urban Studies", "value": 60165, "id": "https://openalex.org/T13520"}, {"name": "Conservation Techniques and Studies", "value": 47156, "id": "https://openalex.org/T12981"}, {"name": "Art Therapy and Mental Health", "value": 35063, "id": "https://openalex.org/T12372"}]}, {"name": "General Arts and Humanities", "children": [{"name": "Italian Literature and Culture", "value": 138021, "id": "https://openalex.org/T13743"}, {"name": "Cultural and Mythological Studies", "value": 56583, "id": "https://openalex.org/T12680"}, {"name": "Corporeality, Perception, and Education", "value": 16679, "id": "https://openalex.org/T13571"}, {"name": "Schopenhauer and Stefan Zweig", "value": 10144, "id": "https://openalex.org/T14366"}]}, {"name": "Visual Arts and Performing Arts", "children": [{"name": "Art, Politics, and Modernism", "value": 136396, "id": "https://openalex.org/T12444"}, {"name": "Theatre and Performance Studies", "value": 118544, "id": "https://openalex.org/T11391"}, {"name": "Latin American history and culture", "value": 107165, "id": "https://openalex.org/T12283"}, {"name": "Art, Aesthetics, and Perception", "value": 97160, "id": "https://openalex.org/T14322"}, {"name": "Art, Technology, and Culture", "value": 96436, "id": "https://openalex.org/T14002"}, {"name": "Architecture and Art History Studies", "value": 85752, "id": "https://openalex.org/T13133"}, {"name": "Art History and Market Analysis", "value": 83727, "id": "https://openalex.org/T13342"}, {"name": "Cinema History and Criticism", "value": 74993, "id": "https://openalex.org/T12803"}, {"name": "Art Education and Development", "value": 64122, "id": "https://openalex.org/T12179"}, {"name": "South Asian Cinema and Culture", "value": 55189, "id": "https://openalex.org/T13334"}, {"name": "Comics and Graphic Narratives", "value": 54349, "id": "https://openalex.org/T12390"}, {"name": "Visual Culture and Art Theory", "value": 47778, "id": "https://openalex.org/T12632"}, {"name": "Cultural and Historical Studies", "value": 38133, "id": "https://openalex.org/T13413"}, {"name": "Architecture, Art, Education", "value": 35600, "id": "https://openalex.org/T13683"}, {"name": "Arts and Performance Studies", "value": 34980, "id": "https://openalex.org/T13860"}, {"name": "Artistic and Creative Research", "value": 33627, "id": "https://openalex.org/T13216"}, {"name": "Creative Drama in Education", "value": 11616, "id": "https://openalex.org/T14243"}]}]}, {"name": "Social Sciences", "children": [{"name": "Sociology and Political Science", "children": [{"name": "French Urban and Social Studies", "value": 683662, "id": "https://openalex.org/T11475"}, {"name": "Chinese history and philosophy", "value": 348478, "id": "https://openalex.org/T10893"}, {"name": "Irish and British Studies", "value": 306751, "id": "https://openalex.org/T11776"}, {"name": "Race, History, and American Society", "value": 255022, "id": "https://openalex.org/T12765"}, {"name": "Sociology and Education Studies", "value": 246557, "id": "https://openalex.org/T10259"}, {"name": "Historical and Environmental Studies", "value": 246417, "id": "https://openalex.org/T13622"}, {"name": "Canadian Identity and History", "value": 230343, "id": "https://openalex.org/T12219"}, {"name": "Education, sociology, and vocational training", "value": 218723, "id": "https://openalex.org/T10153"}, {"name": "Italian Fascism and Post-war Society", "value": 203715, "id": "https://openalex.org/T12337"}, {"name": "Jewish and Middle Eastern Studies", "value": 176206, "id": "https://openalex.org/T11203"}, {"name": "Australian History and Society", "value": 171047, "id": "https://openalex.org/T12525"}, {"name": "Religion, Society, and Development", "value": 164799, "id": "https://openalex.org/T13456"}, {"name": "Diverse Aspects of Tourism Research", "value": 158540, "id": "https://openalex.org/T10055"}, {"name": "Vietnamese History and Culture Studies", "value": 157821, "id": "https://openalex.org/T13802"}, {"name": "Religious and Theological Studies", "value": 155544, "id": "https://openalex.org/T13823"}, {"name": "Digital Games and Media", "value": 155327, "id": "https://openalex.org/T11197"}, {"name": "Historical and Linguistic Studies", "value": 150548, "id": "https://openalex.org/T14210"}, {"name": "Digital Marketing and Social Media", "value": 149622, "id": "https://openalex.org/T10609"}, {"name": "Eastern European Communism and Reforms", "value": 146643, "id": "https://openalex.org/T14005"}, {"name": "Political Economy and Marxism", "value": 145910, "id": "https://openalex.org/T11743"}, {"name": "Islamic Finance and Communication", "value": 142280, "id": "https://openalex.org/T14281"}, {"name": "Criminal Law and Policy", "value": 142219, "id": "https://openalex.org/T13376"}, {"name": "Human Rights and Immigration", "value": 140470, "id": "https://openalex.org/T14490"}, {"name": "Education and Digital Technologies", "value": 139180, "id": "https://openalex.org/T12573"}, {"name": "Religion and Society Interactions", "value": 138168, "id": "https://openalex.org/T11507"}, {"name": "German Social Sciences and History", "value": 136234, "id": "https://openalex.org/T13212"}, {"name": "Migration and Labor Dynamics", "value": 131927, "id": "https://openalex.org/T10349"}, {"name": "Economic and Social Issues", "value": 123834, "id": "https://openalex.org/T13360"}, {"name": "Criminal Justice and Corrections Analysis", "value": 116883, "id": "https://openalex.org/T10318"}, {"name": "Urban, Neighborhood, and Segregation Studies", "value": 116502, "id": "https://openalex.org/T11645"}, {"name": "Migration, Ethnicity, and Economy", "value": 113314, "id": "https://openalex.org/T12693"}, {"name": "Educator Training and Historical Pedagogy", "value": 110590, "id": "https://openalex.org/T11859"}, {"name": "Social Policies and Family", "value": 110294, "id": "https://openalex.org/T13888"}, {"name": "Sport and Mega-Event Impacts", "value": 109770, "id": "https://openalex.org/T11474"}, {"name": "Disaster Management and Resilience", "value": 108514, "id": "https://openalex.org/T10747"}, {"name": "Asian Studies and History", "value": 107353, "id": "https://openalex.org/T11256"}, {"name": "Impact of Technology on Adolescents", "value": 103353, "id": "https://openalex.org/T10355"}, {"name": "German legal, social, and political studies", "value": 101797, "id": "https://openalex.org/T13537"}, {"name": "Terrorism, Counterterrorism, and Political Violence", "value": 98566, "id": "https://openalex.org/T10994"}, {"name": "Historical Gender and Feminism Studies", "value": 94212, "id": "https://openalex.org/T14238"}, {"name": "Central European national history", "value": 93223, "id": "https://openalex.org/T12686"}, {"name": "Multimedia Communication and Technology", "value": 91525, "id": "https://openalex.org/T12720"}, {"name": "Social Acceptance of Renewable Energy", "value": 90464, "id": "https://openalex.org/T12503"}, {"name": "Cuban History and Society", "value": 88382, "id": "https://openalex.org/T12375"}, {"name": "Arctic and Russian Policy Studies", "value": 87997, "id": "https://openalex.org/T12432"}, {"name": "Misinformation and Its Impacts", "value": 87330, "id": "https://openalex.org/T11147"}, {"name": "Sex work and related issues", "value": 85397, "id": "https://openalex.org/T11350"}, {"name": "Psychosocial Factors Impacting Youth", "value": 85034, "id": "https://openalex.org/T13521"}, {"name": "Religious, Philosophical, and Educational Studies", "value": 83288, "id": "https://openalex.org/T14337"}, {"name": "Intergenerational Family Dynamics and Caregiving", "value": 80204, "id": "https://openalex.org/T11712"}, {"name": "Korean Peninsula Historical and Political Studies", "value": 79679, "id": "https://openalex.org/T13337"}, {"name": "Linguistic, Cultural, and Literary Studies", "value": 79152, "id": "https://openalex.org/T14235"}, {"name": "Income, Poverty, and Inequality", "value": 78946, "id": "https://openalex.org/T10446"}, {"name": "Middle East and Rwanda Conflicts", "value": 78191, "id": "https://openalex.org/T13634"}, {"name": "Community-based Tourism Development and Sustainability", "value": 77642, "id": "https://openalex.org/T13136"}, {"name": "Human Rights and Development", "value": 77276, "id": "https://openalex.org/T13035"}, {"name": "Communism, Protests, Social Movements", "value": 77139, "id": "https://openalex.org/T13135"}, {"name": "Crime Patterns and Interventions", "value": 76466, "id": "https://openalex.org/T10574"}, {"name": "Sociopolitical Dynamics in Russia", "value": 74943, "id": "https://openalex.org/T13747"}, {"name": "Social and Economic Solidarity", "value": 74230, "id": "https://openalex.org/T13614"}, {"name": "Crime, Illicit Activities, and Governance", "value": 71988, "id": "https://openalex.org/T11838"}, {"name": "Regional Development and Environment", "value": 71593, "id": "https://openalex.org/T13003"}, {"name": "Digital Economy and Work Transformation", "value": 69984, "id": "https://openalex.org/T12501"}, {"name": "Military, Security, and Education Studies", "value": 68365, "id": "https://openalex.org/T14342"}, {"name": "Marriage and Family Dynamics", "value": 66968, "id": "https://openalex.org/T14348"}, {"name": "Social and Political Issues", "value": 66546, "id": "https://openalex.org/T13491"}, {"name": "Privacy, Security, and Data Protection", "value": 66455, "id": "https://openalex.org/T11045"}, {"name": "Climate Change Communication and Perception", "value": 65800, "id": "https://openalex.org/T11488"}, {"name": "Work-Family Balance Challenges", "value": 65266, "id": "https://openalex.org/T10722"}, {"name": "Socioeconomic Development in MENA", "value": 64479, "id": "https://openalex.org/T13560"}, {"name": "Social and Intergroup Psychology", "value": 64471, "id": "https://openalex.org/T10314"}, {"name": "Qualitative Comparative Analysis Research", "value": 64329, "id": "https://openalex.org/T13051"}, {"name": "Youth Education and Societal Dynamics", "value": 63041, "id": "https://openalex.org/T12714"}, {"name": "Migration, Identity, and Health", "value": 62543, "id": "https://openalex.org/T13534"}, {"name": "Islamic Studies and Radicalism", "value": 62441, "id": "https://openalex.org/T14110"}, {"name": "China's Ethnic Minorities and Relations", "value": 61697, "id": "https://openalex.org/T13073"}, {"name": "Innovation, Technology, and Society", "value": 61067, "id": "https://openalex.org/T14389"}, {"name": "Corruption and Economic Development", "value": 60409, "id": "https://openalex.org/T11042"}, {"name": "Italian Social Issues and Migration", "value": 60356, "id": "https://openalex.org/T13692"}, {"name": "Public Health in Brazil", "value": 59771, "id": "https://openalex.org/T13915"}, {"name": "Contemporary Sociological Theory and Practice", "value": 59699, "id": "https://openalex.org/T12231"}, {"name": "Family Support in Illness", "value": 59572, "id": "https://openalex.org/T13574"}, {"name": "Consumer behavior in food and health", "value": 59420, "id": "https://openalex.org/T14167"}, {"name": "Brazilian cultural history and politics", "value": 59002, "id": "https://openalex.org/T13554"}, {"name": "Middle East Politics and Society", "value": 58523, "id": "https://openalex.org/T13103"}, {"name": "Evolutionary Game Theory and Cooperation", "value": 58500, "id": "https://openalex.org/T11252"}, {"name": "European Cultural and National Identity", "value": 57971, "id": "https://openalex.org/T13914"}, {"name": "Religion and Society in Latin America", "value": 57653, "id": "https://openalex.org/T12987"}, {"name": "Migration, Refugees, and Integration", "value": 57445, "id": "https://openalex.org/T10216"}, {"name": "Critical Theory and Philosophy", "value": 56711, "id": "https://openalex.org/T12397"}, {"name": "Physical Education and Sports Studies", "value": 55641, "id": "https://openalex.org/T13296"}, {"name": "Philosophy, Sociology, Political Theory", "value": 54739, "id": "https://openalex.org/T14080"}, {"name": "Globalization, Historical Perspectives, and International Relations", "value": 53297, "id": "https://openalex.org/T13787"}, {"name": "Law, Rights, and Freedoms", "value": 52405, "id": "https://openalex.org/T14288"}, {"name": "African Studies and Ethnography", "value": 51779, "id": "https://openalex.org/T13162"}, {"name": "Transboundary Water Resource Management", "value": 51568, "id": "https://openalex.org/T11755"}, {"name": "Nonprofit Sector and Volunteering", "value": 51045, "id": "https://openalex.org/T11120"}, {"name": "South African History and Culture", "value": 50547, "id": "https://openalex.org/T11695"}, {"name": "Literary and Cultural Studies", "value": 49893, "id": "https://openalex.org/T13589"}, {"name": "Health, Education, and Cultural Studies", "value": 49120, "id": "https://openalex.org/T13613"}, {"name": "Delphi Technique in Research", "value": 47254, "id": "https://openalex.org/T12443"}, {"name": "Homicide, Infanticide, and Child Abuse", "value": 46363, "id": "https://openalex.org/T13605"}, {"name": "Economic and Social Development", "value": 45298, "id": "https://openalex.org/T12969"}, {"name": "Socioeconomic Development in Asia", "value": 44037, "id": "https://openalex.org/T13228"}, {"name": "Hong Kong and Taiwan Politics", "value": 43235, "id": "https://openalex.org/T12785"}, {"name": "Climate Change, Adaptation, Migration", "value": 42704, "id": "https://openalex.org/T12656"}, {"name": "Political Conflict and Governance", "value": 42426, "id": "https://openalex.org/T10070"}, {"name": "Conflict, Peace, and Violence in Colombia", "value": 42426, "id": "https://openalex.org/T12936"}, {"name": "Political and Social Dynamics in Chile and Latin America", "value": 42134, "id": "https://openalex.org/T13078"}, {"name": "Religion, Ecology, and Ethics", "value": 42110, "id": "https://openalex.org/T13059"}, {"name": "Contemporary and Historical Greek Studies", "value": 41633, "id": "https://openalex.org/T13900"}, {"name": "Survey Methodology and Nonresponse", "value": 41253, "id": "https://openalex.org/T11539"}, {"name": "Torture, Ethics, and Law", "value": 40708, "id": "https://openalex.org/T13076"}, {"name": "Risk Perception and Management", "value": 40574, "id": "https://openalex.org/T11573"}, {"name": "Workplace Violence and Bullying", "value": 40068, "id": "https://openalex.org/T11647"}, {"name": "Legal and Social Philosophy", "value": 39770, "id": "https://openalex.org/T14300"}, {"name": "African studies and sociopolitical issues", "value": 39450, "id": "https://openalex.org/T12635"}, {"name": "Social and Economic Development in India", "value": 39264, "id": "https://openalex.org/T14473"}, {"name": "Marriage and Sexual Relationships", "value": 38747, "id": "https://openalex.org/T13632"}, {"name": "Conferences and Exhibitions Management", "value": 37736, "id": "https://openalex.org/T13098"}, {"name": "Latin American socio-political dynamics", "value": 37507, "id": "https://openalex.org/T12609"}, {"name": "Access Control and Trust", "value": 37110, "id": "https://openalex.org/T10927"}, {"name": "COVID-19 Prevention and Impact", "value": 35440, "id": "https://openalex.org/T13032"}, {"name": "Social Capital and Networks", "value": 35039, "id": "https://openalex.org/T11239"}, {"name": "Peacebuilding and International Security", "value": 33690, "id": "https://openalex.org/T12263"}, {"name": "Globalization and Cultural Identity", "value": 33561, "id": "https://openalex.org/T12903"}, {"name": "Multicultural Socio-Legal Studies", "value": 33415, "id": "https://openalex.org/T14142"}, {"name": "Information Systems Theories and Implementation", "value": 33323, "id": "https://openalex.org/T11024"}, {"name": "Conflict Management and Negotiation", "value": 33239, "id": "https://openalex.org/T11696"}, {"name": "Names, Identity, and Discrimination Research", "value": 32876, "id": "https://openalex.org/T12970"}, {"name": "Data Analysis and Archiving", "value": 32654, "id": "https://openalex.org/T14201"}, {"name": "Halal products and consumer behavior", "value": 32601, "id": "https://openalex.org/T12651"}, {"name": "Geography and Education Methods", "value": 32057, "id": "https://openalex.org/T13306"}, {"name": "Race, Identity, and Education in Brazil", "value": 31815, "id": "https://openalex.org/T12109"}, {"name": "Social and Cultural Dynamics", "value": 31485, "id": "https://openalex.org/T11895"}, {"name": "Qualitative Research Methods and Ethics", "value": 29841, "id": "https://openalex.org/T11981"}, {"name": "Racial and Ethnic Identity Research", "value": 29726, "id": "https://openalex.org/T10652"}, {"name": "Cambodian History and Society", "value": 29221, "id": "https://openalex.org/T13525"}, {"name": "Environmental Justice and Health Disparities", "value": 28161, "id": "https://openalex.org/T12259"}, {"name": "Participatory Visual Research Methods", "value": 27980, "id": "https://openalex.org/T11944"}, {"name": "Children's Rights and Participation", "value": 27974, "id": "https://openalex.org/T11506"}, {"name": "Doping in Sports", "value": 27914, "id": "https://openalex.org/T12700"}, {"name": "Cultural Competency in Health Care", "value": 27692, "id": "https://openalex.org/T12194"}, {"name": "Migration and Exile Studies", "value": 27340, "id": "https://openalex.org/T14062"}, {"name": "Sociology and Education in Brazil", "value": 26670, "id": "https://openalex.org/T12988"}, {"name": "Critical Race Theory in Education", "value": 26335, "id": "https://openalex.org/T11384"}, {"name": "Dengue and Mosquito Control Research", "value": 26229, "id": "https://openalex.org/T14053"}, {"name": "Ombudsman and Human Rights", "value": 25118, "id": "https://openalex.org/T13659"}, {"name": "Global Security and Public Health", "value": 24662, "id": "https://openalex.org/T13055"}, {"name": "Inclusion and Disability in Education and Sport", "value": 23895, "id": "https://openalex.org/T12948"}, {"name": "African Sexualities and LGBTQ+ Issues", "value": 23036, "id": "https://openalex.org/T13843"}, {"name": "National Identity and Symbolism", "value": 22939, "id": "https://openalex.org/T13824"}, {"name": "Weber, Simmel, Sociological Theory", "value": 22360, "id": "https://openalex.org/T12730"}, {"name": "Psychology of Social Influence", "value": 22129, "id": "https://openalex.org/T13841"}, {"name": "Philosophy and Social Theory", "value": 22125, "id": "https://openalex.org/T13119"}, {"name": "Political theory and Gramsci", "value": 21897, "id": "https://openalex.org/T13764"}, {"name": "Intergenerational and Educational Inequality Studies", "value": 21812, "id": "https://openalex.org/T12088"}, {"name": "Foucault, Power, and Ethics", "value": 21460, "id": "https://openalex.org/T12295"}, {"name": "Anarchism and Radical Politics", "value": 21397, "id": "https://openalex.org/T13428"}, {"name": "Media Influence and Politics", "value": 21344, "id": "https://openalex.org/T13718"}, {"name": "Media Discourse and Social  Analysis", "value": 20900, "id": "https://openalex.org/T13947"}, {"name": "Hydropower, Displacement, Environmental Impact", "value": 20801, "id": "https://openalex.org/T13132"}, {"name": "Education for Peace and Conflict Resolution", "value": 20731, "id": "https://openalex.org/T13620"}, {"name": "Political Theology and Sovereignty", "value": 20343, "id": "https://openalex.org/T12311"}, {"name": "Crime, Deviance, and Social Control", "value": 19194, "id": "https://openalex.org/T13728"}, {"name": "Interdisciplinary Cultural and Social Studies", "value": 19063, "id": "https://openalex.org/T14176"}, {"name": "Emotional Labor in Professions", "value": 18269, "id": "https://openalex.org/T12284"}, {"name": "Emile Durkheim and Sociology", "value": 17827, "id": "https://openalex.org/T12839"}, {"name": "Place Attachment and Urban Studies", "value": 17779, "id": "https://openalex.org/T12143"}, {"name": "Ottoman Empire History and Society", "value": 17753, "id": "https://openalex.org/T13441"}, {"name": "Literature, Language, and Rhetoric Studies", "value": 17446, "id": "https://openalex.org/T13707"}, {"name": "Youth, Politics, and Society", "value": 17134, "id": "https://openalex.org/T14038"}, {"name": "Theological Perspectives and Practices", "value": 17080, "id": "https://openalex.org/T13109"}, {"name": "Cyprus History, Politics, Society", "value": 16671, "id": "https://openalex.org/T13576"}, {"name": "Innovation, Sustainability, Human-Machine Systems", "value": 16127, "id": "https://openalex.org/T14350"}, {"name": "Peace and Human Rights Education", "value": 15762, "id": "https://openalex.org/T13014"}, {"name": "Elite Sociology and Global Capitalism", "value": 15709, "id": "https://openalex.org/T14140"}, {"name": "Philosophical and Historical Studies", "value": 14239, "id": "https://openalex.org/T13660"}, {"name": "Colonial History and Postcolonial Studies", "value": 13792, "id": "https://openalex.org/T14141"}, {"name": "Educational Theory and Curriculum Studies", "value": 13755, "id": "https://openalex.org/T13416"}, {"name": "Youth Culture and Social Dynamics", "value": 13526, "id": "https://openalex.org/T13043"}, {"name": "Decadence, Literature, and Society", "value": 12956, "id": "https://openalex.org/T13455"}, {"name": "New Caledonia Indigenous Studies", "value": 12764, "id": "https://openalex.org/T13581"}, {"name": "Critical Realism in Sociology", "value": 12239, "id": "https://openalex.org/T12953"}, {"name": "Focus Groups and Qualitative Methods", "value": 12165, "id": "https://openalex.org/T12679"}, {"name": "Consumer Behavior and Market Dynamics", "value": 11133, "id": "https://openalex.org/T12807"}, {"name": "Extractivism and Socioeconomic Issues", "value": 10910, "id": "https://openalex.org/T13687"}, {"name": "Sociology and Norbert Elias", "value": 10772, "id": "https://openalex.org/T13881"}, {"name": "Social Power and Status Dynamics", "value": 10533, "id": "https://openalex.org/T12892"}, {"name": "Environmental, Ecological, and Cultural Studies", "value": 10512, "id": "https://openalex.org/T13469"}, {"name": "Quality of Life Measurement", "value": 10506, "id": "https://openalex.org/T14440"}, {"name": "Historical and modern epidemiology studies", "value": 10131, "id": "https://openalex.org/T14043"}, {"name": "Mental Health and Well-being", "value": 10049, "id": "https://openalex.org/T14476"}, {"name": "Stalking, Cyberstalking, and Harassment", "value": 9526, "id": "https://openalex.org/T13582"}, {"name": "Gender, Violence, Rights in Latin America", "value": 9276, "id": "https://openalex.org/T13617"}, {"name": "Ukrainian Cultural and Linguistic Studies", "value": 9040, "id": "https://openalex.org/T13320"}, {"name": "Social and Cultural Studies", "value": 8982, "id": "https://openalex.org/T13401"}, {"name": "Diverse Applied Research Studies", "value": 8836, "id": "https://openalex.org/T13550"}, {"name": "Gender, Health, and Social Inequality", "value": 8592, "id": "https://openalex.org/T13503"}, {"name": "Feminist Epistemology and Gender Studies", "value": 7425, "id": "https://openalex.org/T12320"}, {"name": "Humanities and Social Sciences", "value": 6051, "id": "https://openalex.org/T13724"}, {"name": "Education, Politics, and Culture Studies", "value": 5859, "id": "https://openalex.org/T13698"}, {"name": "Diverse Research Studies Overview", "value": 5838, "id": "https://openalex.org/T14111"}, {"name": "Diverse Academic Research Analysis", "value": 5578, "id": "https://openalex.org/T14504"}, {"name": "Diverse Global Research Studies", "value": 5448, "id": "https://openalex.org/T14073"}, {"name": "Interdisciplinary Studies and Sociocultural Dynamics", "value": 5319, "id": "https://openalex.org/T14023"}, {"name": "Feminism, Gender, and Intersectionality", "value": 5082, "id": "https://openalex.org/T13783"}, {"name": "Methodology and Impact of Social Science Research", "value": 4108, "id": "https://openalex.org/T14084"}, {"name": "Global Development and Urbanization", "value": 3756, "id": "https://openalex.org/T14383"}, {"name": "Sociology, Governance, and Technology", "value": 3681, "id": "https://openalex.org/T14422"}, {"name": "Flooding and Environmental Impact", "value": 3660, "id": "https://openalex.org/T13969"}, {"name": "Global History, Politics, and Ideology", "value": 3444, "id": "https://openalex.org/T13631"}, {"name": "Sustainability, Governance, and Employment Studies", "value": 3320, "id": "https://openalex.org/T14202"}, {"name": "Socio-political and Technological Issues", "value": 2902, "id": "https://openalex.org/T14077"}, {"name": "Society, Economy, and Ethics Research", "value": 2839, "id": "https://openalex.org/T13610"}, {"name": "Cultural, Social, and Media Studies", "value": 2772, "id": "https://openalex.org/T14000"}, {"name": "Contemporary Social and Educational Issues", "value": 2691, "id": "https://openalex.org/T13300"}, {"name": "Social Movements and Cultural Identity", "value": 2515, "id": "https://openalex.org/T13982"}, {"name": "Zygmunt Bauman's Sociology", "value": 2288, "id": "https://openalex.org/T13017"}, {"name": "The Impact of Diversity and Innovation on Society", "value": 2163, "id": "https://openalex.org/T13994"}, {"name": "Educational, Social, and Political Issues", "value": 2015, "id": "https://openalex.org/T13835"}, {"name": "Sociology and Cultural Identity Studies", "value": 1988, "id": "https://openalex.org/T13311"}, {"name": "Latin American social science", "value": 1192, "id": "https://openalex.org/T14253"}, {"name": "Globalization and Economic Impact", "value": 951, "id": "https://openalex.org/T14352"}]}, {"name": "Anthropology", "children": [{"name": "Classical Antiquity Studies", "value": 522188, "id": "https://openalex.org/T10165"}, {"name": "Historical and Literary Studies", "value": 260190, "id": "https://openalex.org/T14162"}, {"name": "Historical and Cultural Archaeology Studies", "value": 192153, "id": "https://openalex.org/T12532"}, {"name": "Archaeology and Natural History", "value": 178605, "id": "https://openalex.org/T13939"}, {"name": "African history and culture studies", "value": 170617, "id": "https://openalex.org/T14395"}, {"name": "Global Maritime and Colonial Histories", "value": 153540, "id": "https://openalex.org/T13215"}, {"name": "Eurasian Exchange Networks", "value": 132327, "id": "https://openalex.org/T12890"}, {"name": "Pleistocene-Era Hominins and Archaeology", "value": 116114, "id": "https://openalex.org/T10421"}, {"name": "Colonialism, slavery, and trade", "value": 102081, "id": "https://openalex.org/T12144"}, {"name": "Philippine History and Culture", "value": 81698, "id": "https://openalex.org/T12872"}, {"name": "Death, Funerary Practices, and Mourning", "value": 56417, "id": "https://openalex.org/T14208"}, {"name": "African Studies and Geopolitics", "value": 54773, "id": "https://openalex.org/T13019"}, {"name": "Australian Indigenous Culture and History", "value": 53161, "id": "https://openalex.org/T13705"}, {"name": "European Linguistics and Anthropology", "value": 49817, "id": "https://openalex.org/T14332"}, {"name": "Central European Literary Studies", "value": 45467, "id": "https://openalex.org/T14041"}, {"name": "History of Colonial Brazil", "value": 44049, "id": "https://openalex.org/T12512"}, {"name": "Anthropological Studies and Insights", "value": 40571, "id": "https://openalex.org/T10149"}, {"name": "Latin American Cultural Politics", "value": 33630, "id": "https://openalex.org/T12498"}, {"name": "Anthropology: Ethics, History, Culture", "value": 30181, "id": "https://openalex.org/T14289"}, {"name": "Indigenous Cultures and History", "value": 29457, "id": "https://openalex.org/T13864"}, {"name": "China's Global Influence and Migration", "value": 28916, "id": "https://openalex.org/T13669"}, {"name": "Global and Cross-Cultural Management", "value": 18264, "id": "https://openalex.org/T14031"}, {"name": "Legal and cultural studies analysis", "value": 4714, "id": "https://openalex.org/T13665"}, {"name": "Decolonial Thought and Epistemologies", "value": 3330, "id": "https://openalex.org/T14123"}, {"name": "Cross-Cultural and Social Analysis", "value": 2814, "id": "https://openalex.org/T13741"}]}, {"name": "Political Science and International Relations", "children": [{"name": "American Constitutional Law and Politics", "value": 489859, "id": "https://openalex.org/T13445"}, {"name": "European and International Law Studies", "value": 343873, "id": "https://openalex.org/T13710"}, {"name": "Public Administration and Political Analysis", "value": 288782, "id": "https://openalex.org/T13459"}, {"name": "European history and politics", "value": 263385, "id": "https://openalex.org/T12645"}, {"name": "Historical Influence and Diplomacy", "value": 262149, "id": "https://openalex.org/T13556"}, {"name": "Multiculturalism, Politics, Migration, Gender", "value": 227479, "id": "https://openalex.org/T13379"}, {"name": "Islamic Studies and History", "value": 226661, "id": "https://openalex.org/T10794"}, {"name": "Global Peace and Security Dynamics", "value": 211352, "id": "https://openalex.org/T12752"}, {"name": "Polish Historical and Cultural Studies", "value": 180207, "id": "https://openalex.org/T12764"}, {"name": "Legal case studies and regulations", "value": 155106, "id": "https://openalex.org/T12633"}, {"name": "Social Policy and Reform Studies", "value": 150247, "id": "https://openalex.org/T10443"}, {"name": "Comparative International Legal Studies", "value": 144188, "id": "https://openalex.org/T12669"}, {"name": "International Law and Human Rights", "value": 143238, "id": "https://openalex.org/T10749"}, {"name": "Comparative constitutional jurisprudence studies", "value": 140727, "id": "https://openalex.org/T12332"}, {"name": "African history and culture analysis", "value": 139618, "id": "https://openalex.org/T13504"}, {"name": "Regional Development and Policy", "value": 139561, "id": "https://openalex.org/T12961"}, {"name": "Central European and Russian historical studies", "value": 137489, "id": "https://openalex.org/T13754"}, {"name": "Conflict of Laws and Jurisdiction", "value": 136680, "id": "https://openalex.org/T12767"}, {"name": "European Union Policy and Governance", "value": 136076, "id": "https://openalex.org/T10289"}, {"name": "Political and Social Issues", "value": 132632, "id": "https://openalex.org/T14402"}, {"name": "Religion, Theology, History, Judaism, Christianity", "value": 129357, "id": "https://openalex.org/T14441"}, {"name": "Legal Systems and Judicial Processes", "value": 128694, "id": "https://openalex.org/T13075"}, {"name": "Political and Economic history of UK and US", "value": 124338, "id": "https://openalex.org/T13158"}, {"name": "Historical Legal Studies and Society", "value": 120621, "id": "https://openalex.org/T13763"}, {"name": "International Law and Aviation", "value": 119026, "id": "https://openalex.org/T14515"}, {"name": "Higher Education Governance and Development", "value": 114498, "id": "https://openalex.org/T10546"}, {"name": "Historical Geopolitical and Social Dynamics", "value": 111435, "id": "https://openalex.org/T13993"}, {"name": "Politics and Conflicts in Afghanistan, Pakistan, and Middle East", "value": 106295, "id": "https://openalex.org/T12550"}, {"name": "Electoral Systems and Political Participation", "value": 97993, "id": "https://openalex.org/T10108"}, {"name": "Medieval and Early Modern Justice", "value": 94642, "id": "https://openalex.org/T13739"}, {"name": "Political Philosophy and Ethics", "value": 94406, "id": "https://openalex.org/T10718"}, {"name": "European Criminal Justice and Data Protection", "value": 93063, "id": "https://openalex.org/T12921"}, {"name": "International Relations in Latin America", "value": 90990, "id": "https://openalex.org/T13352"}, {"name": "Policing Practices and Perceptions", "value": 90071, "id": "https://openalex.org/T11076"}, {"name": "Russia and Soviet political economy", "value": 89498, "id": "https://openalex.org/T13186"}, {"name": "South Asian Studies and Conflicts", "value": 88770, "id": "https://openalex.org/T13029"}, {"name": "World Wars: History, Literature, and Impact", "value": 86761, "id": "https://openalex.org/T11971"}, {"name": "Military History and Strategy", "value": 86364, "id": "https://openalex.org/T13494"}, {"name": "Soviet and Russian History", "value": 85233, "id": "https://openalex.org/T11070"}, {"name": "Political Systems and Governance", "value": 83861, "id": "https://openalex.org/T12619"}, {"name": "Asian Geopolitics and Ethnography", "value": 74526, "id": "https://openalex.org/T12956"}, {"name": "Southeast Asian Sociopolitical Studies", "value": 72969, "id": "https://openalex.org/T13002"}, {"name": "China's Socioeconomic Reforms and Governance", "value": 71629, "id": "https://openalex.org/T10628"}, {"name": "Nuclear Issues and Defense", "value": 71248, "id": "https://openalex.org/T13120"}, {"name": "Turkey's Politics and Society", "value": 69480, "id": "https://openalex.org/T11783"}, {"name": "Education and Public Policy", "value": 68112, "id": "https://openalex.org/T13564"}, {"name": "International Relations and Foreign Policy", "value": 67590, "id": "https://openalex.org/T10053"}, {"name": "Military and Defense Studies", "value": 67526, "id": "https://openalex.org/T14086"}, {"name": "Administrative Law and Governance", "value": 65391, "id": "https://openalex.org/T12986"}, {"name": "World Trade Organization Law", "value": 65101, "id": "https://openalex.org/T12156"}, {"name": "Intelligence, Security, War Strategy", "value": 63001, "id": "https://openalex.org/T12572"}, {"name": "Science and Science Education", "value": 60869, "id": "https://openalex.org/T14487"}, {"name": "Labor Law and Work Dynamics", "value": 56388, "id": "https://openalex.org/T14003"}, {"name": "Post-Soviet Geopolitical Dynamics", "value": 56044, "id": "https://openalex.org/T13086"}, {"name": "Commonwealth, Australian Politics and Federalism", "value": 55571, "id": "https://openalex.org/T13653"}, {"name": "Canadian Policy and Governance", "value": 55041, "id": "https://openalex.org/T13655"}, {"name": "Local Government Finance and Decentralization", "value": 53667, "id": "https://openalex.org/T11461"}, {"name": "E-Government and Public Services", "value": 48463, "id": "https://openalex.org/T10953"}, {"name": "European Politics and Security", "value": 47755, "id": "https://openalex.org/T14302"}, {"name": "Political Theory and Influence", "value": 47238, "id": "https://openalex.org/T13196"}, {"name": "Water Governance and Infrastructure", "value": 46974, "id": "https://openalex.org/T12248"}, {"name": "Indonesian Legal and Regulatory Studies", "value": 46881, "id": "https://openalex.org/T14291"}, {"name": "International Science and Diplomacy", "value": 46765, "id": "https://openalex.org/T13726"}, {"name": "Populism, Right-Wing Movements", "value": 46659, "id": "https://openalex.org/T11397"}, {"name": "European and Russian Geopolitical Military Strategies", "value": 45274, "id": "https://openalex.org/T13369"}, {"name": "Politics and Society in Latin America", "value": 44499, "id": "https://openalex.org/T10777"}, {"name": "Political Science Research and Education", "value": 44312, "id": "https://openalex.org/T13721"}, {"name": "Global Educational Policies and Reforms", "value": 44236, "id": "https://openalex.org/T11300"}, {"name": "Cybersecurity and Cyber Warfare Studies", "value": 43732, "id": "https://openalex.org/T12221"}, {"name": "Public Policy and Governance", "value": 43694, "id": "https://openalex.org/T12902"}, {"name": "Cross-Border Cooperation and Integration", "value": 43578, "id": "https://openalex.org/T12690"}, {"name": "Academic Freedom and Politics", "value": 43358, "id": "https://openalex.org/T14181"}, {"name": "Historical Economic and Legal Thought", "value": 41166, "id": "https://openalex.org/T13897"}, {"name": "International Labor and Employment Law", "value": 39144, "id": "https://openalex.org/T13773"}, {"name": "Political Dynamics in Latin America", "value": 36987, "id": "https://openalex.org/T13684"}, {"name": "Security, Politics, and Digital Transformation", "value": 36604, "id": "https://openalex.org/T14282"}, {"name": "Public Administration in Developing Nations", "value": 36331, "id": "https://openalex.org/T12687"}, {"name": "Political Theory and Democracy", "value": 36325, "id": "https://openalex.org/T13291"}, {"name": "Historical Turkish Studies", "value": 35614, "id": "https://openalex.org/T13210"}, {"name": "Global Political and Economic Relations", "value": 35282, "id": "https://openalex.org/T14349"}, {"name": "Polish Law and Legal System", "value": 35180, "id": "https://openalex.org/T12939"}, {"name": "Asian Industrial and Economic Development", "value": 35053, "id": "https://openalex.org/T13057"}, {"name": "German Security and Defense Policies", "value": 33954, "id": "https://openalex.org/T13572"}, {"name": "Historical and Political Studies", "value": 32925, "id": "https://openalex.org/T14237"}, {"name": "Gender and Women's Rights", "value": 31414, "id": "https://openalex.org/T13948"}, {"name": "Legal Issues in Turkey", "value": 26813, "id": "https://openalex.org/T13501"}, {"name": "Post-Communist Economic and Political Transition", "value": 26360, "id": "https://openalex.org/T14433"}, {"name": "Legal Studies and Reforms", "value": 25896, "id": "https://openalex.org/T13875"}, {"name": "Artificial Intelligence in Law", "value": 24566, "id": "https://openalex.org/T13643"}, {"name": "Public Administration and Governance", "value": 24506, "id": "https://openalex.org/T13988"}, {"name": "Central Asia Education and Culture", "value": 23200, "id": "https://openalex.org/T14417"}, {"name": "Indonesian Election Politics and Participation", "value": 22865, "id": "https://openalex.org/T13476"}, {"name": "Ukrainian Legal and Forensic Studies", "value": 22862, "id": "https://openalex.org/T13271"}, {"name": "Literary and Philosophical Studies", "value": 22828, "id": "https://openalex.org/T14036"}, {"name": "Medical, Sociocultural, and Biopolitical Studies", "value": 22382, "id": "https://openalex.org/T14200"}, {"name": "Global Political and Social Dynamics", "value": 21368, "id": "https://openalex.org/T14429"}, {"name": "World Systems and Global Transformations", "value": 20457, "id": "https://openalex.org/T13000"}, {"name": "Hannah Arendt's Political Philosophy", "value": 19702, "id": "https://openalex.org/T12723"}, {"name": "Education, Law, and Society", "value": 18994, "id": "https://openalex.org/T14171"}, {"name": "Intellectual Property Rights and Media", "value": 17615, "id": "https://openalex.org/T14457"}, {"name": "Latin American Legal and Economic Studies", "value": 17536, "id": "https://openalex.org/T14188"}, {"name": "Minority Rights and Languages", "value": 16494, "id": "https://openalex.org/T13549"}, {"name": "Leadership, Human Resources, Global Affairs", "value": 16347, "id": "https://openalex.org/T14338"}, {"name": "International Human Rights and Reproductive Law", "value": 15967, "id": "https://openalex.org/T13942"}, {"name": "Bangladesh Politics, Society, and Development", "value": 15824, "id": "https://openalex.org/T13826"}, {"name": "Policy Transfer and Learning", "value": 15526, "id": "https://openalex.org/T12210"}, {"name": "Land Use and Management", "value": 13560, "id": "https://openalex.org/T14336"}, {"name": "Local Economic Development and Planning", "value": 12948, "id": "https://openalex.org/T14219"}, {"name": "Public health and occupational medicine", "value": 12830, "id": "https://openalex.org/T14209"}, {"name": "History and International Relations", "value": 12245, "id": "https://openalex.org/T14032"}, {"name": "War, Law, and Justice", "value": 11534, "id": "https://openalex.org/T14492"}, {"name": "History, Medicine, and Leadership", "value": 10494, "id": "https://openalex.org/T13998"}, {"name": "Border Security and International Relations", "value": 9151, "id": "https://openalex.org/T14133"}, {"name": "Education and Labor Relations", "value": 8660, "id": "https://openalex.org/T13762"}, {"name": "Globalization and political ideologies", "value": 6127, "id": "https://openalex.org/T13995"}, {"name": "Social Sciences and Humanities", "value": 4375, "id": "https://openalex.org/T14284"}, {"name": "Political Developments and Conflicts", "value": 4327, "id": "https://openalex.org/T13598"}, {"name": "COVID-19, Geopolitics, Technology, Migration", "value": 3461, "id": "https://openalex.org/T14443"}]}, {"name": "Education", "children": [{"name": "Education, Innovation and Language Studies", "value": 443510, "id": "https://openalex.org/T13958"}, {"name": "Education, Psychology, and Social Research", "value": 413239, "id": "https://openalex.org/T13085"}, {"name": "Education Methods and Technologies", "value": 354394, "id": "https://openalex.org/T12826"}, {"name": "Education Systems and Policy", "value": 305351, "id": "https://openalex.org/T13532"}, {"name": "Social and Educational Sciences", "value": 277991, "id": "https://openalex.org/T12021"}, {"name": "Education and Character Development", "value": 222654, "id": "https://openalex.org/T14449"}, {"name": "Research in Social Sciences", "value": 220124, "id": "https://openalex.org/T13184"}, {"name": "Education and Critical Thinking Development", "value": 191699, "id": "https://openalex.org/T11715"}, {"name": "Dutch Social and Cultural Studies", "value": 191449, "id": "https://openalex.org/T13064"}, {"name": "Online and Blended Learning", "value": 181875, "id": "https://openalex.org/T10162"}, {"name": "Educational and Social Studies", "value": 178730, "id": "https://openalex.org/T12925"}, {"name": "Education Pedagogy and Practices", "value": 174265, "id": "https://openalex.org/T10457"}, {"name": "Education and Islamic Studies", "value": 143292, "id": "https://openalex.org/T12998"}, {"name": "Early Childhood Education and Development", "value": 134030, "id": "https://openalex.org/T10589"}, {"name": "Teacher Education and Leadership Studies", "value": 120514, "id": "https://openalex.org/T10008"}, {"name": "Educational Curriculum and Learning Methods", "value": 105225, "id": "https://openalex.org/T13830"}, {"name": "Literacy and Educational Practices", "value": 105127, "id": "https://openalex.org/T13061"}, {"name": "Higher Education Teaching and Evaluation", "value": 104865, "id": "https://openalex.org/T12217"}, {"name": "Academic Research in Diverse Fields", "value": 100167, "id": "https://openalex.org/T12363"}, {"name": "Higher Education Research Studies", "value": 99596, "id": "https://openalex.org/T10267"}, {"name": "Education and Teacher Training", "value": 99184, "id": "https://openalex.org/T14483"}, {"name": "Mathematics Education and Teaching Techniques", "value": 94239, "id": "https://openalex.org/T10130"}, {"name": "Education and Technology Integration", "value": 93284, "id": "https://openalex.org/T13412"}, {"name": "Science and Education Research", "value": 89621, "id": "https://openalex.org/T14376"}, {"name": "Religious Education and Schools", "value": 86182, "id": "https://openalex.org/T12616"}, {"name": "Educational Practices and Policies", "value": 86154, "id": "https://openalex.org/T14061"}, {"name": "Educational Methods and Impacts", "value": 85644, "id": "https://openalex.org/T14462"}, {"name": "Higher Education Learning Practices", "value": 76976, "id": "https://openalex.org/T13844"}, {"name": "STEM Education", "value": 76571, "id": "https://openalex.org/T12590"}, {"name": "Child Development and Digital Technology", "value": 76543, "id": "https://openalex.org/T12060"}, {"name": "Science Education and Pedagogy", "value": 76227, "id": "https://openalex.org/T10072"}, {"name": "Global Education and Multiculturalism", "value": 74744, "id": "https://openalex.org/T12545"}, {"name": "School Choice and Performance", "value": 74271, "id": "https://openalex.org/T10674"}, {"name": "Reflective Practices in Education", "value": 70667, "id": "https://openalex.org/T12500"}, {"name": "Technology-Enhanced Education Studies", "value": 67415, "id": "https://openalex.org/T14182"}, {"name": "Ideological and Political Education", "value": 65560, "id": "https://openalex.org/T13161"}, {"name": "Educational Research and Methods", "value": 64425, "id": "https://openalex.org/T10561"}, {"name": "Diverse Education Studies and Reforms", "value": 63882, "id": "https://openalex.org/T13780"}, {"name": "Educational Methods and Outcomes", "value": 63387, "id": "https://openalex.org/T12931"}, {"name": "Parental Involvement in Education", "value": 62865, "id": "https://openalex.org/T11676"}, {"name": "Education and Cultural Studies", "value": 62483, "id": "https://openalex.org/T12928"}, {"name": "Healthcare innovation and challenges", "value": 62112, "id": "https://openalex.org/T13594"}, {"name": "Historical Education and Society", "value": 61955, "id": "https://openalex.org/T14480"}, {"name": "Educational theories and practices", "value": 60869, "id": "https://openalex.org/T10437"}, {"name": "Foreign Language Teaching Methods", "value": 59972, "id": "https://openalex.org/T13978"}, {"name": "Service-Learning and Community Engagement", "value": 57287, "id": "https://openalex.org/T11806"}, {"name": "Educational Leadership and Practices", "value": 53641, "id": "https://openalex.org/T13884"}, {"name": "Education and Social Development in Ukraine", "value": 52011, "id": "https://openalex.org/T13652"}, {"name": "School Leadership and Teacher Performance", "value": 50735, "id": "https://openalex.org/T12952"}, {"name": "Higher Education and Employability", "value": 50203, "id": "https://openalex.org/T11779"}, {"name": "Innovative Teaching Methods", "value": 48339, "id": "https://openalex.org/T11526"}, {"name": "Child Development and Education", "value": 47509, "id": "https://openalex.org/T13987"}, {"name": "Student Assessment and Feedback", "value": 46808, "id": "https://openalex.org/T10959"}, {"name": "Forest, Soil, and Plant Ecology in China", "value": 45213, "id": "https://openalex.org/T14391"}, {"name": "Arabic Language Education Studies", "value": 44862, "id": "https://openalex.org/T14037"}, {"name": "Educational Methods and Analysis", "value": 44657, "id": "https://openalex.org/T12556"}, {"name": "Educational Environments and Student Outcomes", "value": 41838, "id": "https://openalex.org/T12950"}, {"name": "Collaborative Teaching and Inclusion", "value": 41198, "id": "https://openalex.org/T13131"}, {"name": "Educational Outcomes and Influences", "value": 40873, "id": "https://openalex.org/T13929"}, {"name": "African Education and Politics", "value": 40782, "id": "https://openalex.org/T12204"}, {"name": "Higher Education and Sustainability", "value": 40677, "id": "https://openalex.org/T13464"}, {"name": "Rural and Ethnic Education", "value": 39030, "id": "https://openalex.org/T13425"}, {"name": "Education during COVID-19 pandemic", "value": 38909, "id": "https://openalex.org/T13084"}, {"name": "Historical Education Studies Worldwide", "value": 37575, "id": "https://openalex.org/T13570"}, {"name": "Teacher Professional Development and Motivation", "value": 36941, "id": "https://openalex.org/T13305"}, {"name": "Physical Education and Gymnastics", "value": 35369, "id": "https://openalex.org/T13936"}, {"name": "Writing and Handwriting Education", "value": 34518, "id": "https://openalex.org/T12070"}, {"name": "Evaluation of Teaching Practices", "value": 33252, "id": "https://openalex.org/T11039"}, {"name": "Educational Assessment and Pedagogy", "value": 32948, "id": "https://openalex.org/T12884"}, {"name": "Innovations in Educational Methods", "value": 32413, "id": "https://openalex.org/T12354"}, {"name": "Problem and Project Based Learning", "value": 32236, "id": "https://openalex.org/T11299"}, {"name": "Health Education and Validation", "value": 31929, "id": "https://openalex.org/T13117"}, {"name": "Sustainability in Higher Education", "value": 31469, "id": "https://openalex.org/T11835"}, {"name": "African cultural and philosophical studies", "value": 30969, "id": "https://openalex.org/T12160"}, {"name": "Literature, Musicology, and Cultural Analysis", "value": 30601, "id": "https://openalex.org/T14095"}, {"name": "Inclusive Education and Diversity", "value": 30523, "id": "https://openalex.org/T12591"}, {"name": "Vocational Education and Training", "value": 30234, "id": "https://openalex.org/T14508"}, {"name": "Education, Leadership, and Health Research", "value": 29933, "id": "https://openalex.org/T13395"}, {"name": "Education in Rural Contexts", "value": 29781, "id": "https://openalex.org/T14033"}, {"name": "Vocational and Entrepreneurial Education", "value": 29213, "id": "https://openalex.org/T13872"}, {"name": "Information Technology and Learning", "value": 28952, "id": "https://openalex.org/T13952"}, {"name": "Online Learning Methods and Innovations", "value": 28896, "id": "https://openalex.org/T11101"}, {"name": "Social Skills and Education", "value": 28793, "id": "https://openalex.org/T14277"}, {"name": "Music Education and Analysis", "value": 26637, "id": "https://openalex.org/T14287"}, {"name": "Innovative Educational Techniques", "value": 26577, "id": "https://openalex.org/T13903"}, {"name": "Technology in Education and Healthcare", "value": 26368, "id": "https://openalex.org/T14267"}, {"name": "Education Methods and Practices", "value": 24386, "id": "https://openalex.org/T14290"}, {"name": "Education and Military Integration", "value": 23804, "id": "https://openalex.org/T14136"}, {"name": "Values and Moral Education", "value": 23575, "id": "https://openalex.org/T12531"}, {"name": "Qur\u2019anic Interpretation Studies", "value": 22269, "id": "https://openalex.org/T13646"}, {"name": "Educational Practices and Challenges", "value": 21747, "id": "https://openalex.org/T14227"}, {"name": "Education Discipline and Inequality", "value": 21299, "id": "https://openalex.org/T12474"}, {"name": "Chemistry Education and Research", "value": 20932, "id": "https://openalex.org/T14097"}, {"name": "Indigenous and Place-Based Education", "value": 20759, "id": "https://openalex.org/T14007"}, {"name": "Education in Diverse Contexts", "value": 20612, "id": "https://openalex.org/T13709"}, {"name": "Russian Literature and Bakhtin Studies", "value": 20601, "id": "https://openalex.org/T12966"}, {"name": "Higher Education Practises and Engagement", "value": 20507, "id": "https://openalex.org/T14207"}, {"name": "Education and Communication Studies", "value": 20290, "id": "https://openalex.org/T14060"}, {"name": "Education and experiences of immigrants and refugees", "value": 20272, "id": "https://openalex.org/T13063"}, {"name": "Educational Philosophies and Pedagogies", "value": 19475, "id": "https://openalex.org/T14421"}, {"name": "Youth Substance Use and School Attendance", "value": 19341, "id": "https://openalex.org/T13207"}, {"name": "Educational Leadership and Administration", "value": 17562, "id": "https://openalex.org/T13299"}, {"name": "Pancasila Values in Education", "value": 17459, "id": "https://openalex.org/T13348"}, {"name": "Adult and Continuing Education Topics", "value": 17147, "id": "https://openalex.org/T12345"}, {"name": "Innovative Teaching Methodologies in Social Sciences", "value": 16668, "id": "https://openalex.org/T12978"}, {"name": "Higher Education in Latin America", "value": 16415, "id": "https://openalex.org/T13403"}, {"name": "Global Education Systems and Policies", "value": 15910, "id": "https://openalex.org/T13789"}, {"name": "Educational Leadership and Innovation", "value": 15104, "id": "https://openalex.org/T13895"}, {"name": "Education and Professional Development", "value": 13995, "id": "https://openalex.org/T13658"}, {"name": "Diverse Education and Engineering Focus", "value": 13707, "id": "https://openalex.org/T13930"}, {"name": "Violence, Education, and Gender Studies", "value": 13536, "id": "https://openalex.org/T13981"}, {"name": "E-Learning and COVID-19", "value": 13413, "id": "https://openalex.org/T14240"}, {"name": "Qualitative Research Methods and Applications", "value": 12960, "id": "https://openalex.org/T12880"}, {"name": "Education and Vocational Training", "value": 10838, "id": "https://openalex.org/T14274"}, {"name": "Knowledge Management in Higher Education", "value": 10316, "id": "https://openalex.org/T13273"}, {"name": "Educational Methods and Psychological Studies", "value": 9455, "id": "https://openalex.org/T14271"}, {"name": "Gender, Education, and Development Issues", "value": 8668, "id": "https://openalex.org/T13040"}, {"name": "Educational Practices and Sociocultural Research", "value": 8413, "id": "https://openalex.org/T14425"}, {"name": "Community and Sustainable Development", "value": 8360, "id": "https://openalex.org/T13502"}, {"name": "Critical and Liberation Pedagogy", "value": 7985, "id": "https://openalex.org/T13737"}, {"name": "Psycholinguistics and Behavioral Studies", "value": 6990, "id": "https://openalex.org/T13701"}, {"name": "University Challenges and Reforms", "value": 6872, "id": "https://openalex.org/T13368"}, {"name": "Education and Art Integration", "value": 6290, "id": "https://openalex.org/T14205"}, {"name": "Education, Literature, Philosophy Research", "value": 6264, "id": "https://openalex.org/T14471"}, {"name": "Diverse Academic Research Areas", "value": 6102, "id": "https://openalex.org/T14283"}, {"name": "Impact of Education Environments", "value": 5322, "id": "https://openalex.org/T14122"}, {"name": "Critical Theory and Political Philosophy", "value": 5156, "id": "https://openalex.org/T13351"}, {"name": "Education Practices and Evaluation", "value": 5129, "id": "https://openalex.org/T14482"}, {"name": "Psychodrama and Leishmaniasis Studies", "value": 4924, "id": "https://openalex.org/T14075"}, {"name": "Health and Education Studies", "value": 4215, "id": "https://openalex.org/T14161"}, {"name": "Various Academic Research Studies", "value": 3994, "id": "https://openalex.org/T13056"}, {"name": "Qualitative research in health", "value": 3788, "id": "https://openalex.org/T13662"}, {"name": "Educational Research and Analysis", "value": 3252, "id": "https://openalex.org/T13349"}, {"name": "Teacher Education and Assessments", "value": 3036, "id": "https://openalex.org/T13853"}, {"name": "Cultural and Educational Studies", "value": 2980, "id": "https://openalex.org/T13627"}, {"name": "Social Development and Education Research", "value": 2829, "id": "https://openalex.org/T14153"}, {"name": "Citizenship Education and Democracy", "value": 2061, "id": "https://openalex.org/T13774"}]}, {"name": "General Social Sciences", "children": [{"name": "Social Sciences and Policies", "value": 330796, "id": "https://openalex.org/T13624"}, {"name": "Philosophical Thought and Analysis", "value": 51444, "id": "https://openalex.org/T14198"}, {"name": "Multidisciplinary Research Papers Compilation", "value": 41540, "id": "https://openalex.org/T12913"}, {"name": "Computational and Text Analysis Methods", "value": 36172, "id": "https://openalex.org/T13910"}, {"name": "Social Issues in Poland", "value": 26688, "id": "https://openalex.org/T12877"}, {"name": "Hume's philosophy and hair distribution", "value": 26653, "id": "https://openalex.org/T14371"}, {"name": "Cultural, Linguistic, Economic Studies", "value": 18779, "id": "https://openalex.org/T14375"}, {"name": "Philosophy and Phenomenology Studies", "value": 18454, "id": "https://openalex.org/T13671"}, {"name": "Religion and Sociopolitical Dynamics in Nigeria", "value": 17762, "id": "https://openalex.org/T14228"}, {"name": "HIV, TB, and STIs Epidemiology", "value": 7144, "id": "https://openalex.org/T13586"}, {"name": "Social Science and Policy Research", "value": 6009, "id": "https://openalex.org/T13765"}, {"name": "Information Society and Technology Trends", "value": 5963, "id": "https://openalex.org/T13066"}, {"name": "Appalachian Studies and Mathematics", "value": 5917, "id": "https://openalex.org/T14107"}, {"name": "Contemporary Social and Economic Issues", "value": 4438, "id": "https://openalex.org/T13041"}, {"name": "Islamic Social Reporting", "value": 2957, "id": "https://openalex.org/T14340"}, {"name": "Economic, Educational, Environmental and Organizational Development", "value": 1890, "id": "https://openalex.org/T14087"}]}, {"name": "Law", "children": [{"name": "Law and Political Science", "value": 303949, "id": "https://openalex.org/T12954"}, {"name": "Brazilian Legal Issues", "value": 220411, "id": "https://openalex.org/T12148"}, {"name": "Legal Studies and Policies", "value": 144635, "id": "https://openalex.org/T11876"}, {"name": "Legal Education and Practice Innovations", "value": 139762, "id": "https://openalex.org/T12755"}, {"name": "Legal principles and applications", "value": 121987, "id": "https://openalex.org/T12982"}, {"name": "Criminal Justice and Penology", "value": 113793, "id": "https://openalex.org/T12736"}, {"name": "Comparative and International Law Studies", "value": 103090, "id": "https://openalex.org/T14012"}, {"name": "Legal processes and jurisprudence", "value": 99980, "id": "https://openalex.org/T14115"}, {"name": "Law in Society and Culture", "value": 95057, "id": "https://openalex.org/T13877"}, {"name": "Legal Issues in South Africa", "value": 90734, "id": "https://openalex.org/T12775"}, {"name": "European and International Contract Law", "value": 89957, "id": "https://openalex.org/T12374"}, {"name": "Digitalization, Law, and Regulation", "value": 79057, "id": "https://openalex.org/T13364"}, {"name": "Criminal Law and Evidence", "value": 77984, "id": "https://openalex.org/T14493"}, {"name": "Judicial and Constitutional Studies", "value": 70478, "id": "https://openalex.org/T10802"}, {"name": "Legal and Policy Issues", "value": 61117, "id": "https://openalex.org/T14258"}, {"name": "Legal and Social Justice Studies", "value": 58374, "id": "https://openalex.org/T13101"}, {"name": "EU Law and Policy Analysis", "value": 53439, "id": "https://openalex.org/T14448"}, {"name": "Intellectual Property Law", "value": 48861, "id": "https://openalex.org/T13842"}, {"name": "Social Issues and Policies in Latin America", "value": 44226, "id": "https://openalex.org/T14497"}, {"name": "Environmental law and policy", "value": 44147, "id": "https://openalex.org/T12895"}, {"name": "Family and Matrimonial Law", "value": 39690, "id": "https://openalex.org/T13096"}, {"name": "European Law and Migration", "value": 35234, "id": "https://openalex.org/T14255"}, {"name": "Polish Legal and Social Issues", "value": 33003, "id": "https://openalex.org/T13139"}, {"name": "Discrimination and Equality Law", "value": 32985, "id": "https://openalex.org/T13170"}, {"name": "Legal Issues in Education", "value": 31736, "id": "https://openalex.org/T14017"}, {"name": "Property Rights and Legal Doctrine", "value": 31678, "id": "https://openalex.org/T13357"}, {"name": "Freedom of Expression and Defamation", "value": 30556, "id": "https://openalex.org/T14432"}, {"name": "Legal and Policy Analysis in Indonesia", "value": 29330, "id": "https://openalex.org/T14397"}, {"name": "Jury Decision Making Processes", "value": 26377, "id": "https://openalex.org/T13583"}, {"name": "Data Privacy and Cybersecurity", "value": 25651, "id": "https://openalex.org/T14234"}, {"name": "Religious Freedom and Discrimination", "value": 20169, "id": "https://openalex.org/T13336"}, {"name": "Animal Law and Welfare", "value": 19643, "id": "https://openalex.org/T14206"}, {"name": "Geology and Environmental Impact Studies", "value": 16088, "id": "https://openalex.org/T13021"}, {"name": "Legal Language and Interpretation", "value": 9357, "id": "https://openalex.org/T14013"}, {"name": "Legal Rights and Human Rights", "value": 8599, "id": "https://openalex.org/T14259"}, {"name": "Multidisciplinary Warburg-centric Studies", "value": 7490, "id": "https://openalex.org/T14196"}, {"name": "Indigenous Peoples' Rights and Law", "value": 7425, "id": "https://openalex.org/T13879"}, {"name": "Water Resources and Governance", "value": 6724, "id": "https://openalex.org/T13528"}, {"name": "Evolving Legal Systems and Governance", "value": 5820, "id": "https://openalex.org/T14268"}, {"name": "Government, Law, and Information Management", "value": 4123, "id": "https://openalex.org/T13573"}]}, {"name": "Urban Studies", "children": [{"name": "Social Sciences and Governance", "value": 288557, "id": "https://openalex.org/T13033"}, {"name": "Cultural Industries and Urban Development", "value": 177212, "id": "https://openalex.org/T11410"}, {"name": "Urbanization and City Planning", "value": 139108, "id": "https://openalex.org/T12502"}, {"name": "Urban Development and Societal Issues", "value": 111095, "id": "https://openalex.org/T11858"}, {"name": "Latin American Urban Studies", "value": 108274, "id": "https://openalex.org/T12273"}, {"name": "Urban and Rural Development Challenges", "value": 81381, "id": "https://openalex.org/T12147"}, {"name": "Urban and sociocultural dynamics", "value": 47361, "id": "https://openalex.org/T13513"}, {"name": "Urban Development and Cultural Heritage", "value": 41194, "id": "https://openalex.org/T12995"}, {"name": "Public Spaces through Art", "value": 38628, "id": "https://openalex.org/T13699"}, {"name": "Urban Planning and Governance", "value": 30963, "id": "https://openalex.org/T10239"}, {"name": "Turkish Urban and Social Issues", "value": 22965, "id": "https://openalex.org/T13343"}, {"name": "International Relations and Autism", "value": 17431, "id": "https://openalex.org/T14016"}, {"name": "Healthcare Facilities Design and Sustainability", "value": 16430, "id": "https://openalex.org/T14152"}, {"name": "Sustainable Urban and Rural Development", "value": 15556, "id": "https://openalex.org/T14520"}, {"name": "Advanced Computing and Algorithms", "value": 14967, "id": "https://openalex.org/T13731"}, {"name": "Global Urban Networks and Dynamics", "value": 13023, "id": "https://openalex.org/T12483"}, {"name": "Night-time city culture", "value": 12012, "id": "https://openalex.org/T13850"}, {"name": "Collaborative and Sustainable Housing Initiatives", "value": 10372, "id": "https://openalex.org/T13819"}, {"name": "Immigration Law and Human Rights", "value": 1301, "id": "https://openalex.org/T13694"}]}, {"name": "Cultural Studies", "children": [{"name": "Japanese History and Culture", "value": 227959, "id": "https://openalex.org/T11198"}, {"name": "Diverse Cultural and Historical Studies", "value": 148576, "id": "https://openalex.org/T14379"}, {"name": "Asian Culture and Media Studies", "value": 119447, "id": "https://openalex.org/T13303"}, {"name": "Urbanism, Landscape, and Tourism Studies", "value": 115247, "id": "https://openalex.org/T12670"}, {"name": "Latin American and Latino Studies", "value": 102874, "id": "https://openalex.org/T12242"}, {"name": "Discourse Analysis and Cultural Communication", "value": 100414, "id": "https://openalex.org/T14159"}, {"name": "Asian American and Pacific Histories", "value": 99119, "id": "https://openalex.org/T12323"}, {"name": "Latin American Literature Studies", "value": 79834, "id": "https://openalex.org/T13134"}, {"name": "Arts, Culture, and Music Studies", "value": 76526, "id": "https://openalex.org/T13327"}, {"name": "Balkans: History, Politics, Society", "value": 75867, "id": "https://openalex.org/T12437"}, {"name": "Archaeology and Cultural Heritage", "value": 71631, "id": "https://openalex.org/T13595"}, {"name": "Caribbean history, culture, and politics", "value": 70507, "id": "https://openalex.org/T13222"}, {"name": "Cultural and Artistic Studies", "value": 67405, "id": "https://openalex.org/T14105"}, {"name": "Psychoanalysis and Social Critique", "value": 62975, "id": "https://openalex.org/T12864"}, {"name": "Basque language and culture studies", "value": 60519, "id": "https://openalex.org/T14489"}, {"name": "Contemporary art, education, critique", "value": 58363, "id": "https://openalex.org/T13421"}, {"name": "Gothic Literature and Media Analysis", "value": 54475, "id": "https://openalex.org/T13229"}, {"name": "Immigration and Intercultural Education", "value": 46665, "id": "https://openalex.org/T12711"}, {"name": "Diverse Topics in Contemporary Research", "value": 44257, "id": "https://openalex.org/T14233"}, {"name": "Language and cultural evolution", "value": 39832, "id": "https://openalex.org/T12090"}, {"name": "Argentine historical studies", "value": 31491, "id": "https://openalex.org/T12036"}, {"name": "Cultural and Religious Practices in Indonesia", "value": 30288, "id": "https://openalex.org/T14022"}, {"name": "History and Cultural Heritage", "value": 28270, "id": "https://openalex.org/T14004"}, {"name": "Indigenous Cultures and Socio-Education", "value": 25914, "id": "https://openalex.org/T13448"}, {"name": "Education, Sociology, Communication Studies", "value": 25346, "id": "https://openalex.org/T14125"}, {"name": "Posthumanist Ethics and Activism", "value": 22207, "id": "https://openalex.org/T10738"}, {"name": "Migration, Education, Indigenous Social Dynamics", "value": 17237, "id": "https://openalex.org/T12861"}, {"name": "Tattoo and Body Piercing Complications", "value": 16753, "id": "https://openalex.org/T12901"}, {"name": "Indigenous Studies in Latin America", "value": 14604, "id": "https://openalex.org/T13266"}, {"name": "Diverse Academic Research Studies", "value": 13773, "id": "https://openalex.org/T13786"}, {"name": "Vladimir Nabokov Literary Studies", "value": 12191, "id": "https://openalex.org/T13461"}, {"name": "Diverse multidisciplinary academic research", "value": 11702, "id": "https://openalex.org/T13753"}, {"name": "Afro-Latin American Studies", "value": 11256, "id": "https://openalex.org/T13868"}, {"name": "Social Issues and Sustainability", "value": 8676, "id": "https://openalex.org/T13907"}, {"name": "Multicultural Education and Local Wisdom", "value": 8453, "id": "https://openalex.org/T14251"}, {"name": "Military history and social perspectives", "value": 5033, "id": "https://openalex.org/T14190"}, {"name": "Cultural, Psychoanalytic, and Sociopolitical Reflections", "value": 1516, "id": "https://openalex.org/T14273"}, {"name": "Cultural and Social Studies", "value": 1401, "id": "https://openalex.org/T14298"}]}, {"name": "Demography", "children": [{"name": "SMEs Development and Digital Marketing", "value": 225983, "id": "https://openalex.org/T13053"}, {"name": "Historical Studies in Latin America", "value": 118352, "id": "https://openalex.org/T13460"}, {"name": "Island Studies and Pacific Affairs", "value": 98010, "id": "https://openalex.org/T12629"}, {"name": "Regional Socio-Economic Development Trends", "value": 96097, "id": "https://openalex.org/T13618"}, {"name": "Migration, Aging, and Tourism Studies", "value": 93853, "id": "https://openalex.org/T12783"}, {"name": "Retirement, Disability, and Employment", "value": 92787, "id": "https://openalex.org/T11631"}, {"name": "Youth, Drugs, and Violence", "value": 80310, "id": "https://openalex.org/T12842"}, {"name": "Insurance, Mortality, Demography, Risk Management", "value": 65106, "id": "https://openalex.org/T12011"}, {"name": "History and Politics in Latin America", "value": 59910, "id": "https://openalex.org/T12563"}, {"name": "Family Dynamics and Relationships", "value": 59224, "id": "https://openalex.org/T10585"}, {"name": "Knowledge Societies in the 21st Century", "value": 44568, "id": "https://openalex.org/T14070"}, {"name": "Education and Work Dynamics", "value": 43383, "id": "https://openalex.org/T14458"}, {"name": "Jewish Identity and Society", "value": 39264, "id": "https://openalex.org/T13784"}, {"name": "Technology Use by Older Adults", "value": 37393, "id": "https://openalex.org/T11977"}, {"name": "Tourism, Volunteerism, and Development", "value": 34382, "id": "https://openalex.org/T13839"}, {"name": "Diaspora, migration, transnational identity", "value": 33994, "id": "https://openalex.org/T11648"}, {"name": "Global Educational Reforms and Inequalities", "value": 32196, "id": "https://openalex.org/T13566"}, {"name": "Elder Abuse and Neglect", "value": 27837, "id": "https://openalex.org/T12462"}, {"name": "Migration, Policy, and Dickens Studies", "value": 26519, "id": "https://openalex.org/T14292"}, {"name": "Agricultural and Environmental Management", "value": 24852, "id": "https://openalex.org/T14119"}, {"name": "Evasion and Academic Success Factors", "value": 23891, "id": "https://openalex.org/T14241"}, {"name": "Science, Technology, and Education in Latin America", "value": 23225, "id": "https://openalex.org/T13492"}, {"name": "Sociopolitical Dynamics in Nepal", "value": 21736, "id": "https://openalex.org/T13956"}, {"name": "Culture, Economy, and Development Studies", "value": 21542, "id": "https://openalex.org/T12312"}, {"name": "Workplace Spirituality and Leadership", "value": 20150, "id": "https://openalex.org/T12393"}, {"name": "Migration, Health, Geopolitics, Historical Geography", "value": 18307, "id": "https://openalex.org/T14466"}, {"name": "Cyberloafing and Workplace Behavior", "value": 10619, "id": "https://openalex.org/T13927"}]}, {"name": "Public Administration", "children": [{"name": "Labor Movements and Unions", "value": 202185, "id": "https://openalex.org/T11421"}, {"name": "Social Work Education and Practice", "value": 75532, "id": "https://openalex.org/T11028"}, {"name": "Public Policy and Administration Research", "value": 63163, "id": "https://openalex.org/T10213"}]}, {"name": "Library and Information Sciences", "children": [{"name": "Library Science and Administration", "value": 183488, "id": "https://openalex.org/T12289"}, {"name": "Library Science and Information Literacy", "value": 98825, "id": "https://openalex.org/T10712"}]}, {"name": "Development", "children": [{"name": "International Development and Aid", "value": 180509, "id": "https://openalex.org/T11168"}, {"name": "Regional Development and Innovation", "value": 117548, "id": "https://openalex.org/T12636"}, {"name": "Economic and Technological Developments in Russia", "value": 85271, "id": "https://openalex.org/T12667"}, {"name": "Software Engineering and Design Patterns", "value": 22693, "id": "https://openalex.org/T12490"}, {"name": "Medical and Agricultural Research Studies", "value": 6174, "id": "https://openalex.org/T14044"}, {"name": "Development, Ethics, and Society", "value": 6129, "id": "https://openalex.org/T14418"}, {"name": "Engineering Education and Global Impact", "value": 3003, "id": "https://openalex.org/T14218"}, {"name": "21st Century Education and Governance", "value": 1021, "id": "https://openalex.org/T14027"}]}, {"name": "Communication", "children": [{"name": "Media Studies and Communication", "value": 162733, "id": "https://openalex.org/T10133"}, {"name": "Social Media and Politics", "value": 126658, "id": "https://openalex.org/T10557"}, {"name": "Public Relations and Crisis Communication", "value": 73363, "id": "https://openalex.org/T11121"}, {"name": "Knowledge Management and Sharing", "value": 69597, "id": "https://openalex.org/T12028"}, {"name": "Advertising and Communication Studies", "value": 64828, "id": "https://openalex.org/T13496"}, {"name": "International Student and Expatriate Challenges", "value": 60532, "id": "https://openalex.org/T10907"}, {"name": "Journalism and Media Studies", "value": 51656, "id": "https://openalex.org/T13625"}, {"name": "Radio, Podcasts, and Digital Media", "value": 42513, "id": "https://openalex.org/T13321"}, {"name": "Language, Communication, and Linguistic Studies", "value": 39638, "id": "https://openalex.org/T13795"}, {"name": "Communication and COVID-19 Impact", "value": 38329, "id": "https://openalex.org/T13979"}, {"name": "Wikis in Education and Collaboration", "value": 37865, "id": "https://openalex.org/T12478"}, {"name": "Media, Communication, and Education", "value": 21979, "id": "https://openalex.org/T13317"}, {"name": "Swearing, Euphemism, Multilingualism", "value": 19411, "id": "https://openalex.org/T13959"}, {"name": "Media and Communication Studies", "value": 18385, "id": "https://openalex.org/T13799"}, {"name": "Communication Studies and Media", "value": 11977, "id": "https://openalex.org/T13716"}, {"name": "Cultural Studies and Postmodernism", "value": 2815, "id": "https://openalex.org/T12942"}]}, {"name": "Geography, Planning and Development", "children": [{"name": "Hungarian Social, Economic and Educational Studies", "value": 158493, "id": "https://openalex.org/T13749"}, {"name": "Geographic Information Systems Studies", "value": 111348, "id": "https://openalex.org/T10757"}, {"name": "Pacific and Southeast Asian Studies", "value": 107464, "id": "https://openalex.org/T12473"}, {"name": "Historical Geography and Cartography", "value": 101253, "id": "https://openalex.org/T13854"}, {"name": "Religious Tourism and Spaces", "value": 90638, "id": "https://openalex.org/T12798"}, {"name": "Galician and Iberian cultural studies", "value": 71002, "id": "https://openalex.org/T14052"}, {"name": "Geographies of human-animal interactions", "value": 55824, "id": "https://openalex.org/T11420"}, {"name": "Historical Geography and Geographical Thought", "value": 49619, "id": "https://openalex.org/T12853"}, {"name": "Local Governance and Development", "value": 45766, "id": "https://openalex.org/T13285"}, {"name": "Geography Education and Pedagogy", "value": 36251, "id": "https://openalex.org/T12343"}, {"name": "Nationalism and Cultural Identity", "value": 24725, "id": "https://openalex.org/T13865"}, {"name": "Spatial and Cultural Studies", "value": 12608, "id": "https://openalex.org/T13512"}, {"name": "Local Governance and Planning", "value": 12590, "id": "https://openalex.org/T13247"}, {"name": "Geography and Environmental Studies in Latin America", "value": 7821, "id": "https://openalex.org/T13977"}, {"name": "Global socioeconomic and cultural dynamics", "value": 2324, "id": "https://openalex.org/T13755"}]}, {"name": "Transportation", "children": [{"name": "Legal and Regulatory Analysis", "value": 142755, "id": "https://openalex.org/T13154"}, {"name": "Transportation Planning and Optimization", "value": 112649, "id": "https://openalex.org/T10698"}, {"name": "Urban Transport and Accessibility", "value": 112043, "id": "https://openalex.org/T10298"}, {"name": "Earthquake and Disaster Impact Studies", "value": 99638, "id": "https://openalex.org/T13800"}, {"name": "Cruise Tourism Development and Management", "value": 55539, "id": "https://openalex.org/T13562"}, {"name": "Human Mobility and Location-Based Analysis", "value": 42567, "id": "https://openalex.org/T11980"}, {"name": "Maritime Security and History", "value": 37160, "id": "https://openalex.org/T12985"}, {"name": "transportation and logistics systems", "value": 32048, "id": "https://openalex.org/T12725"}, {"name": "Energy and Environmental Systems", "value": 28934, "id": "https://openalex.org/T14250"}]}, {"name": "Linguistics and Language", "children": [{"name": "Multilingual Education and Policy", "value": 117505, "id": "https://openalex.org/T10265"}, {"name": "French Language Learning Methods", "value": 98091, "id": "https://openalex.org/T13152"}, {"name": "Language and Culture", "value": 96552, "id": "https://openalex.org/T12658"}, {"name": "Linguistic Variation and Morphology", "value": 86184, "id": "https://openalex.org/T11640"}, {"name": "Linguistic and Sociocultural Studies", "value": 45520, "id": "https://openalex.org/T13727"}, {"name": "Cultural and political discourse analysis", "value": 35826, "id": "https://openalex.org/T13814"}]}, {"name": "Human Factors and Ergonomics", "children": [{"name": "Employee Performance and Management", "value": 110223, "id": "https://openalex.org/T14309"}, {"name": "Digital Accessibility for Disabilities", "value": 28380, "id": "https://openalex.org/T12481"}, {"name": "Innovative Education and Learning Practices", "value": 22390, "id": "https://openalex.org/T11466"}]}, {"name": "Health", "children": [{"name": "Vaccine Coverage and Hesitancy", "value": 110135, "id": "https://openalex.org/T10833"}, {"name": "Health disparities and outcomes", "value": 103346, "id": "https://openalex.org/T10235"}, {"name": "Intimate Partner and Family Violence", "value": 93861, "id": "https://openalex.org/T10380"}, {"name": "Religion, Spirituality, and Psychology", "value": 88161, "id": "https://openalex.org/T10509"}, {"name": "Indigenous Health, Education, and Rights", "value": 64479, "id": "https://openalex.org/T10348"}, {"name": "Social Media in Health Education", "value": 47501, "id": "https://openalex.org/T12027"}, {"name": "Migration, Racism, and Human Rights", "value": 46731, "id": "https://openalex.org/T14226"}, {"name": "Gun Ownership and Violence Research", "value": 32309, "id": "https://openalex.org/T12265"}, {"name": "Public Health and Social Inequalities", "value": 29415, "id": "https://openalex.org/T13633"}, {"name": "Social and Behavioral Studies", "value": 29343, "id": "https://openalex.org/T14265"}, {"name": "Health, Education, and Aging", "value": 13471, "id": "https://openalex.org/T13974"}, {"name": "Philosophy and Education Pedagogy", "value": 7468, "id": "https://openalex.org/T13635"}, {"name": "Occupational Health and Global Justice", "value": 2382, "id": "https://openalex.org/T14168"}, {"name": "Venezuelan Migration and Society", "value": 2246, "id": "https://openalex.org/T13524"}]}, {"name": "Gender Studies", "children": [{"name": "Gender, Labor, and Family Dynamics", "value": 109342, "id": "https://openalex.org/T11544"}, {"name": "Sports, Gender, and Society", "value": 101130, "id": "https://openalex.org/T10942"}, {"name": "Demographic Trends and Gender Preferences", "value": 82893, "id": "https://openalex.org/T12728"}, {"name": "Gender Diversity and Inequality", "value": 82174, "id": "https://openalex.org/T11047"}, {"name": "Gender Politics and Representation", "value": 74857, "id": "https://openalex.org/T11432"}, {"name": "Diversity and Career in Medicine", "value": 70175, "id": "https://openalex.org/T10843"}, {"name": "Gender Roles and Identity Studies", "value": 66911, "id": "https://openalex.org/T11888"}, {"name": "Gender, Feminism, and Media", "value": 63024, "id": "https://openalex.org/T11540"}, {"name": "Media, Gender, and Advertising", "value": 59316, "id": "https://openalex.org/T12908"}, {"name": "Gender and Feminist Studies", "value": 55809, "id": "https://openalex.org/T12275"}, {"name": "Gender, Sexuality, and Education", "value": 50664, "id": "https://openalex.org/T11906"}, {"name": "Gender, Security, and Conflict", "value": 43426, "id": "https://openalex.org/T11863"}, {"name": "Gender Studies in Language", "value": 42651, "id": "https://openalex.org/T13173"}, {"name": "Sexual Assault and Victimization Studies", "value": 38550, "id": "https://openalex.org/T11548"}, {"name": "Gender and Technology in Education", "value": 32558, "id": "https://openalex.org/T12515"}, {"name": "Labour Market and Migration", "value": 19818, "id": "https://openalex.org/T13989"}, {"name": "Gender Studies and Social Issues", "value": 15715, "id": "https://openalex.org/T13700"}, {"name": "Feminist Theory and Gender Studies", "value": 10460, "id": "https://openalex.org/T14315"}, {"name": "Feminism, Gender, and Social Issues", "value": 9695, "id": "https://openalex.org/T14439"}, {"name": "Corporate Social Responsibility Disclosure", "value": 8167, "id": "https://openalex.org/T14361"}, {"name": "Feminism, Gender, and Sexuality Studies", "value": 7848, "id": "https://openalex.org/T13926"}]}, {"name": "Safety Research", "children": [{"name": "Employment, Labor, and Gender Studies", "value": 106463, "id": "https://openalex.org/T13911"}, {"name": "Poverty, Education, and Child Welfare", "value": 100541, "id": "https://openalex.org/T11556"}, {"name": "Ethics and Social Impacts of AI", "value": 72743, "id": "https://openalex.org/T10883"}, {"name": "Experimental Behavioral Economics Studies", "value": 59088, "id": "https://openalex.org/T10646"}, {"name": "Child Welfare and Adoption", "value": 58944, "id": "https://openalex.org/T11380"}, {"name": "Agricultural economics and policies", "value": 58473, "id": "https://openalex.org/T11805"}, {"name": "Career Development and Diversity", "value": 46655, "id": "https://openalex.org/T10726"}, {"name": "Disability Education and Employment", "value": 45701, "id": "https://openalex.org/T11514"}, {"name": "Academic integrity and plagiarism", "value": 45549, "id": "https://openalex.org/T11492"}, {"name": "Youth Development and Social Support", "value": 41409, "id": "https://openalex.org/T11998"}, {"name": "Martial Arts: Techniques, Psychology, and Education", "value": 40239, "id": "https://openalex.org/T13730"}, {"name": "Education, Safety, and Science Studies", "value": 35012, "id": "https://openalex.org/T14203"}, {"name": "Educational Tools and Methods", "value": 28708, "id": "https://openalex.org/T14236"}, {"name": "Disability Rights and Representation", "value": 27240, "id": "https://openalex.org/T11003"}, {"name": "Forensic Fingerprint Detection Methods", "value": 18417, "id": "https://openalex.org/T13192"}, {"name": "Social Issues and Policies", "value": 16214, "id": "https://openalex.org/T13906"}, {"name": "Human Resources and Workforce", "value": 11193, "id": "https://openalex.org/T13406"}, {"name": "Catholicism, Bioethics, Media, Education", "value": 9201, "id": "https://openalex.org/T13973"}, {"name": "Social impacts of COVID-19", "value": 8588, "id": "https://openalex.org/T14248"}]}, {"name": "Archeology", "children": [{"name": "Metallurgy and Cultural Artifacts", "value": 83177, "id": "https://openalex.org/T13742"}, {"name": "Archaeology and Rock Art Studies", "value": 69328, "id": "https://openalex.org/T13256"}]}, {"name": "Life-span and Life-course Studies", "children": [{"name": "Sports and Physical Education Studies", "value": 69351, "id": "https://openalex.org/T13488"}, {"name": "Generational Differences and Trends", "value": 10185, "id": "https://openalex.org/T14088"}]}]}, {"name": "Decision Sciences", "children": [{"name": "Information Systems and Management", "children": [{"name": "Scientific Computing and Data Management", "value": 448226, "id": "https://openalex.org/T11986"}, {"name": "Business and Management Studies", "value": 265736, "id": "https://openalex.org/T11530"}, {"name": "Academic Publishing and Open Access", "value": 135837, "id": "https://openalex.org/T13607"}, {"name": "Technology Adoption and User Behaviour", "value": 123688, "id": "https://openalex.org/T10068"}, {"name": "Ethics in Business and Education", "value": 66098, "id": "https://openalex.org/T11058"}, {"name": "Interdisciplinary Research and Collaboration", "value": 43178, "id": "https://openalex.org/T12766"}, {"name": "Research, Science, and Academia", "value": 41286, "id": "https://openalex.org/T14185"}, {"name": "Educational Assessment and Improvement", "value": 33573, "id": "https://openalex.org/T13405"}, {"name": "Big Data Technologies and Applications", "value": 26521, "id": "https://openalex.org/T14280"}, {"name": "Personal Information Management and User Behavior", "value": 26199, "id": "https://openalex.org/T12607"}, {"name": "Education, Management, Technology, Human Resources", "value": 11016, "id": "https://openalex.org/T13611"}, {"name": "Energy Law and Policy", "value": 3858, "id": "https://openalex.org/T13758"}, {"name": "Diverse academic research themes", "value": 3351, "id": "https://openalex.org/T14211"}, {"name": "Professional Masters Programs Analysis", "value": 2397, "id": "https://openalex.org/T14263"}, {"name": "Technology's Impact on Media", "value": 2341, "id": "https://openalex.org/T13696"}]}, {"name": "Statistics, Probability and Uncertainty", "children": [{"name": "Risk and Safety Analysis", "value": 126075, "id": "https://openalex.org/T11357"}, {"name": "Scientific Measurement and Uncertainty Evaluation", "value": 125672, "id": "https://openalex.org/T11890"}, {"name": "scientometrics and bibliometrics research", "value": 91323, "id": "https://openalex.org/T10102"}, {"name": "Meta-analysis and systematic reviews", "value": 83001, "id": "https://openalex.org/T10206"}, {"name": "Probabilistic and Robust Engineering Design", "value": 72492, "id": "https://openalex.org/T10928"}, {"name": "Multidisciplinary Science and Engineering Research", "value": 49620, "id": "https://openalex.org/T14406"}, {"name": "Advanced Statistical Process Monitoring", "value": 45904, "id": "https://openalex.org/T11443"}, {"name": "Reliability and Agreement in Measurement", "value": 18883, "id": "https://openalex.org/T13309"}, {"name": "Innovative Education Methods and Tools", "value": 1557, "id": "https://openalex.org/T13880"}]}, {"name": "Management Science and Operations Research", "children": [{"name": "Complex Systems and Decision Making", "value": 117381, "id": "https://openalex.org/T11810"}, {"name": "Construction Project Management and Performance", "value": 104508, "id": "https://openalex.org/T10395"}, {"name": "Evaluation and Performance Assessment", "value": 104278, "id": "https://openalex.org/T12010"}, {"name": "Multi-Criteria Decision Making", "value": 92095, "id": "https://openalex.org/T10050"}, {"name": "Simulation Techniques and Applications", "value": 85930, "id": "https://openalex.org/T11195"}, {"name": "Stock Market Forecasting Methods", "value": 73997, "id": "https://openalex.org/T11326"}, {"name": "demographic modeling and climate adaptation", "value": 63545, "id": "https://openalex.org/T14509"}, {"name": "Data Quality and Management", "value": 61643, "id": "https://openalex.org/T11719"}, {"name": "Auction Theory and Applications", "value": 56192, "id": "https://openalex.org/T11182"}, {"name": "Psychometric Methodologies and Testing", "value": 53367, "id": "https://openalex.org/T10467"}, {"name": "Efficiency Analysis Using DEA", "value": 49713, "id": "https://openalex.org/T10357"}, {"name": "Forecasting Techniques and Applications", "value": 41321, "id": "https://openalex.org/T11918"}, {"name": "Game Theory and Applications", "value": 40973, "id": "https://openalex.org/T11031"}, {"name": "Fuzzy and Soft Set Theory", "value": 38848, "id": "https://openalex.org/T11671"}, {"name": "Optimal Experimental Design Methods", "value": 34247, "id": "https://openalex.org/T11798"}, {"name": "Probability and Risk Models", "value": 30154, "id": "https://openalex.org/T11720"}, {"name": "Risk and Portfolio Optimization", "value": 29411, "id": "https://openalex.org/T11413"}, {"name": "Operations Management Techniques", "value": 29311, "id": "https://openalex.org/T13886"}, {"name": "Innovation Diffusion and Forecasting", "value": 28517, "id": "https://openalex.org/T12659"}, {"name": "Impact of AI and Big Data on Business and Society", "value": 26891, "id": "https://openalex.org/T14260"}, {"name": "Scheduling and Timetabling Solutions", "value": 23069, "id": "https://openalex.org/T12401"}, {"name": "Grey System Theory Applications", "value": 19231, "id": "https://openalex.org/T12368"}, {"name": "Advanced Bandit Algorithms Research", "value": 18829, "id": "https://openalex.org/T12101"}, {"name": "Innovations and Analysis in Business and Education", "value": 16716, "id": "https://openalex.org/T13480"}, {"name": "Resource-Constrained Project Scheduling", "value": 13311, "id": "https://openalex.org/T12177"}, {"name": "Business Strategies and Management Research", "value": 12141, "id": "https://openalex.org/T12926"}, {"name": "Leadership, Behavior, and Decision-Making Studies", "value": 11660, "id": "https://openalex.org/T14465"}, {"name": "Economic, Social, and Public Health Issues in Russia and Globally", "value": 10743, "id": "https://openalex.org/T13609"}, {"name": "Knowledge Management and Technology", "value": 8863, "id": "https://openalex.org/T14222"}, {"name": "Diverse Interdisciplinary Research Innovations", "value": 7203, "id": "https://openalex.org/T14369"}, {"name": "Diverse scientific research topics", "value": 6759, "id": "https://openalex.org/T14328"}, {"name": "Q Methodology Applications", "value": 5840, "id": "https://openalex.org/T13587"}, {"name": "activated carbon and charcoal", "value": 2902, "id": "https://openalex.org/T14221"}, {"name": "Advanced Scientific and Engineering Studies", "value": 2841, "id": "https://openalex.org/T13612"}]}, {"name": "General Decision Sciences", "children": [{"name": "Decision-Making and Behavioral Economics", "value": 57200, "id": "https://openalex.org/T10315"}, {"name": "Scientific Innovation and Industrial Efficiency", "value": 5120, "id": "https://openalex.org/T14346"}]}]}, {"name": "Psychology", "children": [{"name": "Clinical Psychology", "children": [{"name": "Psychoanalysis and Psychopathology Research", "value": 252786, "id": "https://openalex.org/T11132"}, {"name": "Child and Adolescent Psychosocial and Emotional Development", "value": 190255, "id": "https://openalex.org/T10182"}, {"name": "Health and Well-being Studies", "value": 178203, "id": "https://openalex.org/T14313"}, {"name": "Psychotherapy Techniques and Applications", "value": 146896, "id": "https://openalex.org/T10214"}, {"name": "COVID-19 and Mental Health", "value": 128800, "id": "https://openalex.org/T10168"}, {"name": "Resilience and Mental Health", "value": 125579, "id": "https://openalex.org/T11761"}, {"name": "Eating Disorders and Behaviors", "value": 122254, "id": "https://openalex.org/T10263"}, {"name": "Family and Disability Support Research", "value": 112852, "id": "https://openalex.org/T11632"}, {"name": "Historical and Modern Theater Studies", "value": 109397, "id": "https://openalex.org/T14434"}, {"name": "Grief, Bereavement, and Mental Health", "value": 104383, "id": "https://openalex.org/T11388"}, {"name": "Migration, Health and Trauma", "value": 102107, "id": "https://openalex.org/T10762"}, {"name": "Psychology and Mental Health", "value": 100169, "id": "https://openalex.org/T12844"}, {"name": "Suicide and Self-Harm Studies", "value": 98213, "id": "https://openalex.org/T10376"}, {"name": "Psychiatric care and mental health services", "value": 91931, "id": "https://openalex.org/T13944"}, {"name": "Child Abuse and Trauma", "value": 85501, "id": "https://openalex.org/T10426"}, {"name": "Psychological Treatments and Disorders", "value": 70504, "id": "https://openalex.org/T13118"}, {"name": "Child Therapy and Development", "value": 66036, "id": "https://openalex.org/T13143"}, {"name": "Mindfulness and Compassion Interventions", "value": 65213, "id": "https://openalex.org/T10708"}, {"name": "Counseling, Therapy, and Family Dynamics", "value": 50857, "id": "https://openalex.org/T12245"}, {"name": "Posttraumatic Stress Disorder Research", "value": 50535, "id": "https://openalex.org/T10242"}, {"name": "Psychopathy, Forensic Psychiatry, Sexual Offending", "value": 50086, "id": "https://openalex.org/T10565"}, {"name": "Obsessive-Compulsive Spectrum Disorders", "value": 49618, "id": "https://openalex.org/T11123"}, {"name": "Personality Disorders and Psychopathology", "value": 48676, "id": "https://openalex.org/T11093"}, {"name": "Sexuality, Behavior, and Technology", "value": 48044, "id": "https://openalex.org/T12335"}, {"name": "Historical Psychiatry and Medical Practices", "value": 43754, "id": "https://openalex.org/T12666"}, {"name": "Gambling Behavior and Treatments", "value": 43144, "id": "https://openalex.org/T11705"}, {"name": "Personality Traits and Psychology", "value": 41838, "id": "https://openalex.org/T11040"}, {"name": "Healthcare Decision-Making and Restraints", "value": 41178, "id": "https://openalex.org/T11678"}, {"name": "Body Image and Dysmorphia Studies", "value": 34676, "id": "https://openalex.org/T12663"}, {"name": "Perfectionism, Procrastination, Anxiety Studies", "value": 32557, "id": "https://openalex.org/T12258"}, {"name": "Psychedelics and Drug Studies", "value": 31582, "id": "https://openalex.org/T12553"}, {"name": "Stuttering Research and Treatment", "value": 21392, "id": "https://openalex.org/T12684"}, {"name": "Family Caregiving in Mental Illness", "value": 20989, "id": "https://openalex.org/T12980"}, {"name": "Ego Development and Educational Practices", "value": 20323, "id": "https://openalex.org/T13419"}, {"name": "Psychoanalysis, Philosophy, and Politics", "value": 16901, "id": "https://openalex.org/T12889"}, {"name": "Psychological Treatments and Assessments", "value": 13893, "id": "https://openalex.org/T13272"}, {"name": "Transactional Analysis in Psychotherapy", "value": 10418, "id": "https://openalex.org/T13782"}, {"name": "Semiotics and Cultural Interpretation", "value": 9048, "id": "https://openalex.org/T13262"}]}, {"name": "Social Psychology", "children": [{"name": "Psychology, Coaching, and Therapy", "value": 144025, "id": "https://openalex.org/T12753"}, {"name": "Education, Healthcare and Sociology Research", "value": 101252, "id": "https://openalex.org/T14173"}, {"name": "Primate Behavior and Ecology", "value": 94741, "id": "https://openalex.org/T10699"}, {"name": "LGBTQ Health, Identity, and Policy", "value": 92466, "id": "https://openalex.org/T10156"}, {"name": "Emotional Intelligence and Performance", "value": 85887, "id": "https://openalex.org/T11433"}, {"name": "Neuroendocrine regulation and behavior", "value": 83654, "id": "https://openalex.org/T11541"}, {"name": "Counseling Practices and Supervision", "value": 82202, "id": "https://openalex.org/T11295"}, {"name": "Color perception and design", "value": 78869, "id": "https://openalex.org/T12496"}, {"name": "Mental Health Treatment and Access", "value": 77134, "id": "https://openalex.org/T10272"}, {"name": "Psychological Well-being and Life Satisfaction", "value": 76839, "id": "https://openalex.org/T10475"}, {"name": "Attachment and Relationship Dynamics", "value": 76552, "id": "https://openalex.org/T10677"}, {"name": "Human-Automation Interaction and Safety", "value": 73765, "id": "https://openalex.org/T10525"}, {"name": "Animal and Plant Science Education", "value": 69331, "id": "https://openalex.org/T13435"}, {"name": "Families in Therapy and Culture", "value": 68614, "id": "https://openalex.org/T14295"}, {"name": "Stress and Burnout Research", "value": 66685, "id": "https://openalex.org/T12704"}, {"name": "Bullying, Victimization, and Aggression", "value": 61694, "id": "https://openalex.org/T10485"}, {"name": "Ergonomics and Musculoskeletal Disorders", "value": 60218, "id": "https://openalex.org/T12006"}, {"name": "Motivation and Self-Concept in Sports", "value": 55864, "id": "https://openalex.org/T11400"}, {"name": "Cultural Differences and Values", "value": 51509, "id": "https://openalex.org/T11454"}, {"name": "Music Therapy and Health", "value": 49187, "id": "https://openalex.org/T11768"}, {"name": "Communication in Education and Healthcare", "value": 45581, "id": "https://openalex.org/T12593"}, {"name": "Team Dynamics and Performance", "value": 43183, "id": "https://openalex.org/T10970"}, {"name": "Paranormal Experiences and Beliefs", "value": 42589, "id": "https://openalex.org/T12448"}, {"name": "Action Observation and Synchronization", "value": 39813, "id": "https://openalex.org/T11431"}, {"name": "Memory, Trauma, and Commemoration", "value": 38350, "id": "https://openalex.org/T11104"}, {"name": "Health, Education, and Physical Culture", "value": 37542, "id": "https://openalex.org/T14045"}, {"name": "Humor Studies and Applications", "value": 35460, "id": "https://openalex.org/T11795"}, {"name": "Facilities and Workplace Management", "value": 34912, "id": "https://openalex.org/T12256"}, {"name": "Memory, violence, and history", "value": 34652, "id": "https://openalex.org/T12493"}, {"name": "Recreation, Leisure, Wilderness Management", "value": 34223, "id": "https://openalex.org/T11793"}, {"name": "Deception detection and forensic psychology", "value": 32761, "id": "https://openalex.org/T12268"}, {"name": "Mentoring and Academic Development", "value": 31643, "id": "https://openalex.org/T11756"}, {"name": "Social Robot Interaction and HRI", "value": 31545, "id": "https://openalex.org/T10709"}, {"name": "Social Representations and Identity", "value": 27896, "id": "https://openalex.org/T12175"}, {"name": "Jungian Analytical Psychology", "value": 27654, "id": "https://openalex.org/T12882"}, {"name": "Leadership, Courage, and Heroism Studies", "value": 27557, "id": "https://openalex.org/T14513"}, {"name": "Adventure Sports and Sensation Seeking", "value": 27044, "id": "https://openalex.org/T13060"}, {"name": "Competency Development and Evaluation", "value": 26290, "id": "https://openalex.org/T12802"}, {"name": "Emotions and Moral Behavior", "value": 25764, "id": "https://openalex.org/T12313"}, {"name": "Grit, Self-Efficacy, and Motivation", "value": 23312, "id": "https://openalex.org/T13542"}, {"name": "Mental Health via Writing", "value": 22361, "id": "https://openalex.org/T12488"}, {"name": "Outdoor and Experiential Education", "value": 21744, "id": "https://openalex.org/T12997"}, {"name": "Safety Warnings and Signage", "value": 20640, "id": "https://openalex.org/T14056"}, {"name": "Death Anxiety and Social Exclusion", "value": 20604, "id": "https://openalex.org/T12521"}, {"name": "Forgiveness and Related Behaviors", "value": 16846, "id": "https://openalex.org/T12551"}, {"name": "Cognitive and psychological constructs research", "value": 14808, "id": "https://openalex.org/T13777"}, {"name": "Workaholism, burnout, and well-being", "value": 9273, "id": "https://openalex.org/T14220"}, {"name": "Nostalgia and Consumer Behavior", "value": 8836, "id": "https://openalex.org/T13510"}, {"name": "Technostress in Professional Settings", "value": 8735, "id": "https://openalex.org/T13585"}, {"name": "Health, Work, and Social Studies in Poland", "value": 8167, "id": "https://openalex.org/T13829"}, {"name": "Physical education and sports games research", "value": 6724, "id": "https://openalex.org/T14229"}, {"name": "Contemporary Cultural and Social Studies", "value": 1506, "id": "https://openalex.org/T13968"}]}, {"name": "General Psychology", "children": [{"name": "Academic and Historical Perspectives in Psychology", "value": 138501, "id": "https://openalex.org/T12430"}]}, {"name": "Experimental and Cognitive Psychology", "children": [{"name": "Phonetics and Phonology Research", "value": 129676, "id": "https://openalex.org/T10403"}, {"name": "Language, Metaphor, and Cognition", "value": 126964, "id": "https://openalex.org/T11148"}, {"name": "Diversity and Impact of Dance", "value": 95318, "id": "https://openalex.org/T12051"}, {"name": "Creativity in Education and Neuroscience", "value": 89271, "id": "https://openalex.org/T11079"}, {"name": "Sleep and related disorders", "value": 85474, "id": "https://openalex.org/T10316"}, {"name": "Mental Health Research Topics", "value": 81638, "id": "https://openalex.org/T13283"}, {"name": "Philosophy and Theoretical Science", "value": 60509, "id": "https://openalex.org/T10258"}, {"name": "Cognitive Abilities and Testing", "value": 56731, "id": "https://openalex.org/T11577"}, {"name": "Anxiety, Depression, Psychometrics, Treatment, Cognitive Processes", "value": 55400, "id": "https://openalex.org/T10853"}, {"name": "Evolutionary Psychology and Human Behavior", "value": 53859, "id": "https://openalex.org/T11118"}, {"name": "Phenomenology and Existential Philosophy", "value": 47606, "id": "https://openalex.org/T11592"}, {"name": "Emotion and Mood Recognition", "value": 42442, "id": "https://openalex.org/T10667"}, {"name": "Sleep and Work-Related Fatigue", "value": 41387, "id": "https://openalex.org/T11373"}, {"name": "Education, Achievement, and Giftedness", "value": 38440, "id": "https://openalex.org/T10547"}, {"name": "Psychology Research and Bibliometrics", "value": 38112, "id": "https://openalex.org/T13284"}, {"name": "Multisensory perception and integration", "value": 36953, "id": "https://openalex.org/T12032"}, {"name": "Categorization, perception, and language", "value": 30782, "id": "https://openalex.org/T12694"}, {"name": "Visual and Cognitive Learning Processes", "value": 28019, "id": "https://openalex.org/T11516"}, {"name": "Psychological and Temporal Perspectives Research", "value": 15673, "id": "https://openalex.org/T13536"}, {"name": "Sound Studies and Aurality", "value": 14218, "id": "https://openalex.org/T13380"}, {"name": "Psychological and Educational Research Studies", "value": 13148, "id": "https://openalex.org/T14308"}, {"name": "Cognitive Functions and Memory", "value": 12628, "id": "https://openalex.org/T13471"}, {"name": "Memory, Trauma, and Testimony", "value": 9278, "id": "https://openalex.org/T13211"}, {"name": "Diverse Academia and Research Topics", "value": 7521, "id": "https://openalex.org/T12757"}]}, {"name": "Developmental and Educational Psychology", "children": [{"name": "Innovative Teaching and Learning Methods", "value": 106741, "id": "https://openalex.org/T10636"}, {"name": "Reading and Literacy Development", "value": 102737, "id": "https://openalex.org/T10103"}, {"name": "Hearing Impairment and Communication", "value": 96508, "id": "https://openalex.org/T11285"}, {"name": "Educational Games and Gamification", "value": 95404, "id": "https://openalex.org/T10731"}, {"name": "Behavioral and Psychological Studies", "value": 89147, "id": "https://openalex.org/T10826"}, {"name": "Educational and Psychological Assessments", "value": 84067, "id": "https://openalex.org/T13447"}, {"name": "Psychology of Development and Education", "value": 70551, "id": "https://openalex.org/T12993"}, {"name": "Language Development and Disorders", "value": 68544, "id": "https://openalex.org/T10730"}, {"name": "Children's Physical and Motor Development", "value": 67997, "id": "https://openalex.org/T12241"}, {"name": "Second Language Acquisition and Learning", "value": 65579, "id": "https://openalex.org/T11587"}, {"name": "Child and Animal Learning Development", "value": 51875, "id": "https://openalex.org/T10656"}, {"name": "Sport Psychology and Performance", "value": 46869, "id": "https://openalex.org/T10813"}, {"name": "Educational methodologies and cognitive development", "value": 36078, "id": "https://openalex.org/T14301"}, {"name": "Science Education and Perceptions", "value": 31855, "id": "https://openalex.org/T13600"}, {"name": "Identity, Memory, and Therapy", "value": 29004, "id": "https://openalex.org/T11983"}, {"name": "Student Stress and Coping", "value": 28792, "id": "https://openalex.org/T14085"}, {"name": "Language Acquisition and Education", "value": 26908, "id": "https://openalex.org/T14485"}, {"name": "Learning Styles and Cognitive Differences", "value": 23478, "id": "https://openalex.org/T11820"}, {"name": "Educational Strategies and Epistemologies", "value": 21065, "id": "https://openalex.org/T12887"}, {"name": "Flow Experience in Various Fields", "value": 13538, "id": "https://openalex.org/T13353"}]}, {"name": "Neuropsychology and Physiological Psychology", "children": [{"name": "Developmental and Educational Neuropsychology", "value": 63114, "id": "https://openalex.org/T14104"}, {"name": "Aging and Gerontology Research", "value": 50533, "id": "https://openalex.org/T11265"}]}, {"name": "Applied Psychology", "children": [{"name": "Human Resource Development and Performance Evaluation", "value": 59119, "id": "https://openalex.org/T11994"}, {"name": "Behavioral Health and Interventions", "value": 58855, "id": "https://openalex.org/T11542"}, {"name": "Digital Mental Health Interventions", "value": 54979, "id": "https://openalex.org/T11519"}, {"name": "Psychological Testing and Assessment", "value": 40183, "id": "https://openalex.org/T12848"}, {"name": "Optimism, Hope, and Well-being", "value": 29604, "id": "https://openalex.org/T12485"}, {"name": "Coaching Methods and Impact", "value": 21995, "id": "https://openalex.org/T13821"}, {"name": "Human Behavior and Motivation", "value": 5497, "id": "https://openalex.org/T12787"}]}]}, {"name": "Business, Management and Accounting", "children": [{"name": "Strategy and Management", "children": [{"name": "Corporate Governance and Law", "value": 219351, "id": "https://openalex.org/T14102"}, {"name": "Corporate Governance and Management", "value": 204553, "id": "https://openalex.org/T10910"}, {"name": "Management and Optimization Techniques", "value": 173948, "id": "https://openalex.org/T13706"}, {"name": "Diverse Legal and Medical Studies", "value": 115463, "id": "https://openalex.org/T14362"}, {"name": "Global Trade and Competitiveness", "value": 111023, "id": "https://openalex.org/T12428"}, {"name": "International Arbitration and Investment Law", "value": 110964, "id": "https://openalex.org/T12040"}, {"name": "International Business and FDI", "value": 103278, "id": "https://openalex.org/T10415"}, {"name": "Innovation and Knowledge Management", "value": 98362, "id": "https://openalex.org/T10003"}, {"name": "Business Strategy and Innovation", "value": 96296, "id": "https://openalex.org/T13402"}, {"name": "Financial Reporting and Valuation Research", "value": 95274, "id": "https://openalex.org/T12675"}, {"name": "Transport and Economic Policies", "value": 90585, "id": "https://openalex.org/T13439"}, {"name": "Sustainable Supply Chain Management", "value": 74819, "id": "https://openalex.org/T10539"}, {"name": "Corporate Social Responsibility Reporting", "value": 71824, "id": "https://openalex.org/T10115"}, {"name": "Cooperative Studies and Economics", "value": 66161, "id": "https://openalex.org/T12121"}, {"name": "Global trade, sustainability, and social impact", "value": 60288, "id": "https://openalex.org/T11552"}, {"name": "Management and Organizational Practices", "value": 59987, "id": "https://openalex.org/T12815"}, {"name": "Digital Platforms and Economics", "value": 59934, "id": "https://openalex.org/T11437"}, {"name": "State Capitalism and Financial Governance", "value": 59341, "id": "https://openalex.org/T13901"}, {"name": "Supply Chain Resilience and Risk Management", "value": 49851, "id": "https://openalex.org/T11864"}, {"name": "Dispute Resolution and Class Actions", "value": 45879, "id": "https://openalex.org/T13191"}, {"name": "Public-Private Partnership Projects", "value": 44421, "id": "https://openalex.org/T11939"}, {"name": "Intellectual Capital and Performance Analysis", "value": 40290, "id": "https://openalex.org/T11849"}, {"name": "Corporate Governance and Financial Management", "value": 37478, "id": "https://openalex.org/T13957"}, {"name": "Public Procurement and Policy", "value": 37433, "id": "https://openalex.org/T12779"}, {"name": "Quality and Management Systems", "value": 36814, "id": "https://openalex.org/T13164"}, {"name": "Business Strategies and Innovation", "value": 36495, "id": "https://openalex.org/T13151"}, {"name": "Competitive and Knowledge Intelligence", "value": 34853, "id": "https://openalex.org/T13204"}, {"name": "Organizational Leadership and Management Strategies", "value": 33512, "id": "https://openalex.org/T14356"}, {"name": "Regulation and Compliance Studies", "value": 31460, "id": "https://openalex.org/T12185"}, {"name": "Leadership and Management in Organizations", "value": 31325, "id": "https://openalex.org/T12751"}, {"name": "Political Influence and Corporate Strategies", "value": 29852, "id": "https://openalex.org/T12225"}, {"name": "Regional Economic Development and Innovation", "value": 23811, "id": "https://openalex.org/T13384"}, {"name": "Corporate Identity and Reputation", "value": 22266, "id": "https://openalex.org/T12738"}, {"name": "Franchising Strategies and Performance", "value": 19775, "id": "https://openalex.org/T12933"}, {"name": "Digitalization and Economic Development in Agriculture", "value": 17935, "id": "https://openalex.org/T12662"}, {"name": "Management Systems and Quality Improvement", "value": 15987, "id": "https://openalex.org/T12905"}, {"name": "Legal Systems and Institutions", "value": 14509, "id": "https://openalex.org/T13810"}, {"name": "Strategic Planning and Analysis", "value": 14110, "id": "https://openalex.org/T13137"}, {"name": "Value Engineering and Management", "value": 9177, "id": "https://openalex.org/T14058"}, {"name": "Attention Economy in Education and Business", "value": 8032, "id": "https://openalex.org/T13703"}, {"name": "Digital Economy and Transformation", "value": 7499, "id": "https://openalex.org/T12958"}, {"name": "Governance, Compliance, and Sustainability", "value": 2202, "id": "https://openalex.org/T13616"}]}, {"name": "Accounting", "children": [{"name": "Islamic Finance and Banking Studies", "value": 195276, "id": "https://openalex.org/T11365"}, {"name": "Corporate Finance and Governance", "value": 178965, "id": "https://openalex.org/T10019"}, {"name": "Law, logistics, and international trade", "value": 150292, "id": "https://openalex.org/T14180"}, {"name": "Taxation and Legal Issues", "value": 145341, "id": "https://openalex.org/T14030"}, {"name": "Financial Analysis and Corporate Governance", "value": 133562, "id": "https://openalex.org/T12123"}, {"name": "Business, Education, Mathematics Research", "value": 122352, "id": "https://openalex.org/T14239"}, {"name": "Corporate Taxation and Avoidance", "value": 117473, "id": "https://openalex.org/T11508"}, {"name": "Auditing, Earnings Management, Governance", "value": 108360, "id": "https://openalex.org/T10081"}, {"name": "Financial Literacy, Pension, Retirement Analysis", "value": 91762, "id": "https://openalex.org/T10517"}, {"name": "Private Equity and Venture Capital", "value": 71208, "id": "https://openalex.org/T11903"}, {"name": "Corporate Insolvency and Governance", "value": 59623, "id": "https://openalex.org/T12509"}, {"name": "Accounting and Financial Management", "value": 57042, "id": "https://openalex.org/T13509"}, {"name": "Risk Management in Financial Firms", "value": 44203, "id": "https://openalex.org/T12276"}, {"name": "Working Capital and Financial Performance", "value": 42150, "id": "https://openalex.org/T12544"}, {"name": "Business Law and Ethics", "value": 40146, "id": "https://openalex.org/T13972"}, {"name": "Financial Distress and Bankruptcy Prediction", "value": 30770, "id": "https://openalex.org/T11653"}, {"name": "Financial Literacy and Behavior", "value": 28434, "id": "https://openalex.org/T13744"}, {"name": "Accounting Education and Careers", "value": 25798, "id": "https://openalex.org/T12378"}, {"name": "Accounting Theory and Financial Reporting", "value": 21099, "id": "https://openalex.org/T13366"}, {"name": "Life Cycle Costing Analysis", "value": 17438, "id": "https://openalex.org/T14138"}, {"name": "Banking Systems and Strategies", "value": 16412, "id": "https://openalex.org/T14419"}, {"name": "Banking Sector Performance and Management", "value": 12596, "id": "https://openalex.org/T14183"}]}, {"name": "Management Information Systems", "children": [{"name": "Big Data and Business Intelligence", "value": 182835, "id": "https://openalex.org/T11891"}, {"name": "Quality and Supply Management", "value": 123926, "id": "https://openalex.org/T10164"}, {"name": "Business Process Modeling and Analysis", "value": 109033, "id": "https://openalex.org/T10703"}, {"name": "FinTech, Crowdfunding, Digital Finance", "value": 80843, "id": "https://openalex.org/T11995"}, {"name": "Accounting and Organizational Management", "value": 76964, "id": "https://openalex.org/T10797"}, {"name": "Decision Support System Applications", "value": 75778, "id": "https://openalex.org/T11734"}, {"name": "Outsourcing and Supply Chain Management", "value": 67366, "id": "https://openalex.org/T11912"}, {"name": "Supply Chain and Inventory Management", "value": 59315, "id": "https://openalex.org/T10328"}, {"name": "Advanced Queuing Theory Analysis", "value": 51058, "id": "https://openalex.org/T10974"}, {"name": "Information Technology Governance and Strategy", "value": 44099, "id": "https://openalex.org/T11572"}, {"name": "ERP Systems Implementation and Impact", "value": 36666, "id": "https://openalex.org/T11938"}, {"name": "Optics and Image Analysis", "value": 27216, "id": "https://openalex.org/T14320"}, {"name": "Varied Academic Research Topics", "value": 15108, "id": "https://openalex.org/T14187"}, {"name": "Information Systems and Technology Applications", "value": 14143, "id": "https://openalex.org/T12734"}, {"name": "Financial Reporting and XBRL", "value": 11185, "id": "https://openalex.org/T13794"}, {"name": "Logistics and Transportation Systems", "value": 9143, "id": "https://openalex.org/T14121"}]}, {"name": "Management of Technology and Innovation", "children": [{"name": "Entrepreneurship Studies and Influences", "value": 155682, "id": "https://openalex.org/T10058"}, {"name": "Digital Innovation in Industries", "value": 144772, "id": "https://openalex.org/T12885"}, {"name": "Intellectual Property and Patents", "value": 84700, "id": "https://openalex.org/T10856"}, {"name": "Collaboration in agile enterprises", "value": 59333, "id": "https://openalex.org/T12594"}, {"name": "Innovative Approaches in Technology and Social Development", "value": 54130, "id": "https://openalex.org/T14147"}, {"name": "Management and Marketing Education", "value": 48875, "id": "https://openalex.org/T12671"}, {"name": "Blood donation and transfusion practices", "value": 42151, "id": "https://openalex.org/T12735"}, {"name": "Economic and Technological Systems Analysis", "value": 33382, "id": "https://openalex.org/T13181"}, {"name": "University-Industry-Government Innovation Models", "value": 32015, "id": "https://openalex.org/T13276"}, {"name": "Product Development and Customization", "value": 31076, "id": "https://openalex.org/T11729"}, {"name": "Enterprise Management and Information Systems", "value": 18922, "id": "https://openalex.org/T13985"}, {"name": "Transportation Systems and Infrastructure", "value": 16649, "id": "https://openalex.org/T14014"}, {"name": "Organizational Management and Leadership", "value": 14867, "id": "https://openalex.org/T13963"}, {"name": "Quality Function Deployment in Product Design", "value": 14342, "id": "https://openalex.org/T12945"}, {"name": "Sustainability and Innovation in Business", "value": 11208, "id": "https://openalex.org/T14453"}, {"name": "Education Systems and Policies", "value": 9282, "id": "https://openalex.org/T13529"}]}, {"name": "Organizational Behavior and Human Resource Management", "children": [{"name": "Organizational Management and Innovation", "value": 130833, "id": "https://openalex.org/T11726"}, {"name": "Customer Service Quality and Loyalty", "value": 116342, "id": "https://openalex.org/T10154"}, {"name": "Job Satisfaction and Organizational Behavior", "value": 104191, "id": "https://openalex.org/T10006"}, {"name": "Global Public Health Policies and Epidemiology", "value": 100440, "id": "https://openalex.org/T12816"}, {"name": "Human Resource and Talent Management", "value": 71506, "id": "https://openalex.org/T12843"}, {"name": "Management and Organizational Studies", "value": 69552, "id": "https://openalex.org/T10344"}, {"name": "Corporate Management and Leadership", "value": 68972, "id": "https://openalex.org/T12376"}, {"name": "Healthcare Systems and Technology", "value": 62862, "id": "https://openalex.org/T12918"}, {"name": "Family Business Performance and Succession", "value": 57915, "id": "https://openalex.org/T11843"}, {"name": "Organizational Learning and Leadership", "value": 38779, "id": "https://openalex.org/T13163"}, {"name": "Corporate Law and Human Rights", "value": 37469, "id": "https://openalex.org/T13408"}, {"name": "Safety and Risk Management", "value": 36301, "id": "https://openalex.org/T14410"}, {"name": "Appreciative Inquiry and Organizational Change", "value": 35449, "id": "https://openalex.org/T13226"}, {"name": "Corporate Social Responsibility and Sustainability", "value": 33360, "id": "https://openalex.org/T13603"}, {"name": "Employee Performance and Leadership", "value": 28022, "id": "https://openalex.org/T14436"}, {"name": "Organizational Management and Change", "value": 26117, "id": "https://openalex.org/T13449"}, {"name": "Employee Performance and Motivation", "value": 25238, "id": "https://openalex.org/T11543"}, {"name": "Facility Location and Emergency Management", "value": 23955, "id": "https://openalex.org/T11502"}, {"name": "Employer Branding and e-HRM", "value": 22284, "id": "https://openalex.org/T12415"}, {"name": "Educational and Organizational Development", "value": 22042, "id": "https://openalex.org/T13626"}, {"name": "Organizational Strategy and Culture", "value": 18524, "id": "https://openalex.org/T13803"}, {"name": "AI and HR Technologies", "value": 17792, "id": "https://openalex.org/T13812"}, {"name": "Law, Ethics, and AI Impact", "value": 17372, "id": "https://openalex.org/T14264"}, {"name": "Management Theory and Practice", "value": 17037, "id": "https://openalex.org/T13235"}, {"name": "Organizational Change and Leadership", "value": 14567, "id": "https://openalex.org/T13149"}, {"name": "Education Methods and Integration", "value": 11976, "id": "https://openalex.org/T13431"}, {"name": "Employee Welfare and Language Studies", "value": 10765, "id": "https://openalex.org/T14450"}, {"name": "Organizational Downsizing and Restructuring", "value": 8428, "id": "https://openalex.org/T13642"}, {"name": "Flannery O'Connor and Thomas Merton", "value": 7178, "id": "https://openalex.org/T14026"}, {"name": "Management and Performance Evaluation", "value": 6435, "id": "https://openalex.org/T13580"}]}, {"name": "Industrial relations", "children": [{"name": "Legal and Labor Studies", "value": 124009, "id": "https://openalex.org/T13088"}]}, {"name": "Marketing", "children": [{"name": "Management, Economics, and Public Policy", "value": 118499, "id": "https://openalex.org/T14477"}, {"name": "American History and Culture", "value": 114908, "id": "https://openalex.org/T13025"}, {"name": "Consumer Behavior and Marketing Influence", "value": 101274, "id": "https://openalex.org/T14244"}, {"name": "Environmental Sustainability in Business", "value": 90477, "id": "https://openalex.org/T10880"}, {"name": "Consumer Behavior in Brand Consumption and Identification", "value": 87791, "id": "https://openalex.org/T10145"}, {"name": "Consumer Retail Behavior Studies", "value": 81989, "id": "https://openalex.org/T11536"}, {"name": "Consumer Perception and Purchasing Behavior", "value": 79228, "id": "https://openalex.org/T13169"}, {"name": "Consumer Market Behavior and Pricing", "value": 56612, "id": "https://openalex.org/T11161"}, {"name": "Copyright and Intellectual Property", "value": 55392, "id": "https://openalex.org/T11769"}, {"name": "Marketing and Advertising Strategies", "value": 38992, "id": "https://openalex.org/T13355"}, {"name": "Service and Product Innovation", "value": 38457, "id": "https://openalex.org/T11114"}, {"name": "Sharing Economy and Platforms", "value": 36645, "id": "https://openalex.org/T12392"}, {"name": "Customer churn and segmentation", "value": 26765, "id": "https://openalex.org/T12384"}, {"name": "Consumer Packaging Perceptions and Trends", "value": 24658, "id": "https://openalex.org/T14055"}, {"name": "Securities Regulation and Market Practices", "value": 20039, "id": "https://openalex.org/T14373"}]}, {"name": "Tourism, Leisure and Hospitality Management", "children": [{"name": "Wine Industry and Tourism", "value": 66094, "id": "https://openalex.org/T12399"}, {"name": "Hospitality and Tourism Education", "value": 26008, "id": "https://openalex.org/T12584"}]}, {"name": "Business and International Management", "children": [{"name": "Innovation and Socioeconomic Development", "value": 65463, "id": "https://openalex.org/T12786"}, {"name": "E-commerce and Technology Innovations", "value": 55300, "id": "https://openalex.org/T14139"}]}]}]}, {"name": "Health Sciences", "children": [{"name": "Medicine", "children": [{"name": "Pediatrics, Perinatology and Child Health", "children": [{"name": "Prenatal Screening and Diagnostics", "value": 1671656, "id": "https://openalex.org/T10978"}, {"name": "Fetal and Pediatric Neurological Disorders", "value": 362219, "id": "https://openalex.org/T12552"}, {"name": "Public Health and Nutrition", "value": 227129, "id": "https://openalex.org/T14495"}, {"name": "Global Maternal and Child Health", "value": 161010, "id": "https://openalex.org/T10209"}, {"name": "Birth, Development, and Health", "value": 148614, "id": "https://openalex.org/T11629"}, {"name": "Pharmacological Effects and Toxicity Studies", "value": 142016, "id": "https://openalex.org/T12229"}, {"name": "Assisted Reproductive Technology and Twin Pregnancy", "value": 130561, "id": "https://openalex.org/T11732"}, {"name": "Pharmaceutical studies and practices", "value": 117046, "id": "https://openalex.org/T12547"}, {"name": "Human Health and Disease", "value": 108562, "id": "https://openalex.org/T13091"}, {"name": "Childhood Cancer Survivors' Quality of Life", "value": 81558, "id": "https://openalex.org/T11141"}, {"name": "Pediatric Urology and Nephrology Studies", "value": 73292, "id": "https://openalex.org/T11174"}, {"name": "Ethics and Legal Issues in Pediatric Healthcare", "value": 71984, "id": "https://openalex.org/T14437"}, {"name": "Neonatal and fetal brain pathology", "value": 68572, "id": "https://openalex.org/T11184"}, {"name": "Infant Development and Preterm Care", "value": 66816, "id": "https://openalex.org/T11060"}, {"name": "Neonatal Health and Biochemistry", "value": 63483, "id": "https://openalex.org/T12068"}, {"name": "Maternal and fetal healthcare", "value": 53934, "id": "https://openalex.org/T11389"}, {"name": "Pediatric Pain Management Techniques", "value": 47047, "id": "https://openalex.org/T11292"}, {"name": "Prenatal Substance Exposure Effects", "value": 39741, "id": "https://openalex.org/T11633"}, {"name": "Child Abuse and Related Trauma", "value": 23844, "id": "https://openalex.org/T12235"}, {"name": "Literature Analysis and Criticism", "value": 20946, "id": "https://openalex.org/T13847"}]}, {"name": "Pharmacology", "children": [{"name": "Microbial Natural Products and Biosynthesis", "value": 423283, "id": "https://openalex.org/T10252"}, {"name": "Biological and pharmacological studies of plants", "value": 293912, "id": "https://openalex.org/T13130"}, {"name": "Musculoskeletal pain and rehabilitation", "value": 151903, "id": "https://openalex.org/T10084"}, {"name": "Fungal Biology and Applications", "value": 110863, "id": "https://openalex.org/T11085"}, {"name": "Inflammatory mediators and NSAID effects", "value": 95431, "id": "https://openalex.org/T10678"}, {"name": "Antibiotics Pharmacokinetics and Efficacy", "value": 94103, "id": "https://openalex.org/T11036"}, {"name": "Cannabis and Cannabinoid Research", "value": 87465, "id": "https://openalex.org/T10414"}, {"name": "Healthcare and Venom Research", "value": 80411, "id": "https://openalex.org/T14028"}, {"name": "Drug-Induced Adverse Reactions", "value": 65391, "id": "https://openalex.org/T11117"}, {"name": "Treatment of Major Depression", "value": 58389, "id": "https://openalex.org/T11071"}, {"name": "Pharmacology and Obesity Treatment", "value": 54470, "id": "https://openalex.org/T12539"}, {"name": "Cholinesterase and Neurodegenerative Diseases", "value": 52394, "id": "https://openalex.org/T12023"}, {"name": "Synthesis of Organic Compounds", "value": 49685, "id": "https://openalex.org/T13023"}, {"name": "Coffee research and impacts", "value": 46676, "id": "https://openalex.org/T11264"}, {"name": "Medical and Biological Ozone Research", "value": 37199, "id": "https://openalex.org/T13365"}, {"name": "Berberine and alkaloids research", "value": 33001, "id": "https://openalex.org/T12059"}, {"name": "Flavonoids in Medical Research", "value": 25752, "id": "https://openalex.org/T12582"}, {"name": "Pharmacological Effects of Medicinal Plants", "value": 25102, "id": "https://openalex.org/T13335"}, {"name": "Leech Biology and Applications", "value": 23034, "id": "https://openalex.org/T13767"}, {"name": "Apelin-related biomedical research", "value": 16350, "id": "https://openalex.org/T13505"}, {"name": "Biological Stains and Phytochemicals", "value": 15483, "id": "https://openalex.org/T13921"}, {"name": "Philosophy, Health, and Society", "value": 7646, "id": "https://openalex.org/T13809"}]}, {"name": "Surgery", "children": [{"name": "Biomedical and Chemical Research", "value": 355922, "id": "https://openalex.org/T12930"}, {"name": "Orthopedic Surgery and Rehabilitation", "value": 169806, "id": "https://openalex.org/T10630"}, {"name": "Helicobacter pylori-related gastroenterology studies", "value": 150100, "id": "https://openalex.org/T10276"}, {"name": "Anesthesia and Pain Management", "value": 149307, "id": "https://openalex.org/T10189"}, {"name": "Shoulder Injury and Treatment", "value": 139955, "id": "https://openalex.org/T10280"}, {"name": "Pancreatic function and diabetes", "value": 131980, "id": "https://openalex.org/T10839"}, {"name": "Orthopaedic implants and arthroplasty", "value": 120753, "id": "https://openalex.org/T10512"}, {"name": "Bladder and Urothelial Cancer Treatments", "value": 114241, "id": "https://openalex.org/T10458"}, {"name": "Pancreatitis Pathology and Treatment", "value": 112340, "id": "https://openalex.org/T10760"}, {"name": "Lipoproteins and Cardiovascular Health", "value": 112228, "id": "https://openalex.org/T10394"}, {"name": "Coronary Interventions and Diagnostics", "value": 103410, "id": "https://openalex.org/T10193"}, {"name": "Reconstructive Surgery and Microvascular Techniques", "value": 99788, "id": "https://openalex.org/T10599"}, {"name": "Peripheral Artery Disease Management", "value": 99634, "id": "https://openalex.org/T10926"}, {"name": "Knee injuries and reconstruction techniques", "value": 90105, "id": "https://openalex.org/T10442"}, {"name": "Gastrointestinal disorders and treatments", "value": 88232, "id": "https://openalex.org/T11855"}, {"name": "Esophageal and GI Pathology", "value": 87628, "id": "https://openalex.org/T11658"}, {"name": "Organ Transplantation Techniques and Outcomes", "value": 82307, "id": "https://openalex.org/T10999"}, {"name": "Total Knee Arthroplasty Outcomes", "value": 82225, "id": "https://openalex.org/T10562"}, {"name": "Spinal Fractures and Fixation Techniques", "value": 80625, "id": "https://openalex.org/T10776"}, {"name": "Esophageal Cancer Research and Treatment", "value": 79293, "id": "https://openalex.org/T10619"}, {"name": "Congenital Diaphragmatic Hernia Studies", "value": 79251, "id": "https://openalex.org/T11586"}, {"name": "Transplantation: Methods and Outcomes", "value": 79160, "id": "https://openalex.org/T11189"}, {"name": "Infectious Diseases and Tuberculosis", "value": 75744, "id": "https://openalex.org/T11381"}, {"name": "Hemodynamic Monitoring and Therapy", "value": 71689, "id": "https://openalex.org/T11700"}, {"name": "Salivary Gland Tumors Diagnosis and Treatment", "value": 71456, "id": "https://openalex.org/T11035"}, {"name": "Hernia repair and management", "value": 69376, "id": "https://openalex.org/T10961"}, {"name": "Hip and Femur Fractures", "value": 67143, "id": "https://openalex.org/T11509"}, {"name": "Testicular diseases and treatments", "value": 66783, "id": "https://openalex.org/T11069"}, {"name": "Head and Neck Surgical Oncology", "value": 66217, "id": "https://openalex.org/T11669"}, {"name": "Hip disorders and treatments", "value": 66086, "id": "https://openalex.org/T11218"}, {"name": "Genital Health and Disease", "value": 65947, "id": "https://openalex.org/T11713"}, {"name": "Medical research and treatments", "value": 65039, "id": "https://openalex.org/T14020"}, {"name": "Cardiovascular Syncope and Autonomic Disorders", "value": 64319, "id": "https://openalex.org/T11950"}, {"name": "Orthopedic Infections and Treatments", "value": 62408, "id": "https://openalex.org/T11293"}, {"name": "Cholangiocarcinoma and Gallbladder Cancer Studies", "value": 62251, "id": "https://openalex.org/T11364"}, {"name": "Bariatric Surgery and Outcomes", "value": 60976, "id": "https://openalex.org/T10569"}, {"name": "Tissue Engineering and Regenerative Medicine", "value": 60322, "id": "https://openalex.org/T12264"}, {"name": "Adrenal and Paraganglionic Tumors", "value": 58971, "id": "https://openalex.org/T11054"}, {"name": "Abdominal Trauma and Injuries", "value": 57331, "id": "https://openalex.org/T11267"}, {"name": "Vascular Malformations and Hemangiomas", "value": 55838, "id": "https://openalex.org/T10980"}, {"name": "Surgical Sutures and Adhesives", "value": 55295, "id": "https://openalex.org/T12906"}, {"name": "Diagnosis and treatment of tuberculosis", "value": 53417, "id": "https://openalex.org/T12578"}, {"name": "Trauma Management and Diagnosis", "value": 53410, "id": "https://openalex.org/T11951"}, {"name": "Pediatric Hepatobiliary Diseases and Treatments", "value": 52785, "id": "https://openalex.org/T12460"}, {"name": "Diverticular Disease and Complications", "value": 52086, "id": "https://openalex.org/T12518"}, {"name": "Diagnosis and Treatment of Venous Diseases", "value": 50829, "id": "https://openalex.org/T11453"}, {"name": "Facial Trauma and Fracture Management", "value": 49535, "id": "https://openalex.org/T11562"}, {"name": "Anorectal Disease Treatments and Outcomes", "value": 47998, "id": "https://openalex.org/T11865"}, {"name": "Scoliosis diagnosis and treatment", "value": 46977, "id": "https://openalex.org/T11030"}, {"name": "Surgical Simulation and Training", "value": 46562, "id": "https://openalex.org/T10916"}, {"name": "Eosinophilic Esophagitis", "value": 45154, "id": "https://openalex.org/T12538"}, {"name": "Pelvic and Acetabular Injuries", "value": 44343, "id": "https://openalex.org/T12154"}, {"name": "Cardiac and Coronary Surgery Techniques", "value": 43348, "id": "https://openalex.org/T11055"}, {"name": "Nasal Surgery and Airway Studies", "value": 42991, "id": "https://openalex.org/T11812"}, {"name": "Intestinal and Peritoneal Adhesions", "value": 41885, "id": "https://openalex.org/T12089"}, {"name": "Cholesterol and Lipid Metabolism", "value": 41407, "id": "https://openalex.org/T11618"}, {"name": "Congenital Anomalies and Fetal Surgery", "value": 40364, "id": "https://openalex.org/T12716"}, {"name": "Cardiac Structural Anomalies and Repair", "value": 40299, "id": "https://openalex.org/T12598"}, {"name": "Nerve Injury and Rehabilitation", "value": 39496, "id": "https://openalex.org/T12459"}, {"name": "Intestinal Malrotation and Obstruction Disorders", "value": 39076, "id": "https://openalex.org/T12150"}, {"name": "Breast Implant and Reconstruction", "value": 37954, "id": "https://openalex.org/T11258"}, {"name": "Abdominal vascular conditions and treatments", "value": 37683, "id": "https://openalex.org/T11625"}, {"name": "Muscle and Compartmental Disorders", "value": 36527, "id": "https://openalex.org/T12117"}, {"name": "Reconstructive Facial Surgery Techniques", "value": 36039, "id": "https://openalex.org/T11866"}, {"name": "Cervical and Thoracic Myelopathy", "value": 34608, "id": "https://openalex.org/T11518"}, {"name": "Colorectal and Anal Carcinomas", "value": 33381, "id": "https://openalex.org/T13110"}, {"name": "Management of metastatic bone disease", "value": 32747, "id": "https://openalex.org/T12108"}, {"name": "Thyroid and Parathyroid Surgery", "value": 32026, "id": "https://openalex.org/T11728"}, {"name": "Surgical site infection prevention", "value": 31438, "id": "https://openalex.org/T11080"}, {"name": "Intraperitoneal and Appendiceal Malignancies", "value": 31342, "id": "https://openalex.org/T12064"}, {"name": "Vascular anomalies and interventions", "value": 31217, "id": "https://openalex.org/T12342"}, {"name": "Body Contouring and Surgery", "value": 29735, "id": "https://openalex.org/T12173"}, {"name": "Nausea and vomiting management", "value": 28611, "id": "https://openalex.org/T11785"}, {"name": "Kawasaki Disease and Coronary Complications", "value": 28252, "id": "https://openalex.org/T11892"}, {"name": "Medical Case Reports and Studies", "value": 27676, "id": "https://openalex.org/T13533"}, {"name": "Heparin-Induced Thrombocytopenia and Thrombosis", "value": 27563, "id": "https://openalex.org/T12352"}, {"name": "Head and Neck Anomalies", "value": 26030, "id": "https://openalex.org/T12631"}, {"name": "Congenital gastrointestinal and neural anomalies", "value": 25814, "id": "https://openalex.org/T12237"}, {"name": "Natural Products and Biological Research", "value": 25814, "id": "https://openalex.org/T13828"}, {"name": "Enhanced Recovery After Surgery", "value": 25728, "id": "https://openalex.org/T12020"}, {"name": "Urinary and Genital Oncology Studies", "value": 24544, "id": "https://openalex.org/T12695"}, {"name": "Healthcare Technology and Patient Monitoring", "value": 24236, "id": "https://openalex.org/T13248"}, {"name": "Stoma care and complications", "value": 23552, "id": "https://openalex.org/T12769"}, {"name": "Case Reports on Hematomas", "value": 22464, "id": "https://openalex.org/T13878"}, {"name": "Teratomas and Epidermoid Cysts", "value": 22191, "id": "https://openalex.org/T12183"}, {"name": "Minimally Invasive Surgical Techniques", "value": 22004, "id": "https://openalex.org/T12053"}, {"name": "Xenotransplantation and immune response", "value": 21457, "id": "https://openalex.org/T12654"}, {"name": "Hydrogen's biological and therapeutic effects", "value": 19152, "id": "https://openalex.org/T13775"}, {"name": "Lymphatic Disorders and Treatments", "value": 15768, "id": "https://openalex.org/T12426"}, {"name": "Infectious Aortic and Vascular Conditions", "value": 15697, "id": "https://openalex.org/T12453"}, {"name": "Intraoperative Neuromonitoring and Anesthetic Effects", "value": 14756, "id": "https://openalex.org/T12476"}, {"name": "Spinal Hematomas and Complications", "value": 12590, "id": "https://openalex.org/T13323"}, {"name": "Lymphadenopathy Diagnosis and Analysis", "value": 11192, "id": "https://openalex.org/T13314"}, {"name": "Pectus Deformity Diagnosis and Treatment", "value": 10008, "id": "https://openalex.org/T12830"}, {"name": "Paraquat toxicity studies and treatments", "value": 9036, "id": "https://openalex.org/T13639"}, {"name": "Cardiovascular, Neuropeptides, and Oxidative Stress Research", "value": 6265, "id": "https://openalex.org/T14486"}]}, {"name": "Reproductive Medicine", "children": [{"name": "Legal Cases and Commentary", "value": 353618, "id": "https://openalex.org/T11662"}, {"name": "Science, Research, and Medicine", "value": 185168, "id": "https://openalex.org/T13656"}, {"name": "Reproductive Health and Technologies", "value": 122768, "id": "https://openalex.org/T11156"}, {"name": "Sperm and Testicular Function", "value": 120929, "id": "https://openalex.org/T10116"}, {"name": "Ovarian cancer diagnosis and treatment", "value": 115470, "id": "https://openalex.org/T10550"}, {"name": "Ovarian function and disorders", "value": 84235, "id": "https://openalex.org/T10390"}, {"name": "Endometriosis Research and Treatment", "value": 82078, "id": "https://openalex.org/T10935"}, {"name": "Hypothalamic control of reproductive hormones", "value": 36572, "id": "https://openalex.org/T10960"}]}, {"name": "Obstetrics and Gynecology", "children": [{"name": "Pregnancy and preeclampsia studies", "value": 311092, "id": "https://openalex.org/T10290"}, {"name": "Maternal and Perinatal Health Interventions", "value": 89263, "id": "https://openalex.org/T10453"}, {"name": "Endometrial and Cervical Cancer Treatments", "value": 78311, "id": "https://openalex.org/T10668"}, {"name": "Gestational Diabetes Research and Management", "value": 78219, "id": "https://openalex.org/T10673"}, {"name": "Uterine Myomas and Treatments", "value": 67337, "id": "https://openalex.org/T10989"}, {"name": "Gynecological conditions and treatments", "value": 55650, "id": "https://openalex.org/T11589"}, {"name": "COVID-19 Impact on Reproduction", "value": 51011, "id": "https://openalex.org/T11987"}, {"name": "Ureteral procedures and complications", "value": 39047, "id": "https://openalex.org/T12634"}]}, {"name": "Public Health, Environmental and Occupational Health", "children": [{"name": "Medical and Health Sciences Research", "value": 294747, "id": "https://openalex.org/T13275"}, {"name": "Mosquito-borne diseases and control", "value": 215487, "id": "https://openalex.org/T10166"}, {"name": "Malaria Research and Control", "value": 165977, "id": "https://openalex.org/T10091"}, {"name": "Palliative Care and End-of-Life Issues", "value": 155787, "id": "https://openalex.org/T10177"}, {"name": "Innovations in Medical Education", "value": 155200, "id": "https://openalex.org/T10254"}, {"name": "Biotechnology and Related Fields", "value": 150032, "id": "https://openalex.org/T14293"}, {"name": "Reproductive Biology and Fertility", "value": 148959, "id": "https://openalex.org/T10364"}, {"name": "Obesity, Physical Activity, Diet", "value": 134780, "id": "https://openalex.org/T10010"}, {"name": "Ethics and bioethics in healthcare", "value": 126049, "id": "https://openalex.org/T13147"}, {"name": "Health and Medical Research Impacts", "value": 117570, "id": "https://openalex.org/T12168"}, {"name": "Diverse Approaches in Healthcare and Education Studies", "value": 112124, "id": "https://openalex.org/T13751"}, {"name": "Clinical practice guidelines implementation", "value": 110298, "id": "https://openalex.org/T12664"}, {"name": "Streptococcal Infections and Treatments", "value": 100043, "id": "https://openalex.org/T11153"}, {"name": "Nutritional Studies and Diet", "value": 97319, "id": "https://openalex.org/T10866"}, {"name": "Aging, Health, and Disability", "value": 89625, "id": "https://openalex.org/T12811"}, {"name": "Research on Leishmaniasis Studies", "value": 89520, "id": "https://openalex.org/T10823"}, {"name": "Reproductive Health and Contraception", "value": 81501, "id": "https://openalex.org/T10600"}, {"name": "Maternal Mental Health During Pregnancy and Postpartum", "value": 78866, "id": "https://openalex.org/T10786"}, {"name": "Organ Donation and Transplantation", "value": 74107, "id": "https://openalex.org/T11163"}, {"name": "Ocular Surface and Contact Lens", "value": 69381, "id": "https://openalex.org/T10997"}, {"name": "Zoonotic diseases and public health", "value": 68358, "id": "https://openalex.org/T12492"}, {"name": "Mathematical and Theoretical Epidemiology and Ecology Models", "value": 66615, "id": "https://openalex.org/T10482"}, {"name": "Acute Lymphoblastic Leukemia research", "value": 65520, "id": "https://openalex.org/T10950"}, {"name": "Injury Epidemiology and Prevention", "value": 63173, "id": "https://openalex.org/T11824"}, {"name": "Opioid Use Disorder Treatment", "value": 63097, "id": "https://openalex.org/T10576"}, {"name": "Pregnancy and Medication Impact", "value": 59250, "id": "https://openalex.org/T11964"}, {"name": "Ethics in Clinical Research", "value": 58370, "id": "https://openalex.org/T10582"}, {"name": "Nutrition and Health Studies", "value": 55545, "id": "https://openalex.org/T13112"}, {"name": "Gestational Trophoblastic Disease Studies", "value": 54402, "id": "https://openalex.org/T12587"}, {"name": "Telemedicine and Telehealth Implementation", "value": 51942, "id": "https://openalex.org/T10912"}, {"name": "Medical Education and Admissions", "value": 51277, "id": "https://openalex.org/T12602"}, {"name": "Health Promotion and Cardiovascular Prevention", "value": 49424, "id": "https://openalex.org/T14212"}, {"name": "Digital Imaging in Medicine", "value": 47735, "id": "https://openalex.org/T13953"}, {"name": "Ectopic Pregnancy Diagnosis and Management", "value": 43559, "id": "https://openalex.org/T12096"}, {"name": "Global Health and Surgery", "value": 41689, "id": "https://openalex.org/T11731"}, {"name": "Consumer Attitudes and Food Labeling", "value": 40745, "id": "https://openalex.org/T12057"}, {"name": "Travel-related health issues", "value": 40645, "id": "https://openalex.org/T12402"}, {"name": "Healthcare and Environmental Waste Management", "value": 39500, "id": "https://openalex.org/T12920"}, {"name": "Neonatal and Maternal Infections", "value": 38661, "id": "https://openalex.org/T11961"}, {"name": "Palliative and Oncologic Care", "value": 38312, "id": "https://openalex.org/T13340"}, {"name": "Pregnancy-related medical research", "value": 37915, "id": "https://openalex.org/T12715"}, {"name": "Sex and Gender in Healthcare", "value": 34640, "id": "https://openalex.org/T13252"}, {"name": "Women's cancer prevention and management", "value": 34287, "id": "https://openalex.org/T13544"}, {"name": "Spinal Dysraphism and Malformations", "value": 33139, "id": "https://openalex.org/T11833"}, {"name": "Menstrual Health and Disorders", "value": 32449, "id": "https://openalex.org/T12054"}, {"name": "Occupational exposure and asthma", "value": 32233, "id": "https://openalex.org/T12208"}, {"name": "Female Genital Mutilation/Cutting Issues", "value": 26634, "id": "https://openalex.org/T12655"}, {"name": "Technology and Human Factors in Education and Health", "value": 25613, "id": "https://openalex.org/T14512"}, {"name": "Patient Dignity and Privacy", "value": 23513, "id": "https://openalex.org/T13048"}, {"name": "Down syndrome and intellectual disability research", "value": 21126, "id": "https://openalex.org/T11015"}, {"name": "Pharmaceutical Quality and Counterfeiting", "value": 19333, "id": "https://openalex.org/T12878"}, {"name": "HIV/AIDS oral health manifestations", "value": 19228, "id": "https://openalex.org/T13761"}, {"name": "Male Breast Health Studies", "value": 13478, "id": "https://openalex.org/T13097"}, {"name": "Legal, Health, Environmental and COVID-19 Challenges", "value": 6616, "id": "https://openalex.org/T13945"}]}, {"name": "Epidemiology", "children": [{"name": "Liver Disease Diagnosis and Treatment", "value": 265470, "id": "https://openalex.org/T10351"}, {"name": "Preterm Birth and Chorioamnionitis", "value": 187566, "id": "https://openalex.org/T11290"}, {"name": "Hepatitis B Virus Studies", "value": 153785, "id": "https://openalex.org/T10340"}, {"name": "Cervical Cancer and HPV Research", "value": 146254, "id": "https://openalex.org/T10146"}, {"name": "Influenza Virus Research Studies", "value": 136722, "id": "https://openalex.org/T10167"}, {"name": "Congenital Heart Disease Studies", "value": 133577, "id": "https://openalex.org/T10300"}, {"name": "Acute Ischemic Stroke Management", "value": 128604, "id": "https://openalex.org/T10227"}, {"name": "Mycobacterium research and diagnosis", "value": 127950, "id": "https://openalex.org/T11316"}, {"name": "Bone fractures and treatments", "value": 115272, "id": "https://openalex.org/T10658"}, {"name": "Herpesvirus Infections and Treatments", "value": 114569, "id": "https://openalex.org/T10625"}, {"name": "Healthcare Systems and Public Health", "value": 105499, "id": "https://openalex.org/T12935"}, {"name": "Substance Abuse Treatment and Outcomes", "value": 100638, "id": "https://openalex.org/T10043"}, {"name": "Trypanosoma species research and implications", "value": 95496, "id": "https://openalex.org/T10890"}, {"name": "Respiratory viral infections research", "value": 91819, "id": "https://openalex.org/T11243"}, {"name": "Sepsis Diagnosis and Treatment", "value": 91445, "id": "https://openalex.org/T10218"}, {"name": "Neuroendocrine Tumor Research Advances", "value": 91336, "id": "https://openalex.org/T10754"}, {"name": "Pneumonia and Respiratory Infections", "value": 90365, "id": "https://openalex.org/T10654"}, {"name": "Nail Diseases and Treatments", "value": 89531, "id": "https://openalex.org/T11253"}, {"name": "Cytomegalovirus and herpesvirus research", "value": 87317, "id": "https://openalex.org/T10981"}, {"name": "Breastfeeding Practices and Influences", "value": 87002, "id": "https://openalex.org/T10979"}, {"name": "Virology and Viral Diseases", "value": 83413, "id": "https://openalex.org/T11135"}, {"name": "Traumatic Brain Injury Research", "value": 81140, "id": "https://openalex.org/T10416"}, {"name": "Fungal Infections and Studies", "value": 74420, "id": "https://openalex.org/T11037"}, {"name": "Urinary Tract Infections Management", "value": 74011, "id": "https://openalex.org/T11232"}, {"name": "Adipokines, Inflammation, and Metabolic Diseases", "value": 70131, "id": "https://openalex.org/T10528"}, {"name": "Ophthalmology and Visual Impairment Studies", "value": 64604, "id": "https://openalex.org/T10381"}, {"name": "Autophagy in Disease and Therapy", "value": 61600, "id": "https://openalex.org/T10587"}, {"name": "Infective Endocarditis Diagnosis and Management", "value": 58103, "id": "https://openalex.org/T11551"}, {"name": "Chronic Disease Management Strategies", "value": 53311, "id": "https://openalex.org/T12246"}, {"name": "Meningioma and schwannoma management", "value": 52541, "id": "https://openalex.org/T11251"}, {"name": "Nonmelanoma Skin Cancer Studies", "value": 51258, "id": "https://openalex.org/T11306"}, {"name": "Shoulder and Clavicle Injuries", "value": 48329, "id": "https://openalex.org/T12411"}, {"name": "Burn Injury Management and Outcomes", "value": 47408, "id": "https://openalex.org/T11422"}, {"name": "Pneumocystis jirovecii pneumonia detection and treatment", "value": 46437, "id": "https://openalex.org/T12369"}, {"name": "HIV, Drug Use, Sexual Risk", "value": 44076, "id": "https://openalex.org/T11860"}, {"name": "Inflammatory Myopathies and Dermatomyositis", "value": 43425, "id": "https://openalex.org/T11724"}, {"name": "Data-Driven Disease Surveillance", "value": 42543, "id": "https://openalex.org/T11819"}, {"name": "Autoimmune and Inflammatory Disorders", "value": 40727, "id": "https://openalex.org/T12328"}, {"name": "Multiple and Secondary Primary Cancers", "value": 36677, "id": "https://openalex.org/T14078"}, {"name": "Microscopic Colitis", "value": 30554, "id": "https://openalex.org/T13569"}, {"name": "Burkholderia infections and melioidosis", "value": 15548, "id": "https://openalex.org/T12951"}, {"name": "Restless Legs Syndrome Research", "value": 15308, "id": "https://openalex.org/T12569"}]}, {"name": "Cardiology and Cardiovascular Medicine", "children": [{"name": "Cardiac, Anesthesia and Surgical Outcomes", "value": 237643, "id": "https://openalex.org/T11930"}, {"name": "Cardiac Valve Diseases and Treatments", "value": 169498, "id": "https://openalex.org/T10172"}, {"name": "Cardiac electrophysiology and arrhythmias", "value": 148189, "id": "https://openalex.org/T10217"}, {"name": "Atrial Fibrillation Management and Outcomes", "value": 140197, "id": "https://openalex.org/T10065"}, {"name": "Blood Pressure and Hypertension Studies", "value": 132041, "id": "https://openalex.org/T10144"}, {"name": "Heart Rate Variability and Autonomic Control", "value": 117213, "id": "https://openalex.org/T10745"}, {"name": "Cardiovascular Function and Risk Factors", "value": 115852, "id": "https://openalex.org/T10821"}, {"name": "Cardiac Arrhythmias and Treatments", "value": 104411, "id": "https://openalex.org/T11217"}, {"name": "Heart Failure Treatment and Management", "value": 94264, "id": "https://openalex.org/T10198"}, {"name": "Cardiac pacing and defibrillation studies", "value": 87159, "id": "https://openalex.org/T10598"}, {"name": "Viral Infections and Immunology Research", "value": 85095, "id": "https://openalex.org/T11112"}, {"name": "Cardiomyopathy and Myosin Studies", "value": 83819, "id": "https://openalex.org/T10882"}, {"name": "Acute Myocardial Infarction Research", "value": 77327, "id": "https://openalex.org/T10292"}, {"name": "Cardiac Health and Mental Health", "value": 73952, "id": "https://openalex.org/T11083"}, {"name": "Cardiovascular Health and Disease Prevention", "value": 68557, "id": "https://openalex.org/T10924"}, {"name": "Cardiovascular Disease and Adiposity", "value": 63380, "id": "https://openalex.org/T12979"}, {"name": "Antiplatelet Therapy and Cardiovascular Diseases", "value": 62003, "id": "https://openalex.org/T11064"}, {"name": "ECG Monitoring and Analysis", "value": 59377, "id": "https://openalex.org/T11021"}, {"name": "Cardiovascular Effects of Exercise", "value": 48828, "id": "https://openalex.org/T11922"}, {"name": "Cardiovascular Issues in Pregnancy", "value": 47919, "id": "https://openalex.org/T12230"}, {"name": "Cardiac tumors and thrombi", "value": 45987, "id": "https://openalex.org/T11638"}, {"name": "Cardiovascular Health and Risk Factors", "value": 39021, "id": "https://openalex.org/T13522"}, {"name": "Pericarditis and Cardiac Tamponade", "value": 35517, "id": "https://openalex.org/T12291"}, {"name": "Renin-Angiotensin System Studies", "value": 33882, "id": "https://openalex.org/T11001"}, {"name": "Lipid metabolism and disorders", "value": 32431, "id": "https://openalex.org/T13430"}, {"name": "Chemotherapy-induced cardiotoxicity and mitigation", "value": 29922, "id": "https://openalex.org/T11535"}, {"name": "Cardiac Fibrosis and Remodeling", "value": 28534, "id": "https://openalex.org/T11962"}, {"name": "Takotsubo Cardiomyopathy and Associated Phenomena", "value": 16742, "id": "https://openalex.org/T12082"}, {"name": "Heart rate and cardiovascular health", "value": 8687, "id": "https://openalex.org/T13381"}]}, {"name": "Physiology", "children": [{"name": "Diet and metabolism studies", "value": 226802, "id": "https://openalex.org/T12267"}, {"name": "Asthma and respiratory diseases", "value": 173820, "id": "https://openalex.org/T10051"}, {"name": "Adipose Tissue and Metabolism", "value": 130584, "id": "https://openalex.org/T11457"}, {"name": "Nutrition and Health in Aging", "value": 121431, "id": "https://openalex.org/T10397"}, {"name": "Alzheimer's disease research and treatments", "value": 115130, "id": "https://openalex.org/T10086"}, {"name": "Nitric Oxide and Endothelin Effects", "value": 111426, "id": "https://openalex.org/T10155"}, {"name": "Obstructive Sleep Apnea Research", "value": 107564, "id": "https://openalex.org/T10234"}, {"name": "Smoking Behavior and Cessation", "value": 106966, "id": "https://openalex.org/T10060"}, {"name": "Pain Mechanisms and Treatments", "value": 102113, "id": "https://openalex.org/T10196"}, {"name": "Erythrocyte Function and Pathophysiology", "value": 87870, "id": "https://openalex.org/T12286"}, {"name": "Biomedical Ethics and Regulation", "value": 79575, "id": "https://openalex.org/T13417"}, {"name": "Physical Activity and Health", "value": 78740, "id": "https://openalex.org/T10352"}, {"name": "Voice and Speech Disorders", "value": 77980, "id": "https://openalex.org/T10863"}, {"name": "Spaceflight effects on biology", "value": 74379, "id": "https://openalex.org/T12005"}, {"name": "Biochemical effects in animals", "value": 68216, "id": "https://openalex.org/T13551"}, {"name": "Syphilis Diagnosis and Treatment", "value": 66996, "id": "https://openalex.org/T11934"}, {"name": "Lysosomal Storage Disorders Research", "value": 60198, "id": "https://openalex.org/T10945"}, {"name": "Salivary Gland Disorders and Functions", "value": 57305, "id": "https://openalex.org/T11521"}, {"name": "Clinical Laboratory Practices and Quality Control", "value": 55243, "id": "https://openalex.org/T11314"}, {"name": "Body Composition Measurement Techniques", "value": 52967, "id": "https://openalex.org/T12279"}, {"name": "Thermoregulation and physiological responses", "value": 52577, "id": "https://openalex.org/T11109"}, {"name": "Telomeres, Telomerase, and Senescence", "value": 46375, "id": "https://openalex.org/T10937"}, {"name": "Sarcoidosis and Beryllium Toxicity Research", "value": 44066, "id": "https://openalex.org/T11571"}, {"name": "Simulation-Based Education in Healthcare", "value": 41163, "id": "https://openalex.org/T11238"}, {"name": "Biofield Effects and Biophysics", "value": 32830, "id": "https://openalex.org/T13044"}, {"name": "Dietary Effects on Health", "value": 31259, "id": "https://openalex.org/T12745"}, {"name": "Sympathectomy and Hyperhidrosis Treatments", "value": 28607, "id": "https://openalex.org/T12625"}, {"name": "Histiocytic Disorders and Treatments", "value": 27026, "id": "https://openalex.org/T11909"}, {"name": "Tuberous Sclerosis Complex Research", "value": 26938, "id": "https://openalex.org/T12049"}, {"name": "Pathogenesis and Treatment of Hiccups", "value": 15348, "id": "https://openalex.org/T14344"}]}, {"name": "Infectious Diseases", "children": [{"name": "Tuberculosis Research and Epidemiology", "value": 225481, "id": "https://openalex.org/T10038"}, {"name": "HIV/AIDS Research and Interventions", "value": 150099, "id": "https://openalex.org/T10082"}, {"name": "SARS-CoV-2 and COVID-19 Research", "value": 125899, "id": "https://openalex.org/T10118"}, {"name": "Antimicrobial Resistance in Staphylococcus", "value": 118167, "id": "https://openalex.org/T10195"}, {"name": "Antifungal resistance and susceptibility", "value": 114576, "id": "https://openalex.org/T10150"}, {"name": "COVID-19 Clinical Research Studies", "value": 100950, "id": "https://openalex.org/T10041"}, {"name": "Viral gastroenteritis research and epidemiology", "value": 94593, "id": "https://openalex.org/T10976"}, {"name": "Clostridium difficile and Clostridium perfringens research", "value": 72972, "id": "https://openalex.org/T11288"}, {"name": "Viral Infections and Vectors", "value": 70113, "id": "https://openalex.org/T12047"}, {"name": "HIV/AIDS drug development and treatment", "value": 69196, "id": "https://openalex.org/T10526"}, {"name": "Leprosy Research and Treatment", "value": 53090, "id": "https://openalex.org/T12107"}, {"name": "Parasitic Diseases Research and Treatment", "value": 52023, "id": "https://openalex.org/T11702"}, {"name": "Viral Infections and Outbreaks Research", "value": 48267, "id": "https://openalex.org/T11581"}, {"name": "Amoebic Infections and Treatments", "value": 43455, "id": "https://openalex.org/T12463"}, {"name": "Dermatological diseases and infestations", "value": 38548, "id": "https://openalex.org/T12116"}, {"name": "Parvovirus B19 Infection Studies", "value": 38355, "id": "https://openalex.org/T12849"}, {"name": "Infection Control in Healthcare", "value": 32881, "id": "https://openalex.org/T11000"}, {"name": "SARS-CoV-2 detection and testing", "value": 32611, "id": "https://openalex.org/T11754"}, {"name": "Otolaryngology and Infectious Diseases", "value": 30802, "id": "https://openalex.org/T12297"}, {"name": "Infectious Encephalopathies and Encephalitis", "value": 23829, "id": "https://openalex.org/T13201"}, {"name": "Infectious Disease Case Reports and Treatments", "value": 15773, "id": "https://openalex.org/T12914"}]}, {"name": "Anatomy", "children": [{"name": "Medical and Biological Sciences", "value": 215111, "id": "https://openalex.org/T14134"}]}, {"name": "Radiology, Nuclear Medicine and Imaging", "children": [{"name": "Medical Imaging Techniques and Applications", "value": 200430, "id": "https://openalex.org/T10522"}, {"name": "Monoclonal and Polyclonal Antibodies Research", "value": 200336, "id": "https://openalex.org/T11016"}, {"name": "Cardiac Imaging and Diagnostics", "value": 155362, "id": "https://openalex.org/T10372"}, {"name": "Advanced MRI Techniques and Applications", "value": 144248, "id": "https://openalex.org/T10378"}, {"name": "Radiomics and Machine Learning in Medical Imaging", "value": 130883, "id": "https://openalex.org/T12422"}, {"name": "Radiation Dose and Imaging", "value": 106982, "id": "https://openalex.org/T10844"}, {"name": "Radiopharmaceutical Chemistry and Applications", "value": 86566, "id": "https://openalex.org/T11395"}, {"name": "Advances in Oncology and Radiotherapy", "value": 78327, "id": "https://openalex.org/T13123"}, {"name": "Corneal surgery and disorders", "value": 77504, "id": "https://openalex.org/T10563"}, {"name": "Retinal Imaging and Analysis", "value": 68587, "id": "https://openalex.org/T11438"}, {"name": "Advanced Neuroimaging Techniques and Applications", "value": 64827, "id": "https://openalex.org/T11304"}, {"name": "Radiology practices and education", "value": 61864, "id": "https://openalex.org/T11894"}, {"name": "Effects of Radiation Exposure", "value": 60165, "id": "https://openalex.org/T11359"}, {"name": "Infrared Thermography in Medicine", "value": 54294, "id": "https://openalex.org/T12994"}, {"name": "Peripheral Nerve Disorders", "value": 53506, "id": "https://openalex.org/T10954"}, {"name": "Laser Applications in Dentistry and Medicine", "value": 52227, "id": "https://openalex.org/T11566"}, {"name": "COVID-19 diagnosis using AI", "value": 51148, "id": "https://openalex.org/T11775"}, {"name": "Retinal and Macular Surgery", "value": 49867, "id": "https://openalex.org/T11377"}, {"name": "Optical Imaging and Spectroscopy Techniques", "value": 49110, "id": "https://openalex.org/T10977"}, {"name": "Plasma Applications and Diagnostics", "value": 48790, "id": "https://openalex.org/T10642"}, {"name": "Corneal Surgery and Treatments", "value": 45423, "id": "https://openalex.org/T11828"}, {"name": "MRI in cancer diagnosis", "value": 44691, "id": "https://openalex.org/T11885"}, {"name": "Historical Medical Research and Treatments", "value": 42885, "id": "https://openalex.org/T14275"}, {"name": "Autopsy Techniques and Outcomes", "value": 42462, "id": "https://openalex.org/T12296"}, {"name": "Foreign Body Medical Cases", "value": 34719, "id": "https://openalex.org/T11910"}, {"name": "Boron Compounds in Chemistry", "value": 34240, "id": "https://openalex.org/T12055"}, {"name": "Ultrasound Imaging and Elastography", "value": 32391, "id": "https://openalex.org/T10727"}, {"name": "Retinopathy of Prematurity Studies", "value": 23547, "id": "https://openalex.org/T12484"}, {"name": "Cardiovascular Conditions and Treatments", "value": 23358, "id": "https://openalex.org/T12272"}, {"name": "Nephrotoxicity and Medicinal Plants", "value": 21795, "id": "https://openalex.org/T12962"}]}, {"name": "Pulmonary and Respiratory Medicine", "children": [{"name": "Chronic Obstructive Pulmonary Disease (COPD) Research", "value": 162844, "id": "https://openalex.org/T10143"}, {"name": "Neonatal Respiratory Health Research", "value": 151112, "id": "https://openalex.org/T10549"}, {"name": "Respiratory Support and Mechanisms", "value": 143237, "id": "https://openalex.org/T10322"}, {"name": "Lung Cancer Treatments and Mutations", "value": 129135, "id": "https://openalex.org/T10417"}, {"name": "Cerebrovascular and Carotid Artery Diseases", "value": 126530, "id": "https://openalex.org/T10816"}, {"name": "Lung Cancer Diagnosis and Treatment", "value": 121575, "id": "https://openalex.org/T10202"}, {"name": "Sarcoma Diagnosis and Treatment", "value": 119155, "id": "https://openalex.org/T10253"}, {"name": "Prostate Cancer Treatment and Research", "value": 119146, "id": "https://openalex.org/T10543"}, {"name": "Gastric Cancer Management and Outcomes", "value": 109337, "id": "https://openalex.org/T10696"}, {"name": "Prostate Cancer Diagnosis and Treatment", "value": 108376, "id": "https://openalex.org/T10124"}, {"name": "Tracheal and airway disorders", "value": 104514, "id": "https://openalex.org/T11260"}, {"name": "Gallbladder and Bile Duct Disorders", "value": 100451, "id": "https://openalex.org/T10518"}, {"name": "Medical Imaging and Pathology Studies", "value": 99413, "id": "https://openalex.org/T13759"}, {"name": "Pulmonary Hypertension Research and Treatments", "value": 92925, "id": "https://openalex.org/T10728"}, {"name": "Renal cell carcinoma treatment", "value": 86045, "id": "https://openalex.org/T10449"}, {"name": "Cystic Fibrosis Research Advances", "value": 80476, "id": "https://openalex.org/T10665"}, {"name": "Digital Radiography and Breast Imaging", "value": 78699, "id": "https://openalex.org/T11361"}, {"name": "Interstitial Lung Diseases and Idiopathic Pulmonary Fibrosis", "value": 78328, "id": "https://openalex.org/T10870"}, {"name": "Radiation Therapy and Dosimetry", "value": 75410, "id": "https://openalex.org/T11176"}, {"name": "Kidney Stones and Urolithiasis Treatments", "value": 73356, "id": "https://openalex.org/T10606"}, {"name": "Pleural and Pulmonary Diseases", "value": 72384, "id": "https://openalex.org/T11356"}, {"name": "Occupational and environmental lung diseases", "value": 72131, "id": "https://openalex.org/T11026"}, {"name": "Vasculitis and related conditions", "value": 69354, "id": "https://openalex.org/T10697"}, {"name": "Renal and Vascular Pathologies", "value": 65482, "id": "https://openalex.org/T12067"}, {"name": "Winter Sports Injuries and Performance", "value": 65395, "id": "https://openalex.org/T13176"}, {"name": "Aortic Disease and Treatment Approaches", "value": 64267, "id": "https://openalex.org/T10618"}, {"name": "Aortic aneurysm repair treatments", "value": 64160, "id": "https://openalex.org/T10983"}, {"name": "Inhalation and Respiratory Drug Delivery", "value": 63722, "id": "https://openalex.org/T11651"}, {"name": "Electrolyte and hormonal disorders", "value": 63308, "id": "https://openalex.org/T11967"}, {"name": "Blood properties and coagulation", "value": 59542, "id": "https://openalex.org/T11721"}, {"name": "Ferroptosis and cancer prognosis", "value": 53990, "id": "https://openalex.org/T11297"}, {"name": "Cardiovascular and Diving-Related Complications", "value": 49368, "id": "https://openalex.org/T11579"}, {"name": "Photodynamic Therapy Research Studies", "value": 47507, "id": "https://openalex.org/T10957"}, {"name": "Respiratory and Cough-Related Research", "value": 47496, "id": "https://openalex.org/T12418"}, {"name": "Brain Metastases and Treatment", "value": 40926, "id": "https://openalex.org/T11600"}, {"name": "Automotive and Human Injury Biomechanics", "value": 39274, "id": "https://openalex.org/T11487"}, {"name": "Vascular Procedures and Complications", "value": 39051, "id": "https://openalex.org/T11554"}, {"name": "Veterinary Oncology Research", "value": 37532, "id": "https://openalex.org/T11149"}, {"name": "Infection Control and Ventilation", "value": 36131, "id": "https://openalex.org/T10990"}, {"name": "Advanced Breast Cancer Therapies", "value": 32572, "id": "https://openalex.org/T12829"}, {"name": "Abdominal Surgery and Complications", "value": 31592, "id": "https://openalex.org/T12333"}, {"name": "Coronary Artery Anomalies", "value": 31192, "id": "https://openalex.org/T12018"}, {"name": "Metastasis and carcinoma case studies", "value": 30391, "id": "https://openalex.org/T12992"}, {"name": "Biliary and Gastrointestinal Fistulas", "value": 29763, "id": "https://openalex.org/T13697"}, {"name": "Phonocardiography and Auscultation Techniques", "value": 27105, "id": "https://openalex.org/T12419"}, {"name": "Oral health in cancer treatment", "value": 26610, "id": "https://openalex.org/T12198"}, {"name": "Potassium and Related Disorders", "value": 26592, "id": "https://openalex.org/T12876"}, {"name": "Silymarin and Mushroom Poisoning", "value": 25243, "id": "https://openalex.org/T12689"}, {"name": "Pneumothorax, Barotrauma, Emphysema", "value": 17367, "id": "https://openalex.org/T12818"}, {"name": "Cancer-related cognitive impairment studies", "value": 14264, "id": "https://openalex.org/T13077"}, {"name": "Methemoglobinemia and Tumor Lysis Syndrome", "value": 12960, "id": "https://openalex.org/T12845"}, {"name": "Aortic Thrombus and Embolism", "value": 12316, "id": "https://openalex.org/T13657"}]}, {"name": "Internal Medicine", "children": [{"name": "Venous Thromboembolism Diagnosis and Management", "value": 161438, "id": "https://openalex.org/T10285"}]}, {"name": "Orthopedics and Sports Medicine", "children": [{"name": "Sports Performance and Training", "value": 161172, "id": "https://openalex.org/T10157"}, {"name": "Bone health and osteoporosis research", "value": 92590, "id": "https://openalex.org/T10071"}, {"name": "Sports injuries and prevention", "value": 87593, "id": "https://openalex.org/T11246"}, {"name": "Foot and Ankle Surgery", "value": 72428, "id": "https://openalex.org/T10455"}, {"name": "Tendon Structure and Treatment", "value": 50736, "id": "https://openalex.org/T11068"}, {"name": "Bone and Joint Diseases", "value": 39332, "id": "https://openalex.org/T12209"}, {"name": "Effects of Vibration on Health", "value": 20085, "id": "https://openalex.org/T12269"}]}, {"name": "Ophthalmology", "children": [{"name": "Glaucoma and retinal disorders", "value": 154457, "id": "https://openalex.org/T10250"}, {"name": "Retinal Diseases and Treatments", "value": 97309, "id": "https://openalex.org/T10170"}, {"name": "Intraocular Surgery and Lenses", "value": 80717, "id": "https://openalex.org/T11291"}, {"name": "Ocular Diseases and Beh\u00e7et\u2019s Syndrome", "value": 60134, "id": "https://openalex.org/T11194"}, {"name": "Traumatic Ocular and Foreign Body Injuries", "value": 53141, "id": "https://openalex.org/T11867"}, {"name": "Ocular Oncology and Treatments", "value": 52667, "id": "https://openalex.org/T11328"}, {"name": "Retinal and Optic Conditions", "value": 46879, "id": "https://openalex.org/T12599"}, {"name": "Ocular and Laser Science Research", "value": 43546, "id": "https://openalex.org/T13869"}, {"name": "Ocular Infections and Treatments", "value": 38894, "id": "https://openalex.org/T11826"}, {"name": "Ophthalmology and Visual Health Research", "value": 31787, "id": "https://openalex.org/T14384"}, {"name": "Drug-Induced Ocular Toxicity", "value": 25698, "id": "https://openalex.org/T13467"}, {"name": "Nasolacrimal Duct Obstruction Treatments", "value": 17028, "id": "https://openalex.org/T12523"}]}, {"name": "Psychiatry and Mental health", "children": [{"name": "Epilepsy research and treatment", "value": 151624, "id": "https://openalex.org/T10094"}, {"name": "Schizophrenia research and treatment", "value": 128573, "id": "https://openalex.org/T10023"}, {"name": "Dementia and Cognitive Impairment Research", "value": 126282, "id": "https://openalex.org/T10009"}, {"name": "Attention Deficit Hyperactivity Disorder", "value": 118270, "id": "https://openalex.org/T10537"}, {"name": "Migraine and Headache Studies", "value": 96146, "id": "https://openalex.org/T10498"}, {"name": "Empathy and Medical Education", "value": 80602, "id": "https://openalex.org/T11999"}, {"name": "Cerebral Palsy and Movement Disorders", "value": 79190, "id": "https://openalex.org/T11097"}, {"name": "Sexual function and dysfunction studies", "value": 75939, "id": "https://openalex.org/T10459"}, {"name": "Psychosomatic Disorders and Their Treatments", "value": 73318, "id": "https://openalex.org/T11334"}, {"name": "Bipolar Disorder and Treatment", "value": 62211, "id": "https://openalex.org/T10854"}, {"name": "Child Nutrition and Feeding Issues", "value": 59180, "id": "https://openalex.org/T13393"}, {"name": "Fibromyalgia and Chronic Fatigue Syndrome Research", "value": 57717, "id": "https://openalex.org/T11282"}, {"name": "Electroconvulsive Therapy Studies", "value": 39424, "id": "https://openalex.org/T11921"}, {"name": "Cancer, Stress, Anesthesia, and Immune Response", "value": 32759, "id": "https://openalex.org/T12626"}, {"name": "Neurological Complications and Syndromes", "value": 20182, "id": "https://openalex.org/T12464"}, {"name": "Medicine, History, and Philosophy", "value": 8667, "id": "https://openalex.org/T14511"}]}, {"name": "Pathology and Forensic Medicine", "children": [{"name": "Spine and Intervertebral Disc Pathology", "value": 147808, "id": "https://openalex.org/T10238"}, {"name": "Lymphoma Diagnosis and Treatment", "value": 127529, "id": "https://openalex.org/T10185"}, {"name": "Multiple Sclerosis Research Studies", "value": 102444, "id": "https://openalex.org/T10137"}, {"name": "Vitamin D Research Studies", "value": 91561, "id": "https://openalex.org/T10277"}, {"name": "Systemic Sclerosis and Related Diseases", "value": 89960, "id": "https://openalex.org/T11330"}, {"name": "Genetic factors in colorectal cancer", "value": 79097, "id": "https://openalex.org/T11369"}, {"name": "Autoimmune Bullous Skin Diseases", "value": 65671, "id": "https://openalex.org/T11730"}, {"name": "Parasitic infections in humans and animals", "value": 64302, "id": "https://openalex.org/T11154"}, {"name": "Historical and Scientific Studies", "value": 63594, "id": "https://openalex.org/T14199"}, {"name": "Ophthalmology and Eye Disorders", "value": 63299, "id": "https://openalex.org/T11538"}, {"name": "Alcohol Consumption and Health Effects", "value": 61789, "id": "https://openalex.org/T11207"}, {"name": "Cardiac Ischemia and Reperfusion", "value": 59447, "id": "https://openalex.org/T11057"}, {"name": "Breast Lesions and Carcinomas", "value": 49433, "id": "https://openalex.org/T11134"}, {"name": "Spinal Cord Injury Research", "value": 46884, "id": "https://openalex.org/T10925"}, {"name": "Phytoestrogen effects and research", "value": 45720, "id": "https://openalex.org/T11318"}, {"name": "Tea Polyphenols and Effects", "value": 44169, "id": "https://openalex.org/T11411"}, {"name": "Tumors and Oncological Cases", "value": 37177, "id": "https://openalex.org/T13383"}, {"name": "Trigeminal Neuralgia and Treatments", "value": 26394, "id": "https://openalex.org/T12193"}, {"name": "Biomedical Research and Pathophysiology", "value": 25234, "id": "https://openalex.org/T14415"}, {"name": "Cancer Mechanisms and Therapy", "value": 22865, "id": "https://openalex.org/T13779"}, {"name": "Chemotherapy-induced organ toxicity mitigation", "value": 14166, "id": "https://openalex.org/T12429"}, {"name": "Soft tissue tumors and treatment", "value": 12071, "id": "https://openalex.org/T13363"}, {"name": "Whipple's Disease and Interleukins", "value": 8920, "id": "https://openalex.org/T13834"}]}, {"name": "Oncology", "children": [{"name": "Pancreatic and Hepatic Oncology Research", "value": 145911, "id": "https://openalex.org/T10231"}, {"name": "Cancer Treatment and Pharmacology", "value": 143736, "id": "https://openalex.org/T11752"}, {"name": "Metal complexes synthesis and properties", "value": 137807, "id": "https://openalex.org/T10163"}, {"name": "Peptidase Inhibition and Analysis", "value": 132913, "id": "https://openalex.org/T12505"}, {"name": "Cancer Immunotherapy and Biomarkers", "value": 131162, "id": "https://openalex.org/T10158"}, {"name": "Cutaneous Melanoma Detection and Management", "value": 93362, "id": "https://openalex.org/T10392"}, {"name": "Drug Transport and Resistance Mechanisms", "value": 88180, "id": "https://openalex.org/T10570"}, {"name": "Bone health and treatments", "value": 87865, "id": "https://openalex.org/T11221"}, {"name": "Colorectal Cancer Surgical Treatments", "value": 85902, "id": "https://openalex.org/T10335"}, {"name": "Colorectal Cancer Screening and Detection", "value": 84710, "id": "https://openalex.org/T10552"}, {"name": "Cancer-related Molecular Pathways", "value": 83863, "id": "https://openalex.org/T10583"}, {"name": "Cancer Diagnosis and Treatment", "value": 81931, "id": "https://openalex.org/T12379"}, {"name": "Cancer Cells and Metastasis", "value": 81868, "id": "https://openalex.org/T10336"}, {"name": "Global Cancer Incidence and Screening", "value": 79342, "id": "https://openalex.org/T10556"}, {"name": "CAR-T cell therapy research", "value": 79220, "id": "https://openalex.org/T11491"}, {"name": "Cancer survivorship and care", "value": 71877, "id": "https://openalex.org/T10178"}, {"name": "Viral-associated cancers and disorders", "value": 64577, "id": "https://openalex.org/T10685"}, {"name": "HER2/EGFR in Cancer Research", "value": 61668, "id": "https://openalex.org/T10755"}, {"name": "Cytokine Signaling Pathways and Interactions", "value": 60881, "id": "https://openalex.org/T11503"}, {"name": "Colorectal Cancer Treatments and Studies", "value": 59325, "id": "https://openalex.org/T11067"}, {"name": "COVID-19 and healthcare impacts", "value": 57578, "id": "https://openalex.org/T11296"}, {"name": "Cancer Risks and Factors", "value": 51211, "id": "https://openalex.org/T12103"}, {"name": "Inflammatory Biomarkers in Disease Prognosis", "value": 44916, "id": "https://openalex.org/T11355"}, {"name": "Polyomavirus and related diseases", "value": 43407, "id": "https://openalex.org/T11827"}, {"name": "PARP inhibition in cancer therapy", "value": 36276, "id": "https://openalex.org/T11914"}, {"name": "Lymphatic System and Diseases", "value": 35780, "id": "https://openalex.org/T11469"}, {"name": "Neutropenia and Cancer Infections", "value": 34967, "id": "https://openalex.org/T12172"}, {"name": "Lung Cancer Research Studies", "value": 34468, "id": "https://openalex.org/T12334"}, {"name": "Chemokine receptors and signaling", "value": 33243, "id": "https://openalex.org/T11532"}, {"name": "Vascular Tumors and Angiosarcomas", "value": 29594, "id": "https://openalex.org/T12278"}, {"name": "Ear and Head Tumors", "value": 19797, "id": "https://openalex.org/T14326"}, {"name": "Saffron Plant Research Studies", "value": 17451, "id": "https://openalex.org/T12758"}, {"name": "Cancer Research and Treatment", "value": 15507, "id": "https://openalex.org/T13434"}, {"name": "Clusterin in disease pathology", "value": 7927, "id": "https://openalex.org/T14364"}]}, {"name": "Genetics", "children": [{"name": "Glioma Diagnosis and Treatment", "value": 145883, "id": "https://openalex.org/T10129"}, {"name": "Hemoglobinopathies and Related Disorders", "value": 124228, "id": "https://openalex.org/T10554"}, {"name": "Chronic Lymphocytic Leukemia Research", "value": 98786, "id": "https://openalex.org/T11157"}, {"name": "Mesenchymal stem cell research", "value": 82590, "id": "https://openalex.org/T10176"}, {"name": "Myeloproliferative Neoplasms: Diagnosis and Treatment", "value": 48816, "id": "https://openalex.org/T11628"}, {"name": "Coagulation, Bradykinin, Polyphosphates, and Angioedema", "value": 45723, "id": "https://openalex.org/T11917"}, {"name": "Neurogenetic and Muscular Disorders Research", "value": 43015, "id": "https://openalex.org/T12400"}, {"name": "Vascular Anomalies and Treatments", "value": 27411, "id": "https://openalex.org/T12199"}, {"name": "Congenital Ear and Nasal Anomalies", "value": 11859, "id": "https://openalex.org/T13738"}]}, {"name": "Dermatology", "children": [{"name": "Medicine and Dermatology Studies History", "value": 141492, "id": "https://openalex.org/T13597"}, {"name": "Dermatology and Skin Diseases", "value": 96284, "id": "https://openalex.org/T10837"}, {"name": "Skin Protection and Aging", "value": 67039, "id": "https://openalex.org/T11013"}, {"name": "Contact Dermatitis and Allergies", "value": 63517, "id": "https://openalex.org/T11033"}, {"name": "Cancer and Skin Lesions", "value": 53418, "id": "https://openalex.org/T11868"}, {"name": "Dermatologic Treatments and Research", "value": 46996, "id": "https://openalex.org/T11172"}, {"name": "Acne and Rosacea Treatments and Effects", "value": 44036, "id": "https://openalex.org/T11553"}, {"name": "Cutaneous lymphoproliferative disorders research", "value": 41438, "id": "https://openalex.org/T11811"}, {"name": "Chemotherapy-related skin toxicity", "value": 37125, "id": "https://openalex.org/T12937"}, {"name": "Facial Rejuvenation and Surgery Techniques", "value": 35365, "id": "https://openalex.org/T11322"}, {"name": "Skin Diseases and Diabetes", "value": 28226, "id": "https://openalex.org/T12433"}, {"name": "Dermatological and COVID-19 studies", "value": 23824, "id": "https://openalex.org/T12796"}, {"name": "Hidradenitis Suppurativa and Treatments", "value": 12365, "id": "https://openalex.org/T12731"}]}, {"name": "Hepatology", "children": [{"name": "Hepatitis C virus research", "value": 134464, "id": "https://openalex.org/T10151"}, {"name": "Hepatocellular Carcinoma Treatment and Prognosis", "value": 111891, "id": "https://openalex.org/T10073"}, {"name": "Liver Disease and Transplantation", "value": 105879, "id": "https://openalex.org/T10337"}, {"name": "Liver physiology and pathology", "value": 56531, "id": "https://openalex.org/T10966"}, {"name": "Liver Diseases and Immunity", "value": 38313, "id": "https://openalex.org/T11834"}, {"name": "Hepatitis Viruses Studies and Epidemiology", "value": 36387, "id": "https://openalex.org/T12025"}]}, {"name": "Geriatrics and Gerontology", "children": [{"name": "Pharmaceutical Practices and Patient Outcomes", "value": 131858, "id": "https://openalex.org/T10496"}, {"name": "Frailty in Older Adults", "value": 50291, "id": "https://openalex.org/T11011"}, {"name": "Sirtuins and Resveratrol in Medicine", "value": 31978, "id": "https://openalex.org/T11051"}]}, {"name": "Complementary and alternative medicine", "children": [{"name": "Medical Research and Treatments", "value": 129017, "id": "https://openalex.org/T13444"}, {"name": "Complementary and Alternative Medicine Studies", "value": 87081, "id": "https://openalex.org/T10902"}, {"name": "Traditional Chinese Medicine Studies", "value": 86912, "id": "https://openalex.org/T12647"}, {"name": "Cardiovascular and exercise physiology", "value": 81347, "id": "https://openalex.org/T11209"}, {"name": "Traditional Chinese Medicine Analysis", "value": 65973, "id": "https://openalex.org/T11709"}, {"name": "Acupuncture Treatment Research Studies", "value": 53645, "id": "https://openalex.org/T11327"}, {"name": "Phytochemicals and Medicinal Plants", "value": 44972, "id": "https://openalex.org/T12298"}, {"name": "Medicinal plant effects and applications", "value": 32255, "id": "https://openalex.org/T13919"}, {"name": "Medicinal Plants and Neuroprotection", "value": 31166, "id": "https://openalex.org/T12891"}, {"name": "Ginkgo biloba and Cashew Applications", "value": 22992, "id": "https://openalex.org/T12846"}, {"name": "Phytochemical and Pharmacological Studies", "value": 22734, "id": "https://openalex.org/T13776"}, {"name": "Medicinal Plant Extracts Effects", "value": 22340, "id": "https://openalex.org/T13090"}, {"name": "Herbal Medicine Research Studies", "value": 20877, "id": "https://openalex.org/T13483"}, {"name": "Morinda citrifolia extract uses", "value": 16181, "id": "https://openalex.org/T13792"}, {"name": "Medicinal Plant Studies", "value": 15815, "id": "https://openalex.org/T14461"}, {"name": "Nigella sativa pharmacological applications", "value": 15169, "id": "https://openalex.org/T12750"}, {"name": "Natural Compounds in Disease Treatment", "value": 12253, "id": "https://openalex.org/T13026"}, {"name": "Papaya Research and Applications", "value": 9919, "id": "https://openalex.org/T14478"}, {"name": "Andrographolide Research and Applications", "value": 9225, "id": "https://openalex.org/T13281"}, {"name": "Mangiferin and Mango Extracts", "value": 6318, "id": "https://openalex.org/T13846"}]}, {"name": "Emergency Medicine", "children": [{"name": "Cardiac Arrest and Resuscitation", "value": 123690, "id": "https://openalex.org/T10645"}, {"name": "Trauma and Emergency Care Studies", "value": 85218, "id": "https://openalex.org/T11467"}, {"name": "Poisoning and overdose treatments", "value": 76778, "id": "https://openalex.org/T11635"}, {"name": "Hematological disorders and diagnostics", "value": 76652, "id": "https://openalex.org/T13374"}, {"name": "Emergency and Acute Care Studies", "value": 76111, "id": "https://openalex.org/T11095"}, {"name": "Appendicitis Diagnosis and Management", "value": 61843, "id": "https://openalex.org/T11473"}, {"name": "HIV-related health complications and treatments", "value": 40313, "id": "https://openalex.org/T11655"}, {"name": "Restraint-Related Deaths", "value": 32938, "id": "https://openalex.org/T13001"}, {"name": "Hospital Admissions and Outcomes", "value": 21580, "id": "https://openalex.org/T12174"}, {"name": "Intramuscular injections and effects", "value": 21439, "id": "https://openalex.org/T14126"}, {"name": "Emergency Medicine Education and Research", "value": 6600, "id": "https://openalex.org/T14354"}]}, {"name": "Immunology and Allergy", "children": [{"name": "Cell Adhesion Molecules Research", "value": 121753, "id": "https://openalex.org/T10831"}, {"name": "Allergic Rhinitis and Sensitization", "value": 85349, "id": "https://openalex.org/T10877"}, {"name": "Food Allergy and Anaphylaxis Research", "value": 65698, "id": "https://openalex.org/T10634"}]}, {"name": "Neurology", "children": [{"name": "Parkinson's Disease Mechanisms and Treatments", "value": 120013, "id": "https://openalex.org/T10085"}, {"name": "Traumatic Brain Injury and Neurovascular Disturbances", "value": 117467, "id": "https://openalex.org/T10706"}, {"name": "History of Medical Practice", "value": 97819, "id": "https://openalex.org/T13735"}, {"name": "Neurological disorders and treatments", "value": 85099, "id": "https://openalex.org/T10919"}, {"name": "Intracranial Aneurysms: Treatment and Complications", "value": 82298, "id": "https://openalex.org/T10420"}, {"name": "Botulinum Toxin and Related Neurological Disorders", "value": 80050, "id": "https://openalex.org/T11274"}, {"name": "Myasthenia Gravis and Thymoma", "value": 67459, "id": "https://openalex.org/T11271"}, {"name": "Amyotrophic Lateral Sclerosis Research", "value": 55978, "id": "https://openalex.org/T10855"}, {"name": "Long-Term Effects of COVID-19", "value": 54878, "id": "https://openalex.org/T11368"}, {"name": "Neuroblastoma Research and Treatments", "value": 51716, "id": "https://openalex.org/T12226"}, {"name": "Neurofibromatosis and Schwannoma Cases", "value": 51114, "id": "https://openalex.org/T11173"}, {"name": "Vascular Malformations Diagnosis and Treatment", "value": 47436, "id": "https://openalex.org/T11402"}, {"name": "Intracerebral and Subarachnoid Hemorrhage Research", "value": 46038, "id": "https://openalex.org/T11763"}, {"name": "Alcoholism and Thiamine Deficiency", "value": 44723, "id": "https://openalex.org/T12494"}, {"name": "Peripheral Neuropathies and Disorders", "value": 43078, "id": "https://openalex.org/T11735"}, {"name": "Cerebral Venous Sinus Thrombosis", "value": 40094, "id": "https://openalex.org/T11929"}, {"name": "Facial Nerve Paralysis Treatment and Research", "value": 37720, "id": "https://openalex.org/T12301"}, {"name": "Neurosurgical Procedures and Complications", "value": 30035, "id": "https://openalex.org/T12622"}, {"name": "Autoimmune Neurological Disorders and Treatments", "value": 26403, "id": "https://openalex.org/T11627"}, {"name": "CNS Lymphoma Diagnosis and Treatment", "value": 24303, "id": "https://openalex.org/T12212"}, {"name": "Cerebrovascular and genetic disorders", "value": 16920, "id": "https://openalex.org/T13648"}, {"name": "Parkinson's Disease and Spinal Disorders", "value": 16751, "id": "https://openalex.org/T14286"}]}, {"name": "Rheumatology", "children": [{"name": "Pelvic floor disorders treatments", "value": 119448, "id": "https://openalex.org/T10418"}, {"name": "Systemic Lupus Erythematosus Research", "value": 118305, "id": "https://openalex.org/T10308"}, {"name": "Osteoarthritis Treatment and Mechanisms", "value": 114970, "id": "https://openalex.org/T10105"}, {"name": "Rheumatoid Arthritis Research and Therapies", "value": 112089, "id": "https://openalex.org/T10200"}, {"name": "Folate and B Vitamins Research", "value": 91307, "id": "https://openalex.org/T10499"}, {"name": "Bone Tumor Diagnosis and Treatments", "value": 74174, "id": "https://openalex.org/T10975"}, {"name": "Urticaria and Related Conditions", "value": 64880, "id": "https://openalex.org/T12438"}, {"name": "Spondyloarthritis Studies and Treatments", "value": 47094, "id": "https://openalex.org/T11092"}, {"name": "Soft tissue tumor case studies", "value": 45552, "id": "https://openalex.org/T11991"}, {"name": "Eosinophilic Disorders and Syndromes", "value": 37610, "id": "https://openalex.org/T12600"}, {"name": "Bone and Dental Protein Studies", "value": 36661, "id": "https://openalex.org/T12110"}, {"name": "Urologic and reproductive health conditions", "value": 33504, "id": "https://openalex.org/T12866"}, {"name": "Glycogen Storage Diseases and Myoclonus", "value": 30708, "id": "https://openalex.org/T12604"}, {"name": "Musculoskeletal synovial abnormalities and treatments", "value": 30224, "id": "https://openalex.org/T12800"}, {"name": "IgG4-Related and Inflammatory Diseases", "value": 29634, "id": "https://openalex.org/T11576"}, {"name": "Dupuytren's Contracture and Treatments", "value": 23030, "id": "https://openalex.org/T13313"}, {"name": "Osteomyelitis and Bone Disorders Research", "value": 17424, "id": "https://openalex.org/T13328"}, {"name": "GDF15 and Related Biomarkers", "value": 14602, "id": "https://openalex.org/T13452"}, {"name": "Otitis Media and Relapsing Polychondritis", "value": 13198, "id": "https://openalex.org/T14015"}, {"name": "Moyamoya disease diagnosis and treatment", "value": 12883, "id": "https://openalex.org/T12747"}, {"name": "Oropharyngeal Anatomy and Pathologies", "value": 11799, "id": "https://openalex.org/T13543"}, {"name": "Heterotopic Ossification and Related Conditions", "value": 11688, "id": "https://openalex.org/T12960"}, {"name": "Hypertrophic osteoarthropathy and related conditions", "value": 10958, "id": "https://openalex.org/T14057"}, {"name": "Omental and Epiploic Conditions", "value": 8303, "id": "https://openalex.org/T13962"}]}, {"name": "Endocrinology, Diabetes and Metabolism", "children": [{"name": "Thyroid Disorders and Treatments", "value": 114738, "id": "https://openalex.org/T10293"}, {"name": "Diabetes Management and Research", "value": 112025, "id": "https://openalex.org/T10560"}, {"name": "Diabetes Treatment and Management", "value": 104468, "id": "https://openalex.org/T10401"}, {"name": "Growth Hormone and Insulin-like Growth Factors", "value": 104331, "id": "https://openalex.org/T10748"}, {"name": "Thyroid Cancer Diagnosis and Treatment", "value": 98338, "id": "https://openalex.org/T10329"}, {"name": "Pituitary Gland Disorders and Treatments", "value": 98185, "id": "https://openalex.org/T10832"}, {"name": "Hormonal and reproductive studies", "value": 88610, "id": "https://openalex.org/T11146"}, {"name": "Diabetes, Cardiovascular Risks, and Lipoproteins", "value": 86697, "id": "https://openalex.org/T10027"}, {"name": "Hormonal Regulation and Hypertension", "value": 81426, "id": "https://openalex.org/T11839"}, {"name": "Diabetic Foot Ulcer Assessment and Management", "value": 79515, "id": "https://openalex.org/T11227"}, {"name": "Diet, Metabolism, and Disease", "value": 65254, "id": "https://openalex.org/T12964"}, {"name": "Natural Antidiabetic Agents Studies", "value": 64456, "id": "https://openalex.org/T11140"}, {"name": "Diabetes Management and Education", "value": 62517, "id": "https://openalex.org/T10793"}, {"name": "Adrenal Hormones and Disorders", "value": 56986, "id": "https://openalex.org/T12421"}, {"name": "Hyperglycemia and glycemic control in critically ill and hospitalized patients", "value": 46312, "id": "https://openalex.org/T11623"}, {"name": "Neurological and metabolic disorders", "value": 42788, "id": "https://openalex.org/T13966"}, {"name": "Menopause: Health Impacts and Treatments", "value": 37025, "id": "https://openalex.org/T10694"}, {"name": "Alkaline Phosphatase Research Studies", "value": 26126, "id": "https://openalex.org/T13453"}]}, {"name": "Rehabilitation", "children": [{"name": "Stroke Rehabilitation and Recovery", "value": 114647, "id": "https://openalex.org/T10510"}, {"name": "Wound Healing and Treatments", "value": 82459, "id": "https://openalex.org/T10771"}, {"name": "Musculoskeletal Disorders and Rehabilitation", "value": 73973, "id": "https://openalex.org/T13946"}, {"name": "Exercise and Physiological Responses", "value": 50310, "id": "https://openalex.org/T11585"}, {"name": "Musicians\u2019 Health and Performance", "value": 40231, "id": "https://openalex.org/T14034"}, {"name": "Elbow and Forearm Trauma Treatment", "value": 37359, "id": "https://openalex.org/T11427"}, {"name": "Magnolia and Illicium research", "value": 10297, "id": "https://openalex.org/T13677"}]}, {"name": "Otorhinolaryngology", "children": [{"name": "Head and Neck Cancer Studies", "value": 112255, "id": "https://openalex.org/T10307"}, {"name": "Sinusitis and nasal conditions", "value": 71255, "id": "https://openalex.org/T10984"}, {"name": "Ear Surgery and Otitis Media", "value": 64027, "id": "https://openalex.org/T10861"}]}, {"name": "Hematology", "children": [{"name": "Acute Myeloid Leukemia Research", "value": 110846, "id": "https://openalex.org/T10309"}, {"name": "Multiple Myeloma Research and Treatments", "value": 88623, "id": "https://openalex.org/T10649"}, {"name": "Blood groups and transfusion", "value": 85247, "id": "https://openalex.org/T11660"}, {"name": "Iron Metabolism and Disorders", "value": 82761, "id": "https://openalex.org/T10452"}, {"name": "Platelet Disorders and Treatments", "value": 73534, "id": "https://openalex.org/T10746"}, {"name": "Hematopoietic Stem Cell Transplantation", "value": 73226, "id": "https://openalex.org/T10345"}, {"name": "Chronic Myeloid Leukemia Treatments", "value": 65558, "id": "https://openalex.org/T11215"}, {"name": "Blood Coagulation and Thrombosis Mechanisms", "value": 59693, "id": "https://openalex.org/T10881"}, {"name": "Hemophilia Treatment and Research", "value": 47722, "id": "https://openalex.org/T11280"}, {"name": "Autoimmune and Inflammatory Disorders Research", "value": 44258, "id": "https://openalex.org/T11616"}, {"name": "Erythropoietin and Anemia Treatment", "value": 31225, "id": "https://openalex.org/T11534"}, {"name": "Hemostasis and retained surgical items", "value": 17967, "id": "https://openalex.org/T12548"}]}, {"name": "Urology", "children": [{"name": "Urological Disorders and Treatments", "value": 103797, "id": "https://openalex.org/T11815"}, {"name": "Urinary Bladder and Prostate Research", "value": 94052, "id": "https://openalex.org/T10279"}, {"name": "Periodontal Regeneration and Treatments", "value": 50851, "id": "https://openalex.org/T11570"}, {"name": "Hair Growth and Disorders", "value": 45560, "id": "https://openalex.org/T11167"}, {"name": "Comparative Animal Anatomy Studies", "value": 39385, "id": "https://openalex.org/T13100"}]}, {"name": "Anesthesiology and Pain Medicine", "children": [{"name": "Airway Management and Intubation Techniques", "value": 103763, "id": "https://openalex.org/T10830"}, {"name": "Anesthesia and Sedative Agents", "value": 102530, "id": "https://openalex.org/T10436"}, {"name": "Pain Management and Opioid Use", "value": 47903, "id": "https://openalex.org/T11199"}, {"name": "Pain Management and Treatment", "value": 35365, "id": "https://openalex.org/T11840"}]}, {"name": "Nephrology", "children": [{"name": "Dialysis and Renal Disease Management", "value": 99166, "id": "https://openalex.org/T10291"}, {"name": "Parathyroid Disorders and Treatments", "value": 90873, "id": "https://openalex.org/T10516"}, {"name": "Renal Diseases and Glomerulopathies", "value": 78575, "id": "https://openalex.org/T11029"}, {"name": "Renal function and acid-base balance", "value": 71488, "id": "https://openalex.org/T12840"}, {"name": "Acute Kidney Injury Research", "value": 52358, "id": "https://openalex.org/T10684"}, {"name": "Gout, Hyperuricemia, Uric Acid", "value": 51771, "id": "https://openalex.org/T11139"}, {"name": "Chronic Kidney Disease and Diabetes", "value": 51125, "id": "https://openalex.org/T10408"}]}, {"name": "Health Informatics", "children": [{"name": "Artificial Intelligence in Healthcare and Education", "value": 98640, "id": "https://openalex.org/T11636"}]}, {"name": "Biochemistry", "children": [{"name": "Phytochemicals and Antioxidant Activities", "value": 88771, "id": "https://openalex.org/T10035"}, {"name": "Antioxidant Activity and Oxidative Stress", "value": 67714, "id": "https://openalex.org/T10445"}, {"name": "Blood transfusion and management", "value": 42882, "id": "https://openalex.org/T10693"}]}, {"name": "Gastroenterology", "children": [{"name": "Gastroesophageal reflux and treatments", "value": 83718, "id": "https://openalex.org/T10671"}, {"name": "Gastrointestinal motility and disorders", "value": 79037, "id": "https://openalex.org/T10365"}, {"name": "Gastrointestinal Tumor Research and Treatment", "value": 53566, "id": "https://openalex.org/T11485"}, {"name": "Celiac Disease Research and Management", "value": 49516, "id": "https://openalex.org/T11348"}, {"name": "Gastrointestinal Bleeding Diagnosis and Treatment", "value": 40003, "id": "https://openalex.org/T11378"}]}, {"name": "Transplantation", "children": [{"name": "Renal Transplantation Outcomes and Treatments", "value": 75825, "id": "https://openalex.org/T10373"}, {"name": "Organ and Tissue Transplantation Research", "value": 26960, "id": "https://openalex.org/T12900"}]}, {"name": "Critical Care and Intensive Care Medicine", "children": [{"name": "Intensive Care Unit Cognitive Disorders", "value": 66885, "id": "https://openalex.org/T10867"}, {"name": "Trauma, Hemostasis, Coagulopathy, Resuscitation", "value": 43623, "id": "https://openalex.org/T11116"}, {"name": "Thermal Regulation in Medicine", "value": 42951, "id": "https://openalex.org/T11861"}, {"name": "Ultrasound in Clinical Applications", "value": 39275, "id": "https://openalex.org/T11738"}, {"name": "Nosocomial Infections in ICU", "value": 37640, "id": "https://openalex.org/T11681"}]}, {"name": "Microbiology", "children": [{"name": "Actinomycetales infections and treatment", "value": 57806, "id": "https://openalex.org/T12317"}]}, {"name": "Family Practice", "children": [{"name": "Medication Adherence and Compliance", "value": 35130, "id": "https://openalex.org/T11620"}, {"name": "Clinical Reasoning and Diagnostic Skills", "value": 34722, "id": "https://openalex.org/T12574"}]}]}, {"name": "Health Professions", "children": [{"name": "General Health Professions", "children": [{"name": "Health, Medicine and Society", "value": 257531, "id": "https://openalex.org/T13099"}, {"name": "Health and Medical Studies", "value": 216002, "id": "https://openalex.org/T13022"}, {"name": "Healthcare Systems and Practices", "value": 191362, "id": "https://openalex.org/T14186"}, {"name": "Child and Adolescent Health", "value": 178227, "id": "https://openalex.org/T13883"}, {"name": "Primary Care and Health Outcomes", "value": 164594, "id": "https://openalex.org/T11590"}, {"name": "Ethics in medical practice", "value": 139158, "id": "https://openalex.org/T11537"}, {"name": "Aging, Elder Care, and Social Issues", "value": 138613, "id": "https://openalex.org/T13695"}, {"name": "Health and Lifestyle Studies", "value": 132381, "id": "https://openalex.org/T13861"}, {"name": "Employment and Welfare Studies", "value": 129377, "id": "https://openalex.org/T11959"}, {"name": "Health, Nursing, Elderly Care", "value": 118981, "id": "https://openalex.org/T10312"}, {"name": "Homelessness and Social Issues", "value": 113615, "id": "https://openalex.org/T11464"}, {"name": "Health Sciences Research and Education", "value": 107433, "id": "https://openalex.org/T11744"}, {"name": "Food Security and Health in Diverse Populations", "value": 105691, "id": "https://openalex.org/T11610"}, {"name": "Health and Medical Education", "value": 105249, "id": "https://openalex.org/T12413"}, {"name": "Social and Demographic Issues in Germany", "value": 104590, "id": "https://openalex.org/T14118"}, {"name": "Global Health Care Issues", "value": 103471, "id": "https://openalex.org/T12781"}, {"name": "Dental Education, Practice, Research", "value": 97801, "id": "https://openalex.org/T13457"}, {"name": "Geriatric Care and Nursing Homes", "value": 94411, "id": "https://openalex.org/T11376"}, {"name": "Indigenous Studies and Ecology", "value": 90788, "id": "https://openalex.org/T12614"}, {"name": "Adolescent Sexual and Reproductive Health", "value": 89170, "id": "https://openalex.org/T10327"}, {"name": "Maternal and Neonatal Healthcare", "value": 87876, "id": "https://openalex.org/T12741"}, {"name": "Health and Conflict Studies", "value": 85867, "id": "https://openalex.org/T14090"}, {"name": "Health and Wellbeing Research", "value": 77806, "id": "https://openalex.org/T12480"}, {"name": "Public Health Policies and Education", "value": 77336, "id": "https://openalex.org/T12041"}, {"name": "Mobile Health and mHealth Applications", "value": 74600, "id": "https://openalex.org/T11446"}, {"name": "Healthcare Systems and Challenges", "value": 74162, "id": "https://openalex.org/T12847"}, {"name": "Healthcare Quality and Satisfaction", "value": 66001, "id": "https://openalex.org/T14358"}, {"name": "Interprofessional Education and Collaboration", "value": 63348, "id": "https://openalex.org/T11497"}, {"name": "Workplace Health and Well-being", "value": 62218, "id": "https://openalex.org/T11084"}, {"name": "Healthcare professionals\u2019 stress and burnout", "value": 61756, "id": "https://openalex.org/T10795"}, {"name": "Nursing Roles and Practices", "value": 58361, "id": "https://openalex.org/T11816"}, {"name": "Interpreting and Communication in Healthcare", "value": 50761, "id": "https://openalex.org/T12151"}, {"name": "Global Healthcare and Medical Tourism", "value": 50032, "id": "https://openalex.org/T12681"}, {"name": "Diverse Scientific Research Studies", "value": 49062, "id": "https://openalex.org/T14463"}, {"name": "Mental Health and Patient Involvement", "value": 49030, "id": "https://openalex.org/T11639"}, {"name": "Patient Satisfaction in Healthcare", "value": 46400, "id": "https://openalex.org/T11722"}, {"name": "Patient-Provider Communication in Healthcare", "value": 46076, "id": "https://openalex.org/T10827"}, {"name": "Health Policy Implementation Science", "value": 45583, "id": "https://openalex.org/T10629"}, {"name": "Health, psychology, and well-being", "value": 44666, "id": "https://openalex.org/T12947"}, {"name": "Community Health and Development", "value": 43255, "id": "https://openalex.org/T12196"}, {"name": "Health Literacy and Information Accessibility", "value": 41772, "id": "https://openalex.org/T10737"}, {"name": "Healthcare cost, quality, practices", "value": 41191, "id": "https://openalex.org/T13555"}, {"name": "Health Services Management and Policy", "value": 40405, "id": "https://openalex.org/T13896"}, {"name": "Indigenous Health and Education", "value": 30428, "id": "https://openalex.org/T13822"}, {"name": "Romani and Gypsy Studies", "value": 30014, "id": "https://openalex.org/T12595"}, {"name": "Social Policies and Healthcare Reform", "value": 29661, "id": "https://openalex.org/T13423"}, {"name": "Male Reproductive Health Studies", "value": 23151, "id": "https://openalex.org/T13242"}, {"name": "Doctoral Education Challenges and Solutions", "value": 21202, "id": "https://openalex.org/T11832"}, {"name": "Adolescent Health and Behaviors", "value": 19106, "id": "https://openalex.org/T13805"}, {"name": "Healthcare, Law, Governance, and Management Studies", "value": 3788, "id": "https://openalex.org/T14130"}]}, {"name": "Radiological and Ultrasound Technology", "children": [{"name": "Occupational Health and Safety Research", "value": 150368, "id": "https://openalex.org/T10809"}, {"name": "Radioactivity and Radon Measurements", "value": 61201, "id": "https://openalex.org/T10946"}, {"name": "Family and Patient Care in Intensive Care Units", "value": 48427, "id": "https://openalex.org/T12860"}]}, {"name": "Pharmacy", "children": [{"name": "Medical Malpractice and Liability Issues", "value": 140606, "id": "https://openalex.org/T12339"}, {"name": "Obesity and Health Practices", "value": 51968, "id": "https://openalex.org/T12066"}, {"name": "Infant Health and Development", "value": 45819, "id": "https://openalex.org/T13289"}, {"name": "Oral and gingival health research", "value": 40571, "id": "https://openalex.org/T13768"}, {"name": "Nursing care and research", "value": 35440, "id": "https://openalex.org/T13111"}]}, {"name": "Emergency Medical Services", "children": [{"name": "Disaster Response and Management", "value": 128618, "id": "https://openalex.org/T11430"}, {"name": "Global Health Workforce Issues", "value": 104910, "id": "https://openalex.org/T11990"}, {"name": "Pediatric health and respiratory diseases", "value": 94628, "id": "https://openalex.org/T13770"}, {"name": "Central Venous Catheters and Hemodialysis", "value": 84136, "id": "https://openalex.org/T10641"}, {"name": "Patient Safety and Medication Errors", "value": 48168, "id": "https://openalex.org/T10508"}, {"name": "Dental Trauma and Treatments", "value": 32477, "id": "https://openalex.org/T12367"}, {"name": "Healthcare Operations and Scheduling Optimization", "value": 29192, "id": "https://openalex.org/T11773"}]}, {"name": "Physical Therapy, Sports Therapy and Rehabilitation", "children": [{"name": "Medical Practices and Rehabilitation", "value": 125231, "id": "https://openalex.org/T13986"}, {"name": "Sports and Physical Education Research", "value": 123719, "id": "https://openalex.org/T13224"}, {"name": "Balance, Gait, and Falls Prevention", "value": 69025, "id": "https://openalex.org/T10114"}, {"name": "Physical Education and Training Studies", "value": 65354, "id": "https://openalex.org/T13189"}, {"name": "Physical Education and Pedagogy", "value": 64102, "id": "https://openalex.org/T11718"}, {"name": "Older Adults Driving Studies", "value": 22093, "id": "https://openalex.org/T12315"}, {"name": "Athletic Training and Education", "value": 7496, "id": "https://openalex.org/T14407"}]}, {"name": "Occupational Therapy", "children": [{"name": "Occupational Health and Safety in Workplaces", "value": 96955, "id": "https://openalex.org/T13315"}, {"name": "Occupational Health and Safety Management", "value": 67229, "id": "https://openalex.org/T13233"}, {"name": "Occupational Therapy Practice and Research", "value": 54977, "id": "https://openalex.org/T11759"}, {"name": "Pressure Ulcer Prevention and Management", "value": 35021, "id": "https://openalex.org/T11670"}, {"name": "Occupational Health and Burnout", "value": 33983, "id": "https://openalex.org/T12869"}, {"name": "Occupational Health and Performance", "value": 32981, "id": "https://openalex.org/T12138"}, {"name": "Assistive Technology in Communication and Mobility", "value": 32198, "id": "https://openalex.org/T12207"}, {"name": "Safe Handling of Antineoplastic Drugs", "value": 14044, "id": "https://openalex.org/T13279"}]}, {"name": "Speech and Hearing", "children": [{"name": "School Health and Nursing Education", "value": 94890, "id": "https://openalex.org/T12831"}, {"name": "Noise Effects and Management", "value": 88011, "id": "https://openalex.org/T11692"}, {"name": "History, Culture, and Society", "value": 63352, "id": "https://openalex.org/T14507"}, {"name": "Veterinary Practice and Education Studies", "value": 56033, "id": "https://openalex.org/T13036"}, {"name": "Dysphagia Assessment and Management", "value": 52952, "id": "https://openalex.org/T11358"}, {"name": "Digital Storytelling and Education", "value": 49098, "id": "https://openalex.org/T13071"}, {"name": "Adolescent and Pediatric Healthcare", "value": 45202, "id": "https://openalex.org/T12823"}, {"name": "Neonatal skin health care", "value": 42065, "id": "https://openalex.org/T13206"}, {"name": "Problem Solving Skills Development", "value": 22587, "id": "https://openalex.org/T14040"}, {"name": "Oral and Craniofacial Lesions", "value": 22189, "id": "https://openalex.org/T13813"}]}, {"name": "Medical Laboratory Technology", "children": [{"name": "Quality and Safety in Healthcare", "value": 90155, "id": "https://openalex.org/T13690"}, {"name": "Occupational health in dentistry", "value": 13057, "id": "https://openalex.org/T13866"}]}, {"name": "Health Information Management", "children": [{"name": "Electronic Health Records Systems", "value": 74656, "id": "https://openalex.org/T10350"}, {"name": "Artificial Intelligence in Healthcare", "value": 72753, "id": "https://openalex.org/T11396"}, {"name": "Medical Coding and Health Information", "value": 52672, "id": "https://openalex.org/T14400"}, {"name": "Healthcare Quality and Management", "value": 50207, "id": "https://openalex.org/T12871"}, {"name": "Healthcare Regulation", "value": 42843, "id": "https://openalex.org/T14396"}, {"name": "Dietetics, Nutrition, and Education", "value": 36616, "id": "https://openalex.org/T13960"}, {"name": "Methodologies in Health Research and Practice", "value": 30015, "id": "https://openalex.org/T11555"}, {"name": "Film in Education and Therapy", "value": 26356, "id": "https://openalex.org/T13319"}, {"name": "Global Health and Epidemiology", "value": 24515, "id": "https://openalex.org/T14093"}, {"name": "Innovation in Digital Healthcare Systems", "value": 23393, "id": "https://openalex.org/T13243"}, {"name": "Health, Technology, Consumer Behavior", "value": 15966, "id": "https://openalex.org/T14416"}, {"name": "Trade Secret Protection Methods", "value": 6569, "id": "https://openalex.org/T14447"}]}, {"name": "Complementary and Manual Therapy", "children": [{"name": "Temporomandibular Joint Disorders", "value": 59244, "id": "https://openalex.org/T10852"}, {"name": "Therapeutic Uses of Natural Elements", "value": 57341, "id": "https://openalex.org/T13108"}]}, {"name": "Medical Terminology", "children": [{"name": "Medical Research and Practices", "value": 40128, "id": "https://openalex.org/T14514"}]}]}, {"name": "Nursing", "children": [{"name": "Nutrition and Dietetics", "children": [{"name": "Child Nutrition and Water Access", "value": 152406, "id": "https://openalex.org/T10596"}, {"name": "Food composition and properties", "value": 112655, "id": "https://openalex.org/T10140"}, {"name": "Clinical Nutrition and Gastroenterology", "value": 105291, "id": "https://openalex.org/T10858"}, {"name": "Trace Elements in Health", "value": 88971, "id": "https://openalex.org/T10915"}, {"name": "Fatty Acid Research and Health", "value": 76853, "id": "https://openalex.org/T10387"}, {"name": "Infant Nutrition and Health", "value": 61930, "id": "https://openalex.org/T11294"}, {"name": "Biochemical Analysis and Sensing Techniques", "value": 60390, "id": "https://openalex.org/T11584"}, {"name": "Microbial Metabolites in Food Biotechnology", "value": 59250, "id": "https://openalex.org/T12489"}, {"name": "Vitamin C and Antioxidants Research", "value": 54829, "id": "https://openalex.org/T12554"}, {"name": "Selenium in Biological Systems", "value": 53570, "id": "https://openalex.org/T11107"}, {"name": "Nuts composition and effects", "value": 49691, "id": "https://openalex.org/T12314"}, {"name": "Nutrition, Health and Food Behavior", "value": 45263, "id": "https://openalex.org/T12873"}, {"name": "Sodium Intake and Health", "value": 27548, "id": "https://openalex.org/T12075"}, {"name": "Magnesium in Health and Disease", "value": 26855, "id": "https://openalex.org/T12280"}, {"name": "Vitamin K Research Studies", "value": 23242, "id": "https://openalex.org/T13004"}, {"name": "Food Science and Nutritional Studies", "value": 22308, "id": "https://openalex.org/T13479"}, {"name": "Pomegranate: compositions and health benefits", "value": 16849, "id": "https://openalex.org/T12638"}]}, {"name": "Issues, ethics and legal aspects", "children": [{"name": "Nursing Education, Practice, and Leadership", "value": 112070, "id": "https://openalex.org/T14316"}, {"name": "Nursing Diagnosis and Documentation", "value": 39783, "id": "https://openalex.org/T12790"}]}, {"name": "Leadership and Management", "children": [{"name": "Healthcare Education and Workforce Issues", "value": 54366, "id": "https://openalex.org/T12244"}]}, {"name": "Research and Theory", "children": [{"name": "Nursing education and management", "value": 33640, "id": "https://openalex.org/T10186"}]}]}, {"name": "Dentistry", "children": [{"name": "Periodontics", "children": [{"name": "Oral microbiology and periodontitis research", "value": 120726, "id": "https://openalex.org/T10257"}, {"name": "Dental Health and Care Utilization", "value": 91035, "id": "https://openalex.org/T10368"}, {"name": "Oral Health Pathology and Treatment", "value": 66147, "id": "https://openalex.org/T11452"}, {"name": "Scientific and Engineering Research Topics", "value": 6957, "id": "https://openalex.org/T13324"}]}, {"name": "Oral Surgery", "children": [{"name": "Dental Implant Techniques and Outcomes", "value": 118569, "id": "https://openalex.org/T10359"}, {"name": "Endodontics and Root Canal Treatments", "value": 85233, "id": "https://openalex.org/T10536"}, {"name": "Oral and Maxillofacial Pathology", "value": 70914, "id": "https://openalex.org/T11787"}, {"name": "Dental Radiography and Imaging", "value": 66068, "id": "https://openalex.org/T11363"}, {"name": "Dental Anxiety and Anesthesia Techniques", "value": 40751, "id": "https://openalex.org/T12145"}]}, {"name": "Orthodontics", "children": [{"name": "Dental materials and restorations", "value": 110727, "id": "https://openalex.org/T10113"}, {"name": "Orthodontics and Dentofacial Orthopedics", "value": 68991, "id": "https://openalex.org/T10356"}, {"name": "Dental Erosion and Treatment", "value": 37175, "id": "https://openalex.org/T11958"}]}, {"name": "General Dentistry", "children": [{"name": "Dental Research and COVID-19", "value": 54322, "id": "https://openalex.org/T12439"}]}]}, {"name": "Veterinary", "children": [{"name": "Small Animals", "children": [{"name": "Animal Behavior and Welfare Studies", "value": 75621, "id": "https://openalex.org/T10838"}, {"name": "Helminth infection and control", "value": 68651, "id": "https://openalex.org/T11074"}, {"name": "Animal testing and alternatives", "value": 53698, "id": "https://openalex.org/T12281"}, {"name": "Brucella: diagnosis, epidemiology, treatment", "value": 40588, "id": "https://openalex.org/T11899"}, {"name": "Veterinary Pharmacology and Anesthesia", "value": 36444, "id": "https://openalex.org/T11905"}, {"name": "Animal health and immunology", "value": 34919, "id": "https://openalex.org/T12322"}, {"name": "Infectious Diseases and Mycology", "value": 32836, "id": "https://openalex.org/T13385"}, {"name": "Veterinary Medicine and Surgery", "value": 31102, "id": "https://openalex.org/T11580"}, {"name": "Veterinary Orthopedics and Neurology", "value": 29990, "id": "https://openalex.org/T12249"}, {"name": "Veterinary medicine and infectious diseases", "value": 16761, "id": "https://openalex.org/T13791"}]}, {"name": "Equine", "children": [{"name": "Veterinary Equine Medical Research", "value": 60044, "id": "https://openalex.org/T10872"}]}]}]}]}

==================================================
FILE: src/1_search_omni.py
==================================================
import argparse
import time
import json
import pandas as pd
import requests
import arxiv
from semanticscholar import SemanticScholar
from unpywall import Unpywall
from tqdm import tqdm
import os
import re
from urllib.parse import urlparse
import datetime
from dotenv import load_dotenv
import sys
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
import fitz  # PyMuPDF
try:
    from unpywall.utils import UnpywallCredentials
    from unpywall import Unpywall
    # Monkeypatch or configure cache if library supports it.
    # If not, we just accept no cache or use environmental variable if applicable.
    # Looking at unpywall source (common knowledge), it uses `requests_cache`.
    import requests_cache
    cache_path = os.path.join(os.path.dirname(__file__), "../data/unpaywall_cache")
    requests_cache.install_cache(cache_path, backend='sqlite', expire_after=86400)
except: pass

# --- Suppress Warnings (Must be before imports that trigger them) ---
warnings.filterwarnings("ignore")
os.environ["GRPC_VERBOSITY"] = "ERROR" # Silence Google GRPC warnings

# Load Environment
# Load Environment (Force Override to ignore stale shell vars)
# Load environment variables (Force override to ensure fresh keys)
load_dotenv(override=True)

# Check for Google API
# Check for Google API
try:
    from google import genai
    HAS_GENAI = True
except ImportError:
    HAS_GENAI = False

# Robust Request Session
def get_session():
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

def reconstruct_abstract(inverted_index):
    if not inverted_index: return ""
    max_index = max(max(pos) for pos in inverted_index.values())
    words = [""] * (max_index + 1)
    for word, positions in inverted_index.items():
        for pos in positions: words[pos] = word
    return " ".join(words)

class ResearchCrawler:
    def __init__(self, topic, keywords, author, publication, date_start, date_end, count, sites, keyword_logic='any', no_llm=False):
        self.keyword_logic = keyword_logic if keyword_logic else 'any'
        self.no_llm = no_llm
        
        self.offsets = {'semantic': 0, 'arxiv': 0}
        if os.path.exists("research_catalog.csv"):
            try: os.remove("research_catalog.csv")
            except: pass

        self.raw_topic = topic
        raw_keywords = [k.strip() for k in keywords.split(',')] if keywords else []
        self.keywords_list = list(raw_keywords)
        self.author = author
        self.publication = publication
        
        self.date_start = date_start
        self.date_end = date_end
        self.year_start = int(date_start[:4]) if date_start else 2000
        self.year_end = int(date_end[:4]) if date_end else 2030
        
        self.final_target_count = int(count)
        # Buffer: Fetch 5x what user asked for to allow for high-quality filtering
        self.target_count = int(self.final_target_count * 5.0) 
        
        self.sites = sites if sites else ['all']
        self.results = []
        self.seen_dois = set()
        self.seen_titles = set()
        self.seen_ids = set()
        
        self.session = get_session()
        self.keyword_logic = keyword_logic if keyword_logic else 'any'
        
        self.offsets = {'semantic': 0, 'arxiv': 0}

    def _normalize_date(self, date_str):
        if not date_str: return f"{self.year_start}/01/01"
        try:
            if re.match(r'^\d{4}$', str(date_str)): return f"{date_str}/01/01"
            return str(date_str).replace('-', '/')
        except: return f"{self.year_start}/01/01"

    def _is_date_in_range(self, date_str):
        try:
            d = datetime.datetime.strptime(self._normalize_date(date_str), "%Y/%m/%d").date()
            start = datetime.datetime.strptime(self.date_start, "%Y-%m-%d").date() if self.date_start else None
            end = datetime.datetime.strptime(self.date_end, "%Y-%m-%d").date() if self.date_end else None
            if start and d < start: return False
            if end and d > end: return False
            return True
        except: return True

    def _parse_filename(self, url):
        if not url: return 'Pending_Header_Check'
        path = urlparse(url).path
        filename = os.path.basename(path)
        if filename and (filename.lower().endswith('.pdf') or 'pdf' in url.lower()):
            if not filename.lower().endswith('.pdf'): return filename + ".pdf"
            return filename
        return 'Pending_Header_Check'

    def _validate_full_text(self, pdf_content, keywords):
        """
        Robust Front-Matter Audit:
        Scans first ~2 pages. Ignores 'Movie' annotations to prevent crashes.
        """
        try:
            # 1. Open Document (from bytes)
            doc = fitz.open(stream=pdf_content, filetype="pdf")
            text_block = ""
            
            # 2. Limit to First 2 Pages (Front-Matter)
            for i in range(min(2, doc.page_count)):
                page = doc.load_page(i)
                # Use 'text' mode with flags to be robust
                # PRP 9.9.5: Added MEDIABOX_CLIP to avoid reading hidden/cropped text
                text_block += page.get_text("text", flags=fitz.TEXT_PRESERVE_WHITESPACE | fitz.TEXT_DEHYPHENATE | fitz.TEXT_MEDIABOX_CLIP) + " "
            
            doc.close()
            
            # 3. Fuzzy Regex Check
            blob = text_block.lower()
            
            for k in keywords:
                # Fuzzy Regex Construction
                clean_k = k.replace('"', '').strip().lower()
                fuzzy_k = clean_k.replace(" ", r"[\s\-]*")
                if "crosstalk" in clean_k:
                    fuzzy_k = fuzzy_k.replace("crosstalk", r"cross[\s\-]*talk")
                
                pattern = fuzzy_k + r"s?" 
                
                if re.search(pattern, blob):
                    return True, f"Found match for '{clean_k}'"
                    
            return False, "No keywords found in Front-Matter"
            
        except RuntimeError as e:
            # PRP 9.9.5: Catch specific MuPDF RuntimeErrors (e.g. 'syntax error')
            return False, f"PDF Runtime Logic Error: {e}"
        except Exception as e:
            # Catch general errors
            return False, f"PDF Audit Skipped: {e}"

    def _pre_filter(self, title, date, doi):
        if not self._is_date_in_range(date): return False, "Date out of range"
        
        # Deduplication Check
        if doi and doi in self.seen_dois: return False, "Duplicate DOI"
        
        norm_title = re.sub(r'[^a-z0-9]', '', str(title).lower())
        if norm_title in self.seen_titles: return False, "Duplicate Title"
        
        return True, "Passed"

    def _check_and_download_pdf(self, url, doi):
        """
        Downloads PDF, validates Full Text, and returns (Success, ContentOrUrl)
        """
        if not url: 
            if doi:
                try:
                    res = Unpywall.doi(doi)
                    if res and res.best_oa_location and res.best_oa_location.url:
                        url = res.best_oa_location.url
                except: return False, None
        
        if not url: return False, None
            
        try:
            check_session = requests.Session()
            headers = {'User-Agent': 'Mozilla/5.0'}
            
            # Stream download to avoid memory issues with huge files
            r = check_session.get(url, headers=headers, timeout=15)
            
            if r.status_code == 200 and b'%PDF' in r.content[:1024]:
                # --- STRICT FULL TEXT GATE ---
                # Check directly in memory before saying "Success"
                verify_terms = self.keywords_list if self.keywords_list else [self.raw_topic]
                is_valid, reason = self._validate_full_text(r.content, verify_terms)
                
                if is_valid:
                    return True, url 
                else:
                    # print(f"DEBUG: Rejected {url} (Text Audit Failed: {reason})")
                    return False, None
            
            return False, None
        except Exception:
            return False, None

    def _process_batch(self, candidates):
        """
        Refactored Validation (PRP 9.9.9.1):
        1. Deduplicate (Global seen_ids).
        2. Audit Metadata (Title/Abstract/Keywords).
        3. If keyword found OR inferred by search -> Accept.
        4. PDF Download happens LATER (decoupled).
        """
        # Fuzzy regex for the keyword
        primary_key = self.keywords_list[0].replace('"', '').lower()
        fuzzy_pattern = re.sub(r's?\s+', r'[\\s\\-]*', primary_key) + r's?'
        
        print(f"DEBUG: Processing batch of {len(candidates)} candidates...", flush=True)
        
        for c in candidates:
            # 1. Global Deduplication
            if c['id'] in self.seen_ids:
                continue
            
            # Check Title/DOI early to ensure we don't count duplicates
            norm_title = re.sub(r'[^a-z0-9]', '', str(c['title']).lower())
            if norm_title in self.seen_titles:
                continue
            if c['doi'] and c['doi'] in self.seen_dois:
                continue

            self.seen_ids.add(c['id'])
            # Note: seen_dois and seen_titles are added in _add_final_result
            # but we must check them here to skip processing
            
            # 2. Construct Audit Blob
            # We use the pre-parsed 'description' (abstract) and 'keywords' from execute_openalex_query
            audit_blob = f"{c['title']} {c['description']} {c['keywords']}".lower()
            
            # 3. The Logic Check
            match_found = re.search(fuzzy_pattern, audit_blob)
            
            # Set final_url to the source url since we aren't validating it yet
            c['final_url'] = c['url']
            
            if match_found:
                # print(f"   [Accepted] {c['title'][:60]}...")
                self._add_final_result(c)
            else:
                # 4. The Safety Net (Inferred Acceptance)
                # print(f"   [Accepted (Inferred)] {c['title'][:60]}...")
                self._add_final_result(c)
                
            # Stop if global target met
            if len(self.results) >= self.target_count:
                break

    def _add_final_result(self, c):
        # Add to tracking sets immediately to prevent race-condition duplicates
        if c['doi']: self.seen_dois.add(c['doi'])
        norm_title = re.sub(r'[^a-z0-9]', '', str(c['title']).lower())
        self.seen_titles.add(norm_title)

        self.results.append({
            'Title': c['title'].strip(),
            'Authors': c['authors'],
            'Original_Filename': self._parse_filename(c['final_url']),
            'Publication_Date': self._normalize_date(c['date']),
            'Category': 'Unsorted',
            'Description': c['description'][:3000] + "..." if c['description'] and len(c['description']) > 3000 else c['description'],
            'Is_Paywalled': False,
            'Is_Downloaded': False,
            'Source_URL': c['final_url'],
            'DOI': c['doi'],
            '_Source': c['source_name'],
            'Citation_Count': c.get('citation_count', 0),
            'Search_Vertical': c.get('search_vertical', 'Unsorted')
        })
        print(f"[Accepted] {c['title'][:60]}...", flush=True)

    def resolve_concept_id(self, topic_name):
        return self.resolve_entity_id('concepts', topic_name)

    # ... (skipping unchanged helper methods) ...
    def llm_map_to_openalex_entity(self, user_query):
        """Asks Gemini to map colloquial terms to official OpenAlex Concept Names."""
        client = self.get_genai_client()
        if not client: return None
        
        prompt = (f"What is the single most likely official OpenAlex Concept Name "
                  f"that corresponds to the research topic '{user_query}'? "
                  f"Return ONLY the concept name. Examples: 'Heart Attack' -> 'Myocardial infarction', "
                  f"'Spatial Audio' -> '3D audio'.")
        try:
            models_to_try = ['gemini-2.0-flash-001', 'gemini-2.0-flash-lite-001', 'gemini-2.0-flash']
            for attempt in range(3):
                for model in models_to_try:
                    try:
                        resp = client.models.generate_content(model=model, contents=prompt)
                        if resp.text:
                             predicted_name = resp.text.strip().replace('"', '').replace("'", "")
                             print(f"üß† LLM Semantic Router: '{user_query}' -> '{predicted_name}'")
                             return predicted_name
                    except Exception as e:
                        if "429" in str(e) or "quota" in str(e).lower():
                            continue
                        raise e
                time.sleep((attempt + 1) * 2)
        except: pass
        return None

    def expand_keywords_with_llm(self, keywords):
        """Asks Gemini to generate high-quality synonyms for keywords."""
        if not keywords: return keywords
        client = self.get_genai_client()
        if not client: return keywords
        
        model_name = self.get_best_model(client)
        
        # Clean keywords first
        clean_keys = [k.replace('"', '').strip() for k in keywords]
        input_str = ", ".join(clean_keys)
        
        prompt = (f"Generate 3-4 scientific synonyms or related technical terms for: '{input_str}'. "
                  f"Focus on terms used in academic literature. "
                  f"Return strictly a comma-separated list. No explanations.")
        
        models_to_try = ['gemini-2.0-flash-001', 'gemini-2.0-flash-lite-001', 'gemini-2.0-flash']
        print(f"üß† Expanding Synonyms for: [{input_str}]...")
        resp_text = self._query_llm_with_rotation(prompt)
        if resp_text:
            new_synonyms = [s.strip() for s in resp_text.split(',') if s.strip()]
            print(f"   -> Expansion: {new_synonyms}")
            return list(set(clean_keys + new_synonyms))

        return keywords

            
        return keywords

    def get_technical_synonyms_from_llm(self, titles, seed_keyword, user_topic):
        """
        Uses LLM to extract synonyms, using the User's Topic as a dynamic filter.
        """
        if not titles: return []
        client = self.get_genai_client()
        if not client: return []
        
        model_name = self.get_best_model(client)
        
        prompt = (
            f"CONTEXT: The user is researching '{user_topic}'. "
            f"The primary keyword is '{seed_keyword}'.\n"
            f"SOURCE DATA: Here are recent paper titles from a identified expert in this field:\n"
            f"{' | '.join(titles[:150])}\n\n"
            f"TASK: Identify 15 specific technical synonyms, acronyms, or method names for '{seed_keyword}' "
            f"that are used within the domain of '{user_topic}'.\n\n"
            f"RULES:\n"
            f"1. FILTER IRRELEVANCE: The expert may publish in other fields. IGNORE titles unrelated to '{user_topic}'.\n"
            f"2. PRECISION: If a term is broad (like 'Active Control'), qualify it to fit '{user_topic}' (e.g., 'Active Noise Control').\n"
            f"3. FORMAT: Return ONLY a comma-separated list of phrases (2-4 words). No full titles."
        )
        
        print(f"üß† Synthesizing Expert Vocabulary from {len(titles)} titles (Guided by topic: '{user_topic}')...")
        resp_text = self._query_llm_with_rotation(prompt)

        if resp_text:
             # Basic cleanup
            raw_syns = [s.strip() for s in resp_text.split(',') if len(s.strip()) > 2]
            
            final_syns = []
            for s in raw_syns:
                # Enforce 2-4 word limit logic
                words = s.split()
                if len(words) > 5: continue 
                
                s_clean = s.replace('"', '').replace("'", "")
                final_syns.append(f'"{s_clean}"')
            
            final_syns = final_syns[:15]
            print(f"   -> LLM Suggested: {final_syns}")
            return final_syns
            
        return []

    def resolve_entity_id(self, entity_type, query):
        """Robustly resolves query to ID using deeper searches."""
        # 1. Direct Autocomplete
        try:
            r = self.session.get(f"https://api.openalex.org/autocomplete/{entity_type}", params={"q": query}, timeout=5)
            if r.status_code == 200 and r.json().get('results'):
                res = r.json()['results'][0]
                return res['id'].split('/')[-1]
        except: pass

        # 2. LLM Semantic Router
        if entity_type == 'concepts':
            semantic_name = self.llm_map_to_openalex_entity(query)
            if semantic_name:
                # Force a SEARCH for the semantic name with HIGHER PAGE LIMIT
                try:
                    r = self.session.get(f"https://api.openalex.org/{entity_type}", params={"search": semantic_name, "per-page": 5}, timeout=5)
                    if r.status_code == 200:
                        results = r.json().get('results', [])
                        if results:
                            # Iterate to find exact match or take top
                            for res in results:
                                if res['display_name'].lower() == semantic_name.lower():
                                    print(f"DEBUG: Found ID via LLM Match: {res['display_name']} ({res['id']})")
                                    return res['id'].split('/')[-1]
                            # Fallback to top result
                            return results[0]['id'].split('/')[-1]
                except: pass

        return None

    def execute_openalex_query(self, label, filters, search_query, search_vertical="Unsorted"):
        """Helper to run a specific OpenAlex query strategy with strict quotas."""
        print(f"\nüîé Executing Strategy: {label}")
        print(f"   Query: search='{search_query}' filter='{filters}'")
        
        base_url = "https://api.openalex.org/works"
        current_page = 1
        per_page = 200
        
        # Continuous loop until we meet quota OR exhaust results for this strategy
        while True:
            # Stop if global target met
            if len(self.results) >= self.target_count:
                print(f"‚úÖ Target quota met ({len(self.results)} papers). Stopping.")
                return

            params = {
                "filter": filters,
                "per-page": per_page,
                "page": current_page,
                "select": "title,id,publication_year,open_access,authorships,abstract_inverted_index,doi,keywords,concepts,cited_by_count"
            }
            if search_query: params["search"] = search_query

            try:
                r = self.session.get(base_url, params=params, timeout=10)
                if r.status_code != 200: break
                results = r.json().get('results', [])
                if not results: 
                    print(f"DEBUG: No more results from OpenAlex (Page {current_page}).")
                    break
                
                print(f"DEBUG: Parsing Page {current_page} ({len(results)} raw candidates)...")
                batch = []
                
                for item in results:
                    pdf_url = item.get('open_access', {}).get('oa_url')
                    if not pdf_url: continue # Skip closed access

                    abstract_text = reconstruct_abstract(item.get('abstract_inverted_index')) or ""
                    
                    keywords_list = [k.get('display_name', '') for k in item.get('keywords', [])]
                    keywords_text = " ".join(keywords_list)
                    
                    batch.append({
                        'id': item.get('id'),
                        'title': item.get('title', ""),
                        'authors': ", ".join([a.get("author", {}).get("display_name", "") for a in item.get('authorships', [])]),
                        'date': str(item.get('publication_year', '')),
                        'description': abstract_text,
                        'doi': item.get('doi', '').replace("https://doi.org/", ""),
                        'url': pdf_url, 
                        'source_name': 'OpenAlex',
                        'keywords': keywords_text,
                        'citation_count': item.get('cited_by_count', 0),
                        'search_vertical': search_vertical
                    })
                
                # Trust-Based Validation (PRP 9.9.9.1)
                self._process_batch(batch)
                
                current_page += 1
                if current_page > 50: # Safety cap (10k papers per strategy)
                    break 
                
            except Exception as e: 
                print(f"Error in strategy {label}: {e}")
                break

    def get_genai_client(self):
        """Lazy loader for GenAI Client."""
        if self.no_llm: 
            # print("DEBUG: LLM Disabled by user flag.", flush=True)
            return None
        if not HAS_GENAI or not os.getenv("GOOGLE_API_KEY"): return None
        return genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

    def get_best_model(self, client):
        """Returns the best available Flash model."""
        # Hardcoded for stability and quota optimization
        return 'gemini-2.0-flash-001'

    def _query_llm_with_rotation(self, prompt, context_label="Generic"):
        """
        Unified LLM Query Handler.
        Strict Compliance: NO Rotation. NO Dismissal.
        Persistently attempts to query 'gemini-2.0-flash-001' with backoff.
        """
        if self.no_llm: return None

        key = os.getenv("GOOGLE_API_KEY")
        if not key: 
            print("‚ùå DEBUG: No API Key found in env!")
            return None
        
        print(f"üîë DEBUG: Using Key: {key[:5]}...{key[-3:]}")

        client = self.get_genai_client()
        if not client: return None

        # User forbidden rotation: Stick to the best model.
        target_model = 'gemini-2.0-flash-001'
        
        # Persistence Loop
        for attempt in range(1, 4):
            try:
                resp = client.models.generate_content(model=target_model, contents=prompt)
                if resp.text:
                    return resp.text
            except Exception as e:
                error_str = str(e).lower()
                if "429" in error_str or "quota" in error_str:
                    wait_time = attempt * 10
                    print(f"      ‚ö†Ô∏è Quota Hit on {target_model}. Waiting {wait_time}s... (Attempt {attempt}/3)")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"      ‚ö†Ô∏è API Error on {target_model}: {e}")
                    # Non-quota errors might be fatal to this request, but we don't kill the LLM.
                    return None
        
        print(f"      ‚ùå LLM Failed after 3 retries. Returning None for this request.")
        return None

        print(f"üß† Expanding Topic Scope for: '{topic}'...")
        resp_text = self._query_llm_with_rotation(prompt)
        
        if resp_text:
            new_topics = [t.strip() for t in resp_text.split(',') if t.strip()]
            print(f"   -> Expansion: {new_topics}")
            return list(set([topic] + new_topics))

        return [topic]

    def get_search_verticals_from_llm(self, topic):
        """Generates list of search verticals using model rotation."""
        print("   üß† Defining Search Verticals with LLM...")
        verticals = [topic]
        
        prompt = (
            f"The user is researching '{topic}'. Identify the 15 most distinct, high-yield 'Search Verticals' "
            f"for finding papers in this field. \n"
            f"INSTRUCTIONS:\n"
            f"1. Include Broad Synonyms (e.g., if topic is Spatial Audio -> '3D Audio', 'Immersive Audio')\n"
            f"2. Include Core Sub-disciplines (e.g., 'Binaural', 'Ambisonics', 'Wave Field Synthesis')\n"
            f"3. Return strictly a JSON list of strings, e.g. [\"term1\", \"term2\"]."
        )
        
        resp_text = self._query_llm_with_rotation(prompt)
        if resp_text:
            try:
                # Clean Markdown
                cleaned = resp_text.replace("```json", "").replace("```", "").strip()
                llm_verticals = json.loads(cleaned)
                
                if isinstance(llm_verticals, list):
                    # Sanitize
                    return [str(s).strip() for s in llm_verticals if len(str(s).strip()) > 2]
            except Exception as e:
                print(f"   ‚ö†Ô∏è LLM JSON Parse Failed: {e}. Falling back to text split.")
                # Fallback: Try to clean the string manually (remove brackets/newlines)
                clean_text = resp_text.replace('[', '').replace(']', '').replace('\n', ',')
                return [s.strip().replace('"', '') for s in clean_text.split(',') if len(s.strip()) > 3]
        
        print("   ‚ö†Ô∏è LLM Verticals failed or disabled. Using default.")
        return verticals

    def search_via_iterative_loop(self):
        """
        STRATEGY: Divide and Conquer (PRP 9.9.9).
        Runs separate, targeted searches for distinct sub-fields to maximize recall 
        and bypass OpenAlex query complexity limits.
        """
        # Handle case where no keywords provided - use topic as keyword
        if not self.keywords_list:
            self.keywords_list = [self.raw_topic]
        
        clean_keyword = self.keywords_list[0].replace('"', '')
        print(f"\nüöÄ STARTING ITERATIVE LOOP SEARCH for: '{self.raw_topic}' + '{clean_keyword}'")
        
        # --- STEP 1: GENERATE SEARCH VERTICALS ---
        print("   üß† Defining Search Verticals with LLM...")
        
        verticals = [self.raw_topic] # Default
        

        
        
        verticals = self.get_search_verticals_from_llm(self.raw_topic)
        # Ensure the user's raw topic is always the first loop
        if self.raw_topic not in verticals:
            verticals.insert(0, self.raw_topic)
            
        # Limit to 15 to respect quotas/time
        verticals = verticals[:15]
        print(f"   ‚úÖ Targeted Verticals: {verticals}", flush=True)

        # --- STEP 2: EXECUTE LOOP ---
        for keyword_str in self.keywords_list:
            clean_keyword = keyword_str.replace('"', '').strip()
            
            for vertical in verticals:
                # Remove redundancy
                is_redundant = clean_keyword.lower().strip() == vertical.lower().strip()
                
                if is_redundant:
                    print(f"\n   üîÑ Loop: ('{vertical}') [Base Topic Scan]", flush=True)
                    query = f'("{vertical}")'
                else:
                    print(f"\n   üîÑ Loop: ('{clean_keyword}') AND ('{vertical}')", flush=True)
                    query = f'("{clean_keyword}") AND ("{vertical}")'
                
                # Execute standard query 
                filters = ["is_oa:true", "has_doi:true", "type:article|conference-paper"]
                if self.date_start: filters.append(f"publication_year:>{self.year_start-1}")
                if self.date_end: filters.append(f"publication_year:<{self.year_end+1}")
                filter_str = ",".join(filters)
                
                # Pass the CURRENT keyword as the search_vertical origin
                self.execute_openalex_query(f"Vertical: {vertical}", filter_str, query, search_vertical=clean_keyword)
                
                # Stop if global target met
                if len(self.results) >= self.target_count:
                    break
            
            if len(self.results) >= self.target_count: break
                
        print(f"\n   üèÅ Iterative Loop Complete. Final Catalog Size: {len(self.results)}")

    def search_openalex_text_fallback(self):
        """Standard fallback if backdoor fails."""
        print("üîç Executing Standard Text Fallback...")
        filters = ["is_oa:true", "has_doi:true", "type:article|conference-paper"]
        if self.date_start: filters.append(f"publication_year:>{self.year_start-1}")
        if self.date_end: filters.append(f"publication_year:<{self.year_end+1}")
        filter_str = ",".join(filters)
        
        clean_keywords = [k.replace('"', '') for k in self.keywords_list]
        key_part = " OR ".join([f'"{k}"' for k in clean_keywords]) 
        query_str = f'("{self.raw_topic}") OR ({key_part})' if self.keywords_list else f'"{self.raw_topic}"'
        
        self.execute_openalex_query("Fallback: Text Search", filter_str, query_str)

    def search_arxiv(self):
        # Fallback only
        pass 
    
    def search_semantic_scholar(self):
        # Fallback only
        pass

    def save_results(self):
        df = pd.DataFrame(self.results)
        if not df.empty:
            # Deduplicate by Title and DOI
            df['norm_title'] = df['Title'].apply(lambda x: re.sub(r'[^a-z0-9]', '', str(x).lower()) if x else '')
            df = df.drop_duplicates(subset=['norm_title'])
            df = df.drop_duplicates(subset=['DOI'])
            df = df.drop(columns=['norm_title'], errors='ignore')
            
            df.to_csv("research_catalog.csv", index=False)
            print(f"\n‚úÖ Saved {len(df)} unique papers to research_catalog.csv")
        else:
            print("\n‚ùå No results found.")

    def run(self):
        try:
            print("üöÄ Starting Mission...", flush=True)
            self.search_via_iterative_loop()
            
            # Fallback logic could go here if OpenAlex yields 0 results
            if len(self.results) == 0:
                print("‚ö†Ô∏è OpenAlex yielded 0 results. Trying Standard Text Search...")
                self.search_openalex_text_fallback()

        except KeyboardInterrupt: print("\nUser Interrupted.")
        finally: self.save_results()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--topic", required=True)
    parser.add_argument("--keywords")
    parser.add_argument("--author")
    parser.add_argument("--publication")
    parser.add_argument("--date_start")
    parser.add_argument("--date_end")
    parser.add_argument("--count", default=10, type=int)
    parser.add_argument("--sites")
    parser.add_argument("--keyword_logic", default="any")
    parser.add_argument("--no_llm", action="store_true", help="Disable all LLM/AI features to save quota")
    args = parser.parse_args()
    
    crawler = ResearchCrawler(args.topic, args.keywords, args.author, args.publication, 
                              args.date_start, args.date_end, args.count, args.sites, args.keyword_logic, args.no_llm)
    crawler.run()

==================================================
FILE: src/storage_manager.py
==================================================
import os
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional

class StorageManager:
    """Manages local storage of research missions with automatic cleanup."""
    
    def __init__(self, base_dir: str = "./ScholarStack", max_missions: int = 2):
        self.base_dir = Path(base_dir)
        self.max_missions = max_missions
        self.metadata_file = Path("data/missions.json")
        self.metadata_file.parent.mkdir(exist_ok=True)
        
    def _load_metadata(self) -> Dict:
        """Load mission metadata from JSON file."""
        if self.metadata_file.exists():
            with open(self.metadata_file, 'r') as f:
                return json.load(f)
        return {"missions": []}
    
    def _save_metadata(self, data: Dict):
        """Save mission metadata to JSON file."""
        with open(self.metadata_file, 'w') as f:
            json.dump(data, f, indent=2)
    
    def _get_folder_size(self, folder_path: Path) -> float:
        """Calculate folder size in MB."""
        total_size = 0
        try:
            for item in folder_path.rglob('*'):
                if item.is_file():
                    total_size += item.stat().st_size
        except Exception:
            pass
        return total_size / (1024 * 1024)  # Convert to MB
    
    def register_mission(self, topic: str, paper_count: int, exported_to_drive: bool = False):
        """Register a new mission in metadata."""
        metadata = self._load_metadata()
        
        # Create mission ID from topic and timestamp
        topic_sanitized = topic.replace(' ', '_').replace('/', '_')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        mission_id = f"{topic_sanitized}_{timestamp}"
        
        folder_path = self.base_dir / topic_sanitized
        
        mission = {
            "id": mission_id,
            "topic": topic,
            "created": datetime.now().isoformat(),
            "paper_count": paper_count,
            "size_mb": self._get_folder_size(folder_path) if folder_path.exists() else 0,
            "exported_to_drive": exported_to_drive,
            "folder_path": str(folder_path)
        }
        
        metadata["missions"].append(mission)
        self._save_metadata(metadata)
        
        # Auto-cleanup after registering
        self.cleanup_excess_missions()
        
        return mission_id
    
    def cleanup_excess_missions(self):
        """Remove oldest missions, keeping only max_missions most recent."""
        metadata = self._load_metadata()
        missions = metadata["missions"]
        
        if len(missions) <= self.max_missions:
            return 0  # Nothing to clean
        
        # Sort by creation date (newest first)
        missions.sort(key=lambda x: x["created"], reverse=True)
        
        # Keep only the most recent missions
        missions_to_keep = missions[:self.max_missions]
        missions_to_delete = missions[self.max_missions:]
        
        # Delete old mission folders
        deleted_count = 0
        for mission in missions_to_delete:
            folder_path = Path(mission["folder_path"])
            if folder_path.exists():
                try:
                    shutil.rmtree(folder_path)
                    deleted_count += 1
                    print(f"üóëÔ∏è Deleted old mission: {mission['topic']} ({mission['created'][:10]})")
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to delete {folder_path}: {e}")
        
        # Update metadata
        metadata["missions"] = missions_to_keep
        self._save_metadata(metadata)
        
        return deleted_count
    
    def clear_all_missions(self):
        """Delete all missions (for manual cleanup)."""
        metadata = self._load_metadata()
        deleted_count = 0
        
        for mission in metadata["missions"]:
            folder_path = Path(mission["folder_path"])
            if folder_path.exists():
                try:
                    shutil.rmtree(folder_path)
                    deleted_count += 1
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to delete {folder_path}: {e}")
        
        # Clear metadata
        metadata["missions"] = []
        self._save_metadata(metadata)
        
        return deleted_count
    
    def get_storage_stats(self) -> Dict:
        """Get current storage statistics."""
        metadata = self._load_metadata()
        missions = metadata["missions"]
        
        total_size_mb = 0
        oldest_date = None
        
        for mission in missions:
            total_size_mb += mission.get("size_mb", 0)
            created = datetime.fromisoformat(mission["created"])
            if oldest_date is None or created < oldest_date:
                oldest_date = created
        
        return {
            "mission_count": len(missions),
            "total_size_mb": round(total_size_mb, 2),
            "total_size_gb": round(total_size_mb / 1024, 2),
            "oldest_mission_date": oldest_date.strftime('%Y-%m-%d') if oldest_date else "N/A",
            "missions": missions
        }
    
    def update_mission_export_status(self, topic: str, exported: bool = True):
        """Mark a mission as exported to Google Drive."""
        metadata = self._load_metadata()
        topic_sanitized = topic.replace(' ', '_').replace('/', '_')
        
        for mission in metadata["missions"]:
            if topic_sanitized in mission["id"]:
                mission["exported_to_drive"] = exported
                break
        
        self._save_metadata(metadata)

    def open_mission_folder(self, folder_path: str):
        """Opens the mission folder in the OS file explorer."""
        import subprocess
        import sys
        
        path = str(folder_path) # Ensure string
        if not os.path.exists(path): return False
        
        try:
            if sys.platform == 'darwin':
                subprocess.Popen(['open', path])
            elif sys.platform == 'win32':
                os.startfile(path)
            elif sys.platform.startswith('linux'):
                subprocess.Popen(['xdg-open', path])
            return True
        except Exception as e:
            print(f"Error opening folder: {e}")
            return False


==================================================
FILE: src/drive_manager.py
==================================================
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import os
from tqdm import tqdm

class DriveManager:
    def __init__(self, credentials=None):
        """
        Initializes the Drive Manager with user credentials.
        :param credentials: A valid google.oauth2.credentials.Credentials object (from the user login).
        """
        self.creds = credentials
        self.service = None
        
        if self.creds:
            self.service = build('drive', 'v3', credentials=self.creds)
    
    def get_or_create_folder(self, folder_name):
        """Finds a folder by name or creates it if it doesn't exist."""
        if not self.service:
            raise ValueError("Drive Service not initialized. User not logged in.")

        query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
        results = self.service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()
        items = results.get('files', [])

        if not items:
            # Create folder
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder'
            }
            file = self.service.files().create(body=file_metadata, fields='id').execute()
            return file.get('id')
        else:
            return items[0]['id']

    def upload_library(self, local_library_path):
        """Recursively uploads files from the local library path to Drive."""
        if not self.service:
             raise ValueError("Drive Service not initialized. User not logged in.")
            
        root_folder_id = self.get_or_create_folder('ScholarStack')
        print(f"Target Drive Folder ID: {root_folder_id}")
        
        uploaded_count = 0
        
        # File types to upload
        allowed_extensions = {'.pdf', '.md', '.csv', '.ris', '.bib'}
        
        # MIME type mapping
        mime_types = {
            '.pdf': 'application/pdf',
            '.md': 'text/markdown',
            '.csv': 'text/csv',
            '.ris': 'application/x-research-info-systems',
            '.bib': 'application/x-bibtex'
        }
        
        # Walk through the local directory
        for root, dirs, files in os.walk(local_library_path):
            for filename in files:
                # Skip hidden files
                if filename.startswith('.'):
                    continue
                    
                file_ext = os.path.splitext(filename)[1].lower()
                
                if file_ext in allowed_extensions:
                    file_path = os.path.join(root, filename)
                    
                    # Preserve folder structure relative to library root
                    rel_path = os.path.relpath(root, local_library_path)
                    
                    # Create subfolder if needed
                    if rel_path != '.':
                        parent_folder_id = self.get_or_create_folder(rel_path)
                    else:
                        parent_folder_id = root_folder_id
                    
                    file_metadata = {
                        'name': filename,
                        'parents': [parent_folder_id]
                    }
                    
                    mime_type = mime_types.get(file_ext, 'application/octet-stream')
                    media = MediaFileUpload(file_path, mimetype=mime_type)
                    
                    try:
                        self.service.files().create(
                            body=file_metadata,
                            media_body=media,
                            fields='id'
                        ).execute()
                        uploaded_count += 1
                        print(f"‚úì Uploaded: {filename}")
                    except Exception as e:
                        print(f"Failed to upload {filename}: {e}")
                        
        return uploaded_count


==================================================
FILE: src/hybrid_search_client.py
==================================================
import json
import os
import shutil
from typing import List, Dict, Any

import google.generativeai as genai
import chromadb
from chromadb import Documents, EmbeddingFunction, Embeddings
from rank_bm25 import BM25Okapi

# --- 1. Custom Google Gemini Embedding Function ---
class GeminiEmbeddingFunction(EmbeddingFunction):
    """
    Wrapper for Google's 'text-embedding-004'. 
    """
    def __init__(self, api_key: str, model_name: str = "models/text-embedding-004"):
        genai.configure(api_key=api_key)
        self.model_name = model_name

    def __call__(self, input: Documents) -> Embeddings:
        # Batch embedding with 'retrieval_document' task type
        result = genai.embed_content(
            model=self.model_name,
            content=input,
            task_type="retrieval_document",
            title="Taxonomy Node" 
        )
        return result['embedding']

    def embed_query(self, input: str) -> List[float]:
        # Single query embedding with 'retrieval_query' task type
        result = genai.embed_content(
            model=self.model_name,
            content=input,
            task_type="retrieval_query"
        )
        return result['embedding']


# --- 2. Main Hybrid Search Logic with Caching ---
class HybridTreeSearch:
    def __init__(self, google_api_key: str, persist_dir: str = "./tree_chroma_db"):
        self.persist_dir = persist_dir
        self.gemini_ef = GeminiEmbeddingFunction(api_key=google_api_key)
        
        # Initialize Persistent Client
        self.chroma_client = chromadb.PersistentClient(path=self.persist_dir)
        
        # We always initialize the collection reference
        self.collection_name = "taxonomy_tree"
        self.collection = self.chroma_client.get_or_create_collection(
            name=self.collection_name,
            embedding_function=self.gemini_ef
        )
        
        # In-memory stores for Lexical Search (BM25) and fast retrievals
        self.bm25 = None
        self.doc_store = {} 

    def ingest_tree(self, tree_data: Dict[str, Any], force_rebuild: bool = False):
        """
        Flattens tree and builds indices. 
        CACHE LOGIC: Checks if DB is empty or force_rebuild is True.
        """
        
        # 1. Flatten the tree first (we need this for BM25 regardless of Chroma caching)
        print("Flattening tree structure...")
        flat_nodes = []
        self._flatten_tree(tree_data, [], flat_nodes)
        
        # Populate doc_store and prepare text for BM25
        tokenized_corpus = []
        for i, node in enumerate(flat_nodes):
            node_id = str(i)
            self.doc_store[node_id] = node
            
            # Create rich text representation for search
            text_content = f"{node['node_name']} {node['full_path']}"
            tokenized_corpus.append(text_content.lower().split())

        # 2. Build BM25 Index (Fast, always rebuilt in-memory)
        print(f"Building BM25 index for {len(flat_nodes)} nodes...")
        self.bm25 = BM25Okapi(tokenized_corpus)

        # 3. Check ChromaDB Cache
        existing_count = self.collection.count()
        
        if existing_count > 0 and not force_rebuild:
            print(f"‚úÖ Found {existing_count} cached embeddings in ChromaDB. Skipping ingestion.")
            return

        # 4. Ingestion Logic (Only runs if empty or forced)
        if force_rebuild and existing_count > 0:
            print("Force rebuild requested. Clearing existing collection...")
            self.chroma_client.delete_collection(self.collection_name)
            self.collection = self.chroma_client.get_or_create_collection(
                name=self.collection_name, 
                embedding_function=self.gemini_ef
            )

        print(f"üöÄ Generating embeddings for {len(flat_nodes)} nodes using Gemini (this may take a while)...")
        
        ids = []
        documents = []
        metadatas = []

        for i, node in enumerate(flat_nodes):
            node_id = str(i)
            # Text specifically for the Embedding Model
            # We include context to help distinguishing "Plasma" (Blood) vs "Plasma" (Physics)
            text_for_embedding = f"{node['node_name']} (Context: {node['full_path']})"
            
            ids.append(node_id)
            documents.append(text_for_embedding)
            metadatas.append({
                "path": node['full_path'], 
                "name": node['node_name'], 
                "value": str(node['value']) # Metadata must be string, int, float, or bool
            })

        # Batch Upsert to respect API limits
        batch_size = 50
        for i in range(0, len(ids), batch_size):
            self.collection.upsert(
                ids=ids[i:i+batch_size],
                documents=documents[i:i+batch_size],
                metadatas=metadatas[i:i+batch_size]
            )
            print(f"   Processed {min(i+batch_size, len(ids))}/{len(ids)}...")

        print("Ingestion complete.")

    def _flatten_tree(self, node, ancestry, result_list):
        current_path = ancestry + [node['name']]
        full_path_str = " > ".join(current_path)
        
        entry = {
            'node_name': node['name'],
            'full_path': full_path_str,
            'value': node.get('value', 0),
            'id_ref': node.get('id', '')
        }
        result_list.append(entry)

        if 'children' in node:
            for child in node['children']:
                self._flatten_tree(child, current_path, result_list)

    def search(self, query: str, top_k: int = 5):
        """
        Hybrid Search: BM25 + Gemini Embeddings + Reciprocal Rank Fusion
        """
        # A. BM25 Search
        query_tokens = query.lower().split()
        bm25_scores = self.bm25.get_scores(query_tokens)
        
        # Get top 30 BM25 IDs
        bm25_ranked = sorted(enumerate(bm25_scores), key=lambda x: x[1], reverse=True)[:30]
        bm25_ids = [str(idx) for idx, score in bm25_ranked if score > 0]

        # B. Semantic Search (Chroma)
        results = self.collection.query(
            query_texts=[query], # Chroma calls our Gemini class internally
            n_results=30
        )
        semantic_ids = results['ids'][0]

        # C. Reciprocal Rank Fusion (RRF)
        rrf_score = {}
        k_const = 60

        for rank, doc_id in enumerate(bm25_ids):
            rrf_score[doc_id] = rrf_score.get(doc_id, 0) + (1 / (k_const + rank))

        for rank, doc_id in enumerate(semantic_ids):
            rrf_score[doc_id] = rrf_score.get(doc_id, 0) + (1 / (k_const + rank))

        # Sort and retrieve
        sorted_ids = sorted(rrf_score.keys(), key=lambda x: rrf_score[x], reverse=True)
        
        final_results = []
        for doc_id in sorted_ids[:top_k]:
            if doc_id in self.doc_store:
                final_results.append(self.doc_store[doc_id])
            
        return final_results

# --- Usage ---

if __name__ == "__main__":
    # 1. Configuration
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    if not GOOGLE_API_KEY:
        print("Error: GOOGLE_API_KEY environment variable not set.")
        exit()
    FILE_PATH = 'openalex_tree.json'
    
    # 2. Safety Check
    if not os.path.exists(FILE_PATH):
        print(f"Error: '{FILE_PATH}' not found.")
        exit()

    # 3. Load Data
    with open(FILE_PATH, 'r', encoding='utf-8') as f:
        tree_data = json.load(f)

    # 4. Initialize & Ingest (Cached)
    # Set force_rebuild=True only if you changed the JSON file content
    searcher = HybridTreeSearch(GOOGLE_API_KEY)
    searcher.ingest_tree(tree_data, force_rebuild=False)
    
    # 5. Search Loop
    print("\n--- Search System Ready (Type 'q' to exit) ---")
    while True:
        user_query = input("\nQuery: ")
        if user_query.lower() in ['q', 'quit']:
            break
        
        results = searcher.search(user_query)
        
        print(f"Top results for '{user_query}':")
        for i, res in enumerate(results):
            print(f"{i+1}. {res['node_name']}")
            print(f"   Context: {res['full_path']}")

==================================================
FILE: src/2_cluster_taxonomy.py
==================================================
import pandas as pd
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv
import time
import re
import argparse
import shutil
from collections import Counter
import sys
import typing_extensions

# Load environment variables
# Load environment variables (Force override to prevent stale shell keys)
load_dotenv(override=True)

class PaperClassification(typing_extensions.TypedDict):
    id: str
    category_name: str
    justification_quote: str  # Forces the LLM to prove its work

class TaxonomyResponse(typing_extensions.TypedDict):
    assignments: list[PaperClassification]

def sanitize_folder_name(name):
    """Sanitizes category names for file system compatibility."""
    clean = "".join([c if c.isalnum() or c in (' ', '_', '-') else '' for c in name])
    return clean.strip().replace(' ', '_')

def clean_json_string(json_str):
    """
    Cleans common JSON formatting errors from LLM output.
    1. Removes Markdown code fences (```json, ```).
    2. Escapes unescaped newlines inside strings.
    3. Trims whitespace.
    """
    json_str = json_str.strip()
    if json_str.startswith("```json"):
        json_str = json_str[7:]
    if json_str.startswith("```"):
        json_str = json_str[3:]
    if json_str.endswith("```"):
        json_str = json_str[:-3]
    return json_str.strip()





def get_best_model():
    """Dynamically finds the best available Flash model."""
    try:
        available_models = []
        for m in genai.list_models():
            # Filter for generation models with 'flash' in name
            if 'generateContent' in m.supported_generation_methods and 'flash' in m.name.lower():
                available_models.append(m.name)
        
        if not available_models: 
            return 'models/gemini-pro' # Fallback if no flash
        
        available_models.sort()
        # Phase 1 logic picks the last one (usually latest)
        best_model = available_models[-1]
        print(f"Selected Model: {best_model}", flush=True)
        return best_model
    except:
        return 'models/gemini-1.5-flash'

def cluster_and_categorize(topic, sort_method="Most Relevant", limit=100, no_llm=False, use_keywords=False, fast_mode=False):
    print("=== Phase 3: The Smart Architect (Improved Clustering) ===", flush=True)
    print(f"Topic: {topic}")
    print(f"Prioritize By: {sort_method}, Limit: {limit}", flush=True)
    
    if fast_mode:
        print("‚ö° Fast Mode Enabled: Skipping AI Clustering.", flush=True)
        no_llm = True
    

        
    # --- AUTOMATED CLEANUP ---

        

    csv_filename = "research_catalog.csv"
    data_dir_csv = os.path.join(os.path.dirname(__file__), "../data", csv_filename)
    
    if os.path.exists(csv_filename):
        csv_path = csv_filename
    elif os.path.exists(data_dir_csv):
        csv_path = data_dir_csv
    else:
        print(f"Error: {csv_filename} not found in CWD or ../data/")
        return
    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return

    # 1. Pre-Processing
    initial_count = len(df)
    df = df[df['Title'].str.len() > 15] 
    df = df[~df['Title'].str.lower().isin(['audio', 'spatial audio', 'introduction', 'front matter', 'back matter', 'index'])]
    
    # --- SORTING LOGIC ---
    if sort_method in ["Date: Newest", "Date: Oldest"]:
        # Ensure date format
        df['Publication_Date'] = pd.to_datetime(df['Publication_Date'], errors='coerce')
        
        if sort_method == "Date: Newest":
            print("Sorting papers by Date (Newest First)...")
            df = df.sort_values(by='Publication_Date', ascending=False)
        else: # Oldest
            print("Sorting papers by Date (Oldest First)...")
            df = df.sort_values(by='Publication_Date', ascending=True)
            
    # --- LIMITING LOGIC (BUFFERED) ---
    # We buffer input to AI because some papers might be DISCARDED.
    # User calls this "Musical Chairs". We need to ensure we have enough valid papers left.
    # Buffer Strategy: Double the limit or add 50, whichever is safer.
    process_limit = max(limit * 2, limit + 50)
    if len(df) > process_limit:
        print(f"Trimming {len(df)} papers to {process_limit} for AI processing (Buffer included)...")
        df = df.head(process_limit)
    
    print(f"Loaded {len(df)} valid papers from catalog.")

    if df.empty:
        print("No valid papers to categorize.")
        return

    # 2. AI Categorization Logic
    api_key = os.getenv("GOOGLE_API_KEY")
    taxonomy_map = {}
    ai_success = False

    if not api_key or no_llm:
        if no_llm: print("‚ö†Ô∏è AI Disabled by --no_llm flag.")
        else: print("‚ö†Ô∏è No Google API Key found. Skipping AI Categorization.")
        print(">> Falling back to single folder structure.")
    else:

        # Valid API Key case (Standardized Init)
        genai.configure(api_key=api_key)
        
        # Valid API Key case (Standardized Init)
        genai.configure(api_key=api_key)
        
        # Get unique verticals (handles case where column might be missing)
        if 'Search_Vertical' not in df.columns:
            df['Search_Vertical'] = 'Unsorted'
        unique_verticals = df['Search_Vertical'].unique()
        print(f"DEBUG: Processing {len(unique_verticals)} Keyword Groups for Taxonomy...", flush=True)

        for vertical in unique_verticals:
            print(f"\n   -> Analyzing Group: '{vertical}'...", flush=True)
            v_df = df[df['Search_Vertical'] == vertical]
            
            if v_df.empty: continue

            # Create Payload for this vertical
            papers_payload = []
            for index, row in v_df.iterrows():
                # Use DOI as robust ID
                paper_id = row['DOI'] if pd.notna(row['DOI']) and str(row['DOI']).strip() else row['Title']
                
                # Data Hygiene: Filter short/bad abstracts
                desc = str(row['Description'])
                if len(desc) < 50:
                     desc = f"Title: {row['Title']}" # Force Title-only categorization
                     
                papers_payload.append({
                    "id": paper_id,
                    "title": row['Title'],
                    "description": desc[:500]
                })

            num_papers_v = len(v_df)
            
            # --- Logic for Small Groups ---
            if num_papers_v < 6:
                print(f"      Small group ({num_papers_v} papers). Assigning to '{vertical} Overview'.")
                for p in papers_payload:
                    taxonomy_map[p['id']] = f"{vertical} Overview"
                continue # Skip LLM

            # --- Batching for Large Groups ---
            # Split into batches of max 50 papers to prevent JSON corruption
            BATCH_SIZE = 50
            num_batches = (num_papers_v + BATCH_SIZE - 1) // BATCH_SIZE
            
            if num_batches > 1:
                print(f"      Large group ({num_papers_v} papers). Processing in {num_batches} batches...")
            
            model_name = get_best_model()
            model = genai.GenerativeModel(model_name)
            
            for batch_idx in range(num_batches):
                start_idx = batch_idx * BATCH_SIZE
                end_idx = min((batch_idx + 1) * BATCH_SIZE, num_papers_v)
                batch_payload = papers_payload[start_idx:end_idx]
                batch_size = len(batch_payload)
                
                if num_batches > 1:
                    print(f"      Batch {batch_idx + 1}/{num_batches} ({batch_size} papers)...")
                
                # Dynamic prompt constraints based on batch size
                if batch_size < 20:
                     target_cats = "exactly 2"
                     density_note = f"roughly {int(batch_size/2)} papers"
                elif batch_size < 60:
                     target_cats = "exactly 4"
                     density_note = f"roughly {int(batch_size/4)} papers"
                else:
                     target_cats = "5-8"
                     density_note = "balanced distribution"

                prompt = f"""
                You are an expert academic librarian organizing a specific sub-folder of papers on: "{vertical}" (Topic: {topic}).
                Input: {batch_size} academic papers.
                
                Task:
                1. **Analyze**: Identify **{target_cats}** distinct technical themes within this specific sub-field.
                2. **Assign**: ASSIGN EVERY paper to one of these themes.
                3. **Filter**: If a paper is unrelated to "{vertical}", assign "DISCARD".
                4. **Proof**: For every assignment, you MUST quote a specific phrase from the abstract that justifies your choice.
                
                Critical Constraints:
                1. **Style**: Format category names as **concise Noun Phrases** (e.g., 'Spatial Audio', not 'Papers about Spatial Audio'). Avoid parenthetical qualifiers.
                2. **Context**: These papers are ALREADY filtered by keyword "{vertical}". Do NOT create a category named "{vertical}". Break it down further (e.g. if "{vertical}"="HRTF", use "HRTF Measurement", "HRTF Personalization").
                3. **Broad Clusters**: Do NOT map 1-to-1.
                4. **Forbidden**: "General", "Miscellaneous", "Other".
                5. **Density**: Each theme should have {density_note}.
                
                Papers:
                {json.dumps(batch_payload, indent=2)}
                """
                
                # Retry Loop (Per Batch)
                local_success = False
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        response = model.generate_content(
                            prompt,
                            generation_config=genai.GenerationConfig(
                                response_mime_type="application/json",
                                response_schema=TaxonomyResponse
                            )
                        )
                        
                        if response.text:
                            # Direct JSON parse of the structured output
                            cleaned_text = clean_json_string(response.text)
                            payload = json.loads(cleaned_text)
                            
                            # Process assignments
                            local_map = {}
                            print(f"      Mapped {len(payload.get('assignments', []))} papers:")
                            
                            for item in payload.get('assignments', []):
                                pid = item['id']
                                cat = item['category_name']
                                # 1. Take the full name from the LLM
                                cat_raw = item['category_name'].strip()

                                # 2. Safety Truncate: Only chop if excessively long (> 6 words)
                                words = cat_raw.split()
                                if len(words) > 6:
                                    cat_raw = " ".join(words[:6])

                                # 3. Stopword Cleanup: Remove trailing connectors
                                # Regex targets: and, or, of, the, for, in, on, with, to
                                cat = re.sub(r'[^a-zA-Z0-9]+$', '', cat_raw) # Strip non-alphanumeric (brackets, punctuation)
                                cat = re.sub(r'\s+(and|or|of|the|for|in|on|with|to)$', '', cat, flags=re.IGNORECASE).strip()
                                    
                                quote = item.get('justification_quote', 'No Quote provided')
                                local_map[pid] = cat
                                
                                # Sanity Check Log
                                # Only print first 3 to avoid spamming console, or print all if verbose? 
                                # Let's print all for now as requested by user to "see why"
                                print(f"       [{cat}] <- \"{quote[:60]}...\"")

                            taxonomy_map.update(local_map)
                            local_success = True
                            print(f"      Refined into {len(set(local_map.values()))} categories.", flush=True)
                            break
                    except Exception as e:
                         if "429" in str(e):
                            time.sleep(10) # 429 backoff
                         elif attempt == max_retries - 1:
                            print(f"      ‚ùå Failed to categorize batch: {e}")

                if not local_success:
                     # Fallback for this batch ONLY
                     print(f"      Falling back to '{vertical} Overview' for this batch.")
                     for p in batch_payload:
                         taxonomy_map[p['id']] = f"{vertical} Overview"

                time.sleep(2) # Rate limit hygiene

        if len(taxonomy_map) > 0:
            ai_success = True
        else:
             print(">> Global AI Failure: No categories generated.")


    # Debug: Print Raw Categories
    if ai_success:
        raw_counts = Counter(taxonomy_map.values())
        print("DEBUG RAW AI CATEGORIES:")
        for k, v in raw_counts.items():
            print(f"   '{k}': {v}")
            
    # 3. Post-Processing / Fallback Assignment
    if ai_success:
        # Enforce Orphan Rules
        # New Logic: No Orphan Reassignment
        # We accept singleton categories to prevent "Miscellaneous" bloating.
        counts = Counter(taxonomy_map.values())
        print(f"DEBUG: Category Distribution: {counts}") 
        
        # 1. Map current AI categories to the DataFrame
        mapped_count = 0
        total_rows = len(df)
        for idx, row in df.iterrows():
             pid = row['DOI'] if pd.notna(row['DOI']) and str(row['DOI']).strip() else row['Title']
             cat = taxonomy_map.get(pid, "Miscellaneous")
             if cat != "Miscellaneous": mapped_count += 1
             df.at[idx, '_Temp_Cat'] = cat
        
        print(f"DEBUG: Mapped {mapped_count}/{total_rows} papers to categories. (Rest are Miscellaneous)")
    else:
        # Fallback Mode
        pass

    # 4. Organization
    df['Topic'] = topic
    
    # Base Root (Topic Level)
    topic_sanitized = sanitize_folder_name(topic)
    base_library_root = os.path.join("./ScholarStack", topic_sanitized)
    
    categories_found = set()
    rows_to_drop = []
    df['Directory_Path'] = None

    for index, row in df.iterrows():
        # Robust Lookup
        paper_id = row['DOI'] if pd.notna(row['DOI']) and str(row['DOI']).strip() else row['Title']
        
        # Check taxonomy map
        category = "Miscellaneous"
        if ai_success:
            category = taxonomy_map.get(paper_id, "Miscellaneous")
            
        if category == "DISCARD":
            rows_to_drop.append(index)
            continue
        
        df.at[index, 'Category'] = category
        categories_found.add(category)
        
        # Construct Path
        safe_category = sanitize_folder_name(category)
        
        # Logic: <Topic>/<Keyword?>/<Category>
        # Logic: <Topic>/<Keyword?>/<Category>
        current_root = base_library_root
        
        # Use Keywords as Sub-folders?
        if use_keywords:
            raw_vertical = row.get('Search_Vertical', 'Unsorted')
            safe_vertical = sanitize_folder_name(str(raw_vertical))
            
            # If the keyword IS the topic, put it in a general folder so it doesn't clutter root
            # But generally, we treat the Search Vertical as the Level 2 folder.
            if safe_vertical.lower() == topic_sanitized.lower():
                 current_root = os.path.join(base_library_root, "_General")
            else:
                 current_root = os.path.join(base_library_root, safe_vertical)
        
        # Determine Final Directory
        # Logic: current_root is now <Topic>/<Keyword> (or <Topic> if not using keywords)
        # We ALWAYS append the Category.
        # User explicitly requested strict "Library/Topic/Keyword/Category".
        
        dir_path = os.path.join(current_root, safe_category)
            
        os.makedirs(dir_path, exist_ok=True)
        df.at[index, 'Directory_Path'] = dir_path

    if rows_to_drop:
        print(f"\n--- üóëÔ∏è Rejected Papers Audit ({len(rows_to_drop)}) ---")
        for idx in rows_to_drop:
            print(f"   [Discarded] {df.loc[idx, 'Title']}")
        print("------------------------------------------\n")
        
        df = df.drop(rows_to_drop)
        print(f"Rejected {len(rows_to_drop)} off-topic papers.")

    # --- FINAL TRIM TO EXACT LIMIT ---
    # Now that we've filtered, strictly enforce the user limit
    if len(df) > limit:
         print(f"Final Count {len(df)} > Requested {limit}. Trimming excess to match quota.")
         df = df.head(limit)

    output_csv = "research_catalog_categorized.csv"
    df.to_csv(output_csv, index=False)
    
    print("\n=== Categorization Complete ===")
    if ai_success:
        print(f"AI Organized into {len(categories_found)} Categories.")
    else:
        print("Fallback Mode: Papers saved to 'Miscellaneous'.")
        
    print(f"Structure ready in '{base_library_root}/'")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Smart Architect: Cluster and Filter Papers")
    parser.add_argument("--topic", required=True)
    parser.add_argument("--sort", default="Most Relevant")
    parser.add_argument("--limit", type=int, default=100)
    parser.add_argument("--no_llm", action="store_true")
    parser.add_argument("--use_keywords", action="store_true")
    parser.add_argument("--fast_mode", action="store_true")
    args = parser.parse_args()
    
    cluster_and_categorize(args.topic, args.sort, args.limit, args.no_llm, args.use_keywords, args.fast_mode)



==================================================
FILE: src/alerts_db.py
==================================================
import sqlite3
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional

DB_PATH = os.path.join(os.path.dirname(__file__), "../data/alerts.db")

def init_db():
    """Initialize the alerts database and create tables if they don't exist."""
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS subscriptions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_email TEXT NOT NULL,
            search_query TEXT NOT NULL,
            search_source TEXT NOT NULL,
            frequency TEXT DEFAULT 'daily',
            last_run TIMESTAMP,
            active BOOLEAN DEFAULT 1,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    conn.commit()
    conn.close()
    print(f"‚úÖ Database initialized at {DB_PATH}")

def add_subscription(email: str, query: str, source: str, frequency: str = "daily") -> int:
    """Add a new alert subscription."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT INTO subscriptions (user_email, search_query, search_source, frequency, last_run)
        VALUES (?, ?, ?, ?, ?)
    """, (email, query, source, frequency, datetime.now()))
    
    subscription_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return subscription_id

def get_active_subscriptions() -> List[Dict]:
    """Retrieve all active subscriptions."""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM subscriptions WHERE active = 1
        ORDER BY created_at DESC
    """)
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]

def get_all_subscriptions() -> List[Dict]:
    """Retrieve all subscriptions (active and inactive)."""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM subscriptions
        ORDER BY created_at DESC
    """)
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]

def update_last_run(subscription_id: int, timestamp: datetime):
    """Update the last run timestamp for a subscription."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        UPDATE subscriptions
        SET last_run = ?
        WHERE id = ?
    """, (timestamp, subscription_id))
    
    conn.commit()
    conn.close()

def toggle_subscription(subscription_id: int, active: bool):
    """Enable or disable a subscription."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        UPDATE subscriptions
        SET active = ?
        WHERE id = ?
    """, (1 if active else 0, subscription_id))
    
    conn.commit()
    conn.close()

def delete_subscription(subscription_id: int):
    """Delete a subscription."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("DELETE FROM subscriptions WHERE id = ?", (subscription_id,))
    
    conn.commit()
    conn.close()

def reset_dates_for_testing():
    """Reset all last_run dates to 30 days ago for testing purposes."""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    thirty_days_ago = datetime.now() - timedelta(days=30)
    
    cursor.execute("""
        UPDATE subscriptions
        SET last_run = ?
    """, (thirty_days_ago,))
    
    affected = cursor.rowcount
    conn.commit()
    conn.close()
    
    print(f"‚úÖ Reset {affected} subscription(s) to 30 days ago for testing")

if __name__ == "__main__":
    # Test the database
    init_db()
    print("Database initialized successfully!")


==================================================
FILE: src/app.py
==================================================
import streamlit as st
import os
import sys
import time
import datetime
import shutil
import pandas as pd
import altair as alt
from pipeline_manager import run_full_pipeline
from drive_manager import DriveManager
from auth_manager import get_login_url, get_token_from_code, get_user_info
import alerts_db
import json
from storage_manager import StorageManager

SETTINGS_FILE = os.path.join(os.path.dirname(__file__), "../data/user_settings.json")
HISTORY_FILE = os.path.join(os.path.dirname(__file__), "../data/search_history.json")

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, "r") as f:
                return json.load(f)
        except: return {}
    return {}

def save_settings(settings):
    try:
        # Convert dates to str for JSON
        serializable = {}
        for k, v in settings.items():
            if isinstance(v, (datetime.date, datetime.datetime)):
                serializable[k] = v.isoformat()
            else:
                serializable[k] = v
        with open(SETTINGS_FILE, "w") as f:
            json.dump(serializable, f, indent=2)
    except Exception as e:
        print(f"Error saving settings: {e}")

def render_visualizations(csv_path):
    """
    Renders visualizations from the catalog CSV:
    1. Research Timeline (Year Distribution)
    2. Impact Analysis (Citation Counts)
    """
    try:
        df = pd.read_csv(csv_path)
        
        # --- 1. Research Timeline ---
        # Ensure we have a year column
        if 'Year' not in df.columns:
            if 'Publication_Date' in df.columns:
                df['Year'] = df['Publication_Date'].astype(str).str[:4]
        
        if 'Year' in df.columns:
            # Clean Year data
            def clean_year(y):
                try:
                    if pd.isna(y) or str(y).lower() in ['nan', 'none', '']: return None
                    return int(float(str(y).split('-')[0]))
                except:
                    return None
                    
            df['Year_Clean'] = df['Year'].apply(clean_year)
            
            # Remove None/Unknown years for proper timeline
            valid_years = df[df['Year_Clean'].notna()]['Year_Clean']
            
            if len(valid_years) > 0:
                # Get year range
                min_year = int(valid_years.min())
                max_year = int(valid_years.max())
                
                # Create complete year range
                all_years = pd.DataFrame({'Year': range(min_year, max_year + 1)})
                
                # Count papers per year
                year_counts = df[df['Year_Clean'].notna()].groupby('Year_Clean').size().reset_index(name='Count')
                year_counts['Year'] = year_counts['Year_Clean'].astype(int)
                
                # Merge to fill missing years with 0
                timeline_data = all_years.merge(year_counts[['Year', 'Count']], on='Year', how='left').fillna(0)
                timeline_data['Count'] = timeline_data['Count'].astype(int)
                
                st.subheader("Research Timeline")
                
                # Use Altair for proper time axis
                timeline_chart = alt.Chart(timeline_data).mark_bar().encode(
                    x=alt.X('Year:Q', axis=alt.Axis(format='d', title='Year'), scale=alt.Scale(domain=[min_year, max_year])),
                    y=alt.Y('Count:Q', title='Number of Papers'),
                    tooltip=[alt.Tooltip('Year:Q', format='d'), 'Count:Q']
                ).properties(
                    height=300
                ).configure_view(
                    strokeWidth=0  # Disable scroll-zoom
                )
                
                st.altair_chart(timeline_chart, use_container_width=True)
                st.divider()

        # --- 2. Impact Analysis (Citation Counts) ---
        print(f"DEBUG: Checking for Citation_Count. Columns: {df.columns}")
        if 'Citation_Count' in df.columns and 'Title' in df.columns:
            # Drop rows with NaN citations, titles
            cit_df = df.dropna(subset=['Citation_Count', 'Title']).copy()
            print(f"DEBUG: Rows after initial drop: {len(cit_df)}")
            
            # Ensure proper types
            cit_df['Citation_Count'] = pd.to_numeric(cit_df['Citation_Count'], errors='coerce').fillna(0)
            cit_df['Authors'] = cit_df['Authors'].fillna("Unknown")
            
            # Sort Layout: Low to High (Ascending)
            cit_df = cit_df.sort_values(by='Citation_Count', ascending=True)
            
            st.subheader("Citation Impact (Low to High)")
            
            c = alt.Chart(cit_df).mark_bar().encode(
                x=alt.X('Title', sort=None, axis=alt.Axis(labels=False, title="Paper Title")),
                y=alt.Y('Citation_Count', title="Citations"),
                tooltip=['Title', 'Authors', 'Citation_Count']
            ).configure_view(
                strokeWidth=0  # Disable scroll-zoom
            )
            
            st.altair_chart(c, use_container_width=True)
            st.divider()
        
    except Exception as e:
        print(f"Visualization error: {e}")

def save_history(settings):
    try:
        entry = settings.copy()
        entry['timestamp'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Convert dates
        for k, v in entry.items():
            if isinstance(v, (datetime.date, datetime.datetime)):
                entry[k] = v.isoformat()
        
        history = []
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, "r") as f:
                history = json.load(f)
        
        history.insert(0, entry) # Newest first
        history = history[:50] # Keep last 50
        
        with open(HISTORY_FILE, "w") as f:
            json.dump(history, f, indent=2)
    except Exception as e:
        print(f"Error saving history: {e}")

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r") as f:
                return pd.DataFrame(json.load(f))
        except: return pd.DataFrame()
    return pd.DataFrame()

@st.dialog("Search History", width="large")
def search_history_modal():
    st.write("Select rows to process.")
    df = load_history()
    
    if df.empty:
        st.info("No history found.")
        if st.button("Close"):
            st.session_state.history_open = False
            st.rerun()
        return

    # Modern Selection API
    event = st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        on_select="rerun",
        selection_mode="multi-row",
        height=400
    )
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("üìÇ Load Selected", type="primary", use_container_width=True):
            if len(event.selection.rows) == 0:
                st.warning("Select 1 entry.")
            elif len(event.selection.rows) > 1:
                st.error("Select ONLY 1 entry to load.")
            else:
                idx = event.selection.rows[0]
                selected_row = df.iloc[idx].to_dict()
                
                # Restore Dates
                if 'date_start' in selected_row and selected_row['date_start']:
                    try: selected_row['date_start'] = datetime.date.fromisoformat(selected_row['date_start'])
                    except: pass
                if 'date_end' in selected_row and selected_row['date_end']:
                    try: selected_row['date_end'] = datetime.date.fromisoformat(selected_row['date_end'])
                    except: pass
                    
                save_settings(selected_row)
                st.toast("Settings Loaded!", icon="‚úÖ")
                time.sleep(0.5)
                # Close modal on load
                st.session_state.history_open = False
                st.rerun()

    with col2:
        if st.button("üóëÔ∏è Delete Selected", type="secondary", use_container_width=True):
            if len(event.selection.rows) == 0:
                st.warning("Select entries.")
            else:
                rows_to_delete = event.selection.rows
                try:
                    with open(HISTORY_FILE, "r") as f:
                        full_history = json.load(f)
                    
                    for r_idx in sorted(rows_to_delete, reverse=True):
                        if r_idx < len(full_history):
                            full_history.pop(r_idx)
                            
                    with open(HISTORY_FILE, "w") as f:
                        json.dump(full_history, f, indent=2)
                        
                    st.toast("Entries Deleted.", icon="üóëÔ∏è")
                    time.sleep(0.5)
                    st.rerun() # This will now re-open the modal because history_open is True
                except Exception as e:
                    st.error(f"Error: {e}")
        
st.set_page_config(
    page_title="ScholarStack",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown(
    """
    <style>
    [data-testid="stSidebar"] {
        min-width: 400px;
        max-width: 800px;
    }
    .stApp > header {
        visibility: hidden;
    }
    [data-testid="stStatusWidget"] {
        visibility: hidden;
    }
    /* Top Right User Profile */
    .user-profile {
        background-color: #f0f2f6;
        padding: 8px 15px;
        border-radius: 20px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: flex;
        align-items: center;
        gap: 10px;
    }
    .user-avatar {
        width: 30px;
        height: 30px;
        border-radius: 50%;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# --- Authentication Logic ---
if 'credentials' not in st.session_state:
    st.session_state.credentials = None
if 'user_info' not in st.session_state:
    st.session_state.user_info = None

query_params = st.query_params
if "code" in query_params and not st.session_state.credentials:
    code = query_params["code"]
    creds = get_token_from_code(code)
    if creds:
        st.session_state.credentials = creds
        st.session_state.user_info = get_user_info(creds)
        st.query_params.clear()
        st.rerun()

# --- Top Bar ---
if st.session_state.user_info:
    user = st.session_state.user_info
    name = user.get('name', 'User')
    picture = user.get('picture', '')
    
    # Profile and sign-out in top right
    st.markdown(f"""
    <div style="display: flex; flex-direction: column; align-items: flex-end; gap: 10px; padding: 10px;">
        <div class="user-profile">
            <img src="{picture}" class="user-avatar" onerror="this.style.display='none'">
            <span>{name}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Sign-out button aligned to right
    col1, col2 = st.columns([5, 1])
    with col2:
        if st.button("Sign Out", key="signout_btn", use_container_width=True):
            st.session_state.credentials = None
            st.session_state.user_info = None
            st.rerun()
else:
    # Sign-in button in top right
    col1, col2 = st.columns([5, 1])
    with col2:
        login_url = get_login_url()
        if login_url:
            st.markdown(f"""
            <a href="{login_url}" target="_self">
                <button style="background-color: white; border: 1px solid #dadce0; color: #3c4043; padding: 8px 16px; border-radius: 4px; font-weight: 500; cursor: pointer; display: flex; align-items: center; gap: 8px; width: 100%;">
                    <img src="https://www.gstatic.com/firebasejs/ui/2.0.0/images/auth/google.svg" width="18">
                    Sign in with Google
                </button>
            </a>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <button style="background-color: #f1f3f4; border: 1px solid #dadce0; color: #9aa0a6; padding: 8px 16px; border-radius: 4px; font-weight: 500; cursor: not-allowed; display: flex; align-items: center; gap: 8px; width: 100%;" title="Upload client_secrets.json to enable">
                <img src="https://www.gstatic.com/firebasejs/ui/2.0.0/images/auth/google.svg" width="18" style="opacity: 0.5;">
                Sign in with Google (Disabled)
            </button>
            """, unsafe_allow_html=True)

# Initialize Session State
if 'pipeline_run' not in st.session_state:
    st.session_state.pipeline_run = False
if 'zip_path' not in st.session_state:
    st.session_state.zip_path = None
if 'temp_dir' not in st.session_state:
    st.session_state.temp_dir = None
if 'catalog_content' not in st.session_state:
    st.session_state.catalog_content = None
if 'recent_topics' not in st.session_state:
    st.session_state.recent_topics = []
if 'temp_dir_to_cleanup' not in st.session_state:
    st.session_state.temp_dir_to_cleanup = None
if 'timeline_csv' not in st.session_state:
    st.session_state.timeline_csv = None

st.title("üìö ScholarStack")
st.caption("Your AI Research Librarian")

# --- Success State ---
if st.session_state.pipeline_run and st.session_state.zip_path and os.path.exists(st.session_state.zip_path):
    st.success("‚úÖ Mission Complete! Your library is ready.")
    col_hero_1, col_hero_2, col_hero_3 = st.columns([1, 2, 1])
    with col_hero_2:
        subcol1, subcol2 = st.columns(2)
        with subcol1:
            # 1. Calculate Size
            try:
                zip_size_mb = os.path.getsize(st.session_state.zip_path) / (1024*1024)
            except: zip_size_mb = 0
            
            # 2. Strategy Selection
            if zip_size_mb > 500:
                # LARGE FILE STRATEGY: Static Serve
                st.warning(f"‚ö†Ô∏è File is large ({zip_size_mb:.0f} MB). Browser download may fail.")
                
                # Copy/Link to static folder
                static_dir = "static"
                if not os.path.exists(static_dir): os.makedirs(static_dir)
                
                zip_filename = os.path.basename(st.session_state.zip_path)
                static_path = os.path.join(static_dir, zip_filename)
                
                # Check if exists
                if not os.path.exists(static_path):
                     try:
                         # Try Symlink first (Zero Space)
                         os.symlink(os.path.abspath(st.session_state.zip_path), static_path)
                         # Note: Use abspath for symlink source
                     except OSError:
                         # Fallback to copy if symlink fails (e.g. permission or Windows)
                         import shutil
                         shutil.copy2(st.session_state.zip_path, static_path)
                
                # Render HTML Link
                # Note: 'app/static/' is the standard mount point for the 'static' folder in Streamlit
                download_url = f"app/static/{zip_filename}" 
                st.markdown(f'<a href="{download_url}" download="{zip_filename}" style="display: inline-block; padding: 0.5em 1em; color: white; background-color: #FF4B4B; border-radius: 4px; text-decoration: none;">üì¶ Download ZIP (Direct Link)</a>', unsafe_allow_html=True)
                
            else:
                # NORMAL STRATEGY: In-Memory
                with open(st.session_state.zip_path, "rb") as f:
                    st.download_button("üì¶ DOWNLOAD ZIP", f, file_name=os.path.basename(st.session_state.zip_path), mime="application/zip", use_container_width=True, type="primary")
            
            # 3. Local Fallback
            if st.button("üìÇ OPEN FOLDER (Local)", key="open_folder_hero", use_container_width=True, help="Opens the folder on the server machine (useful if running locally)."):
                 # Open directory containing the zip
                 target_dir = os.path.dirname(st.session_state.zip_path)
                 StorageManager().open_mission_folder(target_dir)

        with subcol2:
            if st.button("‚òÅÔ∏è Save to Drive", use_container_width=True):
                if not st.session_state.credentials:
                    st.error("Please Sign In (top right) to use Google Drive.")
                elif st.session_state.temp_dir:
                    lib_path = os.path.join(st.session_state.temp_dir, "ScholarStack")
                    if os.path.exists(lib_path):
                        with st.spinner("Uploading..."):
                            try:
                                dm = DriveManager(credentials=st.session_state.credentials)
                                count = dm.upload_library(lib_path)
                                st.toast(f"‚úÖ Uploaded {count} papers to Drive.", icon="‚òÅÔ∏è")
                            except Exception as e:
                                st.error(f"Drive Error: {e}")
                    else:
                        st.error("ScholarStack folder not found.")
                else:
                    st.error("Session expired.")
    st.divider()
    if st.session_state.catalog_content:
        st.subheader("üìù Library Catalog Preview")
        with st.container(height=500):
            st.markdown(st.session_state.catalog_content)
        st.divider()
        
    if st.session_state.timeline_csv:
        render_visualizations(st.session_state.timeline_csv)

# --- Sidebar ---
def close_history():
    st.session_state.history_open = False

with st.sidebar:
    # Mission button at top
    start_btn = st.button("üöÄ Start Research Mission", type="primary", use_container_width=True, on_click=close_history)
    st.divider()
    
    # Grouped: History and Alerts
    if st.button("üìú View Search History", use_container_width=True):
        st.session_state.history_open = True
        st.rerun()
        
    if st.session_state.get('history_open', False):
        search_history_modal()
    
    # --- Alert Management ---
    with st.expander("üì¨ Manage Alerts"):
        st.write("**Save Current Search as Alert**")
        
        # Initialize alerts database
        alerts_db.init_db()
        
        # Auto-fill email if user is signed in
        default_email = ""
        email_disabled = False
        if st.session_state.user_info:
            default_email = st.session_state.user_info.get('email', '')
            email_disabled = True
        
        alert_email = st.text_input(
            "Email for notifications",
            value=default_email,
            placeholder="your.email@gmail.com" if not default_email else "",
            disabled=email_disabled,
            key="alert_email_input",
            help="Sign in with Google to auto-fill" if not default_email else "Using your Google account email"
        )
        
        alert_frequency = st.selectbox(
            "Check frequency",
            options=["hourly", "daily", "weekly", "biweekly", "monthly"],
            format_func=lambda x: {
                "hourly": "‚ö° Hourly (every hour)",
                "daily": "üìÖ Daily (once per day)",
                "weekly": "üìÜ Weekly (every Monday)",
                "biweekly": "üìÜ Bi-weekly (every 2 weeks)",
                "monthly": "üìÜ Monthly (once per month)"
            }[x],
            index=1,  # Default to daily
            key="alert_frequency_input"
        )
        
        if st.button("üíæ Save Current Search as Alert", use_container_width=True):
            if not alert_email or '@' not in alert_email:
                st.error("Please enter a valid email address")
            else:
                # Get current search parameters
                current_topic = st.session_state.get('topic_input_std', '')
                current_keywords = st.session_state.get('keywords_input_std', '')
                
                if not current_topic and not current_keywords:
                    st.warning("Please enter a topic or keywords first")
                else:
                    query = f"{current_topic} + {current_keywords}" if current_keywords else current_topic
                    sub_id = alerts_db.add_subscription(
                        email=alert_email,
                        query=query,
                        source="OpenAlex",
                        frequency=alert_frequency
                    )
                    st.success(f"‚úÖ Alert saved! (ID: {sub_id})")
                    st.rerun()
        
        st.divider()
        st.write("**Active Alerts**")
        
        subscriptions = alerts_db.get_all_subscriptions()
        
        if not subscriptions:
            st.info("No alerts saved yet")
        else:
            for sub in subscriptions:
                # Compact display with icons
                status_icon = "‚úÖ" if sub['active'] else "‚è∏Ô∏è"
                freq_label = {
                    "hourly": "‚ö°",
                    "daily": "üìÖ",
                    "weekly": "üìÜ",
                    "biweekly": "üìÜ",
                    "monthly": "üìÜ"
                }.get(sub.get('frequency', 'daily'), "üìÖ")
                
                # Parse query to show topic prominently
                query = sub['search_query']
                if ' + ' in query:
                    parts = query.split(' + ', 1)
                    topic = parts[0]
                    keywords = parts[1] if len(parts) > 1 else ""
                    display_query = f"**{topic}**"
                    if keywords:
                        display_query += f" + {keywords}"
                else:
                    display_query = f"**{query}**"
                
                # Query display
                st.markdown(f"{status_icon} {freq_label} {display_query}")
                st.caption(f"üìß {sub['user_email']}")
                
                # Action buttons in single row
                col1, col2 = st.columns(2)
                with col1:
                    btn_icon = "‚è∏Ô∏è" if sub['active'] else "‚ñ∂Ô∏è"
                    btn_label = f"{btn_icon}"
                    if st.button(btn_label, key=f"toggle_{sub['id']}", use_container_width=True, help="Pause" if sub['active'] else "Resume"):
                        alerts_db.toggle_subscription(sub['id'], not sub['active'])
                        st.rerun()
                
                with col2:
                    if st.button("üóëÔ∏è", key=f"delete_{sub['id']}", use_container_width=True, help="Delete"):
                        alerts_db.delete_subscription(sub['id'])
                        st.rerun()
                
                st.divider()
    
    st.divider()
    
    # --- Storage Management ---
    with st.expander("üíæ Storage Management"):
        storage_mgr = StorageManager(max_missions=int(os.getenv("MAX_MISSIONS", "2")))
        stats = storage_mgr.get_storage_stats()
        
        st.write(f"**Missions Stored:** {stats['mission_count']}")
        st.write(f"**Total Size:** {stats['total_size_gb']} GB")
        if stats['oldest_mission_date'] != "N/A":
            st.write(f"**Oldest:** {stats['oldest_mission_date']}")
        
        if st.button("üóëÔ∏è Clear All Missions", use_container_width=True):
            deleted = storage_mgr.clear_all_missions()
            st.success(f"Deleted {deleted} mission(s)")
            st.rerun()
    
    st.divider()

    st.header("Research Parameters")

    # --- Load Settings ---
    saved = load_settings()    
    
    # Defaults logic
    def get_setting(key, default):
        # Prefer session state if set (from buttons), else saved, else default
        return saved.get(key, default)

    default_topic = st.session_state.get('selected_topic', get_setting('topic', ""))
    default_keywords = get_setting('keywords', "")
    
    # Logic Map for Radio Index
    logic_saved = get_setting('keyword_logic', 'Match Any (OR)')
    logic_idx = 0 if "Any" in logic_saved else 1
    
    default_author = get_setting('author', "")
    default_pub = get_setting('publication', "")
    default_count = get_setting('count', 10)
    
    sort_saved = get_setting('sort_method', "Most Relevant")
    sort_opts = ["Most Relevant", "Date: Newest", "Date: Oldest", "Citations: Most", "Citations: Least"]
    try: sort_idx = sort_opts.index(sort_saved)
    except: sort_idx = 0
    
    auto_saved = get_setting('auto_folders', True)
    key_sub_saved = get_setting('use_keywords_subfolders', False)
    
    # Dates
    use_start_saved = get_setting('use_start_date', False)
    use_end_saved = get_setting('use_end_date', False)
    try: d_start_saved = datetime.date.fromisoformat(get_setting('date_start', "2023-01-01"))
    except: d_start_saved = datetime.date.today() - datetime.timedelta(days=365*2)
    try: d_end_saved = datetime.date.fromisoformat(get_setting('date_end', "2025-01-01"))
    except: d_end_saved = datetime.date.today()
    
    # REVERTED: Back to standard text_input
    topic = st.text_input(
        "Research Topic (Required)", 
        value=default_topic, 
        placeholder="e.g., Generative Audio",
        key="topic_input_std"
    )
    
    keywords = st.text_input(
        "Additional Keywords (Comma-separated)", 
        value=default_keywords,
        placeholder="e.g., crosstalk cancellation, binaural synthesis",
        key="keywords_input_std"
    )


    keyword_logic = st.radio(
        "Keyword Logic",
        options=["Match Any (OR)", "Match All (AND)"],
        index=logic_idx,
        horizontal=True,
        help="Choose 'Match Any' to find papers containing ANY of the comma-separated keywords. Choose 'Match All' to find papers containing ALL of them."
    )
    
    logic_val = "any" if "Any" in keyword_logic else "all"
    
    with st.expander("Advanced Filters"):
        author = st.text_input("Author", value=default_author, placeholder="e.g., Yann LeCun", key="author_input")
        publication = st.text_input("Publication/Venue", value=default_pub, placeholder="e.g., ICASSP", key="pub_input")
        
        st.write("Date Range:")
        col_d1, col_d2 = st.columns(2)
        use_start_date = st.checkbox("Start Date", value=use_start_saved)
        use_end_date = st.checkbox("End Date", value=use_end_saved)
        today = datetime.date.today()
        
        d_start_val = st.date_input("From", value=d_start_saved, max_value=today) if use_start_date else None
        d_end_val = st.date_input("To", value=d_end_saved, max_value=today) if use_end_date else None
        
        all_sites = st.checkbox("Select All Sources", value=True)
        site_options = ["ArXiv", "Scholar", "Semantic Scholar", "CORE", "DOAJ"]
        site_map = {"ArXiv": "arxiv", "Scholar": "scholar", "Semantic Scholar": "semantic", "CORE": "core", "DOAJ": "doaj"}
        selected_sites_labels = site_options if all_sites else [s for s in site_options if st.checkbox(s, value=True)]
        selected_sites = [site_map[label] for label in selected_sites_labels]

    count = st.number_input("Target Paper Count", min_value=1, max_value=1000, value=default_count)
    
    sort_method = st.radio(
        "Prioritize By",
        options=sort_opts,
        index=sort_idx,
        help="Decides which papers to keep when trimming the list to your Target Count."
    )
    
    # Research Mode (Fast vs Deep)
    research_mode = st.radio(
        "Research Mode",
        ["Fast (Direct Only)", "Deep (Comprehensive)"],
        index=1, # Default to Deep
        help="Fast: Skips AI sorting and deep scraping (15m). Deep: Full AI + Web Search (90m)."
    )
    is_fast_ui = "Fast" in research_mode

    st.write("Organization:")
    col_org1, col_org2 = st.columns(2)
    
    # Logic: If Fast, disable Auto-Categorization (since we skip LLM)
    auto_val = auto_saved
    auto_disabled = False
    if is_fast_ui:
        auto_val = False
        auto_disabled = True
        
    auto_folders = col_org1.checkbox(
        "Enable AI Auto-Categorization", 
        value=auto_val, 
        disabled=auto_disabled,
        help="Use LLM to sort papers into sub-folders. (Disabled in Fast Mode)"
    )
    use_keywords_subfolders = col_org2.checkbox("Use Keywords as Sub-folders", value=key_sub_saved, help="Create a parent folder for each Search Term/Keyword.")

    
    filename_format_saved = get_setting('filename_format', "Title")
    filename_format = st.selectbox(
        "PDF Filename Format",
        options=["Title", "Author - Year - Title", "Year - Journal - Title"],
        index=["Title", "Author - Year - Title", "Year - Journal - Title"].index(filename_format_saved) if filename_format_saved in ["Title", "Author - Year - Title", "Year - Journal - Title"] else 0,
        help="Choose how downloaded PDF files should be named."
    )
    
    st.divider()
    
    # Removed Settings Section as requested
    user_api_key = os.getenv("GOOGLE_API_KEY")

# --- Execution ---
if start_btn:
    if not topic:
        st.error("Please enter a Research Topic.")
    else:
        # Auto-cleanup old missions before starting new one
        storage_mgr = StorageManager(max_missions=int(os.getenv("MAX_MISSIONS", "2")))
        deleted = storage_mgr.cleanup_excess_missions()
        if deleted > 0:
            st.info(f"üóëÔ∏è Auto-cleaned {deleted} old mission(s) to free space")
        
        st.session_state.pipeline_run = False
        st.session_state.zip_path = None
        st.session_state.catalog_content = None
        st.session_state.timeline_csv = None # Reset timeline
        st.session_state.history_open = False # Prevent zombie modal
        
        if st.session_state.temp_dir_to_cleanup:
            try: shutil.rmtree(st.session_state.temp_dir_to_cleanup)
            except: pass

        if topic not in st.session_state.recent_topics:
            st.session_state.recent_topics.insert(0, topic)
            if len(st.session_state.recent_topics) > 5: st.session_state.recent_topics.pop()
        
        # --- Persistence & History ---
        current_settings = {
            "topic": topic,
            "keywords": keywords,
            "keyword_logic": keyword_logic,
            "author": author,
            "publication": publication,
            "count": count,
            "sort_method": sort_method,
            "auto_folders": auto_folders,
            "use_keywords_subfolders": use_keywords_subfolders,
            "filename_format": filename_format,
            "use_start_date": use_start_date,
            "use_end_date": use_end_date,
            "date_start": d_start_val,
            "date_end": d_end_val
        }
        save_settings(current_settings)
        save_history(current_settings)
        # -----------------------------
        
        st.subheader("üì° Mission Control Log")
        log_container = st.empty()
        full_log = ""
        status_box = st.status("Initializing Agent...", expanded=True)
        
        try:
            status_box.write("üîç Phase 1: Scouting Academic Sources...")
            d_start_str = d_start_val.strftime("%Y-%m-%d") if d_start_val else None
            d_end_str = d_end_val.strftime("%Y-%m-%d") if d_end_val else None

            api_key_to_use = user_api_key if user_api_key else None

            is_fast = "Fast" in research_mode 

            pipeline_gen = run_full_pipeline(
                topic=topic,
                keywords=keywords,
                keyword_logic=logic_val,
                author=author,
                publication=publication,
                date_start=d_start_str,
                date_end=d_end_str,
                sites=selected_sites,
                count=count,
                sort_method=sort_method,
                google_api_key=api_key_to_use,
                auto_folders=auto_folders,
                use_keywords=use_keywords_subfolders,
                filename_format=filename_format,
                is_fast_mode=is_fast
            )
            
            final_zip_path = None
            temp_dir = None
            
            for line in pipeline_gen:
                if isinstance(line, tuple):
                    if line[0] == "RETURN_PATH": final_zip_path = line[1]
                    elif line[0] == "TEMP_DIR": temp_dir = line[1]
                    elif line[0] == "CATALOG_CSV":
                        # Render visualizations immediately AND save for persistence
                        render_visualizations(line[1])
                        st.session_state.timeline_csv = line[1]
                else:
                    full_log += line + "\n"
                    log_container.code(full_log, language="bash")

            if final_zip_path and os.path.exists(final_zip_path):
                status_box.update(label="Mission Complete!", state="complete", expanded=False)
                st.session_state.pipeline_run = True
                st.session_state.zip_path = final_zip_path
                st.session_state.temp_dir = temp_dir
                st.session_state.temp_dir_to_cleanup = temp_dir
                
                found_catalog = False
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file.endswith(".md") and "Catalog" in file:
                            with open(os.path.join(root, file), "r", encoding="utf-8") as f:
                                st.session_state.catalog_content = f.read()
                            found_catalog = True; break
                    if found_catalog: break
                
                st.rerun()
            else:
                status_box.update(label="Mission Failed", state="error")
                st.error("Pipeline finished, but no output was generated.")
        except Exception as e:
            status_box.update(label="System Error", state="error")
            st.error(f"An error occurred: {e}")

if not start_btn and not st.session_state.pipeline_run:
    st.info("üëà Use the sidebar to configure your research mission.")

st.divider()
st.caption("Universal Research Pipeline | Built with Streamlit, Python, and Google Gemini.")


==================================================
FILE: src/3_download_library.py
==================================================
import pandas as pd
import requests
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
import os
import re
import csv
import json
import shutil
from urllib.parse import urlparse, unquote
from tqdm import tqdm
import time
import random
from bs4 import BeautifulSoup
from googlesearch import search
from ddgs import DDGS
from unpywall import Unpywall
from unpywall.utils import UnpywallCredentials
UnpywallCredentials('vv@scholar-stack.com') # Using user email logic or placeholder

def sanitize_filename(name):
    """Sanitizes filenames to be OS-safe."""
    return re.sub(r'[<>:"/\\|?*]', '', name).strip()

def generate_filename(paper, format_option="Title"):
    """
    Generates a filename based on the user's selected format.
    Options: 'Title', 'Author - Year - Title', 'Year - Journal - Title'
    """
    title = paper.get('Title', 'Untitled')
    # Basic clean first
    title = sanitize_filename(title)
    
    if format_option == "Title":
        base = title
    elif format_option == "Author - Year - Title":
        # Extract first author
        authors_raw = paper.get('Authors', [])
        # If it's a string (from CSV), split it
        if isinstance(authors_raw, str):
            authors_list = authors_raw.split(';')
        else:
            authors_list = authors_raw
            
        first_auth = "Unknown"
        if authors_list and len(authors_list) > 0:
            first_auth = authors_list[0].split(',')[0].strip() # Just surname if possible
            first_auth = sanitize_filename(first_auth)
            
        year = str(paper.get('Year', '0000'))
        base = f"{first_auth} - {year} - {title}"
        
    elif format_option == "Year - Journal - Title":
        year = str(paper.get('Year', '0000'))
        journal = paper.get('Journal', 'Journal')
        if not journal or str(journal) == 'nan': journal = "Journal"
        journal = sanitize_filename(journal)
        base = f"{year} - {journal} - {title}"
    else:
        base = title
        
    # Truncate to avoid OS errors (255 max, keeping extension room)
    if len(base) > 240:
        base = base[:240]
        
    return base + ".pdf"

def get_filename_from_cd(cd):
    """Get filename from content-disposition header."""
    if not cd:
        return None
    fname = re.findall(r'filename=["\']?([^"\';]+)["\']?', cd)
    if len(fname) == 0:
        return None
    return fname[0].strip()

def create_markdown_catalog(papers, topic, output_path, search_params=None):
    """Generates a human-readable Markdown catalog."""
    with open(output_path, "w", encoding="utf-8") as f:
        downloaded_count = sum(1 for p in papers if p.get('is_downloaded'))
        f.write(f"# Library Catalog: {topic}\n\n")
        
        if search_params:
            f.write("## Search Settings\n")
            for k, v in search_params.items():
                if v: f.write(f"- **{k}:** {v}\n")
            f.write("\n")
            
        f.write(f"**Total Papers Listed:** {len(papers)}  \n")
        f.write(f"**Total Papers Downloaded:** {downloaded_count}  \n")
        f.write(f"**Generated:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n\n")
        
        # Sort keys for grouping? Assuming papers list is already sorted or we group here.
        # But 'papers' is a list of dicts. We need to group by Category.
        # Simple approach: Convert back to DF for easy grouping or use itertools.groupby
        # Let's stick to simple iteration if already sorted, or just re-sort.
        papers_sorted = sorted(papers, key=lambda x: (x.get('category', 'Uncategorized'), x.get('title', '')))
        
        current_cat = None
        for paper in papers_sorted:
            cat = paper.get('category', 'Uncategorized')
            if cat != current_cat:
                f.write(f"## {cat}\n\n")
                f.write("| Title | First Author | Year | Journal | Citations | Link |\n")
                f.write("|---|---|---|---|---|---|\n")
                current_cat = cat
            
            title = paper.get('title', 'Unknown Title').replace('|', '-') # Escape pipes
            
            authors_list = paper.get('authors', [])
            if not authors_list:
                first_author = "Unknown"
            else:
                first_author = authors_list[0]
                if len(authors_list) > 1:
                    first_author += " et al."
            
            year = str(paper.get('year', ''))
            journal = str(paper.get('journal', ''))
            citations = str(paper.get('citation_count', ''))
            if citations == 'None': citations = ''
            
            url = paper.get('url', '')
            link = f"[Source]({url})" if url else "N/A"
            
            f.write(f"| {title} | {first_author} | {year} | {journal} | {citations} | {link} |\n")
        f.write("\n")

def create_csv_catalog(papers, output_path):
    """Generates a strictly quoted CSV catalog."""
    headers = ['Title', 'Authors', 'Year', 'Journal', 'DOI', 'Citation_Count', 'URL', 'PDF_Link', 'Filename', 'Abstract']
    
    with open(output_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=headers, quoting=csv.QUOTE_ALL)
        writer.writeheader()
        
        for p in papers:
            authors_str = "; ".join(p.get('authors', []))
            writer.writerow({
                'Title': p.get('title', ''),
                'Authors': authors_str,
                'Year': p.get('year', ''),
                'Journal': p.get('journal', ''),
                'DOI': p.get('doi', ''),
                'Citation_Count': p.get('citation_count', 0),
                'URL': p.get('url', ''),
                'PDF_Link': p.get('pdf_url', ''),
                'Filename': p.get('filename', ''),
                'Abstract': p.get('abstract', '')
            })

def create_ris_catalog(papers, output_path):
    """Generates an RIS file for reference managers."""
    with open(output_path, 'w', encoding='utf-8') as f:
        for p in papers:
            f.write("TY  - JOUR\n")
            f.write(f"TI  - {p.get('title', '')}\n")
            
            for auth in p.get('authors', []):
                f.write(f"AU  - {auth}\n")
                
            f.write(f"PY  - {p.get('year', '')}\n")
            f.write(f"JO  - {p.get('journal', '')}\n")
            
            if p.get('doi'): f.write(f"DO  - {p.get('doi')}\n")
            if p.get('url'): f.write(f"UR  - {p.get('url')}\n")
            if p.get('pdf_url'): f.write(f"L1  - {p.get('pdf_url')}\n")
            if p.get('abstract'): f.write(f"AB  - {p.get('abstract')}\n")
            
            f.write("ER  - \n\n")

def generate_citation_key(paper, existing_keys):
    """Generates a unique BibTeX citation key: [FirstAuthor][Year][FirstTitleWord]"""
    # 1. First Author
    authors = paper.get('authors', [])
    if authors:
        # Assuming "First Last" or "Last, First". Heuristic: split by space, take last part of first element?
        # Standardized format usually "First Last" in list?
        # Let's try to be smart. Remove weird chars.
        first_auth_full = authors[0]
        # remove content in parens if any
        first_auth_full = re.sub(r'\(.*?\)', '', first_auth_full).strip()
        # Take last word as surname (rough heuristic)
        surname = first_auth_full.split()[-1] if first_auth_full else "Unknown"
        surname = "".join(filter(str.isalnum, surname))
    else:
        surname = "Unknown"
        
    # 2. Year
    year = str(paper.get('year', '0000'))
    if not year.isdigit(): year = "0000"
    
    # 3. First Word of Title
    title = paper.get('title', 'Untitled')
    # filtered title
    title_words = [w for w in re.split(r'[^a-zA-Z0-9]', title) if w]
    first_word = title_words[0] if title_words else "Doc"
    
    base_key = f"{surname}{year}{first_word}"
    
    key = base_key
    suffix = 97 # 'a'
    while key in existing_keys:
        key = f"{base_key}_{chr(suffix)}"
        suffix += 1
        if suffix > 122: # z
             key = f"{base_key}_{suffix}" # Fallback to numbers if we run out of letters
    
    return key

def create_bibtex_catalog(papers, output_path):
    """Generates a BibTeX file for LaTeX support."""
    existing_keys = set()
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for p in papers:
            # Generate Unique Key
            cite_key = generate_citation_key(p, existing_keys)
            existing_keys.add(cite_key)
            
            # Format Authors (BibTeX uses "Last, First and Last, First" or "First Last and First Last")
            # We have "First Last" strings. Join with " and ".
            authors_bib = " and ".join(p.get('authors', []))
            
            f.write(f"@article{{{cite_key},\n")
            f.write(f"  title = {{{p.get('title', '')}}},\n")
            f.write(f"  author = {{{authors_bib}}},\n")
            f.write(f"  year = {{{p.get('year', '')}}},\n")
            f.write(f"  journal = {{{p.get('journal', '')}}},\n")
            if p.get('doi'): f.write(f"  doi = {{{p.get('doi')}}},\n")
            if p.get('url'): f.write(f"  url = {{{p.get('url')}}},\n")
            if p.get('abstract'): 
                 # Basic escaping for abstract
                 abs_text = p.get('abstract', '').replace('%', '\\%').replace('{', '\\{').replace('}', '\\}')
                 f.write(f"  abstract = {{{abs_text}}}\n")
            f.write("}\n\n")

def sanitize_folder_name(name):
    clean = "".join([c if c.isalnum() or c in (' ', '_', '-') else '' for c in name])
    return clean.strip().replace(' ', '_')

# ... (skipping unchanged helpers) ...

def download_library(limit=None, sort_by="Most Relevant", **kwargs):
    print("=== Phase 4: The Physical Librarian (V9: Robust) ===")
    
    csv_path = "research_catalog_categorized.csv"
    if not os.path.exists(csv_path):
        print(f"Error: {csv_path} not found.")
        return

    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return
    
    if 'Is_Downloaded' not in df.columns:
        df['Is_Downloaded'] = False
        
    if 'Directory_Path' not in df.columns:
        print("Error: 'Directory_Path' column missing.")
        return

    if 'Topic' not in df.columns or df['Topic'].isnull().all():
        print("Error: 'Topic' column missing.")
        return
        
    current_topic = df['Topic'].iloc[0]
    print(f"Processing Topic: {current_topic}")
    
    # --- NEW: Prioritization & Trimming Logic ---
    print(f"Applying Filter: Sort by '{sort_by}', Limit to {limit} papers.")
    
    # Ensure Publication_Date is comparable
    if 'Publication_Date' in df.columns:
        df['Publication_Date'] = pd.to_datetime(df['Publication_Date'], errors='coerce')
    
    # 1. Sort
    if sort_by == "Date: Newest":
        df = df.sort_values(by='Publication_Date', ascending=False)
    elif sort_by == "Date: Oldest":
        df = df.sort_values(by='Publication_Date', ascending=True)
    elif sort_by == "Citations: Most":
        print("Sorting papers by Citations (Most First)...")
        if 'Citation_Count' in df.columns:
            df['Citation_Count'] = pd.to_numeric(df['Citation_Count'], errors='coerce').fillna(0)
            df = df.sort_values(by='Citation_Count', ascending=False)
    elif sort_by == "Citations: Least":
        print("Sorting papers by Citations (Least First)...")
        if 'Citation_Count' in df.columns:
            df['Citation_Count'] = pd.to_numeric(df['Citation_Count'], errors='coerce').fillna(0)
            df = df.sort_values(by='Citation_Count', ascending=True)
    # else: "Most Relevant" -> assumes input order is relevance (from API)

    # 2. Trim
    if limit:
        original_count = len(df)
        df = df.head(limit)
        print(f"Trimmed candidate list from {original_count} to {len(df)} papers.")
    
    success_count = 0
    fail_count = 0
    
    # --- NEW: Parallel Download Logic ---
    def process_paper_wrapper(args):
        index, row = args
        
        target_dir = row['Directory_Path'] if pd.notna(row['Directory_Path']) else os.path.join("./ScholarStack", sanitize_folder_name(current_topic))
        os.makedirs(target_dir, exist_ok=True)
        
        success, final_url, fname, paywalled = False, None, None, False
        
        if row['Is_Downloaded']:
             return (index, True, row['Source_URL'], row['Original_Filename'], False)

        try:
            # 1. Primary Download
            url = row['Source_URL']
            doi = row['DOI']
            title = row['Title']
            
            # Use original filename if possible, else sanitizer
            filename = row['Original_Filename'] 
            if not filename or filename == 'Pending_Header_Check':
                filename = sanitize_filename(title[:50]) + ".pdf"
            
            path = os.path.join(target_dir, filename)
            
            success = download_file(url, path)
            
            # ... (Rest of download logic is handled inside download_file or wrapper, minimizing code duplicaton here)
            # Actually, to avoid re-writing 200 lines, I assume download_file handles logic.
            # But wait, original code had a huge loop. I should keep the helper I wrote in previous turn? 
            # Ah, I don't see the helper in the viewed file. Did I lose it?
            # No, I am REPLACING the whole function. I must re-implement the loop logic carefully.
            # OR I use the helper if it exists.
            # Let's check line 448 in existing file... ah, I only viewed 450+.
            
            # Wait, the replace block covers up to line 603 (end of file).
            # I must ensure I don't lose the parallel logic I added earlier.
            
            # Let me just re-implement the ThreadPool logic cleanly here, assuming helpers exist.
            # Actually, I should use the `download_library` I see in lines 395-450, and extends it.
            
            # The parallel logic was added in a previous turn (Step 567 in logs).
            # I need to make sure I don't overwrite it with a bad copy.
            
            pass 
        except: pass
        return (index, False, None, None, True)

    # RE-READING: I see I am replacing `create_markdown_catalog` and `download_library`.
    # I need to make sure I include the PARALLEL LOGIC I added in the previous session.
    # Since I cannot see the full `process_paper_wrapper` from my `view_file` (it started at 350 and I see the top of `download_library` at 395), I must be careful.
    
    # ACTUALLY, I will ONLY replace `create_markdown_catalog` and the END of `download_library` where the catalog is generated.
    # I will split this into TWO edits to be safe.
    
    # Edit 1: update `create_markdown_catalog` (lines 33-65).
    # Edit 2: update the END of `download_library` (lines 578-583) to pass params.
    
    return # Dummy return to stop this tool call from running with this massive block.

# ABORTING MASSIVE REPLACEMENT. Splitting into smaller, safer edits.

def sanitize_folder_name(name):
    clean = "".join([c if c.isalnum() or c in (' ', '_', '-') else '' for c in name])
    return clean.strip().replace(' ', '_')

def get_pdf_from_unpywall(doi):
    """Fallback: Try to find a direct PDF link via Unpywall."""
    if not doi or str(doi) == 'nan': return None
    try:
        # 1. Unpywall requires a LIST of DOIs
        res = Unpywall.doi([doi])
        if res is not None and not res.empty:
             # Try PDF URL first
             best_url = res.iloc[0].get('best_oa_location.url_for_pdf')
             if best_url: return best_url
             
             # Fallback to generic URL (sometimes it's a direct download link disguised)
             fallback_url = res.iloc[0].get('best_oa_location.url')
             if fallback_url: return fallback_url
             
             # Fallback to FIRST oa location if 'best' is weird
             first_url = res.iloc[0].get('first_oa_location.url')
             if first_url: return first_url
    except Exception as e: 
        pass
    return None

def get_pdf_from_meta_tags(url):
    """Scrapes landing page for <meta name='citation_pdf_url'> OR visible PDF links."""
    if not url or url.lower().endswith('.pdf'): return None
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}
        r = requests.get(url, headers=headers, timeout=5)
        
        if r.status_code == 200:
            soup = BeautifulSoup(r.content, 'html.parser')
            
            # 1. Standard Google Scholar Meta Tag
            meta_pdf = soup.find('meta', attrs={'name': 'citation_pdf_url'})
            if meta_pdf and meta_pdf.get('content'):
                candidate = meta_pdf['content']
                if 'localhost' in candidate and 'tu-berlin' in url:
                    candidate = candidate.replace('http://localhost:4000', 'https://depositonce.tu-berlin.de')
                print(f"   [Meta Scraper] Found PDF (Meta): {candidate}")
                return candidate
            
            # 2. Body Scanning (The "Click the Button" Strategy)
            # Find all <a> tags with href containing '.pdf'
            from urllib.parse import urljoin
            
            # Strategy A: Strict .pdf extension
            links = soup.find_all('a', href=True)
            for link in links:
                href = link['href']
                text = link.text.lower()
                
                # Check for PDF extension
                if href.lower().endswith('.pdf') or 'type=pdf' in href.lower():
                    # Check for "Full Text", "Download", "View" to prioritize good links
                    # Or closest link if list is short? 
                    # Let's take the first one that looks like a paper download
                    full_url = urljoin(url, href)
                    print(f"   [Page Scraper] Found PDF link: {full_url}")
                    return full_url
            
            # Strategy B: Button text contains "PDF"
            for link in links:
                if 'pdf' in link.text.lower() or 'download' in link.text.lower():
                     full_url = urljoin(url, link['href'])
                     # A bit risky, but better than nothing
                     if 'javascript' not in full_url:
                        print(f"   [Page Scraper] Found PDF button: {full_url}")
                        return full_url
                        
    except Exception as e: 
        print(f"   [Meta Scraper] Error scraping {url}: {e}")
        pass
    return None

def attempt_secondary_search(title):
    """Fallback: Search Semantic Scholar for alternative PDF links or DOIs."""
    if not title or len(str(title)) < 10: return None
    
    print(f"   [Secondary Search] Hunting for '{title[:30]}...'")
    for attempt in range(2):
        try:
            # 1. Search Semantic Scholar
            params = {'query': title, 'limit': 1, 'fields': 'title,openAccessPdf,externalIds,url'}
            r = requests.get('https://api.semanticscholar.org/graph/v1/paper/search', params=params, timeout=5)
            
            if r.status_code == 200:
                data = r.json()
                if data.get('data'):
                    paper = data['data'][0]
                    # Fuzzy Title Check
                    match_ratio = len(set(title.lower().split()) & set(paper['title'].lower().split())) / len(title.split())
                    
                    if match_ratio > 0.6:
                        # Strategy A: OpenAccess PDF from S2
                        pdf_info = paper.get('openAccessPdf')
                        if pdf_info and pdf_info.get('url'):
                            cand_url = pdf_info['url']
                            # Fix ArXiv Abs links
                            if 'arxiv.org/abs' in cand_url:
                                cand_url = cand_url.replace('/abs/', '/pdf/') + ".pdf"
                            
                            # Skip known bad domains if they don't look like PDFs
                            if 'aes.org' in cand_url and not cand_url.endswith('.pdf'):
                                pass
                            else:
                                print(f"   [Secondary Search] Found URL: {cand_url}")
                                return cand_url
                        
                        # Strategy B: Found a new DOI? Try Unpywall again!
                        ids = paper.get('externalIds', {})
                        new_doi = ids.get('DOI')
                        if new_doi:
                            print(f"   [Secondary Search] Found DOI {new_doi}. Re-trying Unpywall...")
                            unp_url = get_pdf_from_unpywall(new_doi)
                            if unp_url: return unp_url

                        # Strategy C: ArXiv ID?
                        if ids.get('ArXiv'):
                            arxiv_id = ids.get('ArXiv')
                            return f"https://arxiv.org/pdf/{arxiv_id}.pdf"
                
                break # Success or no match
                            
            elif r.status_code == 429:
                 wait = (attempt + 1) * 5
                 print(f"   [Secondary Search] Rate Limit Hit. Waiting {wait}s...")
                 time.sleep(wait)
                 continue
                 
        except: pass
        
    # time.sleep(2) # Politeness delay removed for speed

    return None

def attempt_ddg_fallback(title):
    """Fallback: Use DuckDuckGo to find PDF candidates (Direct or via Landing Page)."""
    print(f"   [DDG Rescue] Hunting for '{title[:30]}...'")
    candidates = []
    seen_urls = set()
    
    try:
        with DDGS() as ddgs:
            # 1. Strict PDF Search
            query = f'"{title}" filetype:pdf'
            results = list(ddgs.text(query, max_results=3))
            
            for r in results:
                url = r.get('href', '')
                if url in seen_urls: continue
                
                if url.lower().endswith('.pdf'):
                    if 'researchgate.net' in url: continue
                    print(f"   [DDG Rescue] Found PDF Candidate: {url}")
                    candidates.append(url)
                    seen_urls.add(url)
            
            # 2. Relaxed Search & Scrape
            query = f'{title} pdf'
            results = list(ddgs.text(query, max_results=5))
            for r in results:
                url = r.get('href', '')
                if url in seen_urls: continue
                
                # A. Direct PDF
                if url.lower().endswith('.pdf'):
                    if 'researchgate.net' in url: continue
                    print(f"   [DDG Rescue] Found PDF Candidate (Ext): {url}")
                    candidates.append(url)
                    seen_urls.add(url)
                    continue
                
                # B. ArXiv Check
                if 'arxiv.org/abs' in url:
                    pdf_url = url.replace('/abs/', '/pdf/') + ".pdf"
                    print(f"   [DDG Rescue] Found ArXiv Candidate: {pdf_url}")
                    candidates.append(pdf_url)
                    seen_urls.add(pdf_url)
                    continue
                    
                # C. Landing Page Scrape (The "Human Click" Strategy)
                if 'books.google' in url or 'scholar.google' in url or 'researchgate.net' in url: continue
                
                # Only scrape if we don't have enough candidates yet
                if len(candidates) >= 3: break
                
                print(f"   [DDG Rescue] Checking candidate page: {url}")
                scraped_pdf = get_pdf_from_meta_tags(url)
                if scraped_pdf and scraped_pdf not in seen_urls:
                    print(f"   [DDG Rescue] Extracted PDF from page: {scraped_pdf}")
                    candidates.append(scraped_pdf)
                    seen_urls.add(scraped_pdf)

    except Exception as e:
        print(f"   [DDG Rescue] Error: {e}")
        
    return candidates  # Returns list

def attempt_google_fallback(title):
    """Last Resort: Mimic User's 'Google It' behavior."""
    print(f"   [Google Rescue] Hunting for '{title[:30]}...'")
    try:
        # Strict search first
        query = f'"{title}" filetype:pdf'
        results = search(query, num_results=3, advanced=True)
        for r in results:
            if r.url.endswith('.pdf'):
                print(f"   [Google Rescue] Found PDF: {r.url}")
                return r.url
        
        # Looser search: Check HEAD of top results
        query = f'{title} pdf'
        print(f"   [Google Rescue] Deep Scanning for: {query}")
        
        # 1. Fetch Candidates (up to 7)
        candidates = []
        try:
             results = search(query, num_results=7, advanced=True)
             for r in results:
                 candidates.append(r.url)
        except: pass
        
        for url in candidates:
            # A. Known Patterns
            if 'arxiv.org/abs' in url:
                pdf_url = url.replace('/abs/', '/pdf/') + ".pdf"
                print(f"   [Google Rescue] Found ArXiv: {pdf_url}")
                return pdf_url
            
            # B. Extension Check
            if url.lower().endswith('.pdf'):
                print(f"   [Google Rescue] Found PDF (Ext): {url}")
                return url
                
            # C. HEAD CHECK (The "Nuclear" Option)
            # Checks if a URL *serves* a PDF even if it doesn't look like one
            try:
                h_headers = {'User-Agent': random.choice([
                    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                ])}
                # Quick HEAD request (3s timeout)
                h = requests.head(url, headers=h_headers, timeout=3, allow_redirects=True)
                
                # Check Content-Type
                ct = h.headers.get('Content-Type', '').lower()
                if 'application/pdf' in ct:
                    print(f"   [Google Rescue] Found PDF (HEAD): {url}")
                    return url
                    
                # Content-Disposition check
                cd = h.headers.get('Content-Disposition', '').lower()
                if 'pdf' in cd and 'attachment' in cd:
                     print(f"   [Google Rescue] Found PDF (Disp): {url}")
                     return url
                     
            except: pass
            
    except Exception as e:
        pass
    return None

def download_file(url, local_path):
    """Robust download with retries and header validation."""
    if not url: return False
    
    user_agents = [
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/115.0',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0'
    ]
    
    # 1. Try Direct Method
    for attempt in range(2):
        try:
            ua = random.choice(user_agents)
            headers = {
                'User-Agent': ua,
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Referer': 'https://scholar.google.com/'
            }
            
            # Special Handling for MDPI (needs cookies sometimes, but headers usually work)
            if 'mdpi.com' in url:
                headers['Upgrade-Insecure-Requests'] = '1'
                headers['Sec-Fetch-Dest'] = 'document'
                headers['Sec-Fetch-Mode'] = 'navigate'
                headers['Sec-Fetch-Site'] = 'none'
                headers['Sec-Fetch-User'] = '?1'

            # SSL Verify=False for older academic repos (IOA, TU-Berlin sometimes have cert issues)
            # Timeout reduced to 10s to fail fast
            r = requests.get(url, headers=headers, stream=True, timeout=10, verify=False)
            
            if r.status_code == 403:
                time.sleep(2) # Backoff for 403
                continue
                
            if r.status_code == 200:
                # Content-Type Check (Permissive)
                ct = r.headers.get('Content-Type', '').lower()
                if 'text/html' in ct and len(r.content) < 50000:
                    # Likely a landing page, not a PDF
                    pass 
                else:
                    with open(local_path, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            f.write(chunk)
                    
                    # Validate Magic Bytes
                    if os.path.exists(local_path):
                        with open(local_path, 'rb') as f:
                            head = f.read(1024)
                        if b'%PDF' in head:
                            return True
                        else:
                            os.remove(local_path) # Corrupt
        except Exception: 
            pass
            
    return False

def download_library(limit=None, sort_by="Most Relevant", filename_format="Title", fast_mode=False, **kwargs):
    print("=== Phase 4: The Physical Librarian (V9: Robust) ===")
    
    csv_path = "research_catalog_categorized.csv"
    if not os.path.exists(csv_path):
        print(f"Error: {csv_path} not found.")
        return

    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return
    
    if 'Is_Downloaded' not in df.columns:
        df['Is_Downloaded'] = False
        
    if 'Directory_Path' not in df.columns:
        print("Error: 'Directory_Path' column missing.")
        return

    if 'Topic' not in df.columns or df['Topic'].isnull().all():
        print("Error: 'Topic' column missing.")
        return
        
    current_topic = df['Topic'].iloc[0]
    print(f"Processing Topic: {current_topic}")
    
    # --- NEW: Prioritization & Trimming Logic ---
    print(f"Applying Filter: Sort by '{sort_by}', Limit to {limit} papers.")
    
    # Ensure Publication_Date is comparable
    if 'Publication_Date' in df.columns:
        df['Publication_Date'] = pd.to_datetime(df['Publication_Date'], errors='coerce')
    
    # 1. Sort
    if sort_by == "Date: Newest":
        df = df.sort_values(by='Publication_Date', ascending=False)
    elif sort_by == "Date: Oldest":
        df = df.sort_values(by='Publication_Date', ascending=True)
    elif sort_by == "Citations: Most":
        print("Sorting papers by Citations (Most First)...")
        if 'Citation_Count' in df.columns:
            df['Citation_Count'] = pd.to_numeric(df['Citation_Count'], errors='coerce').fillna(0)
            df = df.sort_values(by='Citation_Count', ascending=False)
    elif sort_by == "Citations: Least":
        print("Sorting papers by Citations (Least First)...")
        if 'Citation_Count' in df.columns:
            df['Citation_Count'] = pd.to_numeric(df['Citation_Count'], errors='coerce').fillna(0)
            df = df.sort_values(by='Citation_Count', ascending=True)
    # else: "Most Relevant" -> assumes input order is relevance (from API)

    # 2. Trim
    if limit:
        original_count = len(df)
        df = df.head(limit)
        print(f"Trimmed candidate list from {original_count} to {len(df)} papers.")
    
    success_count = 0
    fail_count = 0
    
    print(f"Found {len(df)} papers. Starting download process...")

    print(f"Found {len(df)} papers. Starting download process (Parallel Execution)...")

    # --- Helper Function for Threading ---
    def process_paper_wrapper(args):
        index, row = args
        title = row.get('Title', 'Unknown_Paper')
        dest_folder = row.get('Directory_Path')
        if not dest_folder: return (index, False, None, None, True)
            
        if not os.path.exists(dest_folder):
            os.makedirs(dest_folder, exist_ok=True)
            
        # Use new custom filename generator
        filename = generate_filename(row, format_option=filename_format)
        local_path = os.path.join(dest_folder, filename)
        
        # --- RESUME LOGIC: Check if file physically exists ---
        if os.path.exists(local_path) and os.path.getsize(local_path) > 1024:
             # Assume success if file exists and > 1KB
             return (index, True, row.get('Source_URL'), filename, False)
        
        url = row.get('Source_URL')
        doi = row.get('DOI')
        
        downloaded = False
        final_url = url
        
        # 1. Try Existing URL
        if url and str(url).startswith('http') and 'doi.org' not in str(url):
            if download_file(url, local_path):
                return (index, True, url, filename, False)
        
        # 2. Try Unpaywall via DOI
        if doi:
             new_url = get_pdf_from_unpywall(doi)
             if new_url:
                 if download_file(new_url, local_path):
                     return (index, True, new_url, filename, False)

        # 3. Try Meta Tags
        if url and str(url).startswith('http'):
             pdf_url = get_pdf_from_meta_tags(url)
             if pdf_url:
                 if download_file(pdf_url, local_path):
                     return (index, True, pdf_url, filename, False)

        if not fast_mode:
            # 4. Secondary Search (S2)
            new_url = attempt_secondary_search(title)
            if new_url:
                if download_file(new_url, local_path):
                     return (index, True, new_url, filename, False)

        if not fast_mode:
            # 5. DDG Rescue (Multi-Candidate)
            candidates = attempt_ddg_fallback(title)
            if candidates:
                for cand_url in candidates:
                    if download_file(cand_url, local_path):
                         return (index, True, cand_url, filename, False)
        
        return (index, False, None, None, True)

    # --- Execute Parallel Loop ---
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    # Prepare arguments
    tasks = [(i, row) for i, row in df.iterrows()]
    
    # Max Workers = 4 to balance speed and stability
    with ThreadPoolExecutor(max_workers=4) as executor:
        future_to_paper = {executor.submit(process_paper_wrapper, task): task for task in tasks}
        
        processed_count = 0
        checkpoint_interval = 10
        
        for future in tqdm(as_completed(future_to_paper), total=len(tasks), desc="Downloading (Parallel)"):
            try:
                idx, success, final_url, fname, paywalled = future.result()
                
                if success:
                    df.at[idx, 'Is_Downloaded'] = True
                    df.at[idx, 'Source_URL'] = final_url
                    df.at[idx, 'Original_Filename'] = fname
                    df.at[idx, 'Is_Paywalled'] = False
                    success_count += 1
                else:
                    df.at[idx, 'Is_Downloaded'] = False
                    df.at[idx, 'Is_Paywalled'] = True
                    fail_count += 1
                
                processed_count += 1
                
                # Checkpoint: Save progress every N papers
                if processed_count % checkpoint_interval == 0:
                    df.to_csv(csv_path, index=False)
                    
            except Exception as e:
                print(f"Error processing future: {e}")
                
        # Final save after loop
        df.to_csv(csv_path, index=False)

    print("\nStarting Clean Up and Export...")
    
    unique_paths = df['Directory_Path'].dropna().unique()
    
    # 1. Create JSON Indexes
    for folder_path in unique_paths:
        if not os.path.exists(folder_path): continue
        papers_in_folder = df[df['Directory_Path'] == folder_path]
        index_data = []
        for _, paper in papers_in_folder.iterrows():
            if paper.get('Is_Downloaded', False):
                index_data.append({
                    "Title": paper['Title'],
                    "Authors": paper.get('Authors', 'Unknown'),
                    "Filename": paper.get('Original_Filename'),
                    "Description": paper.get('Description'),
                    "Source_URL": paper.get('Source_URL')
                })
        
        if index_data:
            with open(os.path.join(folder_path, "index.json"), "w") as f:
                json.dump(index_data, f, indent=2)

    # 2. Cleanup Empty Folders
    topic_sanitized = sanitize_folder_name(current_topic)
    topic_root = os.path.join("./ScholarStack", topic_sanitized)

    print("Cleaning up target folders...")
    # 1. Clean Leaf Folders (Categories)
    for folder_path in unique_paths:
        if not os.path.exists(folder_path): continue
        try:
            files = os.listdir(folder_path)
            has_pdf = any(f.lower().endswith('.pdf') for f in files)
            # If no PDFs, assume failed category -> nuke it
            if not has_pdf:
                shutil.rmtree(folder_path)
        except Exception: pass

    # 2. Clean Empty Parents (Keywords)
    # Walk bottom-up
    if os.path.exists(topic_root):
        for root, dirs, files in os.walk(topic_root, topdown=False):
            # Ignore root itself
            if root == topic_root: continue
            
            # Check if empty or only .DS_Store
            clean_files = [f for f in files if f != ".DS_Store"]
            if not clean_files and not dirs:
                try:
                     shutil.rmtree(root)
                     print(f"Removed empty folder: {os.path.basename(root)}")
                except: pass

    zip_name = f"ScholarStack_{topic_sanitized}"
    
    # 3. Standardize Metadata & Generate Catalogs
    print("Standardizing metadata and generating catalogs...")
    
    standardized_papers = []
    for _, row in df.iterrows():
        # Parse Authors safely
        auth_raw = row.get('Authors', '')
        if pd.isna(auth_raw): auth_raw = ""
        # Assuming comma separated in CSV, but checking given headers
        # Implementation Plan says "join list with semicolon" for CSV output
        # But INPUT is likely comma-separated string from earlier steps?
        # Let's try to split by comma, and clean
        if isinstance(auth_raw, str):
            authors_list = [a.strip() for a in auth_raw.split(',')]
        else:
            authors_list = []
            
        # Parse Year
        pub_date = row.get('Publication_Date', '')
        year = ""
        try:
            if pd.notna(pub_date):
                 year = str(pub_date)[:4]
        except: pass
        
        p_obj = {
            'title': row.get('Title', ''),
            'authors': authors_list,
            'year': year,
            'date': str(row.get('Publication_Date', '')),
            'journal': row.get('_Source', 'Unknown'), # Mapping _Source to Journal/Venue for now
            'doi': row.get('DOI', ''),
            'url': row.get('Source_URL', ''),
            'pdf_url': row.get('Source_URL', '') if str(row.get('Source_URL', '')).endswith('.pdf') else '', # Rough guess
            'abstract': str(row.get('Description', '')) if pd.notna(row.get('Description', '')) else '',
            'citation_count': row.get('Citation_Count', 0),
            'filename': row.get('Original_Filename', ''),
            'category': row.get('Category', 'Uncategorized'),
            'is_downloaded': row.get('Is_Downloaded', False),
            'status': "Downloaded" if row.get('Is_Downloaded') else "Missing/Paywalled"
        }
        standardized_papers.append(p_obj)

    if os.path.exists(topic_root):
        cat_base = os.path.join(topic_root, f"Catalog_{topic_sanitized}")
        
        # A. Markdown
        search_params = {
            "Topics": current_topic,
            "Keywords": kwargs.get('keywords', 'N/A'),
            "Sort Order": sort_by,
            "Limit": limit,
            "Date Range": kwargs.get('date_range', 'All Time')
        }
        create_markdown_catalog(standardized_papers, current_topic, cat_base + ".md", search_params)
        
        # B. CSV
        create_csv_catalog(standardized_papers, cat_base + ".csv")
        
        # C. RIS
        create_ris_catalog(standardized_papers, cat_base + ".ris")
        
        # D. BibTeX (PRP #11)
        create_bibtex_catalog(standardized_papers, cat_base + ".bib")

    # 4. Zip - Create archive with ScholarStack/Topic structure
    scholarstack_root = "./ScholarStack"
    if os.path.exists(topic_root):
        # Zip the entire ScholarStack folder to preserve the directory structure
        shutil.make_archive(zip_name, 'zip', scholarstack_root)
        print(f"READY FOR DOWNLOAD: {zip_name}.zip")
    else:
        print(f"ERROR: Folder does not exist: {topic_root}")
    
    df.to_csv("final_library_catalog.csv", index=False)
    
    print("\n=== Process Complete ===")
    print(f"Successfully downloaded: {success_count} / {len(df)}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--limit", type=int, default=10, help="Max papers to download")
    parser.add_argument("--sort", type=str, default="Most Relevant", help="Sort criteria")
    
    # Metadata Args
    parser.add_argument("--keywords", type=str, default="", help="Keywords used")
    parser.add_argument("--date_start", type=str, default="", help="Start Year")
    parser.add_argument("--date_end", type=str, default="", help="End Year")
    parser.add_argument("--filename_format", type=str, default="Title", help="PDF Filename Format")
    parser.add_argument("--fast_mode", action="store_true")
    
    args = parser.parse_args()
    
    # Format Date Range
    d_range = "All Time"
    if args.date_start or args.date_end:
        d_range = f"{args.date_start} - {args.date_end}"
    
    # Pass as kwargs
    download_library(
        limit=args.limit, 
        sort_by=args.sort, 
        filename_format=args.filename_format,
        fast_mode=args.fast_mode,
        keywords=args.keywords, 
        date_range=d_range
    )


==================================================
FILE: src/alert_scheduler.py
==================================================
"""
Helper functions for determining if an alert should run based on frequency.
"""
from datetime import datetime, timedelta

def should_run_alert(last_run_str: str, frequency: str) -> bool:
    """
    Determine if an alert should run based on its frequency and last run time.
    
    Args:
        last_run_str: ISO format timestamp string of last run
        frequency: One of 'hourly', 'daily', 'weekly', 'biweekly', 'monthly'
    
    Returns:
        True if alert should run, False otherwise
    """
    if not last_run_str:
        return True  # Never run before
    
    try:
        last_run = datetime.fromisoformat(last_run_str)
    except:
        return True  # Invalid timestamp, run anyway
    
    now = datetime.now()
    time_since_last = now - last_run
    
    # Frequency thresholds
    if frequency == 'hourly':
        return time_since_last >= timedelta(hours=1)
    elif frequency == 'daily':
        return time_since_last >= timedelta(days=1)
    elif frequency == 'weekly':
        return time_since_last >= timedelta(weeks=1)
    elif frequency == 'biweekly':
        return time_since_last >= timedelta(weeks=2)
    elif frequency == 'monthly':
        return time_since_last >= timedelta(days=30)
    else:
        return time_since_last >= timedelta(days=1)  # Default to daily

def get_frequency_display(frequency: str) -> str:
    """Get human-readable frequency label."""
    labels = {
        'hourly': '‚ö° Hourly',
        'daily': 'üìÖ Daily',
        'weekly': 'üìÜ Weekly',
        'biweekly': 'üìÜ Bi-weekly',
        'monthly': 'üìÜ Monthly'
    }
    return labels.get(frequency, frequency)


==================================================
FILE: src/auth_manager.py
==================================================
import os
import google_auth_oauthlib.flow
from googleapiclient.discovery import build
import streamlit as st

# Configuration
CLIENT_SECRETS_FILE = "client_secrets.json"
SCOPES = [
    "https://www.googleapis.com/auth/userinfo.profile",
    "https://www.googleapis.com/auth/userinfo.email",
    "https://www.googleapis.com/auth/drive.file",
    "openid"
]

# Note: In production, this must be your actual deployed URL (e.g. https://your-app.com)
# For local/dev, localhost is fine.
REDIRECT_URI = "http://localhost:8501" 

def get_flow():
    """Creates the OAuth flow object."""
    if not os.path.exists(CLIENT_SECRETS_FILE):
        return None
        
    flow = google_auth_oauthlib.flow.Flow.from_client_secrets_file(
        CLIENT_SECRETS_FILE,
        scopes=SCOPES,
        redirect_uri=REDIRECT_URI
    )
    return flow

def get_login_url():
    """Generates the Google Login URL."""
    flow = get_flow()
    if not flow:
        return None
    
    authorization_url, state = flow.authorization_url(
        access_type='offline',
        include_granted_scopes='true',
        prompt='consent'
    )
    return authorization_url

def get_token_from_code(code):
    """Exchanges the auth code for a token."""
    flow = get_flow()
    if not flow:
        return None
        
    flow.fetch_token(code=code)
    credentials = flow.credentials
    return credentials

def get_user_info(credentials):
    """Fetches user profile info using the credentials."""
    try:
        service = build('oauth2', 'v2', credentials=credentials)
        user_info = service.userinfo().get().execute()
        return user_info
    except:
        return None


==================================================
FILE: src/pipeline_manager.py
==================================================
import subprocess
import os
import sys
import tempfile
import shutil

def run_full_pipeline(topic, keywords=None, author=None, publication=None, 
                      date_start=None, date_end=None, sites=None, count=10, 
                      sort_method="Most Relevant", google_api_key=None, keyword_logic='any',
                      auto_folders=True, use_keywords=False, filename_format="Title", is_fast_mode=False):
    """
    Orchestrates the full research pipeline in an isolated temporary directory.
    Yields log lines for real-time UI updates.
    Returns the path to the final zip file.
    """
    
    # 1. Setup Isolation Chamber (Temp Directory)
    # This ensures multiple users don't overwrite each other's files
    temp_dir = tempfile.mkdtemp(prefix="scholar_stack_mission_")
    current_dir = os.getcwd()
    
    # Get absolute paths to the scripts (since we will change execution context)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    script_1 = os.path.join(base_dir, "1_search_omni.py")
    script_2 = os.path.join(base_dir, "2_cluster_taxonomy.py")
    script_3 = os.path.join(base_dir, "3_download_library.py")
    
    yield f"üöÄ Starting Mission in Isolated Workspace..."
    # yield f"DEBUG: Workspace: {temp_dir}"

    # Prepare environment with API key
    env = os.environ.copy()
    if google_api_key:
        env["GOOGLE_API_KEY"] = google_api_key

    try:
        # --- Phase 1: Search ---
        yield f"--- Starting Phase 1: Search (Topic: {topic}) ---"
        
        # Buffer the search count to account for Phase 2 filtering/deduplication
        buffered_count = int(int(count) * 1.5) + 5
        search_cmd = [
            sys.executable, script_1,
            "--topic", topic,
            "--count", str(buffered_count)
        ]
        
        if keywords:
            search_cmd.extend(["--keywords", keywords])
        if author:
            search_cmd.extend(["--author", author])
        if publication:
            search_cmd.extend(["--publication", publication])
        if date_start:
            search_cmd.extend(["--date_start", date_start])
        if date_end:
            search_cmd.extend(["--date_end", date_end])
        if sites:
            sites_str = ",".join(sites)
            search_cmd.extend(["--sites", sites_str])
        
        if keyword_logic:
            search_cmd.extend(["--keyword_logic", keyword_logic])

        # Execute inside temp_dir
        process = subprocess.Popen(
            search_cmd, 
            cwd=temp_dir,
            env=env,
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            text=True, 
            bufsize=1
        )
        
        for line in process.stdout:
            yield line.strip()
        
        process.wait()
        if process.returncode != 0:
            yield "‚ùå Phase 1 Failed."
            return None
        yield "‚úÖ Phase 1 Complete."

        # --- Phase 2: Cluster & Categorize ---
        yield "--- Starting Phase 2: AI Clustering ---"
        
        cluster_cmd = [
            sys.executable, script_2,
            "--topic", topic,
            "--sort", sort_method,
            "--limit", str(count)
        ]
        
        if not auto_folders:
            cluster_cmd.append("--no_llm")
        
        if use_keywords:
            cluster_cmd.append("--use_keywords")
            
        if is_fast_mode:
            cluster_cmd.append("--fast_mode")
        
        process = subprocess.Popen(
            cluster_cmd, 
            cwd=temp_dir,
            env=env,
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            text=True, 
            bufsize=1
        )
        
        for line in process.stdout:
            yield line.strip()
            
        process.wait()
        if process.returncode != 0:
            yield "‚ùå Phase 2 Failed."
            return None
        yield "‚úÖ Phase 2 Complete."

        # --- Phase 3: Download & Export ---
        yield "--- Starting Phase 3: Download & Export ---"
        
        download_cmd = [
            sys.executable, script_3,
            "--limit", str(count),
            "--sort", sort_method,
            "--filename_format", filename_format
        ]
        
        # Pass metadata strings
        if keywords:
            download_cmd.extend(["--keywords", keywords])
            
        if date_start:
            download_cmd.extend(["--date_start", str(date_start)])
        if date_end:
            download_cmd.extend(["--date_end", str(date_end)])
            
        if is_fast_mode:
            download_cmd.append("--fast_mode")
        
        process = subprocess.Popen(
            download_cmd, 
            cwd=temp_dir,
            env=env,
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            text=True, 
            bufsize=1
        )
        
        for line in process.stdout:
            yield line.strip()
            
        process.wait()
        if process.returncode != 0:
            yield "‚ùå Phase 3 Failed."
            return None
        yield "‚úÖ Phase 3 Complete."
        
        # Check for final catalog to render timeline
        final_csv = os.path.join(temp_dir, "final_library_catalog.csv")
        if os.path.exists(final_csv):
             yield ("CATALOG_CSV", final_csv)

        # --- Validate Output ---
        # Find the zip file in the temp dir
        # The script creates "ScholarStack_{SanitizedTopic}.zip"
        # We don't know the exact sanitization logic of the script perfectly here,
        # so we look for any .zip file.
        
        zip_file = None
        for f in os.listdir(temp_dir):
            if f.endswith(".zip"):
                zip_file = os.path.join(temp_dir, f)
                break
        
        if zip_file and os.path.exists(zip_file):
            yield f"üéâ Pipeline Success! Output ready."
            yield ("RETURN_PATH", zip_file) # Pass the temp path back
            yield ("TEMP_DIR", temp_dir)    # Pass temp dir so app can cleanup later? 
                                            # Actually app reads immediately.
                                            # We rely on OS to cleanup /tmp or do it manually later.
        else:
            yield "‚ö†Ô∏è Pipeline finished, but zip file was not found."
            return None

    except Exception as e:
        yield f"‚ùå Critical Pipeline Error: {e}"
        return None

if __name__ == "__main__":
    print("Running Test Pipeline...")
    gen = run_full_pipeline("Audio Inpainting", count=5, sites=['arxiv'])
    for line in gen:
        print(line)

